{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProjeto 1 - Multilayer Perceptron - Redes Neurais\n",
    "## Reconhecimento de Dígitos com MLP\n",
    "### Grupo: Josenildo Vicente de Araújo (jva@cin.ufpe.br), Lucas Thierry Chaves Muniz (ltcm@cin.ufpe.br), Nicholas Henrique Justino Ferreira (nhjf@cin.ufpe.br), Renato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O seguinte MiniProjeto tem como objetivo praticar os conceitos e teorias aprendidas na disciplina de Redes Neurais a respeito do funcionamento do modelo de rede neural Multilayer Perceptron. De maneira a variar os parâmetros do modelo treinado e observar seus resultados. A rede utilizada em questão, tem como função fazer o reconhecimento de dígitos escritos manualmente por 250 pessoas, entre as quais eram estudantes do Ensino Médio e funcionários do Departamento do Censo dos Estados Unidos. O conjunto desses dígitos está reunido no _dataset_ MNIST, que possuí 60000 imagens para treinamento do modelo da rede neural e 10000 imagens para teste do modelo da rede neural. Cada uma dessas imagens são formadas por 784 _pixels_ (28x28) em uma escala da cor cinza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começamos pela importação do pacote da biblioteca da rede MLP (_network_) e da biblioteca da importação do dataset <i>(mnist_loader)</i>. Através da biblioteca <i>mnist_loader</i> importamos o _dataset_ e o divimos em três conjuntos: <i>training_data</i>, <i>validation_data</i> e <i>test_data</i>. O <i>training_data</i> será usado para treinar o nosso modelo de MLP e ajustar seus parâmetros automaticamente, o <i>validation_data</i> não será usado neste momento, mas é um conjunto essencial para descobrir como ajustar os hiper-parâmetros, e, por fim, o <i>test_data</i> será usado para testar o modelo de MLP treinado em dados não vistos para medir a sua performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network, network_tanh, mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar o modelo de MLP, invocamos o construtor do biblioteca _network_ (_Network_) informando um vetor que significa a quantidade de neurônios em cada camada da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método \"SGD\" da rede, diz respeito ao Gradiente Descendente Estocástico, que é um algoritmo de otimização usado para minimizar o erro da saída dos neurônios nas camadas. O termo Estocástico diz respeito a uma aproximação estocástica da otimização do Gradiente Descendente, pois este algoritmo utiliza _mini batches_ aleátorias do conjunto de treinamento em cada época para acelerar o processo de estimação do Gradiente. Neste método especificamos, respectivamente, o conjunto de treinamento do modelo, o número de épocas, a quantidade dos _mini batches_, a taxa de aprendizagem e o conjunto de teste para que seja possível verificar a acurácia total do modelo a cada época treinada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo abaixo, definimos que a rede terá 784 neurônios na primeira camada, a camada de entrada, sendo cada um desses neurônios correspondendo a uma entrada de _pixel_ da imagem, já na segunda camada terá 30 neurônios e a última camada, a camada de saída, possuirá 10 neurônios, um neurônio correspondendo a cada uma das possibilidades do dígito (0 a 9). Assim como, define-se o número de épocas sendo 30, a quantidade de _mini batches_ sendo 10, a taxa de aprendizagem sendo 0.1 e o conjunto de testes definido pelo <i>mnist_loader</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.60337006 0.6700542  0.17834395 0.4064026  0.         0.07142857\n",
      " 0.2173913  0.53715776 0.23550177 0.36115007]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.60      0.74      1543\n",
      "           1       0.87      0.67      0.76      1476\n",
      "           2       0.03      0.18      0.05       157\n",
      "           3       0.74      0.41      0.53      1843\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.07      0.00        14\n",
      "           6       0.01      0.22      0.01        23\n",
      "           7       0.80      0.54      0.64      1534\n",
      "           8       0.48      0.24      0.32      1983\n",
      "           9       0.51      0.36      0.42      1426\n",
      "\n",
      "   micro avg       0.45      0.45      0.45     10000\n",
      "   macro avg       0.44      0.33      0.35     10000\n",
      "weighted avg       0.70      0.45      0.54     10000\n",
      "\n",
      "Epoch 0: 4509 / 10000\n",
      "Accuracy = 45.09%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.66642857 0.8516129  0.4270557  0.53376206 0.         0.33333333\n",
      " 0.28571429 0.65783497 0.38429506 0.4554878 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.78      1400\n",
      "           1       0.93      0.85      0.89      1240\n",
      "           2       0.47      0.43      0.45      1131\n",
      "           3       0.82      0.53      0.65      1555\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.33      0.00         3\n",
      "           6       0.01      0.29      0.02        28\n",
      "           7       0.85      0.66      0.74      1321\n",
      "           8       0.66      0.38      0.49      1681\n",
      "           9       0.74      0.46      0.56      1640\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     10000\n",
      "   macro avg       0.54      0.46      0.46     10000\n",
      "weighted avg       0.77      0.56      0.64     10000\n",
      "\n",
      "Epoch 1: 5573 / 10000\n",
      "Accuracy = 55.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.72698908 0.89534884 0.54363376 0.58305313 0.         0.33333333\n",
      " 0.56744186 0.70150435 0.46102151 0.4897343 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.73      0.82      1282\n",
      "           1       0.95      0.90      0.92      1204\n",
      "           2       0.74      0.54      0.63      1398\n",
      "           3       0.86      0.58      0.69      1487\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.33      0.00         6\n",
      "           6       0.13      0.57      0.21       215\n",
      "           7       0.86      0.70      0.77      1263\n",
      "           8       0.70      0.46      0.56      1488\n",
      "           9       0.80      0.49      0.61      1656\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     10000\n",
      "   macro avg       0.60      0.53      0.52     10000\n",
      "weighted avg       0.82      0.61      0.69     10000\n",
      "\n",
      "Epoch 2: 6144 / 10000\n",
      "Accuracy = 61.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.78692699 0.91932773 0.76011029 0.65243004 0.         0.16666667\n",
      " 0.67788057 0.75879828 0.58934708 0.51234196]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86      1178\n",
      "           1       0.96      0.92      0.94      1190\n",
      "           2       0.80      0.76      0.78      1088\n",
      "           3       0.88      0.65      0.75      1358\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.17      0.00         6\n",
      "           6       0.84      0.68      0.75      1189\n",
      "           7       0.86      0.76      0.81      1165\n",
      "           8       0.70      0.59      0.64      1164\n",
      "           9       0.84      0.51      0.64      1661\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.68      0.58      0.62     10000\n",
      "weighted avg       0.85      0.70      0.76     10000\n",
      "\n",
      "Epoch 3: 6962 / 10000\n",
      "Accuracy = 69.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81114012 0.93531915 0.78434941 0.67394578        nan 0.18181818\n",
      " 0.72467532 0.74104235 0.56979405 0.54792746]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.88      1149\n",
      "           1       0.97      0.94      0.95      1175\n",
      "           2       0.84      0.78      0.81      1099\n",
      "           3       0.89      0.67      0.77      1328\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.18      0.00        11\n",
      "           6       0.87      0.72      0.79      1155\n",
      "           7       0.89      0.74      0.81      1228\n",
      "           8       0.77      0.57      0.65      1311\n",
      "           9       0.84      0.55      0.66      1544\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.70      0.60      0.63     10000\n",
      "weighted avg       0.87      0.71      0.78     10000\n",
      "\n",
      "Epoch 4: 7130 / 10000\n",
      "Accuracy = 71.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "network.py:136: RuntimeWarning: invalid value encountered in divide\n",
      "  matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
      "C:\\Python27\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.8294849  0.94818653 0.79294756 0.70770453        nan 0.46511628\n",
      " 0.7319933  0.78238342 0.56499637 0.54781507]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89      1126\n",
      "           1       0.97      0.95      0.96      1158\n",
      "           2       0.85      0.79      0.82      1106\n",
      "           3       0.88      0.71      0.79      1259\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.02      0.47      0.04        43\n",
      "           6       0.91      0.73      0.81      1194\n",
      "           7       0.88      0.78      0.83      1158\n",
      "           8       0.80      0.56      0.66      1377\n",
      "           9       0.86      0.55      0.67      1579\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.71      0.64      0.65     10000\n",
      "weighted avg       0.88      0.72      0.79     10000\n",
      "\n",
      "Epoch 5: 7243 / 10000\n",
      "Accuracy = 72.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86481481 0.95644599 0.826742   0.77272727        nan 0.61787365\n",
      " 0.77728873 0.76139188 0.65926558 0.59368421]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.91      1080\n",
      "           1       0.97      0.96      0.96      1148\n",
      "           2       0.85      0.83      0.84      1062\n",
      "           3       0.86      0.77      0.81      1122\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.45      0.62      0.52       649\n",
      "           6       0.92      0.78      0.84      1136\n",
      "           7       0.89      0.76      0.82      1207\n",
      "           8       0.79      0.66      0.72      1171\n",
      "           9       0.84      0.59      0.70      1425\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.75      0.68      0.71     10000\n",
      "weighted avg       0.85      0.76      0.80     10000\n",
      "\n",
      "Epoch 6: 7598 / 10000\n",
      "Accuracy = 75.98%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89347409 0.95164076 0.80883679 0.80890538        nan 0.69948187\n",
      " 0.79927339 0.78011794 0.72258065 0.57901907]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      1042\n",
      "           1       0.97      0.95      0.96      1158\n",
      "           2       0.87      0.81      0.84      1109\n",
      "           3       0.86      0.81      0.84      1078\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.61      0.70      0.65       772\n",
      "           6       0.92      0.80      0.85      1101\n",
      "           7       0.90      0.78      0.84      1187\n",
      "           8       0.80      0.72      0.76      1085\n",
      "           9       0.84      0.58      0.69      1468\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.77      0.70      0.73     10000\n",
      "weighted avg       0.87      0.78      0.82     10000\n",
      "\n",
      "Epoch 7: 7782 / 10000\n",
      "Accuracy = 77.82%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90416263 0.95332757 0.8109319  0.81954887        nan 0.69053118\n",
      " 0.80765725 0.79792746 0.75905975 0.58266129]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93      1033\n",
      "           1       0.97      0.95      0.96      1157\n",
      "           2       0.88      0.81      0.84      1116\n",
      "           3       0.86      0.82      0.84      1064\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.67      0.69      0.68       866\n",
      "           6       0.92      0.81      0.86      1097\n",
      "           7       0.90      0.80      0.85      1158\n",
      "           8       0.80      0.76      0.78      1021\n",
      "           9       0.86      0.58      0.69      1488\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.78      0.71      0.74     10000\n",
      "weighted avg       0.87      0.79      0.82     10000\n",
      "\n",
      "Epoch 8: 7864 / 10000\n",
      "Accuracy = 78.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91788856 0.95663487 0.82720588 0.81085973 0.         0.72315036\n",
      " 0.80818182 0.79085521 0.75406699 0.59004093]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1023\n",
      "           1       0.97      0.96      0.96      1153\n",
      "           2       0.87      0.83      0.85      1088\n",
      "           3       0.89      0.81      0.85      1105\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.68      0.72      0.70       838\n",
      "           6       0.93      0.81      0.86      1100\n",
      "           7       0.91      0.79      0.85      1181\n",
      "           8       0.81      0.75      0.78      1045\n",
      "           9       0.86      0.59      0.70      1466\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.72      0.75     10000\n",
      "weighted avg       0.88      0.79      0.83     10000\n",
      "\n",
      "Epoch 9: 7920 / 10000\n",
      "Accuracy = 79.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92082111 0.96003475 0.80776014 0.82439926        nan 0.73286876\n",
      " 0.8003581  0.80622837 0.78712871 0.59481583]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1023\n",
      "           1       0.97      0.96      0.97      1151\n",
      "           2       0.89      0.81      0.85      1134\n",
      "           3       0.88      0.82      0.85      1082\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.71      0.73      0.72       861\n",
      "           6       0.93      0.80      0.86      1117\n",
      "           7       0.91      0.81      0.85      1156\n",
      "           8       0.82      0.79      0.80      1010\n",
      "           9       0.86      0.59      0.70      1466\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.79      0.72      0.75     10000\n",
      "weighted avg       0.89      0.80      0.84     10000\n",
      "\n",
      "Epoch 10: 7979 / 10000\n",
      "Accuracy = 79.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92097561 0.96003475 0.83609576 0.84205519        nan 0.71817193\n",
      " 0.82396313 0.81611208 0.78446602 0.58305758]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1025\n",
      "           1       0.97      0.96      0.97      1151\n",
      "           2       0.88      0.84      0.86      1086\n",
      "           3       0.88      0.84      0.86      1051\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.74      0.72      0.73       919\n",
      "           6       0.93      0.82      0.88      1085\n",
      "           7       0.91      0.82      0.86      1142\n",
      "           8       0.83      0.78      0.81      1030\n",
      "           9       0.87      0.58      0.70      1511\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.73      0.76     10000\n",
      "weighted avg       0.89      0.80      0.84     10000\n",
      "\n",
      "Epoch 11: 8017 / 10000\n",
      "Accuracy = 80.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92913386 0.9609375  0.82242152 0.86023622        nan 0.70362694\n",
      " 0.8279371  0.80775862 0.77767266 0.60639777]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1016\n",
      "           1       0.98      0.96      0.97      1152\n",
      "           2       0.89      0.82      0.85      1115\n",
      "           3       0.87      0.86      0.86      1016\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.76      0.70      0.73       965\n",
      "           6       0.93      0.83      0.88      1081\n",
      "           7       0.91      0.81      0.86      1160\n",
      "           8       0.84      0.78      0.81      1057\n",
      "           9       0.86      0.61      0.71      1438\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.73      0.76     10000\n",
      "weighted avg       0.89      0.80      0.84     10000\n",
      "\n",
      "Epoch 12: 8047 / 10000\n",
      "Accuracy = 80.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92367906 0.95775862 0.82659479 0.83813953        nan 0.72263549\n",
      " 0.82460973 0.81336806 0.82168186 0.60438056]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1022\n",
      "           1       0.98      0.96      0.97      1160\n",
      "           2       0.89      0.83      0.86      1113\n",
      "           3       0.89      0.84      0.86      1075\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.76      0.72      0.74       941\n",
      "           6       0.94      0.82      0.88      1089\n",
      "           7       0.91      0.81      0.86      1152\n",
      "           8       0.83      0.82      0.83       987\n",
      "           9       0.88      0.60      0.71      1461\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.80      0.73      0.77     10000\n",
      "weighted avg       0.90      0.81      0.85     10000\n",
      "\n",
      "Epoch 13: 8085 / 10000\n",
      "Accuracy = 80.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.9211295  0.9609375  0.82146078 0.8548233  1.         0.72584034\n",
      " 0.8344186  0.82265145 0.78977273 0.61234397]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1027\n",
      "           1       0.98      0.96      0.97      1152\n",
      "           2       0.88      0.82      0.85      1109\n",
      "           3       0.89      0.85      0.87      1047\n",
      "           4       0.00      1.00      0.00         1\n",
      "           5       0.77      0.73      0.75       952\n",
      "           6       0.94      0.83      0.88      1075\n",
      "           7       0.91      0.82      0.86      1139\n",
      "           8       0.86      0.79      0.82      1056\n",
      "           9       0.88      0.61      0.72      1442\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.83      0.77     10000\n",
      "weighted avg       0.90      0.81      0.85     10000\n",
      "\n",
      "Epoch 14: 8102 / 10000\n",
      "Accuracy = 81.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92647059 0.96344648 0.82005372 0.85632184 1.         0.72651357\n",
      " 0.8356546  0.83067376 0.79528302 0.61357341]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1020\n",
      "           1       0.98      0.96      0.97      1149\n",
      "           2       0.89      0.82      0.85      1117\n",
      "           3       0.89      0.86      0.87      1044\n",
      "           4       0.00      1.00      0.01         3\n",
      "           5       0.78      0.73      0.75       958\n",
      "           6       0.94      0.84      0.88      1077\n",
      "           7       0.91      0.83      0.87      1128\n",
      "           8       0.87      0.80      0.83      1060\n",
      "           9       0.88      0.61      0.72      1444\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.84      0.77     10000\n",
      "weighted avg       0.90      0.81      0.85     10000\n",
      "\n",
      "Epoch 15: 8127 / 10000\n",
      "Accuracy = 81.27%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93762376 0.96850394 0.91071429 0.87366375 0.80168776 0.83816425\n",
      " 0.88247012 0.91330049 0.85350966 0.82751938]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1010\n",
      "           1       0.98      0.97      0.97      1143\n",
      "           2       0.89      0.91      0.90      1008\n",
      "           3       0.89      0.87      0.88      1029\n",
      "           4       0.77      0.80      0.79       948\n",
      "           5       0.78      0.84      0.81       828\n",
      "           6       0.92      0.88      0.90      1004\n",
      "           7       0.90      0.91      0.91      1015\n",
      "           8       0.86      0.85      0.86       983\n",
      "           9       0.85      0.83      0.84      1032\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "Epoch 16: 8831 / 10000\n",
      "Accuracy = 88.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9288499  0.96681223 0.91783567 0.87354086 0.81460674 0.84185493\n",
      " 0.89340102 0.91300098 0.86590437 0.89177489]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1026\n",
      "           1       0.98      0.97      0.97      1145\n",
      "           2       0.89      0.92      0.90       998\n",
      "           3       0.89      0.87      0.88      1028\n",
      "           4       0.89      0.81      0.85      1068\n",
      "           5       0.79      0.84      0.82       841\n",
      "           6       0.92      0.89      0.91       985\n",
      "           7       0.91      0.91      0.91      1023\n",
      "           8       0.86      0.87      0.86       962\n",
      "           9       0.82      0.89      0.85       924\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 17: 8923 / 10000\n",
      "Accuracy = 89.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93326791 0.97012302 0.92690355 0.86935639 0.84154589 0.86625767\n",
      " 0.87968442 0.91428571 0.86196319 0.88333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1019\n",
      "           1       0.97      0.97      0.97      1138\n",
      "           2       0.88      0.93      0.91       985\n",
      "           3       0.90      0.87      0.88      1041\n",
      "           4       0.89      0.84      0.86      1035\n",
      "           5       0.79      0.87      0.83       815\n",
      "           6       0.93      0.88      0.90      1014\n",
      "           7       0.90      0.91      0.91      1015\n",
      "           8       0.87      0.86      0.86       978\n",
      "           9       0.84      0.88      0.86       960\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 18: 8961 / 10000\n",
      "Accuracy = 89.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93170732 0.97438163 0.92       0.88310413 0.84330484 0.87437811\n",
      " 0.89336016 0.91139241 0.86030151 0.89180672]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1025\n",
      "           1       0.97      0.97      0.97      1132\n",
      "           2       0.89      0.92      0.91      1000\n",
      "           3       0.89      0.88      0.89      1018\n",
      "           4       0.90      0.84      0.87      1053\n",
      "           5       0.79      0.87      0.83       804\n",
      "           6       0.93      0.89      0.91       994\n",
      "           7       0.91      0.91      0.91      1027\n",
      "           8       0.88      0.86      0.87       995\n",
      "           9       0.84      0.89      0.87       952\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 19: 8997 / 10000\n",
      "Accuracy = 89.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93164062 0.97359155 0.92462312 0.88454012 0.86060019 0.85463072\n",
      " 0.90142276 0.90979631 0.8836478  0.88636364]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1024\n",
      "           1       0.97      0.97      0.97      1136\n",
      "           2       0.89      0.92      0.91       995\n",
      "           3       0.90      0.88      0.89      1022\n",
      "           4       0.91      0.86      0.88      1033\n",
      "           5       0.82      0.85      0.84       853\n",
      "           6       0.93      0.90      0.91       984\n",
      "           7       0.91      0.91      0.91      1031\n",
      "           8       0.87      0.88      0.87       954\n",
      "           9       0.85      0.89      0.87       968\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 20: 9028 / 10000\n",
      "Accuracy = 90.28%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9297561  0.97017544 0.92315369 0.89306931 0.86324786 0.88220859\n",
      " 0.9020202  0.9140625  0.86895161 0.90410959]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1025\n",
      "           1       0.97      0.97      0.97      1140\n",
      "           2       0.90      0.92      0.91      1002\n",
      "           3       0.89      0.89      0.89      1010\n",
      "           4       0.93      0.86      0.89      1053\n",
      "           5       0.81      0.88      0.84       815\n",
      "           6       0.93      0.90      0.92       990\n",
      "           7       0.91      0.91      0.91      1024\n",
      "           8       0.89      0.87      0.88       992\n",
      "           9       0.85      0.90      0.88       949\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 21: 9063 / 10000\n",
      "Accuracy = 90.63%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9334638  0.97185576 0.924      0.89949749 0.86653956 0.87395957\n",
      " 0.90539166 0.91431353 0.86686687 0.90390707]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1022\n",
      "           1       0.97      0.97      0.97      1137\n",
      "           2       0.90      0.92      0.91      1000\n",
      "           3       0.89      0.90      0.89       995\n",
      "           4       0.93      0.87      0.90      1049\n",
      "           5       0.82      0.87      0.85       841\n",
      "           6       0.93      0.91      0.92       983\n",
      "           7       0.91      0.91      0.91      1027\n",
      "           8       0.89      0.87      0.88       999\n",
      "           9       0.85      0.90      0.88       947\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 22: 9073 / 10000\n",
      "Accuracy = 90.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94076999 0.96853147 0.9258517  0.88629738 0.87911025 0.87395957\n",
      " 0.90918367 0.91512195 0.87615148 0.90406674]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1013\n",
      "           1       0.98      0.97      0.97      1144\n",
      "           2       0.90      0.93      0.91       998\n",
      "           3       0.90      0.89      0.89      1029\n",
      "           4       0.93      0.88      0.90      1034\n",
      "           5       0.82      0.87      0.85       841\n",
      "           6       0.93      0.91      0.92       980\n",
      "           7       0.91      0.92      0.91      1025\n",
      "           8       0.88      0.88      0.88       977\n",
      "           9       0.86      0.90      0.88       959\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 23: 9093 / 10000\n",
      "Accuracy = 90.93%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93891626 0.96847636 0.92507493 0.89390963 0.87717602 0.87236534\n",
      " 0.90231621 0.91764706 0.88271605 0.90431125]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1015\n",
      "           1       0.97      0.97      0.97      1142\n",
      "           2       0.90      0.93      0.91      1001\n",
      "           3       0.90      0.89      0.90      1018\n",
      "           4       0.92      0.88      0.90      1034\n",
      "           5       0.84      0.87      0.85       854\n",
      "           6       0.94      0.90      0.92       993\n",
      "           7       0.91      0.92      0.91      1020\n",
      "           8       0.88      0.88      0.88       972\n",
      "           9       0.85      0.90      0.88       951\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 24: 9097 / 10000\n",
      "Accuracy = 90.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93799213 0.97444934 0.92492492 0.89970209 0.87957611 0.87093023\n",
      " 0.90596562 0.91796875 0.87436677 0.91216931]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1016\n",
      "           1       0.97      0.97      0.97      1135\n",
      "           2       0.90      0.92      0.91       999\n",
      "           3       0.90      0.90      0.90      1007\n",
      "           4       0.93      0.88      0.90      1038\n",
      "           5       0.84      0.87      0.86       860\n",
      "           6       0.94      0.91      0.92       989\n",
      "           7       0.91      0.92      0.92      1024\n",
      "           8       0.89      0.87      0.88       987\n",
      "           9       0.85      0.91      0.88       945\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 25: 9112 / 10000\n",
      "Accuracy = 91.12%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94076999 0.97444934 0.93016194 0.89039767 0.88791423 0.88347206\n",
      " 0.90716448 0.91642371 0.87373737 0.90899582]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1013\n",
      "           1       0.97      0.97      0.97      1135\n",
      "           2       0.89      0.93      0.91       988\n",
      "           3       0.91      0.89      0.90      1031\n",
      "           4       0.93      0.89      0.91      1026\n",
      "           5       0.83      0.88      0.86       841\n",
      "           6       0.94      0.91      0.92       991\n",
      "           7       0.92      0.92      0.92      1029\n",
      "           8       0.89      0.87      0.88       990\n",
      "           9       0.86      0.91      0.88       956\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 26: 9126 / 10000\n",
      "Accuracy = 91.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93897638 0.97361478 0.92778335 0.89910979 0.88997079 0.88730724\n",
      " 0.90471414 0.91812865 0.871      0.91966173]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1016\n",
      "           1       0.98      0.97      0.97      1137\n",
      "           2       0.90      0.93      0.91       997\n",
      "           3       0.90      0.90      0.90      1011\n",
      "           4       0.93      0.89      0.91      1027\n",
      "           5       0.84      0.89      0.86       843\n",
      "           6       0.94      0.90      0.92       997\n",
      "           7       0.92      0.92      0.92      1026\n",
      "           8       0.89      0.87      0.88      1000\n",
      "           9       0.86      0.92      0.89       946\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.91      0.91     10000\n",
      "\n",
      "Epoch 27: 9142 / 10000\n",
      "Accuracy = 91.42%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93897638 0.97275923 0.92807193 0.90019763 0.88513514 0.8766007\n",
      " 0.91335372 0.92082111 0.87894201 0.91692955]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1016\n",
      "           1       0.98      0.97      0.97      1138\n",
      "           2       0.90      0.93      0.91      1001\n",
      "           3       0.90      0.90      0.90      1012\n",
      "           4       0.93      0.89      0.91      1036\n",
      "           5       0.84      0.88      0.86       859\n",
      "           6       0.94      0.91      0.92       981\n",
      "           7       0.92      0.92      0.92      1023\n",
      "           8       0.89      0.88      0.88       983\n",
      "           9       0.86      0.92      0.89       951\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.91      0.91     10000\n",
      "\n",
      "Epoch 28: 9145 / 10000\n",
      "Accuracy = 91.45%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93621197 0.97614841 0.92692693 0.89882122 0.88974855 0.88703924\n",
      " 0.91286727 0.91731518 0.8691774  0.93033226]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1019\n",
      "           1       0.97      0.98      0.97      1132\n",
      "           2       0.90      0.93      0.91       999\n",
      "           3       0.91      0.90      0.90      1018\n",
      "           4       0.94      0.89      0.91      1034\n",
      "           5       0.84      0.89      0.86       841\n",
      "           6       0.94      0.91      0.93       987\n",
      "           7       0.92      0.92      0.92      1028\n",
      "           8       0.90      0.87      0.88      1009\n",
      "           9       0.86      0.93      0.89       933\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 29: 9155 / 10000\n",
      "Accuracy = 91.55%\n"
     ]
    }
   ],
   "source": [
    "net = network.Network([784, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 0.1, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode-se ver, o modelo com esses hiper-parâmetros obteve uma acurácia total de 83.43% em sua última época. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, varia-se o número de épocas de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.42155221 0.57578947 0.         0.31110052 0.10204082 0.08333333\n",
      " 0.5        0.59253618 0.21848739 0.34130926]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.42      0.54      1791\n",
      "           1       0.96      0.58      0.72      1900\n",
      "           2       0.00      0.00      0.00        33\n",
      "           3       0.65      0.31      0.42      2099\n",
      "           4       0.04      0.10      0.05       343\n",
      "           5       0.00      0.08      0.00        24\n",
      "           6       0.02      0.50      0.04        44\n",
      "           7       0.76      0.59      0.66      1313\n",
      "           8       0.05      0.22      0.09       238\n",
      "           9       0.75      0.34      0.47      2215\n",
      "\n",
      "   micro avg       0.41      0.41      0.41     10000\n",
      "   macro avg       0.40      0.31      0.30     10000\n",
      "weighted avg       0.72      0.41      0.52     10000\n",
      "\n",
      "Epoch 0: 4147 / 10000\n",
      "Accuracy = 41.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.59947299 0.7235023  0.04347826 0.43264659 0.34570597 0.2\n",
      " 0.55555556 0.75179211 0.42474608 0.51988835]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.60      0.73      1518\n",
      "           1       0.97      0.72      0.83      1519\n",
      "           2       0.00      0.04      0.00        23\n",
      "           3       0.81      0.43      0.56      1893\n",
      "           4       0.48      0.35      0.40      1374\n",
      "           5       0.00      0.20      0.00         5\n",
      "           6       0.02      0.56      0.04        36\n",
      "           7       0.82      0.75      0.78      1116\n",
      "           8       0.47      0.42      0.45      1083\n",
      "           9       0.74      0.52      0.61      1433\n",
      "\n",
      "   micro avg       0.54      0.54      0.54     10000\n",
      "   macro avg       0.52      0.46      0.44     10000\n",
      "weighted avg       0.76      0.54      0.62     10000\n",
      "\n",
      "Epoch 1: 5369 / 10000\n",
      "Accuracy = 53.69%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.66930266 0.80264123 0.08823529 0.44311377 0.45904888 0.375\n",
      " 0.57142857 0.81931166 0.47327653 0.59875583]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.79      1391\n",
      "           1       0.96      0.80      0.88      1363\n",
      "           2       0.00      0.09      0.01        34\n",
      "           3       0.88      0.44      0.59      2004\n",
      "           4       0.71      0.46      0.56      1514\n",
      "           5       0.00      0.38      0.01         8\n",
      "           6       0.04      0.57      0.07        63\n",
      "           7       0.83      0.82      0.83      1046\n",
      "           8       0.63      0.47      0.54      1291\n",
      "           9       0.76      0.60      0.67      1286\n",
      "\n",
      "   micro avg       0.59      0.59      0.59     10000\n",
      "   macro avg       0.58      0.53      0.49     10000\n",
      "weighted avg       0.81      0.59      0.67     10000\n",
      "\n",
      "Epoch 2: 5888 / 10000\n",
      "Accuracy = 58.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.70037175 0.79312813 0.39877301 0.52817746 0.55466472 0.5\n",
      " 0.63908046 0.82286785 0.50640543 0.65188834]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81      1345\n",
      "           1       0.98      0.79      0.88      1397\n",
      "           2       0.06      0.40      0.11       163\n",
      "           3       0.87      0.53      0.66      1668\n",
      "           4       0.77      0.55      0.65      1372\n",
      "           5       0.00      0.50      0.01         8\n",
      "           6       0.29      0.64      0.40       435\n",
      "           7       0.85      0.82      0.84      1067\n",
      "           8       0.69      0.51      0.58      1327\n",
      "           9       0.79      0.65      0.71      1218\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     10000\n",
      "   macro avg       0.63      0.61      0.56     10000\n",
      "weighted avg       0.81      0.64      0.70     10000\n",
      "\n",
      "Epoch 3: 6383 / 10000\n",
      "Accuracy = 63.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81076389 0.88780488 0.72580645 0.64020772 0.71806569 0.47619048\n",
      " 0.69784173 0.86766169 0.61071429 0.73963964]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.88      1152\n",
      "           1       0.96      0.89      0.92      1230\n",
      "           2       0.57      0.73      0.64       806\n",
      "           3       0.85      0.64      0.73      1348\n",
      "           4       0.80      0.72      0.76      1096\n",
      "           5       0.01      0.48      0.02        21\n",
      "           6       0.81      0.70      0.75      1112\n",
      "           7       0.85      0.87      0.86      1005\n",
      "           8       0.70      0.61      0.65      1120\n",
      "           9       0.81      0.74      0.77      1110\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.73      0.72      0.70     10000\n",
      "weighted avg       0.82      0.74      0.78     10000\n",
      "\n",
      "Epoch 4: 7424 / 10000\n",
      "Accuracy = 74.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82049037 0.9120603  0.79787234 0.67596899 0.74588665 0.52631579\n",
      " 0.75412844 0.85428571 0.63950399 0.77946768]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88      1142\n",
      "           1       0.96      0.91      0.94      1194\n",
      "           2       0.73      0.80      0.76       940\n",
      "           3       0.86      0.68      0.76      1290\n",
      "           4       0.83      0.75      0.79      1094\n",
      "           5       0.01      0.53      0.02        19\n",
      "           6       0.86      0.75      0.80      1090\n",
      "           7       0.87      0.85      0.86      1050\n",
      "           8       0.74      0.64      0.69      1129\n",
      "           9       0.81      0.78      0.80      1052\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.76      0.75      0.73     10000\n",
      "weighted avg       0.85      0.77      0.81     10000\n",
      "\n",
      "Epoch 5: 7735 / 10000\n",
      "Accuracy = 77.35%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8311229  0.92554992 0.828125   0.69984076 0.75896057 0.57575758\n",
      " 0.77422303 0.86859903 0.65418118 0.79521531]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      1131\n",
      "           1       0.96      0.93      0.94      1182\n",
      "           2       0.77      0.83      0.80       960\n",
      "           3       0.87      0.70      0.78      1256\n",
      "           4       0.86      0.76      0.81      1116\n",
      "           5       0.02      0.58      0.04        33\n",
      "           6       0.88      0.77      0.83      1094\n",
      "           7       0.87      0.87      0.87      1035\n",
      "           8       0.77      0.65      0.71      1148\n",
      "           9       0.82      0.80      0.81      1045\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.78      0.77      0.75     10000\n",
      "weighted avg       0.86      0.79      0.82     10000\n",
      "\n",
      "Epoch 6: 7902 / 10000\n",
      "Accuracy = 79.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82995595 0.93367347 0.85062241 0.736356   0.79506641 0.6625\n",
      " 0.78467153 0.87695312 0.64497529 0.79549719]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      1135\n",
      "           1       0.97      0.93      0.95      1176\n",
      "           2       0.79      0.85      0.82       964\n",
      "           3       0.87      0.74      0.80      1191\n",
      "           4       0.85      0.80      0.82      1054\n",
      "           5       0.06      0.66      0.11        80\n",
      "           6       0.90      0.78      0.84      1096\n",
      "           7       0.87      0.88      0.88      1024\n",
      "           8       0.80      0.64      0.72      1214\n",
      "           9       0.84      0.80      0.82      1066\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.79      0.79      0.76     10000\n",
      "weighted avg       0.87      0.80      0.83     10000\n",
      "\n",
      "Epoch 7: 8017 / 10000\n",
      "Accuracy = 80.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85989011 0.93962585 0.85934292 0.71394799 0.81932367 0.75692308\n",
      " 0.82612872 0.88834476 0.73776908 0.82296651]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      1092\n",
      "           1       0.97      0.94      0.96      1176\n",
      "           2       0.81      0.86      0.83       974\n",
      "           3       0.90      0.71      0.80      1269\n",
      "           4       0.86      0.82      0.84      1035\n",
      "           5       0.28      0.76      0.40       325\n",
      "           6       0.90      0.83      0.86      1041\n",
      "           7       0.88      0.89      0.89      1021\n",
      "           8       0.77      0.74      0.76      1022\n",
      "           9       0.85      0.82      0.84      1045\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.82      0.82      0.81     10000\n",
      "weighted avg       0.86      0.83      0.84     10000\n",
      "\n",
      "Epoch 8: 8262 / 10000\n",
      "Accuracy = 82.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.89645254 0.94434932 0.88701162 0.76909871 0.84737364 0.79051988\n",
      " 0.83269598 0.9063745  0.81497326 0.84353741]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      1043\n",
      "           1       0.97      0.94      0.96      1168\n",
      "           2       0.81      0.89      0.85       947\n",
      "           3       0.89      0.77      0.82      1165\n",
      "           4       0.87      0.85      0.86      1009\n",
      "           5       0.58      0.79      0.67       654\n",
      "           6       0.91      0.83      0.87      1046\n",
      "           7       0.89      0.91      0.90      1004\n",
      "           8       0.78      0.81      0.80       935\n",
      "           9       0.86      0.84      0.85      1029\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Epoch 9: 8557 / 10000\n",
      "Accuracy = 85.57%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90609874 0.95324675 0.87399194 0.80492252 0.84414327 0.78987342\n",
      " 0.87122736 0.90963257 0.8447694  0.85643564]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1033\n",
      "           1       0.97      0.95      0.96      1155\n",
      "           2       0.84      0.87      0.86       992\n",
      "           3       0.87      0.80      0.84      1097\n",
      "           4       0.89      0.84      0.87      1033\n",
      "           5       0.70      0.79      0.74       790\n",
      "           6       0.90      0.87      0.89       994\n",
      "           7       0.89      0.91      0.90      1007\n",
      "           8       0.77      0.84      0.81       889\n",
      "           9       0.86      0.86      0.86      1010\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.87      0.86     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "Epoch 10: 8681 / 10000\n",
      "Accuracy = 86.81%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9090029  0.94768439 0.89128205 0.82146161 0.86521308 0.80528846\n",
      " 0.86939182 0.90452756 0.85412027 0.87537994]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1033\n",
      "           1       0.97      0.95      0.96      1166\n",
      "           2       0.84      0.89      0.87       975\n",
      "           3       0.88      0.82      0.85      1081\n",
      "           4       0.89      0.87      0.88      1009\n",
      "           5       0.75      0.81      0.78       832\n",
      "           6       0.91      0.87      0.89      1003\n",
      "           7       0.89      0.90      0.90      1016\n",
      "           8       0.79      0.85      0.82       898\n",
      "           9       0.86      0.88      0.87       987\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "Epoch 11: 8766 / 10000\n",
      "Accuracy = 87.66%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92110454 0.95176572 0.88776542 0.84281581 0.86328125 0.79283315\n",
      " 0.886619   0.90649606 0.85810056 0.87399194]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      1014\n",
      "           1       0.97      0.95      0.96      1161\n",
      "           2       0.85      0.89      0.87       989\n",
      "           3       0.87      0.84      0.85      1037\n",
      "           4       0.90      0.86      0.88      1024\n",
      "           5       0.79      0.79      0.79       893\n",
      "           6       0.91      0.89      0.90       979\n",
      "           7       0.90      0.91      0.90      1016\n",
      "           8       0.79      0.86      0.82       895\n",
      "           9       0.86      0.87      0.87       992\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "Epoch 12: 8807 / 10000\n",
      "Accuracy = 88.07%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9193707  0.95431034 0.89877301 0.84971098 0.85976789 0.82167832\n",
      " 0.89036885 0.91252485 0.84803401 0.87600806]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      1017\n",
      "           1       0.98      0.95      0.96      1160\n",
      "           2       0.85      0.90      0.87       978\n",
      "           3       0.87      0.85      0.86      1038\n",
      "           4       0.91      0.86      0.88      1034\n",
      "           5       0.79      0.82      0.81       858\n",
      "           6       0.91      0.89      0.90       976\n",
      "           7       0.89      0.91      0.90      1006\n",
      "           8       0.82      0.85      0.83       941\n",
      "           9       0.86      0.88      0.87       992\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 13: 8851 / 10000\n",
      "Accuracy = 88.51%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91878669 0.95266781 0.90796277 0.84932821 0.87131631 0.82694541\n",
      " 0.89035533 0.91089109 0.85546039 0.87787788]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1022\n",
      "           1       0.98      0.95      0.96      1162\n",
      "           2       0.85      0.91      0.88       967\n",
      "           3       0.88      0.85      0.86      1042\n",
      "           4       0.90      0.87      0.89      1018\n",
      "           5       0.80      0.83      0.81       861\n",
      "           6       0.92      0.89      0.90       985\n",
      "           7       0.89      0.91      0.90      1010\n",
      "           8       0.82      0.86      0.84       934\n",
      "           9       0.87      0.88      0.87       999\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 14: 8881 / 10000\n",
      "Accuracy = 88.81%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92133727 0.95517241 0.90618557 0.85658915 0.86973555 0.82359679\n",
      " 0.89856557 0.9147671  0.86373391 0.87227723]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1017\n",
      "           1       0.98      0.96      0.97      1160\n",
      "           2       0.85      0.91      0.88       970\n",
      "           3       0.88      0.86      0.87      1032\n",
      "           4       0.90      0.87      0.89      1021\n",
      "           5       0.81      0.82      0.81       873\n",
      "           6       0.92      0.90      0.91       976\n",
      "           7       0.90      0.91      0.91      1009\n",
      "           8       0.83      0.86      0.84       932\n",
      "           9       0.87      0.87      0.87      1010\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 15: 8901 / 10000\n",
      "Accuracy = 89.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92406312 0.95682211 0.89959432 0.85009488 0.882      0.83962264\n",
      " 0.89795918 0.91321499 0.87229437 0.86888454]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1014\n",
      "           1       0.98      0.96      0.97      1158\n",
      "           2       0.86      0.90      0.88       986\n",
      "           3       0.89      0.85      0.87      1054\n",
      "           4       0.90      0.88      0.89      1000\n",
      "           5       0.80      0.84      0.82       848\n",
      "           6       0.92      0.90      0.91       980\n",
      "           7       0.90      0.91      0.91      1014\n",
      "           8       0.83      0.87      0.85       924\n",
      "           9       0.88      0.87      0.87      1022\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 16: 8922 / 10000\n",
      "Accuracy = 89.22%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91976517 0.95599655 0.90778689 0.84097287 0.87807276 0.85238095\n",
      " 0.89725331 0.91535433 0.87842278 0.88159204]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1022\n",
      "           1       0.98      0.96      0.97      1159\n",
      "           2       0.86      0.91      0.88       976\n",
      "           3       0.89      0.84      0.86      1069\n",
      "           4       0.91      0.88      0.89      1017\n",
      "           5       0.80      0.85      0.83       840\n",
      "           6       0.92      0.90      0.91       983\n",
      "           7       0.90      0.92      0.91      1016\n",
      "           8       0.82      0.88      0.85       913\n",
      "           9       0.88      0.88      0.88      1005\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 17: 8942 / 10000\n",
      "Accuracy = 89.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.92519685 0.95513374 0.90797546 0.84839925 0.87634936 0.8547619\n",
      " 0.89858012 0.91560353 0.87473233 0.89057751]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1016\n",
      "           1       0.98      0.96      0.97      1159\n",
      "           2       0.86      0.91      0.88       978\n",
      "           3       0.89      0.85      0.87      1062\n",
      "           4       0.91      0.88      0.89      1019\n",
      "           5       0.80      0.85      0.83       840\n",
      "           6       0.92      0.90      0.91       986\n",
      "           7       0.91      0.92      0.91      1019\n",
      "           8       0.84      0.87      0.86       934\n",
      "           9       0.87      0.89      0.88       987\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 18: 8962 / 10000\n",
      "Accuracy = 89.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92878338 0.95772217 0.90844354 0.86028708 0.884273   0.86396181\n",
      " 0.90224033 0.91952895 0.86951983 0.89235412]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1011\n",
      "           1       0.98      0.96      0.97      1159\n",
      "           2       0.87      0.91      0.89       983\n",
      "           3       0.89      0.86      0.87      1045\n",
      "           4       0.91      0.88      0.90      1011\n",
      "           5       0.81      0.86      0.84       838\n",
      "           6       0.92      0.90      0.91       982\n",
      "           7       0.91      0.92      0.92      1019\n",
      "           8       0.86      0.87      0.86       958\n",
      "           9       0.88      0.89      0.89       994\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 19: 9002 / 10000\n",
      "Accuracy = 90.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92300195 0.95693368 0.91443299 0.87028074 0.87992126 0.84772727\n",
      " 0.91322314 0.91609756 0.88012959 0.89145729]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1026\n",
      "           1       0.98      0.96      0.97      1161\n",
      "           2       0.86      0.91      0.89       970\n",
      "           3       0.89      0.87      0.88      1033\n",
      "           4       0.91      0.88      0.89      1016\n",
      "           5       0.84      0.85      0.84       880\n",
      "           6       0.92      0.91      0.92       968\n",
      "           7       0.91      0.92      0.91      1025\n",
      "           8       0.84      0.88      0.86       926\n",
      "           9       0.88      0.89      0.89       995\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 20: 9009 / 10000\n",
      "Accuracy = 90.09%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92737978 0.95941278 0.90442656 0.8700291  0.88385827 0.8677686\n",
      " 0.91170431 0.91992188 0.87368421 0.89665653]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1019\n",
      "           1       0.98      0.96      0.97      1158\n",
      "           2       0.87      0.90      0.89       994\n",
      "           3       0.89      0.87      0.88      1031\n",
      "           4       0.91      0.88      0.90      1016\n",
      "           5       0.82      0.87      0.85       847\n",
      "           6       0.93      0.91      0.92       974\n",
      "           7       0.92      0.92      0.92      1024\n",
      "           8       0.85      0.87      0.86       950\n",
      "           9       0.88      0.90      0.89       987\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 21: 9030 / 10000\n",
      "Accuracy = 90.30%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93195266 0.96187175 0.90789474 0.8776908  0.88484252 0.85632184\n",
      " 0.91469681 0.92270059 0.86869748 0.89484328]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1014\n",
      "           1       0.98      0.96      0.97      1154\n",
      "           2       0.87      0.91      0.89       988\n",
      "           3       0.89      0.88      0.88      1022\n",
      "           4       0.92      0.88      0.90      1016\n",
      "           5       0.84      0.86      0.85       870\n",
      "           6       0.93      0.91      0.92       973\n",
      "           7       0.92      0.92      0.92      1022\n",
      "           8       0.85      0.87      0.86       952\n",
      "           9       0.88      0.89      0.89       989\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 22: 9038 / 10000\n",
      "Accuracy = 90.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9294809  0.96020761 0.91335372 0.86956522 0.88692232 0.86442642\n",
      " 0.91555098 0.9252704  0.86743215 0.90214067]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1021\n",
      "           1       0.98      0.96      0.97      1156\n",
      "           2       0.87      0.91      0.89       981\n",
      "           3       0.89      0.87      0.88      1035\n",
      "           4       0.92      0.89      0.90      1017\n",
      "           5       0.84      0.86      0.85       863\n",
      "           6       0.93      0.92      0.92       971\n",
      "           7       0.92      0.93      0.92      1017\n",
      "           8       0.85      0.87      0.86       958\n",
      "           9       0.88      0.90      0.89       981\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.91     10000\n",
      "\n",
      "Epoch 23: 9049 / 10000\n",
      "Accuracy = 90.49%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93235294 0.95862069 0.91317671 0.87451362 0.8958959  0.87617925\n",
      " 0.91778006 0.91933916 0.86645963 0.89278557]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1020\n",
      "           1       0.98      0.96      0.97      1160\n",
      "           2       0.87      0.91      0.89       979\n",
      "           3       0.89      0.87      0.88      1028\n",
      "           4       0.91      0.90      0.90       999\n",
      "           5       0.83      0.88      0.85       848\n",
      "           6       0.93      0.92      0.92       973\n",
      "           7       0.92      0.92      0.92      1029\n",
      "           8       0.86      0.87      0.86       966\n",
      "           9       0.88      0.89      0.89       998\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 24: 9061 / 10000\n",
      "Accuracy = 90.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93059629 0.95948276 0.90662651 0.86039886 0.89285714 0.8784267\n",
      " 0.91880781 0.92885375 0.88367129 0.89489489]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1023\n",
      "           1       0.98      0.96      0.97      1160\n",
      "           2       0.88      0.91      0.89       996\n",
      "           3       0.90      0.86      0.88      1053\n",
      "           4       0.92      0.89      0.90      1008\n",
      "           5       0.83      0.88      0.85       839\n",
      "           6       0.93      0.92      0.93       973\n",
      "           7       0.91      0.93      0.92      1012\n",
      "           8       0.85      0.88      0.87       937\n",
      "           9       0.89      0.89      0.89       999\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.90     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 25: 9067 / 10000\n",
      "Accuracy = 90.67%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9324192  0.96521739 0.90753769 0.87439143 0.89939638 0.86836028\n",
      " 0.91786448 0.92367906 0.87278415 0.89919355]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1021\n",
      "           1       0.98      0.97      0.97      1150\n",
      "           2       0.88      0.91      0.89       995\n",
      "           3       0.89      0.87      0.88      1027\n",
      "           4       0.91      0.90      0.90       994\n",
      "           5       0.84      0.87      0.86       866\n",
      "           6       0.93      0.92      0.93       974\n",
      "           7       0.92      0.92      0.92      1022\n",
      "           8       0.86      0.87      0.87       959\n",
      "           9       0.88      0.90      0.89       992\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 26: 9076 / 10000\n",
      "Accuracy = 90.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.93418468 0.96110631 0.91046278 0.87162162 0.89141165 0.875\n",
      " 0.91991786 0.92639843 0.88155136 0.91011236]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1018\n",
      "           1       0.98      0.96      0.97      1157\n",
      "           2       0.88      0.91      0.89       994\n",
      "           3       0.89      0.87      0.88      1036\n",
      "           4       0.92      0.89      0.91      1013\n",
      "           5       0.84      0.88      0.86       856\n",
      "           6       0.94      0.92      0.93       974\n",
      "           7       0.92      0.93      0.92      1019\n",
      "           8       0.86      0.88      0.87       954\n",
      "           9       0.88      0.91      0.90       979\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 27: 9095 / 10000\n",
      "Accuracy = 90.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93780849 0.95951766 0.91008991 0.86048689 0.89239882 0.87412587\n",
      " 0.92962185 0.92277615 0.89956803 0.90964467]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1013\n",
      "           1       0.98      0.96      0.97      1161\n",
      "           2       0.88      0.91      0.90      1001\n",
      "           3       0.91      0.86      0.88      1068\n",
      "           4       0.92      0.89      0.91      1013\n",
      "           5       0.84      0.87      0.86       858\n",
      "           6       0.92      0.93      0.93       952\n",
      "           7       0.92      0.92      0.92      1023\n",
      "           8       0.86      0.90      0.88       926\n",
      "           9       0.89      0.91      0.90       985\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 28: 9106 / 10000\n",
      "Accuracy = 91.06%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93688363 0.96434783 0.9107322  0.87332054 0.89634748 0.88028169\n",
      " 0.9214876  0.92647059 0.88179916 0.91194332]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1014\n",
      "           1       0.98      0.96      0.97      1150\n",
      "           2       0.88      0.91      0.90       997\n",
      "           3       0.90      0.87      0.89      1042\n",
      "           4       0.92      0.90      0.91      1013\n",
      "           5       0.84      0.88      0.86       852\n",
      "           6       0.93      0.92      0.93       968\n",
      "           7       0.92      0.93      0.92      1020\n",
      "           8       0.87      0.88      0.87       956\n",
      "           9       0.89      0.91      0.90       988\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 29: 9116 / 10000\n",
      "Accuracy = 91.16%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93503937 0.95951766 0.90485629 0.87849566 0.88867188 0.88561321\n",
      " 0.9170082  0.93545184 0.88736842 0.91666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1016\n",
      "           1       0.98      0.96      0.97      1161\n",
      "           2       0.88      0.90      0.89      1009\n",
      "           3       0.90      0.88      0.89      1037\n",
      "           4       0.93      0.89      0.91      1024\n",
      "           5       0.84      0.89      0.86       848\n",
      "           6       0.93      0.92      0.93       976\n",
      "           7       0.92      0.94      0.93      1007\n",
      "           8       0.87      0.89      0.88       950\n",
      "           9       0.88      0.92      0.90       972\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 30: 9120 / 10000\n",
      "Accuracy = 91.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93688363 0.96190476 0.92057026 0.8705104  0.8914956  0.88167053\n",
      " 0.92604167 0.93096647 0.88529718 0.91778006]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1014\n",
      "           1       0.98      0.96      0.97      1155\n",
      "           2       0.88      0.92      0.90       982\n",
      "           3       0.91      0.87      0.89      1058\n",
      "           4       0.93      0.89      0.91      1023\n",
      "           5       0.85      0.88      0.87       862\n",
      "           6       0.93      0.93      0.93       960\n",
      "           7       0.92      0.93      0.92      1014\n",
      "           8       0.87      0.89      0.88       959\n",
      "           9       0.89      0.92      0.90       973\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 31: 9133 / 10000\n",
      "Accuracy = 91.33%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93510324 0.96117343 0.91317365 0.87714286 0.88640777 0.88139535\n",
      " 0.92984293 0.9302554  0.89518717 0.91786448]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1017\n",
      "           1       0.98      0.96      0.97      1159\n",
      "           2       0.89      0.91      0.90      1002\n",
      "           3       0.91      0.88      0.89      1050\n",
      "           4       0.93      0.89      0.91      1030\n",
      "           5       0.85      0.88      0.87       860\n",
      "           6       0.93      0.93      0.93       955\n",
      "           7       0.92      0.93      0.93      1018\n",
      "           8       0.86      0.90      0.88       935\n",
      "           9       0.89      0.92      0.90       974\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 32: 9138 / 10000\n",
      "Accuracy = 91.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93516699 0.9595525  0.91649899 0.89073171 0.89577188 0.88452656\n",
      " 0.93006263 0.92578125 0.88425443 0.91504606]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1018\n",
      "           1       0.98      0.96      0.97      1162\n",
      "           2       0.88      0.92      0.90       994\n",
      "           3       0.90      0.89      0.90      1025\n",
      "           4       0.93      0.90      0.91      1017\n",
      "           5       0.86      0.88      0.87       866\n",
      "           6       0.93      0.93      0.93       958\n",
      "           7       0.92      0.93      0.92      1024\n",
      "           8       0.87      0.88      0.88       959\n",
      "           9       0.89      0.92      0.90       977\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.91      0.92     10000\n",
      "\n",
      "Epoch 33: 9149 / 10000\n",
      "Accuracy = 91.49%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93523062 0.96277056 0.90401567 0.89202335 0.907      0.87557078\n",
      " 0.93459916 0.93123772 0.89529915 0.91191191]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1019\n",
      "           1       0.98      0.96      0.97      1155\n",
      "           2       0.89      0.90      0.90      1021\n",
      "           3       0.91      0.89      0.90      1028\n",
      "           4       0.92      0.91      0.92      1000\n",
      "           5       0.86      0.88      0.87       876\n",
      "           6       0.92      0.93      0.93       948\n",
      "           7       0.92      0.93      0.93      1018\n",
      "           8       0.86      0.90      0.88       936\n",
      "           9       0.90      0.91      0.91       999\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 34: 9162 / 10000\n",
      "Accuracy = 91.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93903638 0.9595525  0.91097923 0.90863454 0.908      0.87150838\n",
      " 0.92924037 0.93117011 0.89229145 0.91146881]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1017\n",
      "           1       0.98      0.96      0.97      1162\n",
      "           2       0.89      0.91      0.90      1011\n",
      "           3       0.90      0.91      0.90       996\n",
      "           4       0.92      0.91      0.92      1000\n",
      "           5       0.87      0.87      0.87       895\n",
      "           6       0.93      0.93      0.93       961\n",
      "           7       0.92      0.93      0.93      1017\n",
      "           8       0.87      0.89      0.88       947\n",
      "           9       0.90      0.91      0.90       994\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 35: 9175 / 10000\n",
      "Accuracy = 91.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.93799213 0.96444059 0.91007905 0.88642926 0.89852217 0.89163722\n",
      " 0.93132154 0.9302554  0.89028213 0.91938776]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1016\n",
      "           1       0.98      0.96      0.97      1153\n",
      "           2       0.89      0.91      0.90      1012\n",
      "           3       0.91      0.89      0.90      1039\n",
      "           4       0.93      0.90      0.91      1015\n",
      "           5       0.85      0.89      0.87       849\n",
      "           6       0.93      0.93      0.93       961\n",
      "           7       0.92      0.93      0.93      1018\n",
      "           8       0.87      0.89      0.88       957\n",
      "           9       0.89      0.92      0.91       980\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 36: 9171 / 10000\n",
      "Accuracy = 91.71%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93535749 0.96200345 0.91417166 0.88985507 0.91515152 0.89485981\n",
      " 0.93035343 0.93300493 0.88410256 0.9178499 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1021\n",
      "           1       0.98      0.96      0.97      1158\n",
      "           2       0.89      0.91      0.90      1002\n",
      "           3       0.91      0.89      0.90      1035\n",
      "           4       0.92      0.92      0.92       990\n",
      "           5       0.86      0.89      0.88       856\n",
      "           6       0.93      0.93      0.93       962\n",
      "           7       0.92      0.93      0.93      1015\n",
      "           8       0.89      0.88      0.88       975\n",
      "           9       0.90      0.92      0.91       986\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 37: 9187 / 10000\n",
      "Accuracy = 91.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94164194 0.96524761 0.91451292 0.89092664 0.90918164 0.8891455\n",
      " 0.93416928 0.92773438 0.89051095 0.91902834]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1011\n",
      "           1       0.98      0.97      0.97      1151\n",
      "           2       0.89      0.91      0.90      1006\n",
      "           3       0.91      0.89      0.90      1036\n",
      "           4       0.93      0.91      0.92      1002\n",
      "           5       0.86      0.89      0.88       866\n",
      "           6       0.93      0.93      0.93       957\n",
      "           7       0.92      0.93      0.93      1024\n",
      "           8       0.88      0.89      0.88       959\n",
      "           9       0.90      0.92      0.91       988\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 38: 9193 / 10000\n",
      "Accuracy = 91.93%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93915604 0.96527778 0.91983968 0.88634193 0.90405539 0.89566237\n",
      " 0.934238   0.93320236 0.88716356 0.92433538]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1019\n",
      "           1       0.98      0.97      0.97      1152\n",
      "           2       0.89      0.92      0.90       998\n",
      "           3       0.92      0.89      0.90      1047\n",
      "           4       0.93      0.90      0.92      1011\n",
      "           5       0.86      0.90      0.88       853\n",
      "           6       0.93      0.93      0.93       958\n",
      "           7       0.92      0.93      0.93      1018\n",
      "           8       0.88      0.89      0.88       966\n",
      "           9       0.90      0.92      0.91       978\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 39: 9199 / 10000\n",
      "Accuracy = 91.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9418146  0.96608696 0.92237903 0.88867562 0.91356784 0.89812646\n",
      " 0.9360587  0.92794547 0.87829615 0.92190669]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1014\n",
      "           1       0.98      0.97      0.97      1150\n",
      "           2       0.89      0.92      0.90       992\n",
      "           3       0.92      0.89      0.90      1042\n",
      "           4       0.93      0.91      0.92       995\n",
      "           5       0.86      0.90      0.88       854\n",
      "           6       0.93      0.94      0.93       954\n",
      "           7       0.93      0.93      0.93      1027\n",
      "           8       0.89      0.88      0.88       986\n",
      "           9       0.90      0.92      0.91       986\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 40: 9204 / 10000\n",
      "Accuracy = 92.04%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94094488 0.96283492 0.91674926 0.89621726 0.91474423 0.89964994\n",
      " 0.93625914 0.93682132 0.88717949 0.92206478]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1016\n",
      "           1       0.98      0.96      0.97      1157\n",
      "           2       0.90      0.92      0.91      1009\n",
      "           3       0.91      0.90      0.91      1031\n",
      "           4       0.93      0.91      0.92       997\n",
      "           5       0.86      0.90      0.88       857\n",
      "           6       0.94      0.94      0.94       957\n",
      "           7       0.92      0.94      0.93      1013\n",
      "           8       0.89      0.89      0.89       975\n",
      "           9       0.90      0.92      0.91       988\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 41: 9223 / 10000\n",
      "Accuracy = 92.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93897638 0.96363636 0.92007992 0.8908046  0.91108891 0.89779326\n",
      " 0.93153527 0.93762376 0.89511942 0.92284264]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1016\n",
      "           1       0.98      0.96      0.97      1155\n",
      "           2       0.89      0.92      0.91      1001\n",
      "           3       0.92      0.89      0.91      1044\n",
      "           4       0.93      0.91      0.92      1001\n",
      "           5       0.87      0.90      0.88       861\n",
      "           6       0.94      0.93      0.93       964\n",
      "           7       0.92      0.94      0.93      1010\n",
      "           8       0.89      0.90      0.89       963\n",
      "           9       0.90      0.92      0.91       985\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 42: 9219 / 10000\n",
      "Accuracy = 92.19%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9418146  0.96286701 0.92015968 0.89423077 0.90656064 0.90046838\n",
      " 0.93056995 0.93849206 0.89419087 0.92012133]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1014\n",
      "           1       0.98      0.96      0.97      1158\n",
      "           2       0.89      0.92      0.91      1002\n",
      "           3       0.92      0.89      0.91      1040\n",
      "           4       0.93      0.91      0.92      1006\n",
      "           5       0.86      0.90      0.88       854\n",
      "           6       0.94      0.93      0.93       965\n",
      "           7       0.92      0.94      0.93      1008\n",
      "           8       0.89      0.89      0.89       964\n",
      "           9       0.90      0.92      0.91       989\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 43: 9219 / 10000\n",
      "Accuracy = 92.19%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94019608 0.96444059 0.91749503 0.89922481 0.90954274 0.90198366\n",
      " 0.93541667 0.93768546 0.89197531 0.92573754]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1020\n",
      "           1       0.98      0.96      0.97      1153\n",
      "           2       0.89      0.92      0.91      1006\n",
      "           3       0.92      0.90      0.91      1032\n",
      "           4       0.93      0.91      0.92      1006\n",
      "           5       0.87      0.90      0.88       857\n",
      "           6       0.94      0.94      0.94       960\n",
      "           7       0.92      0.94      0.93      1011\n",
      "           8       0.89      0.89      0.89       972\n",
      "           9       0.90      0.93      0.91       983\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 44: 9233 / 10000\n",
      "Accuracy = 92.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.93835616 0.96605744 0.91932271 0.90262902 0.91308691 0.89552239\n",
      " 0.93528184 0.93235294 0.89197531 0.92930328]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1022\n",
      "           1       0.98      0.97      0.97      1149\n",
      "           2       0.89      0.92      0.91      1004\n",
      "           3       0.92      0.90      0.91      1027\n",
      "           4       0.93      0.91      0.92      1001\n",
      "           5       0.87      0.90      0.88       871\n",
      "           6       0.94      0.94      0.94       958\n",
      "           7       0.93      0.93      0.93      1020\n",
      "           8       0.89      0.89      0.89       972\n",
      "           9       0.90      0.93      0.91       976\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 45: 9234 / 10000\n",
      "Accuracy = 92.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93652344 0.96774194 0.92       0.8976834  0.91243781 0.89734717\n",
      " 0.93444329 0.93339863 0.89337474 0.93216855]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1024\n",
      "           1       0.98      0.97      0.97      1147\n",
      "           2       0.89      0.92      0.91      1000\n",
      "           3       0.92      0.90      0.91      1036\n",
      "           4       0.93      0.91      0.92      1005\n",
      "           5       0.87      0.90      0.88       867\n",
      "           6       0.94      0.93      0.94       961\n",
      "           7       0.93      0.93      0.93      1021\n",
      "           8       0.89      0.89      0.89       966\n",
      "           9       0.90      0.93      0.92       973\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 46: 9235 / 10000\n",
      "Accuracy = 92.35%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9375     0.96286701 0.91956306 0.89825581 0.92121212 0.8956422\n",
      " 0.93920335 0.93774704 0.9        0.92230071]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1024\n",
      "           1       0.98      0.96      0.97      1158\n",
      "           2       0.90      0.92      0.91      1007\n",
      "           3       0.92      0.90      0.91      1032\n",
      "           4       0.93      0.92      0.92       990\n",
      "           5       0.88      0.90      0.89       872\n",
      "           6       0.94      0.94      0.94       954\n",
      "           7       0.92      0.94      0.93      1012\n",
      "           8       0.89      0.90      0.89       960\n",
      "           9       0.91      0.92      0.91       991\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.92      0.92     10000\n",
      "\n",
      "Epoch 47: 9244 / 10000\n",
      "Accuracy = 92.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9410609  0.96363636 0.91848907 0.90615836 0.92762487 0.90277778\n",
      " 0.93167702 0.93261719 0.89609053 0.92633703]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1018\n",
      "           1       0.98      0.96      0.97      1155\n",
      "           2       0.90      0.92      0.91      1006\n",
      "           3       0.92      0.91      0.91      1023\n",
      "           4       0.93      0.93      0.93       981\n",
      "           5       0.87      0.90      0.89       864\n",
      "           6       0.94      0.93      0.94       966\n",
      "           7       0.93      0.93      0.93      1024\n",
      "           8       0.89      0.90      0.90       972\n",
      "           9       0.91      0.93      0.92       991\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 48: 9256 / 10000\n",
      "Accuracy = 92.56%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93829579 0.9644714  0.92292292 0.8976834  0.91317365 0.90184758\n",
      " 0.93625914 0.93948413 0.89333333 0.92769857]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1021\n",
      "           1       0.98      0.96      0.97      1154\n",
      "           2       0.89      0.92      0.91       999\n",
      "           3       0.92      0.90      0.91      1036\n",
      "           4       0.93      0.91      0.92      1002\n",
      "           5       0.88      0.90      0.89       866\n",
      "           6       0.94      0.94      0.94       957\n",
      "           7       0.92      0.94      0.93      1008\n",
      "           8       0.89      0.89      0.89       975\n",
      "           9       0.90      0.93      0.92       982\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.92      0.92     10000\n",
      "\n",
      "Epoch 49: 9244 / 10000\n",
      "Accuracy = 92.44%\n"
     ]
    }
   ],
   "source": [
    "net = network.Network([784, 30, 10])\n",
    "net.SGD(training_data, 50, 10, 0.1, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[      nan       nan       nan 0.1010202 1.              nan       nan\n",
      " 1.              nan       nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       1.00      0.10      0.18      9998\n",
      "           4       0.00      1.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      1.00      0.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.21      0.02     10000\n",
      "weighted avg       1.00      0.10      0.18     10000\n",
      "\n",
      "Epoch 0: 1012 / 10000\n",
      "Accuracy = 10.12%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.42689698 0.77966102 0.22082019 0.31343284 0.64516129 0.35087719\n",
      " 0.58787466 0.65275708 0.39561856 0.54243542]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.43      0.53      1621\n",
      "           1       0.93      0.78      0.85      1357\n",
      "           2       0.07      0.22      0.10       317\n",
      "           3       0.02      0.31      0.04        67\n",
      "           4       0.77      0.65      0.70      1178\n",
      "           5       0.11      0.35      0.17       285\n",
      "           6       0.90      0.59      0.71      1468\n",
      "           7       0.85      0.65      0.74      1342\n",
      "           8       0.63      0.40      0.49      1552\n",
      "           9       0.44      0.54      0.48       813\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     10000\n",
      "   macro avg       0.54      0.49      0.48     10000\n",
      "weighted avg       0.72      0.55      0.61     10000\n",
      "\n",
      "Epoch 1: 5495 / 10000\n",
      "Accuracy = 54.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.746337   0.86359968 0.62641899 0.54320988 0.79393939 0.58928571\n",
      " 0.80869565 0.79103139 0.58745247 0.65559441]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79      1092\n",
      "           1       0.94      0.86      0.90      1239\n",
      "           2       0.59      0.63      0.61       969\n",
      "           3       0.52      0.54      0.53       972\n",
      "           4       0.80      0.79      0.80       990\n",
      "           5       0.26      0.59      0.36       392\n",
      "           6       0.87      0.81      0.84      1035\n",
      "           7       0.86      0.79      0.82      1115\n",
      "           8       0.63      0.59      0.61      1052\n",
      "           9       0.74      0.66      0.70      1144\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.74      0.71      0.72     10000\n",
      "\n",
      "Epoch 2: 7124 / 10000\n",
      "Accuracy = 71.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.79193401 0.91351805 0.76108871 0.69230769 0.82352941 0.70992366\n",
      " 0.83005894 0.84310019 0.66849315 0.78358974]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      1091\n",
      "           1       0.96      0.91      0.94      1191\n",
      "           2       0.73      0.76      0.75       992\n",
      "           3       0.72      0.69      0.71      1053\n",
      "           4       0.84      0.82      0.83      1003\n",
      "           5       0.42      0.71      0.53       524\n",
      "           6       0.88      0.83      0.86      1018\n",
      "           7       0.87      0.84      0.86      1058\n",
      "           8       0.75      0.67      0.71      1095\n",
      "           9       0.76      0.78      0.77       975\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.78      0.78      0.78     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "Epoch 3: 7867 / 10000\n",
      "Accuracy = 78.67%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83207547 0.91583333 0.82135524 0.72710952 0.81091251 0.77635783\n",
      " 0.84872299 0.85824494 0.78555799 0.79879276]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86      1060\n",
      "           1       0.97      0.92      0.94      1200\n",
      "           2       0.78      0.82      0.80       974\n",
      "           3       0.80      0.73      0.76      1114\n",
      "           4       0.88      0.81      0.84      1063\n",
      "           5       0.54      0.78      0.64       626\n",
      "           6       0.90      0.85      0.87      1018\n",
      "           7       0.87      0.86      0.86      1037\n",
      "           8       0.74      0.79      0.76       914\n",
      "           9       0.79      0.80      0.79       994\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.82      0.81     10000\n",
      "weighted avg       0.83      0.82      0.82     10000\n",
      "\n",
      "Epoch 4: 8205 / 10000\n",
      "Accuracy = 82.05%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86788814 0.92217573 0.824      0.80116959 0.85129741 0.79511533\n",
      " 0.85380117 0.87920792 0.80570222 0.80490196]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89      1037\n",
      "           1       0.97      0.92      0.95      1195\n",
      "           2       0.80      0.82      0.81      1000\n",
      "           3       0.81      0.80      0.81      1026\n",
      "           4       0.87      0.85      0.86      1002\n",
      "           5       0.66      0.80      0.72       737\n",
      "           6       0.91      0.85      0.88      1026\n",
      "           7       0.86      0.88      0.87      1010\n",
      "           8       0.78      0.81      0.79       947\n",
      "           9       0.81      0.80      0.81      1020\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.85      0.84      0.85     10000\n",
      "\n",
      "Epoch 5: 8435 / 10000\n",
      "Accuracy = 84.35%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88161694 0.94092466 0.8389662  0.82837302 0.85058594 0.82707775\n",
      " 0.87025948 0.88252715 0.7952048  0.82779456]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91      1039\n",
      "           1       0.97      0.94      0.95      1168\n",
      "           2       0.82      0.84      0.83      1006\n",
      "           3       0.83      0.83      0.83      1008\n",
      "           4       0.89      0.85      0.87      1024\n",
      "           5       0.69      0.83      0.75       746\n",
      "           6       0.91      0.87      0.89      1002\n",
      "           7       0.87      0.88      0.88      1013\n",
      "           8       0.82      0.80      0.81      1001\n",
      "           9       0.81      0.83      0.82       993\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Epoch 6: 8566 / 10000\n",
      "Accuracy = 85.66%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87664783 0.94682676 0.83204633 0.85626283 0.85463415 0.81905911\n",
      " 0.8927477  0.88408644 0.83263158 0.85744017]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      1062\n",
      "           1       0.97      0.95      0.96      1166\n",
      "           2       0.84      0.83      0.83      1036\n",
      "           3       0.83      0.86      0.84       974\n",
      "           4       0.89      0.85      0.87      1025\n",
      "           5       0.76      0.82      0.79       829\n",
      "           6       0.91      0.89      0.90       979\n",
      "           7       0.88      0.88      0.88      1018\n",
      "           8       0.81      0.83      0.82       950\n",
      "           9       0.82      0.86      0.84       961\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.87      0.86     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "Epoch 7: 8675 / 10000\n",
      "Accuracy = 86.75%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88124411 0.94696322 0.84901961 0.84984985 0.87775551 0.82696897\n",
      " 0.9015544  0.90834192 0.82969886 0.84350394]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92      1061\n",
      "           1       0.98      0.95      0.96      1169\n",
      "           2       0.84      0.85      0.84      1020\n",
      "           3       0.84      0.85      0.85       999\n",
      "           4       0.89      0.88      0.88       998\n",
      "           5       0.78      0.83      0.80       838\n",
      "           6       0.91      0.90      0.90       965\n",
      "           7       0.86      0.91      0.88       971\n",
      "           8       0.82      0.83      0.82       963\n",
      "           9       0.85      0.84      0.85      1016\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "Epoch 8: 8734 / 10000\n",
      "Accuracy = 87.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.88541667 0.95423143 0.86039604 0.83641675 0.86017358 0.84289277\n",
      " 0.90143737 0.89515331 0.8329918  0.88514226]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      1056\n",
      "           1       0.97      0.95      0.96      1158\n",
      "           2       0.84      0.86      0.85      1010\n",
      "           3       0.85      0.84      0.84      1027\n",
      "           4       0.91      0.86      0.88      1037\n",
      "           5       0.76      0.84      0.80       802\n",
      "           6       0.92      0.90      0.91       974\n",
      "           7       0.88      0.90      0.89      1011\n",
      "           8       0.83      0.83      0.83       976\n",
      "           9       0.83      0.89      0.86       949\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.88      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "Epoch 9: 8772 / 10000\n",
      "Accuracy = 87.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89443378 0.95833333 0.87537688 0.84926108 0.8729064  0.83729216\n",
      " 0.89655172 0.90761421 0.83198381 0.87244898]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      1042\n",
      "           1       0.97      0.96      0.97      1152\n",
      "           2       0.84      0.88      0.86       995\n",
      "           3       0.85      0.85      0.85      1015\n",
      "           4       0.90      0.87      0.89      1015\n",
      "           5       0.79      0.84      0.81       842\n",
      "           6       0.92      0.90      0.91       986\n",
      "           7       0.87      0.91      0.89       985\n",
      "           8       0.84      0.83      0.84       988\n",
      "           9       0.85      0.87      0.86       980\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "Epoch 10: 8815 / 10000\n",
      "Accuracy = 88.15%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89398281 0.95761246 0.87887888 0.85685885 0.85578748 0.85207824\n",
      " 0.9004065  0.88781431 0.83484391 0.90539054]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      1047\n",
      "           1       0.98      0.96      0.97      1156\n",
      "           2       0.85      0.88      0.86       999\n",
      "           3       0.85      0.86      0.86      1006\n",
      "           4       0.92      0.86      0.89      1054\n",
      "           5       0.78      0.85      0.82       818\n",
      "           6       0.92      0.90      0.91       984\n",
      "           7       0.89      0.89      0.89      1034\n",
      "           8       0.85      0.83      0.84       993\n",
      "           9       0.82      0.91      0.86       909\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 11: 8838 / 10000\n",
      "Accuracy = 88.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90019194 0.96254355 0.88787879 0.85940594 0.88125613 0.85114046\n",
      " 0.91170431 0.89083821 0.82741617 0.89830508]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1042\n",
      "           1       0.97      0.96      0.97      1148\n",
      "           2       0.85      0.89      0.87       990\n",
      "           3       0.86      0.86      0.86      1010\n",
      "           4       0.91      0.88      0.90      1019\n",
      "           5       0.79      0.85      0.82       833\n",
      "           6       0.93      0.91      0.92       974\n",
      "           7       0.89      0.89      0.89      1026\n",
      "           8       0.86      0.83      0.84      1014\n",
      "           9       0.84      0.90      0.87       944\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 12: 8886 / 10000\n",
      "Accuracy = 88.86%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89932886 0.96512642 0.88568588 0.86593843 0.87669903 0.85053381\n",
      " 0.91104294 0.90019763 0.84670051 0.89778714]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1043\n",
      "           1       0.98      0.97      0.97      1147\n",
      "           2       0.86      0.89      0.87      1006\n",
      "           3       0.86      0.87      0.86      1007\n",
      "           4       0.92      0.88      0.90      1030\n",
      "           5       0.80      0.85      0.83       843\n",
      "           6       0.93      0.91      0.92       978\n",
      "           7       0.89      0.90      0.89      1012\n",
      "           8       0.86      0.85      0.85       985\n",
      "           9       0.84      0.90      0.87       949\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 13: 8916 / 10000\n",
      "Accuracy = 89.16%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.901341   0.95934256 0.89156627 0.87077535 0.88287402 0.85697259\n",
      " 0.91675231 0.90665343 0.84011917 0.89748954]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1044\n",
      "           1       0.98      0.96      0.97      1156\n",
      "           2       0.86      0.89      0.88       996\n",
      "           3       0.87      0.87      0.87      1006\n",
      "           4       0.91      0.88      0.90      1016\n",
      "           5       0.81      0.86      0.83       839\n",
      "           6       0.93      0.92      0.92       973\n",
      "           7       0.89      0.91      0.90      1007\n",
      "           8       0.87      0.84      0.85      1007\n",
      "           9       0.85      0.90      0.87       956\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 14: 8939 / 10000\n",
      "Accuracy = 89.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90288462 0.9643168  0.89787664 0.87227723 0.88746298 0.84830805\n",
      " 0.91242363 0.89157793 0.85524975 0.90274841]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1040\n",
      "           1       0.98      0.96      0.97      1149\n",
      "           2       0.86      0.90      0.88       989\n",
      "           3       0.87      0.87      0.87      1010\n",
      "           4       0.92      0.89      0.90      1013\n",
      "           5       0.82      0.85      0.83       857\n",
      "           6       0.94      0.91      0.92       982\n",
      "           7       0.90      0.89      0.89      1033\n",
      "           8       0.86      0.86      0.86       981\n",
      "           9       0.85      0.90      0.87       946\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 15: 8952 / 10000\n",
      "Accuracy = 89.52%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90201729 0.96521739 0.89374379 0.87824351 0.89108911 0.85850178\n",
      " 0.91446029 0.89157793 0.86238532 0.90346275]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1041\n",
      "           1       0.98      0.97      0.97      1150\n",
      "           2       0.87      0.89      0.88      1007\n",
      "           3       0.87      0.88      0.87      1002\n",
      "           4       0.92      0.89      0.90      1010\n",
      "           5       0.81      0.86      0.83       841\n",
      "           6       0.94      0.91      0.93       982\n",
      "           7       0.90      0.89      0.89      1033\n",
      "           8       0.87      0.86      0.87       981\n",
      "           9       0.85      0.90      0.88       953\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 16: 8977 / 10000\n",
      "Accuracy = 89.77%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90864917 0.97192982 0.89141165 0.88449848 0.89151874 0.86255924\n",
      " 0.91158537 0.91191191 0.849      0.8959596 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      1029\n",
      "           1       0.98      0.97      0.97      1140\n",
      "           2       0.88      0.89      0.88      1013\n",
      "           3       0.86      0.88      0.87       987\n",
      "           4       0.92      0.89      0.91      1014\n",
      "           5       0.82      0.86      0.84       844\n",
      "           6       0.94      0.91      0.92       984\n",
      "           7       0.89      0.91      0.90       999\n",
      "           8       0.87      0.85      0.86      1000\n",
      "           9       0.88      0.90      0.89       990\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 17: 8995 / 10000\n",
      "Accuracy = 89.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.90229885 0.9668701  0.90606061 0.88059701 0.89572989 0.875\n",
      " 0.91437309 0.91170635 0.85214785 0.89847716]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1044\n",
      "           1       0.98      0.97      0.97      1147\n",
      "           2       0.87      0.91      0.89       990\n",
      "           3       0.88      0.88      0.88      1005\n",
      "           4       0.92      0.90      0.91      1007\n",
      "           5       0.82      0.88      0.84       832\n",
      "           6       0.94      0.91      0.93       981\n",
      "           7       0.89      0.91      0.90      1008\n",
      "           8       0.88      0.85      0.86      1001\n",
      "           9       0.88      0.90      0.89       985\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 18: 9017 / 10000\n",
      "Accuracy = 90.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91788856 0.96855895 0.9009901  0.8875502  0.901      0.87350835\n",
      " 0.90981964 0.90855457 0.86377397 0.90020367]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1023\n",
      "           1       0.98      0.97      0.97      1145\n",
      "           2       0.88      0.90      0.89      1010\n",
      "           3       0.88      0.89      0.88       996\n",
      "           4       0.92      0.90      0.91      1000\n",
      "           5       0.82      0.87      0.85       838\n",
      "           6       0.95      0.91      0.93       998\n",
      "           7       0.90      0.91      0.90      1017\n",
      "           8       0.88      0.86      0.87       991\n",
      "           9       0.88      0.90      0.89       982\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.91     10000\n",
      "\n",
      "Epoch 19: 9047 / 10000\n",
      "Accuracy = 90.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92164545 0.96858639 0.90566038 0.88       0.89812067 0.89408867\n",
      " 0.91046278 0.90909091 0.86686687 0.90647482]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1021\n",
      "           1       0.98      0.97      0.97      1146\n",
      "           2       0.88      0.91      0.89      1007\n",
      "           3       0.89      0.88      0.89      1025\n",
      "           4       0.92      0.90      0.91      1011\n",
      "           5       0.81      0.89      0.85       812\n",
      "           6       0.94      0.91      0.93       994\n",
      "           7       0.89      0.91      0.90      1012\n",
      "           8       0.89      0.87      0.88       999\n",
      "           9       0.87      0.91      0.89       973\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 20: 9072 / 10000\n",
      "Accuracy = 90.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91128255 0.97027972 0.91028226 0.88246817 0.90277778 0.88969697\n",
      " 0.9185336  0.9077527  0.86519115 0.90490798]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      1037\n",
      "           1       0.98      0.97      0.97      1144\n",
      "           2       0.88      0.91      0.89       992\n",
      "           3       0.89      0.88      0.89      1021\n",
      "           4       0.93      0.90      0.91      1008\n",
      "           5       0.82      0.89      0.85       825\n",
      "           6       0.94      0.92      0.93       982\n",
      "           7       0.90      0.91      0.90      1019\n",
      "           8       0.88      0.87      0.87       994\n",
      "           9       0.88      0.90      0.89       978\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 21: 9075 / 10000\n",
      "Accuracy = 90.75%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92443572 0.9720035  0.91356784 0.87741313 0.91238671 0.87990488\n",
      " 0.91348089 0.90606654 0.87679671 0.90539166]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1019\n",
      "           1       0.98      0.97      0.98      1143\n",
      "           2       0.88      0.91      0.90       995\n",
      "           3       0.90      0.88      0.89      1036\n",
      "           4       0.92      0.91      0.92       993\n",
      "           5       0.83      0.88      0.85       841\n",
      "           6       0.95      0.91      0.93       994\n",
      "           7       0.90      0.91      0.90      1022\n",
      "           8       0.88      0.88      0.88       974\n",
      "           9       0.88      0.91      0.89       983\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 22: 9095 / 10000\n",
      "Accuracy = 90.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92007797 0.97030568 0.91356784 0.88910891 0.91675127 0.87470726\n",
      " 0.91708797 0.90980392 0.87769784 0.89730808]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1026\n",
      "           1       0.98      0.97      0.97      1145\n",
      "           2       0.88      0.91      0.90       995\n",
      "           3       0.89      0.89      0.89      1010\n",
      "           4       0.92      0.92      0.92       985\n",
      "           5       0.84      0.87      0.86       854\n",
      "           6       0.95      0.92      0.93       989\n",
      "           7       0.90      0.91      0.91      1020\n",
      "           8       0.88      0.88      0.88       973\n",
      "           9       0.89      0.90      0.89      1003\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 23: 9101 / 10000\n",
      "Accuracy = 91.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9192607  0.97287839 0.915      0.88286544 0.90287413 0.89346247\n",
      " 0.92065107 0.91386139 0.88319672 0.90524194]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1028\n",
      "           1       0.98      0.97      0.98      1143\n",
      "           2       0.89      0.92      0.90      1000\n",
      "           3       0.90      0.88      0.89      1033\n",
      "           4       0.93      0.90      0.92      1009\n",
      "           5       0.83      0.89      0.86       826\n",
      "           6       0.94      0.92      0.93       983\n",
      "           7       0.90      0.91      0.91      1010\n",
      "           8       0.89      0.88      0.88       976\n",
      "           9       0.89      0.91      0.90       992\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 24: 9121 / 10000\n",
      "Accuracy = 91.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92906404 0.9720035  0.92588832 0.88115942 0.90128332 0.8969697\n",
      " 0.91117764 0.91347099 0.87362086 0.9142562 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1015\n",
      "           1       0.98      0.97      0.98      1143\n",
      "           2       0.88      0.93      0.90       985\n",
      "           3       0.90      0.88      0.89      1035\n",
      "           4       0.93      0.90      0.92      1013\n",
      "           5       0.83      0.90      0.86       825\n",
      "           6       0.95      0.91      0.93      1002\n",
      "           7       0.90      0.91      0.91      1017\n",
      "           8       0.89      0.87      0.88       997\n",
      "           9       0.88      0.91      0.90       968\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 25: 9129 / 10000\n",
      "Accuracy = 91.29%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92367906 0.97285464 0.919      0.88965517 0.91540785 0.88507109\n",
      " 0.92097264 0.91113281 0.88121827 0.90789474]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1022\n",
      "           1       0.98      0.97      0.98      1142\n",
      "           2       0.89      0.92      0.90      1000\n",
      "           3       0.89      0.89      0.89      1015\n",
      "           4       0.93      0.92      0.92       993\n",
      "           5       0.84      0.89      0.86       844\n",
      "           6       0.95      0.92      0.93       987\n",
      "           7       0.91      0.91      0.91      1024\n",
      "           8       0.89      0.88      0.89       985\n",
      "           9       0.89      0.91      0.90       988\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 26: 9140 / 10000\n",
      "Accuracy = 91.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.92563601 0.97370727 0.91741294 0.89239882 0.90737052 0.88995215\n",
      " 0.91911021 0.91210938 0.87261785 0.91640867]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1022\n",
      "           1       0.98      0.97      0.98      1141\n",
      "           2       0.89      0.92      0.91      1005\n",
      "           3       0.90      0.89      0.89      1013\n",
      "           4       0.93      0.91      0.92      1004\n",
      "           5       0.83      0.89      0.86       836\n",
      "           6       0.95      0.92      0.93       989\n",
      "           7       0.91      0.91      0.91      1024\n",
      "           8       0.89      0.87      0.88       997\n",
      "           9       0.88      0.92      0.90       969\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 27: 9139 / 10000\n",
      "Accuracy = 91.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91868345 0.97460595 0.92284569 0.90149254 0.9126506  0.89963724\n",
      " 0.91733871 0.91980198 0.87261785 0.902     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1033\n",
      "           1       0.98      0.97      0.98      1142\n",
      "           2       0.89      0.92      0.91       998\n",
      "           3       0.90      0.90      0.90      1005\n",
      "           4       0.93      0.91      0.92       996\n",
      "           5       0.83      0.90      0.87       827\n",
      "           6       0.95      0.92      0.93       992\n",
      "           7       0.90      0.92      0.91      1010\n",
      "           8       0.89      0.87      0.88       997\n",
      "           9       0.89      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 28: 9153 / 10000\n",
      "Accuracy = 91.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91618497 0.97292576 0.92562814 0.882805   0.9244898  0.90763547\n",
      " 0.92638037 0.91889219 0.87943262 0.89832182]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1038\n",
      "           1       0.98      0.97      0.98      1145\n",
      "           2       0.89      0.93      0.91       995\n",
      "           3       0.91      0.88      0.90      1041\n",
      "           4       0.92      0.92      0.92       980\n",
      "           5       0.83      0.91      0.87       812\n",
      "           6       0.95      0.93      0.94       978\n",
      "           7       0.90      0.92      0.91      1011\n",
      "           8       0.89      0.88      0.89       987\n",
      "           9       0.90      0.90      0.90      1013\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.91      0.92      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 29: 9161 / 10000\n",
      "Accuracy = 91.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91876209 0.97462817 0.9248497  0.89665354 0.92622951 0.90255786\n",
      " 0.92456677 0.91772772 0.87263682 0.90248756]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1034\n",
      "           1       0.98      0.97      0.98      1143\n",
      "           2       0.89      0.92      0.91       998\n",
      "           3       0.90      0.90      0.90      1016\n",
      "           4       0.92      0.93      0.92       976\n",
      "           5       0.83      0.90      0.87       821\n",
      "           6       0.95      0.92      0.94       981\n",
      "           7       0.91      0.92      0.91      1021\n",
      "           8       0.90      0.87      0.89      1005\n",
      "           9       0.90      0.90      0.90      1005\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 30: 9171 / 10000\n",
      "Accuracy = 91.71%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92405063 0.97889182 0.92102665 0.89083821 0.911      0.90400972\n",
      " 0.92020202 0.92011834 0.8825332  0.90514632]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95      1027\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.90      0.92      0.91      1013\n",
      "           3       0.90      0.89      0.90      1026\n",
      "           4       0.93      0.91      0.92      1000\n",
      "           5       0.83      0.90      0.87       823\n",
      "           6       0.95      0.92      0.94       990\n",
      "           7       0.91      0.92      0.91      1014\n",
      "           8       0.89      0.88      0.88       979\n",
      "           9       0.89      0.91      0.90       991\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 31: 9169 / 10000\n",
      "Accuracy = 91.69%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92961877 0.97805092 0.9246779  0.8974359  0.91317365 0.90424242\n",
      " 0.92299899 0.92300099 0.87103175 0.9122449 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1023\n",
      "           1       0.98      0.98      0.98      1139\n",
      "           2       0.90      0.92      0.91      1009\n",
      "           3       0.90      0.90      0.90      1014\n",
      "           4       0.93      0.91      0.92      1002\n",
      "           5       0.84      0.90      0.87       825\n",
      "           6       0.95      0.92      0.94       987\n",
      "           7       0.91      0.92      0.92      1013\n",
      "           8       0.90      0.87      0.89      1008\n",
      "           9       0.89      0.91      0.90       980\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 32: 9187 / 10000\n",
      "Accuracy = 91.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93405512 0.97891037 0.93       0.89422135 0.90746269 0.90689238\n",
      " 0.91927346 0.9265144  0.8776329  0.90480962]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1016\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.90      0.93      0.92      1000\n",
      "           3       0.90      0.89      0.90      1021\n",
      "           4       0.93      0.91      0.92      1005\n",
      "           5       0.84      0.91      0.87       827\n",
      "           6       0.95      0.92      0.93       991\n",
      "           7       0.91      0.93      0.92      1007\n",
      "           8       0.90      0.88      0.89       997\n",
      "           9       0.89      0.90      0.90       998\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 33: 9190 / 10000\n",
      "Accuracy = 91.90%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93320236 0.97548161 0.93286573 0.89160156 0.92182741 0.91119221\n",
      " 0.91935484 0.92907093 0.87215064 0.89990089]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1018\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.90      0.93      0.92       998\n",
      "           3       0.90      0.89      0.90      1024\n",
      "           4       0.92      0.92      0.92       985\n",
      "           5       0.84      0.91      0.87       822\n",
      "           6       0.95      0.92      0.94       992\n",
      "           7       0.90      0.93      0.92      1001\n",
      "           8       0.90      0.87      0.89      1009\n",
      "           9       0.90      0.90      0.90      1009\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 34: 9195 / 10000\n",
      "Accuracy = 91.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93150685 0.97889182 0.93048659 0.90727817 0.91408591 0.89473684\n",
      " 0.93142272 0.92436149 0.88064193 0.91047813]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1022\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.91      0.93      0.92      1007\n",
      "           3       0.90      0.91      0.90      1003\n",
      "           4       0.93      0.91      0.92      1001\n",
      "           5       0.86      0.89      0.88       855\n",
      "           6       0.95      0.93      0.94       977\n",
      "           7       0.92      0.92      0.92      1018\n",
      "           8       0.90      0.88      0.89       997\n",
      "           9       0.89      0.91      0.90       983\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 35: 9216 / 10000\n",
      "Accuracy = 92.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.93608653 0.97889182 0.9332004  0.8973607  0.91591592 0.91105769\n",
      " 0.92959184 0.92668622 0.87875752 0.91093117]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1017\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.91      0.93      0.92      1003\n",
      "           3       0.91      0.90      0.90      1023\n",
      "           4       0.93      0.92      0.92       999\n",
      "           5       0.85      0.91      0.88       832\n",
      "           6       0.95      0.93      0.94       980\n",
      "           7       0.92      0.93      0.92      1023\n",
      "           8       0.90      0.88      0.89       998\n",
      "           9       0.89      0.91      0.90       988\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 36: 9228 / 10000\n",
      "Accuracy = 92.28%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92794547 0.97889182 0.93460765 0.9        0.9112426  0.91435464\n",
      " 0.93244626 0.91980676 0.87537388 0.92116183]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1027\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.90      0.93      0.92       994\n",
      "           3       0.91      0.90      0.90      1020\n",
      "           4       0.94      0.91      0.93      1014\n",
      "           5       0.85      0.91      0.88       829\n",
      "           6       0.95      0.93      0.94       977\n",
      "           7       0.93      0.92      0.92      1035\n",
      "           8       0.90      0.88      0.89      1003\n",
      "           9       0.88      0.92      0.90       964\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 37: 9224 / 10000\n",
      "Accuracy = 92.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93339863 0.97885463 0.935      0.89417476 0.92502533 0.91116447\n",
      " 0.92966361 0.92906404 0.87549801 0.9084507 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1021\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.91      0.94      0.92      1000\n",
      "           3       0.91      0.89      0.90      1030\n",
      "           4       0.93      0.93      0.93       987\n",
      "           5       0.85      0.91      0.88       833\n",
      "           6       0.95      0.93      0.94       981\n",
      "           7       0.92      0.93      0.92      1015\n",
      "           8       0.90      0.88      0.89      1004\n",
      "           9       0.89      0.91      0.90       994\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 38: 9229 / 10000\n",
      "Accuracy = 92.29%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93523062 0.97807018 0.93353175 0.89648438 0.91783567 0.90307329\n",
      " 0.92777213 0.92487805 0.8927477  0.91615542]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1019\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.91      0.93      0.92      1008\n",
      "           3       0.91      0.90      0.90      1024\n",
      "           4       0.93      0.92      0.93       998\n",
      "           5       0.86      0.90      0.88       846\n",
      "           6       0.95      0.93      0.94       983\n",
      "           7       0.92      0.92      0.92      1025\n",
      "           8       0.90      0.89      0.90       979\n",
      "           9       0.89      0.92      0.90       978\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 39: 9237 / 10000\n",
      "Accuracy = 92.37%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92718447 0.97635727 0.93247269 0.88825215 0.92588832 0.91452991\n",
      " 0.92966361 0.92807882 0.89722508 0.9030969 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1030\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.91      0.93      0.92      1007\n",
      "           3       0.92      0.89      0.90      1047\n",
      "           4       0.93      0.93      0.93       985\n",
      "           5       0.84      0.91      0.88       819\n",
      "           6       0.95      0.93      0.94       981\n",
      "           7       0.92      0.93      0.92      1015\n",
      "           8       0.90      0.90      0.90       973\n",
      "           9       0.90      0.90      0.90      1001\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 40: 9231 / 10000\n",
      "Accuracy = 92.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93614931 0.97803163 0.93806194 0.90205681 0.9287169  0.90736342\n",
      " 0.92517695 0.92061955 0.8910387  0.90643863]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1018\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.91      0.94      0.92      1001\n",
      "           3       0.91      0.90      0.91      1021\n",
      "           4       0.93      0.93      0.93       982\n",
      "           5       0.86      0.91      0.88       842\n",
      "           6       0.96      0.93      0.94       989\n",
      "           7       0.93      0.92      0.92      1033\n",
      "           8       0.90      0.89      0.89       982\n",
      "           9       0.89      0.91      0.90       994\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.92      0.92     10000\n",
      "\n",
      "Epoch 41: 9244 / 10000\n",
      "Accuracy = 92.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9297561  0.97633655 0.93768844 0.90801187 0.92690355 0.90510083\n",
      " 0.93435897 0.92412451 0.88276553 0.9019019 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1025\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.90      0.94      0.92       995\n",
      "           3       0.91      0.91      0.91      1011\n",
      "           4       0.93      0.93      0.93       985\n",
      "           5       0.86      0.91      0.88       843\n",
      "           6       0.95      0.93      0.94       975\n",
      "           7       0.92      0.92      0.92      1028\n",
      "           8       0.90      0.88      0.89       998\n",
      "           9       0.89      0.90      0.90       999\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 42: 9237 / 10000\n",
      "Accuracy = 92.37%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93523062 0.97889182 0.93806194 0.90891089 0.91434263 0.91807229\n",
      " 0.92886179 0.92864125 0.87860697 0.9118541 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1019\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.91      0.94      0.92      1001\n",
      "           3       0.91      0.91      0.91      1010\n",
      "           4       0.93      0.91      0.92      1004\n",
      "           5       0.85      0.92      0.89       830\n",
      "           6       0.95      0.93      0.94       984\n",
      "           7       0.92      0.93      0.93      1023\n",
      "           8       0.91      0.88      0.89      1005\n",
      "           9       0.89      0.91      0.90       987\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 43: 9250 / 10000\n",
      "Accuracy = 92.50%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92628516 0.97721297 0.93267327 0.90649606 0.92253521 0.90930788\n",
      " 0.93346981 0.92509728 0.88376754 0.91933816]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1031\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.91      0.93      0.92      1010\n",
      "           3       0.91      0.91      0.91      1016\n",
      "           4       0.93      0.92      0.93       994\n",
      "           5       0.85      0.91      0.88       838\n",
      "           6       0.95      0.93      0.94       977\n",
      "           7       0.93      0.93      0.93      1028\n",
      "           8       0.91      0.88      0.89       998\n",
      "           9       0.88      0.92      0.90       967\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.92      0.92     10000\n",
      "\n",
      "Epoch 44: 9246 / 10000\n",
      "Accuracy = 92.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.93811395 0.97635727 0.92822026 0.90039062 0.92712551 0.91676719\n",
      " 0.9318413  0.92585366 0.88709677 0.91446029]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1018\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.91      0.93      0.92      1017\n",
      "           3       0.91      0.90      0.91      1024\n",
      "           4       0.93      0.93      0.93       988\n",
      "           5       0.85      0.92      0.88       829\n",
      "           6       0.96      0.93      0.94       983\n",
      "           7       0.92      0.93      0.92      1025\n",
      "           8       0.90      0.89      0.90       992\n",
      "           9       0.89      0.91      0.90       982\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 45: 9255 / 10000\n",
      "Accuracy = 92.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92891918 0.97721297 0.93893894 0.90631164 0.92611336 0.91486811\n",
      " 0.93009119 0.9296875  0.88654618 0.91313131]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1027\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.91      0.94      0.92       999\n",
      "           3       0.91      0.91      0.91      1014\n",
      "           4       0.93      0.93      0.93       988\n",
      "           5       0.86      0.91      0.88       834\n",
      "           6       0.96      0.93      0.94       987\n",
      "           7       0.93      0.93      0.93      1024\n",
      "           8       0.91      0.89      0.90       996\n",
      "           9       0.90      0.91      0.90       990\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.92      0.93      0.92     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 46: 9261 / 10000\n",
      "Accuracy = 92.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93339863 0.97552448 0.93366337 0.90215264 0.91975928 0.92048193\n",
      " 0.93442623 0.93824701 0.87833828 0.91472081]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1021\n",
      "           1       0.98      0.98      0.98      1144\n",
      "           2       0.91      0.93      0.92      1010\n",
      "           3       0.91      0.90      0.91      1022\n",
      "           4       0.93      0.92      0.93       997\n",
      "           5       0.86      0.92      0.89       830\n",
      "           6       0.95      0.93      0.94       976\n",
      "           7       0.92      0.94      0.93      1004\n",
      "           8       0.91      0.88      0.89      1011\n",
      "           9       0.89      0.91      0.90       985\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.92      0.93      0.92     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 47: 9258 / 10000\n",
      "Accuracy = 92.58%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92718447 0.97635727 0.9445005  0.89845261 0.92973523 0.92317073\n",
      " 0.93103448 0.9320197  0.88743719 0.90447761]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1030\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.91      0.94      0.93       991\n",
      "           3       0.92      0.90      0.91      1034\n",
      "           4       0.93      0.93      0.93       982\n",
      "           5       0.85      0.92      0.88       820\n",
      "           6       0.96      0.93      0.94       986\n",
      "           7       0.92      0.93      0.93      1015\n",
      "           8       0.91      0.89      0.90       995\n",
      "           9       0.90      0.90      0.90      1005\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.92      0.93      0.92     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 48: 9261 / 10000\n",
      "Accuracy = 92.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9308666  0.97719298 0.93103448 0.90392157 0.92719919 0.92457421\n",
      " 0.93265306 0.93235294 0.88159204 0.91751527]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1027\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.92      0.93      0.92      1015\n",
      "           3       0.91      0.90      0.91      1020\n",
      "           4       0.93      0.93      0.93       989\n",
      "           5       0.85      0.92      0.89       822\n",
      "           6       0.95      0.93      0.94       980\n",
      "           7       0.93      0.93      0.93      1020\n",
      "           8       0.91      0.88      0.90      1005\n",
      "           9       0.89      0.92      0.91       982\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 49: 9266 / 10000\n",
      "Accuracy = 92.66%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9236715  0.97721297 0.92822026 0.90569745 0.92547835 0.91898428\n",
      " 0.93367347 0.93326791 0.89012097 0.92126789]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1035\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.91      0.93      0.92      1017\n",
      "           3       0.91      0.91      0.91      1018\n",
      "           4       0.94      0.93      0.93       993\n",
      "           5       0.85      0.92      0.88       827\n",
      "           6       0.96      0.93      0.94       980\n",
      "           7       0.93      0.93      0.93      1019\n",
      "           8       0.91      0.89      0.90       992\n",
      "           9       0.89      0.92      0.91       978\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 50: 9266 / 10000\n",
      "Accuracy = 92.66%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93177388 0.9763986  0.93195266 0.89932236 0.92369478 0.92466586\n",
      " 0.93110436 0.93510324 0.89484328 0.92173018]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1026\n",
      "           1       0.98      0.98      0.98      1144\n",
      "           2       0.92      0.93      0.92      1014\n",
      "           3       0.92      0.90      0.91      1033\n",
      "           4       0.94      0.92      0.93       996\n",
      "           5       0.85      0.92      0.89       823\n",
      "           6       0.96      0.93      0.94       987\n",
      "           7       0.93      0.94      0.93      1017\n",
      "           8       0.91      0.89      0.90       989\n",
      "           9       0.89      0.92      0.90       971\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 51: 9278 / 10000\n",
      "Accuracy = 92.78%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93268293 0.97637795 0.93818544 0.90155945 0.92821031 0.92279855\n",
      " 0.93387589 0.93589744 0.88977956 0.91515152]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1025\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.91      0.94      0.92      1003\n",
      "           3       0.92      0.90      0.91      1026\n",
      "           4       0.93      0.93      0.93       989\n",
      "           5       0.86      0.92      0.89       829\n",
      "           6       0.96      0.93      0.95       983\n",
      "           7       0.92      0.94      0.93      1014\n",
      "           8       0.91      0.89      0.90       998\n",
      "           9       0.90      0.92      0.91       990\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 52: 9282 / 10000\n",
      "Accuracy = 92.82%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93255132 0.9763986  0.93818544 0.90569745 0.93660532 0.92067308\n",
      " 0.92922144 0.93564356 0.89346734 0.9077381 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1023\n",
      "           1       0.98      0.98      0.98      1144\n",
      "           2       0.91      0.94      0.92      1003\n",
      "           3       0.91      0.91      0.91      1018\n",
      "           4       0.93      0.94      0.93       978\n",
      "           5       0.86      0.92      0.89       832\n",
      "           6       0.96      0.93      0.94       989\n",
      "           7       0.92      0.94      0.93      1010\n",
      "           8       0.91      0.89      0.90       995\n",
      "           9       0.91      0.91      0.91      1008\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 53: 9284 / 10000\n",
      "Accuracy = 92.84%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.93093385 0.97721297 0.93385982 0.90588235 0.93023256 0.92168675\n",
      " 0.93577982 0.93510324 0.89056225 0.91979695]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1028\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.92      0.93      0.93      1013\n",
      "           3       0.91      0.91      0.91      1020\n",
      "           4       0.94      0.93      0.93       989\n",
      "           5       0.86      0.92      0.89       830\n",
      "           6       0.96      0.94      0.95       981\n",
      "           7       0.93      0.94      0.93      1017\n",
      "           8       0.91      0.89      0.90       996\n",
      "           9       0.90      0.92      0.91       985\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 54: 9289 / 10000\n",
      "Accuracy = 92.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9334638  0.97554585 0.93452381 0.90606654 0.93394309 0.921875\n",
      " 0.93110436 0.93516699 0.89415323 0.91818182]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1022\n",
      "           1       0.98      0.98      0.98      1145\n",
      "           2       0.91      0.93      0.92      1008\n",
      "           3       0.92      0.91      0.91      1022\n",
      "           4       0.94      0.93      0.93       984\n",
      "           5       0.86      0.92      0.89       832\n",
      "           6       0.96      0.93      0.94       987\n",
      "           7       0.93      0.94      0.93      1018\n",
      "           8       0.91      0.89      0.90       992\n",
      "           9       0.90      0.92      0.91       990\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 55: 9292 / 10000\n",
      "Accuracy = 92.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93444227 0.97807018 0.93718843 0.89788054 0.93319838 0.92606061\n",
      " 0.93299492 0.93596059 0.88733799 0.92150866]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1022\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.91      0.94      0.92      1003\n",
      "           3       0.92      0.90      0.91      1038\n",
      "           4       0.94      0.93      0.94       988\n",
      "           5       0.86      0.93      0.89       825\n",
      "           6       0.96      0.93      0.95       985\n",
      "           7       0.92      0.94      0.93      1015\n",
      "           8       0.91      0.89      0.90      1003\n",
      "           9       0.90      0.92      0.91       981\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 56: 9291 / 10000\n",
      "Accuracy = 92.91%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93535749 0.97807018 0.93657086 0.9038835  0.93319838 0.92615012\n",
      " 0.93394309 0.93248532 0.88811189 0.92339122]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1021\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.92      0.94      0.93      1009\n",
      "           3       0.92      0.90      0.91      1030\n",
      "           4       0.94      0.93      0.94       988\n",
      "           5       0.86      0.93      0.89       826\n",
      "           6       0.96      0.93      0.95       984\n",
      "           7       0.93      0.93      0.93      1022\n",
      "           8       0.91      0.89      0.90      1001\n",
      "           9       0.90      0.92      0.91       979\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 57: 9298 / 10000\n",
      "Accuracy = 92.98%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93719333 0.9780894  0.93039216 0.89595376 0.93577982 0.92086331\n",
      " 0.93469388 0.93143976 0.8982706  0.91963377]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1019\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.92      0.93      0.92      1020\n",
      "           3       0.92      0.90      0.91      1038\n",
      "           4       0.93      0.94      0.94       981\n",
      "           5       0.86      0.92      0.89       834\n",
      "           6       0.96      0.93      0.95       980\n",
      "           7       0.93      0.93      0.93      1021\n",
      "           8       0.91      0.90      0.90       983\n",
      "           9       0.90      0.92      0.91       983\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 58: 9290 / 10000\n",
      "Accuracy = 92.90%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93437806 0.97807018 0.9296875  0.90625    0.92864322 0.92298436\n",
      " 0.93299492 0.93516699 0.89606458 0.92790937]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1021\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.92      0.93      0.93      1024\n",
      "           3       0.92      0.91      0.91      1024\n",
      "           4       0.94      0.93      0.93       995\n",
      "           5       0.86      0.92      0.89       831\n",
      "           6       0.96      0.93      0.95       985\n",
      "           7       0.93      0.94      0.93      1018\n",
      "           8       0.91      0.90      0.90       991\n",
      "           9       0.89      0.93      0.91       971\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 59: 9300 / 10000\n",
      "Accuracy = 93.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9334638  0.97725284 0.93669634 0.90448343 0.92871486 0.91411765\n",
      " 0.93387589 0.93608653 0.90843621 0.92244898]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1022\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.92      0.94      0.93      1011\n",
      "           3       0.92      0.90      0.91      1026\n",
      "           4       0.94      0.93      0.94       996\n",
      "           5       0.87      0.91      0.89       850\n",
      "           6       0.96      0.93      0.95       983\n",
      "           7       0.93      0.94      0.93      1017\n",
      "           8       0.91      0.91      0.91       972\n",
      "           9       0.90      0.92      0.91       980\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 60: 9305 / 10000\n",
      "Accuracy = 93.05%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93529412 0.97723292 0.93385982 0.90757129 0.93401015 0.92326139\n",
      " 0.93292683 0.94053518 0.89167503 0.91691692]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1020\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.92      0.93      0.93      1013\n",
      "           3       0.91      0.91      0.91      1017\n",
      "           4       0.94      0.93      0.94       985\n",
      "           5       0.86      0.92      0.89       834\n",
      "           6       0.96      0.93      0.95       984\n",
      "           7       0.92      0.94      0.93      1009\n",
      "           8       0.91      0.89      0.90       997\n",
      "           9       0.91      0.92      0.91       999\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 61: 9301 / 10000\n",
      "Accuracy = 93.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93990148 0.97723292 0.93669634 0.90855457 0.93414387 0.9222488\n",
      " 0.93394309 0.93589744 0.88392857 0.92089249]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1015\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.92      0.94      0.93      1011\n",
      "           3       0.91      0.91      0.91      1017\n",
      "           4       0.94      0.93      0.94       987\n",
      "           5       0.86      0.92      0.89       836\n",
      "           6       0.96      0.93      0.95       984\n",
      "           7       0.92      0.94      0.93      1014\n",
      "           8       0.91      0.88      0.90      1008\n",
      "           9       0.90      0.92      0.91       986\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 62: 9301 / 10000\n",
      "Accuracy = 93.01%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.9372549  0.97725284 0.93222004 0.89750958 0.93414387 0.92753623\n",
      " 0.93756397 0.92912621 0.89868288 0.92857143]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1020\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.92      0.93      0.93      1018\n",
      "           3       0.93      0.90      0.91      1044\n",
      "           4       0.94      0.93      0.94       987\n",
      "           5       0.86      0.93      0.89       828\n",
      "           6       0.96      0.94      0.95       977\n",
      "           7       0.93      0.93      0.93      1030\n",
      "           8       0.91      0.90      0.90       987\n",
      "           9       0.89      0.93      0.91       966\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 63: 9306 / 10000\n",
      "Accuracy = 93.06%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93093385 0.97727273 0.93596059 0.90144928 0.93232323 0.93057247\n",
      " 0.93577982 0.93281402 0.90253807 0.92915811]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1028\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.94      0.93      1015\n",
      "           3       0.92      0.90      0.91      1035\n",
      "           4       0.94      0.93      0.94       990\n",
      "           5       0.86      0.93      0.89       821\n",
      "           6       0.96      0.94      0.95       981\n",
      "           7       0.93      0.93      0.93      1027\n",
      "           8       0.91      0.90      0.91       985\n",
      "           9       0.90      0.93      0.91       974\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 64: 9315 / 10000\n",
      "Accuracy = 93.15%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93274854 0.97898424 0.93170732 0.9079334  0.92522433 0.92133492\n",
      " 0.93954918 0.9416996  0.90417941 0.92820513]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1026\n",
      "           1       0.99      0.98      0.98      1142\n",
      "           2       0.93      0.93      0.93      1025\n",
      "           3       0.92      0.91      0.91      1021\n",
      "           4       0.95      0.93      0.94      1003\n",
      "           5       0.87      0.92      0.89       839\n",
      "           6       0.96      0.94      0.95       976\n",
      "           7       0.93      0.94      0.93      1012\n",
      "           8       0.91      0.90      0.91       981\n",
      "           9       0.90      0.93      0.91       975\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 65: 9320 / 10000\n",
      "Accuracy = 93.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94549058 0.97812773 0.93936382 0.89741131 0.93232323 0.92762364\n",
      " 0.9319797  0.93627451 0.89717742 0.92573754]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1009\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.92      0.94      0.93      1006\n",
      "           3       0.93      0.90      0.91      1043\n",
      "           4       0.94      0.93      0.94       990\n",
      "           5       0.86      0.93      0.89       829\n",
      "           6       0.96      0.93      0.94       985\n",
      "           7       0.93      0.94      0.93      1020\n",
      "           8       0.91      0.90      0.91       992\n",
      "           9       0.90      0.93      0.91       983\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 66: 9318 / 10000\n",
      "Accuracy = 93.18%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9408284  0.97727273 0.93960396 0.90406977 0.93597561 0.92601432\n",
      " 0.93380855 0.93793103 0.89378758 0.92472024]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1014\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.94      0.93      1010\n",
      "           3       0.92      0.90      0.91      1032\n",
      "           4       0.94      0.94      0.94       984\n",
      "           5       0.87      0.93      0.90       838\n",
      "           6       0.96      0.93      0.95       982\n",
      "           7       0.93      0.94      0.93      1015\n",
      "           8       0.92      0.89      0.90       998\n",
      "           9       0.90      0.92      0.91       983\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 67: 9321 / 10000\n",
      "Accuracy = 93.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94100295 0.9780894  0.9395441  0.90241546 0.93245968 0.92565947\n",
      " 0.94045175 0.93450635 0.88679245 0.92975207]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1017\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.92      0.94      0.93      1009\n",
      "           3       0.92      0.90      0.91      1035\n",
      "           4       0.94      0.93      0.94       992\n",
      "           5       0.87      0.93      0.89       834\n",
      "           6       0.96      0.94      0.95       974\n",
      "           7       0.93      0.93      0.93      1023\n",
      "           8       0.92      0.89      0.90      1007\n",
      "           9       0.89      0.93      0.91       968\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 68: 9317 / 10000\n",
      "Accuracy = 93.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94175716 0.97812773 0.94117647 0.90600775 0.92011834 0.92491061\n",
      " 0.93591048 0.9308666  0.89537223 0.93592437]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1013\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.91      0.94      0.93      1003\n",
      "           3       0.93      0.91      0.92      1032\n",
      "           4       0.95      0.92      0.93      1014\n",
      "           5       0.87      0.92      0.90       839\n",
      "           6       0.96      0.94      0.95       983\n",
      "           7       0.93      0.93      0.93      1027\n",
      "           8       0.91      0.90      0.90       994\n",
      "           9       0.88      0.94      0.91       952\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 69: 9317 / 10000\n",
      "Accuracy = 93.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9408284  0.97814685 0.94053518 0.90086622 0.93502538 0.92583732\n",
      " 0.93306288 0.93811395 0.89959432 0.92573754]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1014\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.94      0.93      1009\n",
      "           3       0.93      0.90      0.91      1039\n",
      "           4       0.94      0.94      0.94       985\n",
      "           5       0.87      0.93      0.90       836\n",
      "           6       0.96      0.93      0.95       986\n",
      "           7       0.93      0.94      0.93      1018\n",
      "           8       0.91      0.90      0.91       986\n",
      "           9       0.90      0.93      0.91       983\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 70: 9325 / 10000\n",
      "Accuracy = 93.25%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93469786 0.97558849 0.94405594 0.90652386 0.93979592 0.92925659\n",
      " 0.93319838 0.93457031 0.89267803 0.92827869]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1026\n",
      "           1       0.99      0.98      0.98      1147\n",
      "           2       0.92      0.94      0.93      1001\n",
      "           3       0.92      0.91      0.91      1027\n",
      "           4       0.94      0.94      0.94       980\n",
      "           5       0.87      0.93      0.90       834\n",
      "           6       0.96      0.93      0.95       988\n",
      "           7       0.93      0.93      0.93      1024\n",
      "           8       0.91      0.89      0.90       997\n",
      "           9       0.90      0.93      0.91       976\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 71: 9325 / 10000\n",
      "Accuracy = 93.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.93990148 0.97473868 0.94223108 0.90241546 0.92592593 0.93037215\n",
      " 0.93131313 0.93190661 0.8969697  0.93632568]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1015\n",
      "           1       0.99      0.97      0.98      1148\n",
      "           2       0.92      0.94      0.93      1004\n",
      "           3       0.92      0.90      0.91      1035\n",
      "           4       0.94      0.93      0.93       999\n",
      "           5       0.87      0.93      0.90       833\n",
      "           6       0.96      0.93      0.95       990\n",
      "           7       0.93      0.93      0.93      1028\n",
      "           8       0.91      0.90      0.90       990\n",
      "           9       0.89      0.94      0.91       958\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 72: 9318 / 10000\n",
      "Accuracy = 93.18%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94296952 0.97812773 0.946      0.89846743 0.93896236 0.93470375\n",
      " 0.93414387 0.93190661 0.89043825 0.9327818 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1017\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.92      0.95      0.93      1000\n",
      "           3       0.93      0.90      0.91      1044\n",
      "           4       0.94      0.94      0.94       983\n",
      "           5       0.87      0.93      0.90       827\n",
      "           6       0.96      0.93      0.95       987\n",
      "           7       0.93      0.93      0.93      1028\n",
      "           8       0.92      0.89      0.90      1004\n",
      "           9       0.89      0.93      0.91       967\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 73: 9333 / 10000\n",
      "Accuracy = 93.33%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94001967 0.97898424 0.93793103 0.90416263 0.93245968 0.92583732\n",
      " 0.93476045 0.93885602 0.90345528 0.92393509]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1017\n",
      "           1       0.99      0.98      0.98      1142\n",
      "           2       0.92      0.94      0.93      1015\n",
      "           3       0.92      0.90      0.91      1033\n",
      "           4       0.94      0.93      0.94       992\n",
      "           5       0.87      0.93      0.90       836\n",
      "           6       0.96      0.93      0.95       981\n",
      "           7       0.93      0.94      0.93      1014\n",
      "           8       0.91      0.90      0.91       984\n",
      "           9       0.90      0.92      0.91       986\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 74: 9328 / 10000\n",
      "Accuracy = 93.28%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94013739 0.97892888 0.94246032 0.90279115 0.93421053 0.93140794\n",
      " 0.93781855 0.93639922 0.89132602 0.93195876]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1019\n",
      "           1       0.98      0.98      0.98      1139\n",
      "           2       0.92      0.94      0.93      1008\n",
      "           3       0.93      0.90      0.92      1039\n",
      "           4       0.94      0.93      0.94       988\n",
      "           5       0.87      0.93      0.90       831\n",
      "           6       0.96      0.94      0.95       981\n",
      "           7       0.93      0.94      0.93      1022\n",
      "           8       0.92      0.89      0.90      1003\n",
      "           9       0.90      0.93      0.91       970\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 75: 9333 / 10000\n",
      "Accuracy = 93.33%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94187192 0.97641921 0.93694581 0.90962672 0.93985729 0.93157263\n",
      " 0.93502538 0.9372549  0.89009901 0.92944785]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1015\n",
      "           1       0.99      0.98      0.98      1145\n",
      "           2       0.92      0.94      0.93      1015\n",
      "           3       0.92      0.91      0.91      1018\n",
      "           4       0.94      0.94      0.94       981\n",
      "           5       0.87      0.93      0.90       833\n",
      "           6       0.96      0.94      0.95       985\n",
      "           7       0.93      0.94      0.93      1020\n",
      "           8       0.92      0.89      0.91      1010\n",
      "           9       0.90      0.93      0.91       978\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 76: 9334 / 10000\n",
      "Accuracy = 93.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94094488 0.97814685 0.94047619 0.90749757 0.93259557 0.92517815\n",
      " 0.93597561 0.93984221 0.89919355 0.92645557]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1016\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.94      0.93      1008\n",
      "           3       0.92      0.91      0.92      1027\n",
      "           4       0.94      0.93      0.94       994\n",
      "           5       0.87      0.93      0.90       842\n",
      "           6       0.96      0.94      0.95       984\n",
      "           7       0.93      0.94      0.93      1014\n",
      "           8       0.92      0.90      0.91       992\n",
      "           9       0.90      0.93      0.91       979\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 77: 9334 / 10000\n",
      "Accuracy = 93.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93915604 0.97812773 0.94223108 0.90679612 0.93807107 0.93173653\n",
      " 0.93407708 0.93731636 0.894      0.9283521 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1019\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.92      0.94      0.93      1004\n",
      "           3       0.92      0.91      0.92      1030\n",
      "           4       0.94      0.94      0.94       985\n",
      "           5       0.87      0.93      0.90       835\n",
      "           6       0.96      0.93      0.95       986\n",
      "           7       0.93      0.94      0.93      1021\n",
      "           8       0.92      0.89      0.91      1000\n",
      "           9       0.90      0.93      0.91       977\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 78: 9336 / 10000\n",
      "Accuracy = 93.36%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94466403 0.97812773 0.93713163 0.90163934 0.93724696 0.93045564\n",
      " 0.93794507 0.93793103 0.90010091 0.92441267]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1012\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.92      0.94      0.93      1018\n",
      "           3       0.93      0.90      0.91      1037\n",
      "           4       0.94      0.94      0.94       988\n",
      "           5       0.87      0.93      0.90       834\n",
      "           6       0.96      0.94      0.95       983\n",
      "           7       0.93      0.94      0.93      1015\n",
      "           8       0.92      0.90      0.91       991\n",
      "           9       0.90      0.92      0.91       979\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 79: 9336 / 10000\n",
      "Accuracy = 93.36%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94373149 0.97810858 0.94059406 0.90494665 0.93724696 0.93181818\n",
      " 0.93692777 0.93891626 0.89919355 0.92222222]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1013\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.92      0.94      0.93      1010\n",
      "           3       0.92      0.90      0.91      1031\n",
      "           4       0.94      0.94      0.94       988\n",
      "           5       0.87      0.93      0.90       836\n",
      "           6       0.96      0.94      0.95       983\n",
      "           7       0.93      0.94      0.93      1015\n",
      "           8       0.92      0.90      0.91       992\n",
      "           9       0.90      0.92      0.91       990\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 80: 9340 / 10000\n",
      "Accuracy = 93.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94280079 0.97814685 0.94071146 0.90241546 0.93340061 0.93181818\n",
      " 0.93604061 0.93731636 0.90374873 0.93025641]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1014\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.94      0.93      1012\n",
      "           3       0.92      0.90      0.91      1035\n",
      "           4       0.94      0.93      0.94       991\n",
      "           5       0.87      0.93      0.90       836\n",
      "           6       0.96      0.94      0.95       985\n",
      "           7       0.93      0.94      0.93      1021\n",
      "           8       0.92      0.90      0.91       987\n",
      "           9       0.90      0.93      0.91       975\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.93      0.93     10000\n",
      "\n",
      "Epoch 81: 9343 / 10000\n",
      "Accuracy = 93.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94378698 0.97814685 0.94035785 0.90416263 0.93447581 0.93622142\n",
      " 0.93788187 0.93978282 0.8961039  0.92581301]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1014\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.94      0.93      1006\n",
      "           3       0.92      0.90      0.91      1033\n",
      "           4       0.94      0.93      0.94       992\n",
      "           5       0.87      0.94      0.90       831\n",
      "           6       0.96      0.94      0.95       982\n",
      "           7       0.93      0.94      0.93      1013\n",
      "           8       0.92      0.90      0.91      1001\n",
      "           9       0.90      0.93      0.91       984\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 82: 9342 / 10000\n",
      "Accuracy = 93.42%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94198623 0.97731239 0.93891626 0.9015444  0.93447581 0.93381468\n",
      " 0.9389002  0.93811395 0.90211907 0.93106996]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1017\n",
      "           1       0.99      0.98      0.98      1146\n",
      "           2       0.92      0.94      0.93      1015\n",
      "           3       0.92      0.90      0.91      1036\n",
      "           4       0.94      0.93      0.94       992\n",
      "           5       0.87      0.93      0.90       831\n",
      "           6       0.96      0.94      0.95       982\n",
      "           7       0.93      0.94      0.93      1018\n",
      "           8       0.92      0.90      0.91       991\n",
      "           9       0.90      0.93      0.91       972\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.93      0.93     10000\n",
      "\n",
      "Epoch 83: 9344 / 10000\n",
      "Accuracy = 93.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94198623 0.97902098 0.93713163 0.90494665 0.93360161 0.92984542\n",
      " 0.93985729 0.93633692 0.90825688 0.93004115]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1017\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.94      0.93      1018\n",
      "           3       0.92      0.90      0.91      1031\n",
      "           4       0.95      0.93      0.94       994\n",
      "           5       0.88      0.93      0.90       841\n",
      "           6       0.96      0.94      0.95       981\n",
      "           7       0.93      0.94      0.93      1021\n",
      "           8       0.91      0.91      0.91       981\n",
      "           9       0.90      0.93      0.91       972\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.93      0.93     10000\n",
      "\n",
      "Epoch 84: 9348 / 10000\n",
      "Accuracy = 93.48%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94285714 0.97725284 0.94146825 0.90545809 0.92828685 0.92280702\n",
      " 0.93985729 0.93646139 0.90273556 0.93632568]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1015\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.92      0.94      0.93      1008\n",
      "           3       0.92      0.91      0.91      1026\n",
      "           4       0.95      0.93      0.94      1004\n",
      "           5       0.88      0.92      0.90       855\n",
      "           6       0.96      0.94      0.95       981\n",
      "           7       0.93      0.94      0.93      1023\n",
      "           8       0.91      0.90      0.91       987\n",
      "           9       0.89      0.94      0.91       958\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 85: 9341 / 10000\n",
      "Accuracy = 93.41%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9410609  0.97816594 0.93879566 0.89951691 0.93636364 0.93001186\n",
      " 0.93985729 0.93450635 0.91143151 0.9266055 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1018\n",
      "           1       0.99      0.98      0.98      1145\n",
      "           2       0.92      0.94      0.93      1013\n",
      "           3       0.92      0.90      0.91      1035\n",
      "           4       0.94      0.94      0.94       990\n",
      "           5       0.88      0.93      0.90       843\n",
      "           6       0.96      0.94      0.95       981\n",
      "           7       0.93      0.93      0.93      1023\n",
      "           8       0.91      0.91      0.91       971\n",
      "           9       0.90      0.93      0.91       981\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 86: 9343 / 10000\n",
      "Accuracy = 93.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94565217 0.97731239 0.94071146 0.90067502 0.93541877 0.93206198\n",
      " 0.93794507 0.93731636 0.90780142 0.93312757]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1012\n",
      "           1       0.99      0.98      0.98      1146\n",
      "           2       0.92      0.94      0.93      1012\n",
      "           3       0.92      0.90      0.91      1037\n",
      "           4       0.94      0.94      0.94       991\n",
      "           5       0.88      0.93      0.90       839\n",
      "           6       0.96      0.94      0.95       983\n",
      "           7       0.93      0.94      0.93      1021\n",
      "           8       0.92      0.91      0.91       987\n",
      "           9       0.90      0.93      0.92       972\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 87: 9354 / 10000\n",
      "Accuracy = 93.54%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94285714 0.97812773 0.93811395 0.90319458 0.93883792 0.9352518\n",
      " 0.93781855 0.94274432 0.90110999 0.92230071]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1015\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.93      0.94      0.93      1018\n",
      "           3       0.92      0.90      0.91      1033\n",
      "           4       0.94      0.94      0.94       981\n",
      "           5       0.87      0.94      0.90       834\n",
      "           6       0.96      0.94      0.95       981\n",
      "           7       0.93      0.94      0.94      1013\n",
      "           8       0.92      0.90      0.91       991\n",
      "           9       0.91      0.92      0.91       991\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.93      0.93     10000\n",
      "\n",
      "Epoch 88: 9346 / 10000\n",
      "Accuracy = 93.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94285714 0.97900262 0.9416996  0.89483748 0.93086172 0.93309438\n",
      " 0.93711968 0.92850242 0.91358025 0.93828452]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1015\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.92      0.94      0.93      1012\n",
      "           3       0.93      0.89      0.91      1046\n",
      "           4       0.95      0.93      0.94       998\n",
      "           5       0.88      0.93      0.90       837\n",
      "           6       0.96      0.94      0.95       986\n",
      "           7       0.93      0.93      0.93      1035\n",
      "           8       0.91      0.91      0.91       972\n",
      "           9       0.89      0.94      0.91       956\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.93      0.93     10000\n",
      "\n",
      "Epoch 89: 9345 / 10000\n",
      "Accuracy = 93.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94204322 0.97729258 0.9408284  0.89903846 0.94117647 0.9375\n",
      " 0.9389002  0.93835616 0.90241449 0.9369183 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1018\n",
      "           1       0.99      0.98      0.98      1145\n",
      "           2       0.92      0.94      0.93      1014\n",
      "           3       0.93      0.90      0.91      1040\n",
      "           4       0.95      0.94      0.94       986\n",
      "           5       0.87      0.94      0.90       832\n",
      "           6       0.96      0.94      0.95       982\n",
      "           7       0.93      0.94      0.94      1022\n",
      "           8       0.92      0.90      0.91       994\n",
      "           9       0.90      0.94      0.92       967\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.94      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 90: 9359 / 10000\n",
      "Accuracy = 93.59%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94664032 0.97731239 0.93793103 0.89549377 0.93914807 0.94082126\n",
      " 0.93794507 0.94455446 0.90596562 0.92712551]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1012\n",
      "           1       0.99      0.98      0.98      1146\n",
      "           2       0.92      0.94      0.93      1015\n",
      "           3       0.92      0.90      0.91      1043\n",
      "           4       0.94      0.94      0.94       986\n",
      "           5       0.87      0.94      0.91       828\n",
      "           6       0.96      0.94      0.95       983\n",
      "           7       0.93      0.94      0.94      1010\n",
      "           8       0.92      0.91      0.91       989\n",
      "           9       0.91      0.93      0.92       988\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.94      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 91: 9357 / 10000\n",
      "Accuracy = 93.57%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94757666 0.97729258 0.93990148 0.89788054 0.93920973 0.93444577\n",
      " 0.93807107 0.93385214 0.9040404  0.93555094]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1011\n",
      "           1       0.99      0.98      0.98      1145\n",
      "           2       0.92      0.94      0.93      1015\n",
      "           3       0.92      0.90      0.91      1038\n",
      "           4       0.94      0.94      0.94       987\n",
      "           5       0.88      0.93      0.91       839\n",
      "           6       0.96      0.94      0.95       985\n",
      "           7       0.93      0.93      0.93      1028\n",
      "           8       0.92      0.90      0.91       990\n",
      "           9       0.89      0.94      0.91       962\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 92: 9353 / 10000\n",
      "Accuracy = 93.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94762846 0.97814685 0.94538232 0.89741131 0.93467337 0.93127962\n",
      " 0.93807107 0.93823529 0.90456853 0.9357513 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1012\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.95      0.93      1007\n",
      "           3       0.93      0.90      0.91      1043\n",
      "           4       0.95      0.93      0.94       995\n",
      "           5       0.88      0.93      0.91       844\n",
      "           6       0.96      0.94      0.95       985\n",
      "           7       0.93      0.94      0.93      1020\n",
      "           8       0.91      0.90      0.91       985\n",
      "           9       0.89      0.94      0.91       965\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.94      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 93: 9357 / 10000\n",
      "Accuracy = 93.57%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9410609  0.97816594 0.94455446 0.89721422 0.93724696 0.93325387\n",
      " 0.93718338 0.93646139 0.91095189 0.93106996]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1018\n",
      "           1       0.99      0.98      0.98      1145\n",
      "           2       0.92      0.94      0.93      1010\n",
      "           3       0.92      0.90      0.91      1041\n",
      "           4       0.94      0.94      0.94       988\n",
      "           5       0.88      0.93      0.90       839\n",
      "           6       0.97      0.94      0.95       987\n",
      "           7       0.93      0.94      0.93      1023\n",
      "           8       0.91      0.91      0.91       977\n",
      "           9       0.90      0.93      0.91       972\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 94: 9353 / 10000\n",
      "Accuracy = 93.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94389764 0.97814685 0.94274432 0.89463602 0.93629929 0.9354067\n",
      " 0.93991853 0.93737769 0.90678825 0.93174767]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1016\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.93      0.94      0.93      1013\n",
      "           3       0.92      0.89      0.91      1044\n",
      "           4       0.94      0.94      0.94       989\n",
      "           5       0.88      0.94      0.91       836\n",
      "           6       0.96      0.94      0.95       982\n",
      "           7       0.93      0.94      0.93      1022\n",
      "           8       0.92      0.91      0.91       987\n",
      "           9       0.89      0.93      0.91       967\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 95: 9352 / 10000\n",
      "Accuracy = 93.52%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94940476 0.97731239 0.93817468 0.89951691 0.94010152 0.92941176\n",
      " 0.93991853 0.93915604 0.91215526 0.93039918]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1008\n",
      "           1       0.99      0.98      0.98      1146\n",
      "           2       0.93      0.94      0.93      1019\n",
      "           3       0.92      0.90      0.91      1035\n",
      "           4       0.94      0.94      0.94       985\n",
      "           5       0.89      0.93      0.91       850\n",
      "           6       0.96      0.94      0.95       982\n",
      "           7       0.93      0.94      0.94      1019\n",
      "           8       0.92      0.91      0.91       979\n",
      "           9       0.90      0.93      0.92       977\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 96: 9362 / 10000\n",
      "Accuracy = 93.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94757666 0.97812773 0.94001967 0.89539347 0.93580742 0.93034238\n",
      " 0.94081633 0.93829579 0.90927625 0.93756504]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1011\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.93      0.94      0.93      1017\n",
      "           3       0.92      0.90      0.91      1042\n",
      "           4       0.95      0.94      0.94       997\n",
      "           5       0.88      0.93      0.91       847\n",
      "           6       0.96      0.94      0.95       980\n",
      "           7       0.93      0.94      0.94      1021\n",
      "           8       0.92      0.91      0.91       981\n",
      "           9       0.89      0.94      0.91       961\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.94      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 97: 9359 / 10000\n",
      "Accuracy = 93.59%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94565217 0.97900262 0.93823529 0.89539347 0.93473896 0.93413174\n",
      " 0.93724696 0.93921569 0.9137577  0.93505155]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1012\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.93      0.94      0.93      1020\n",
      "           3       0.92      0.90      0.91      1042\n",
      "           4       0.95      0.93      0.94       996\n",
      "           5       0.87      0.93      0.90       835\n",
      "           6       0.97      0.94      0.95       988\n",
      "           7       0.93      0.94      0.94      1020\n",
      "           8       0.91      0.91      0.91       974\n",
      "           9       0.90      0.94      0.92       970\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.94      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 98: 9358 / 10000\n",
      "Accuracy = 93.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94940476 0.97812773 0.9410609  0.89788054 0.93567839 0.93017751\n",
      " 0.94093686 0.93829579 0.90780142 0.93665628]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1008\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.93      0.94      0.93      1018\n",
      "           3       0.92      0.90      0.91      1038\n",
      "           4       0.95      0.94      0.94       995\n",
      "           5       0.88      0.93      0.91       845\n",
      "           6       0.96      0.94      0.95       982\n",
      "           7       0.93      0.94      0.94      1021\n",
      "           8       0.92      0.91      0.91       987\n",
      "           9       0.89      0.94      0.91       963\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 99: 9362 / 10000\n",
      "Accuracy = 93.62%\n"
     ]
    }
   ],
   "source": [
    "net = network.Network([784, 30, 10])\n",
    "net.SGD(training_data, 100, 10, 0.1, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tem-se o resultado de que um aumento no número de épocas resulta em uma melhora na acurácia total do modelo, visto que quantas mais épocas melhor o modelo ajusta seus parâmetros, que chegou a 93.26% em sua última época."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, varia-se o número da taxa de aprendizagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.7122571  0.87747036        nan 0.56170483 0.65992509 0.11111111\n",
      " 0.75238095 0.7710944  0.60416667 0.76195122]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82      1338\n",
      "           1       0.98      0.88      0.93      1265\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.87      0.56      0.68      1572\n",
      "           4       0.90      0.66      0.76      1335\n",
      "           5       0.00      0.11      0.00         9\n",
      "           6       0.91      0.75      0.82      1155\n",
      "           7       0.90      0.77      0.83      1197\n",
      "           8       0.68      0.60      0.64      1104\n",
      "           9       0.77      0.76      0.77      1025\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.70      0.58      0.63     10000\n",
      "weighted avg       0.88      0.71      0.78     10000\n",
      "\n",
      "Epoch 0: 7068 / 10000\n",
      "Accuracy = 70.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.77841374 0.91178895 0.         0.55835381 0.7918512  0.1686747\n",
      " 0.75523889 0.88090551 0.586657   0.76740088]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.86      1223\n",
      "           1       0.97      0.91      0.94      1213\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.90      0.56      0.69      1628\n",
      "           4       0.91      0.79      0.85      1129\n",
      "           5       0.02      0.17      0.03        83\n",
      "           6       0.94      0.76      0.84      1193\n",
      "           7       0.87      0.88      0.88      1016\n",
      "           8       0.83      0.59      0.69      1379\n",
      "           9       0.86      0.77      0.81      1135\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.73      0.62      0.66     10000\n",
      "weighted avg       0.90      0.74      0.80     10000\n",
      "\n",
      "Epoch 1: 7351 / 10000\n",
      "Accuracy = 73.51%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89755639 0.95094664 0.87311828 0.89662447 0.88811881 0.8226601\n",
      " 0.90593047 0.89463415 0.78074357 0.8590998 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1064\n",
      "           1       0.97      0.95      0.96      1162\n",
      "           2       0.79      0.87      0.83       930\n",
      "           3       0.84      0.90      0.87       948\n",
      "           4       0.91      0.89      0.90      1010\n",
      "           5       0.75      0.82      0.78       812\n",
      "           6       0.92      0.91      0.92       978\n",
      "           7       0.89      0.89      0.89      1025\n",
      "           8       0.84      0.78      0.81      1049\n",
      "           9       0.87      0.86      0.86      1022\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "Epoch 2: 8787 / 10000\n",
      "Accuracy = 87.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9185257  0.96344648 0.90010299 0.89049587 0.86591124 0.82300885\n",
      " 0.90293225 0.88836329 0.86495177 0.90841321]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1031\n",
      "           1       0.98      0.96      0.97      1149\n",
      "           2       0.85      0.90      0.87       971\n",
      "           3       0.85      0.89      0.87       968\n",
      "           4       0.93      0.87      0.90      1059\n",
      "           5       0.83      0.82      0.83       904\n",
      "           6       0.93      0.90      0.92       989\n",
      "           7       0.91      0.89      0.90      1057\n",
      "           8       0.83      0.86      0.85       933\n",
      "           9       0.85      0.91      0.88       939\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 3: 8943 / 10000\n",
      "Accuracy = 89.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91779497 0.96855895 0.90789474 0.89559877 0.92592593 0.86285714\n",
      " 0.90854271 0.89760766 0.86974359 0.89839034]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1034\n",
      "           1       0.98      0.97      0.97      1145\n",
      "           2       0.87      0.91      0.89       988\n",
      "           3       0.87      0.90      0.88       977\n",
      "           4       0.92      0.93      0.92       972\n",
      "           5       0.85      0.86      0.85       875\n",
      "           6       0.94      0.91      0.93       995\n",
      "           7       0.91      0.90      0.90      1045\n",
      "           8       0.87      0.87      0.87       975\n",
      "           9       0.89      0.90      0.89       994\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 4: 9068 / 10000\n",
      "Accuracy = 90.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9345887  0.96354167 0.90551181 0.86509434 0.91356784 0.90060606\n",
      " 0.91304348 0.92269574 0.88241415 0.90650407]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1009\n",
      "           1       0.98      0.96      0.97      1152\n",
      "           2       0.89      0.91      0.90      1016\n",
      "           3       0.91      0.87      0.89      1060\n",
      "           4       0.93      0.91      0.92       995\n",
      "           5       0.83      0.90      0.87       825\n",
      "           6       0.94      0.91      0.93       989\n",
      "           7       0.91      0.92      0.91      1009\n",
      "           8       0.87      0.88      0.88       961\n",
      "           9       0.88      0.91      0.90       984\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 5: 9116 / 10000\n",
      "Accuracy = 91.16%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93663366 0.96935201 0.92346425 0.87345385 0.90999011 0.90510083\n",
      " 0.9126506  0.89413989 0.89412998 0.92675159]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1010\n",
      "           1       0.98      0.97      0.97      1142\n",
      "           2       0.89      0.92      0.91       993\n",
      "           3       0.91      0.87      0.89      1051\n",
      "           4       0.94      0.91      0.92      1011\n",
      "           5       0.86      0.91      0.88       843\n",
      "           6       0.95      0.91      0.93       996\n",
      "           7       0.92      0.89      0.91      1058\n",
      "           8       0.88      0.89      0.88       954\n",
      "           9       0.87      0.93      0.89       942\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 6: 9152 / 10000\n",
      "Accuracy = 91.52%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92675781 0.97621145 0.92047714 0.90009891 0.92378049 0.89516129\n",
      " 0.90656064 0.93154762 0.89781022 0.90790791]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1024\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.90      0.92      0.91      1006\n",
      "           3       0.90      0.90      0.90      1011\n",
      "           4       0.93      0.92      0.92       984\n",
      "           5       0.87      0.90      0.88       868\n",
      "           6       0.95      0.91      0.93      1006\n",
      "           7       0.91      0.93      0.92      1008\n",
      "           8       0.88      0.90      0.89       959\n",
      "           9       0.90      0.91      0.90       999\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 7: 9198 / 10000\n",
      "Accuracy = 91.98%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92871094 0.96774194 0.92131474 0.88888889 0.90116279 0.91856287\n",
      " 0.9412382  0.92534381 0.89693878 0.92283951]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1024\n",
      "           1       0.98      0.97      0.97      1147\n",
      "           2       0.90      0.92      0.91      1004\n",
      "           3       0.91      0.89      0.90      1035\n",
      "           4       0.95      0.90      0.92      1032\n",
      "           5       0.86      0.92      0.89       835\n",
      "           6       0.94      0.94      0.94       953\n",
      "           7       0.92      0.93      0.92      1018\n",
      "           8       0.90      0.90      0.90       980\n",
      "           9       0.89      0.92      0.91       972\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 8: 9218 / 10000\n",
      "Accuracy = 92.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.92961877 0.97283085 0.91921182 0.91208791 0.92439516 0.93285372\n",
      " 0.92323232 0.91283525 0.89361702 0.92805755]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1023\n",
      "           1       0.98      0.97      0.98      1141\n",
      "           2       0.90      0.92      0.91      1015\n",
      "           3       0.90      0.91      0.91      1001\n",
      "           4       0.93      0.92      0.93       992\n",
      "           5       0.87      0.93      0.90       834\n",
      "           6       0.95      0.92      0.94       990\n",
      "           7       0.93      0.91      0.92      1044\n",
      "           8       0.91      0.89      0.90       987\n",
      "           9       0.89      0.93      0.91       973\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 9: 9254 / 10000\n",
      "Accuracy = 92.54%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9396637  0.97195443 0.92559524 0.91035857 0.93353783 0.92705882\n",
      " 0.92842536 0.92135922 0.88789683 0.9203629 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1011\n",
      "           1       0.98      0.97      0.97      1141\n",
      "           2       0.90      0.93      0.91      1008\n",
      "           3       0.90      0.91      0.91      1004\n",
      "           4       0.93      0.93      0.93       978\n",
      "           5       0.88      0.93      0.90       850\n",
      "           6       0.95      0.93      0.94       978\n",
      "           7       0.92      0.92      0.92      1030\n",
      "           8       0.92      0.89      0.90      1008\n",
      "           9       0.90      0.92      0.91       992\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 10: 9272 / 10000\n",
      "Accuracy = 92.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92878049 0.97449428 0.94564103 0.90936255 0.92115768 0.90628571\n",
      " 0.93237705 0.91803279 0.89067202 0.92901235]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1025\n",
      "           1       0.98      0.97      0.98      1137\n",
      "           2       0.89      0.95      0.92       975\n",
      "           3       0.90      0.91      0.91      1004\n",
      "           4       0.94      0.92      0.93      1002\n",
      "           5       0.89      0.91      0.90       875\n",
      "           6       0.95      0.93      0.94       976\n",
      "           7       0.93      0.92      0.92      1037\n",
      "           8       0.91      0.89      0.90       997\n",
      "           9       0.89      0.93      0.91       972\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 11: 9264 / 10000\n",
      "Accuracy = 92.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93437806 0.9753304  0.92475248 0.90818363 0.92964824 0.89444444\n",
      " 0.94731296 0.9294809  0.90172239 0.93163265]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1021\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.91      0.92      0.91      1010\n",
      "           3       0.90      0.91      0.90      1002\n",
      "           4       0.94      0.93      0.94       995\n",
      "           5       0.90      0.89      0.90       900\n",
      "           6       0.94      0.95      0.94       949\n",
      "           7       0.92      0.93      0.93      1021\n",
      "           8       0.91      0.90      0.91       987\n",
      "           9       0.90      0.93      0.92       980\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 12: 9286 / 10000\n",
      "Accuracy = 92.86%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.949      0.9771529  0.91860465 0.91875627 0.9305835  0.92316514\n",
      " 0.93142272 0.93222004 0.91143151 0.92307692]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1000\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.92      0.92      0.92      1032\n",
      "           3       0.91      0.92      0.91       997\n",
      "           4       0.94      0.93      0.94       994\n",
      "           5       0.90      0.92      0.91       872\n",
      "           6       0.95      0.93      0.94       977\n",
      "           7       0.92      0.93      0.93      1018\n",
      "           8       0.91      0.91      0.91       971\n",
      "           9       0.92      0.92      0.92      1001\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 13: 9323 / 10000\n",
      "Accuracy = 93.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9416996  0.97375328 0.92277615 0.90401567 0.94324045 0.9342723\n",
      " 0.93904959 0.94288577 0.9008016  0.91437008]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1012\n",
      "           1       0.98      0.97      0.98      1143\n",
      "           2       0.91      0.92      0.92      1023\n",
      "           3       0.91      0.90      0.91      1021\n",
      "           4       0.93      0.94      0.94       969\n",
      "           5       0.89      0.93      0.91       852\n",
      "           6       0.95      0.94      0.94       968\n",
      "           7       0.92      0.94      0.93       998\n",
      "           8       0.92      0.90      0.91       998\n",
      "           9       0.92      0.91      0.92      1016\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 14: 9321 / 10000\n",
      "Accuracy = 93.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95568983 0.97717296 0.93048659 0.90167158 0.93617021 0.93208431\n",
      " 0.9380805  0.94578313 0.88867188 0.91913215]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       993\n",
      "           1       0.98      0.98      0.98      1139\n",
      "           2       0.91      0.93      0.92      1007\n",
      "           3       0.91      0.90      0.90      1017\n",
      "           4       0.94      0.94      0.94       987\n",
      "           5       0.89      0.93      0.91       854\n",
      "           6       0.95      0.94      0.94       969\n",
      "           7       0.92      0.95      0.93       996\n",
      "           8       0.93      0.89      0.91      1024\n",
      "           9       0.92      0.92      0.92      1014\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 15: 9329 / 10000\n",
      "Accuracy = 93.29%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95119522 0.97546012 0.93181818 0.87921348 0.94189602 0.96168109\n",
      " 0.93877551 0.94810379 0.89751244 0.93086172]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1004\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.91      0.93      0.92      1012\n",
      "           3       0.93      0.88      0.90      1068\n",
      "           4       0.94      0.94      0.94       981\n",
      "           5       0.87      0.96      0.91       809\n",
      "           6       0.96      0.94      0.95       980\n",
      "           7       0.92      0.95      0.94      1002\n",
      "           8       0.93      0.90      0.91      1005\n",
      "           9       0.92      0.93      0.93       998\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.94      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 16: 9353 / 10000\n",
      "Accuracy = 93.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94915254 0.97623239 0.94608342 0.91269841 0.93737374 0.93882353\n",
      " 0.92756539 0.93984221 0.8804243  0.93502538]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1003\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.90      0.95      0.92       983\n",
      "           3       0.91      0.91      0.91      1008\n",
      "           4       0.95      0.94      0.94       990\n",
      "           5       0.89      0.94      0.92       850\n",
      "           6       0.96      0.93      0.94       994\n",
      "           7       0.93      0.94      0.93      1014\n",
      "           8       0.94      0.88      0.91      1037\n",
      "           9       0.91      0.94      0.92       985\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.93      0.93     10000\n",
      "\n",
      "Epoch 17: 9346 / 10000\n",
      "Accuracy = 93.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94455446 0.97623239 0.94011976 0.91708292 0.9402229  0.94464075\n",
      " 0.93124368 0.93535749 0.89292731 0.93617021]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1010\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.91      0.94      0.93      1002\n",
      "           3       0.91      0.92      0.91      1001\n",
      "           4       0.95      0.94      0.94       987\n",
      "           5       0.90      0.94      0.92       849\n",
      "           6       0.96      0.93      0.95       989\n",
      "           7       0.93      0.94      0.93      1021\n",
      "           8       0.93      0.89      0.91      1018\n",
      "           9       0.92      0.94      0.93       987\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 18: 9362 / 10000\n",
      "Accuracy = 93.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94637537 0.9762533  0.93359762 0.90625    0.93756294 0.92775229\n",
      " 0.94196891 0.94152626 0.91632653 0.92729084]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1007\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.91      0.93      0.92      1009\n",
      "           3       0.92      0.91      0.91      1024\n",
      "           4       0.95      0.94      0.94       993\n",
      "           5       0.91      0.93      0.92       872\n",
      "           6       0.95      0.94      0.95       965\n",
      "           7       0.92      0.94      0.93      1009\n",
      "           8       0.92      0.92      0.92       980\n",
      "           9       0.92      0.93      0.92      1004\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 19: 9361 / 10000\n",
      "Accuracy = 93.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95582329 0.96465517 0.9375     0.90652386 0.94666667 0.94090382\n",
      " 0.9319797  0.94152626 0.92395833 0.91740413]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       996\n",
      "           1       0.99      0.96      0.98      1160\n",
      "           2       0.92      0.94      0.93      1008\n",
      "           3       0.92      0.91      0.91      1027\n",
      "           4       0.94      0.95      0.94       975\n",
      "           5       0.91      0.94      0.93       863\n",
      "           6       0.96      0.93      0.94       985\n",
      "           7       0.92      0.94      0.93      1009\n",
      "           8       0.91      0.92      0.92       960\n",
      "           9       0.92      0.92      0.92      1017\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 20: 9370 / 10000\n",
      "Accuracy = 93.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94175716 0.97621145 0.94646465 0.91295747 0.94153226 0.92914286\n",
      " 0.94039054 0.93469786 0.90108803 0.94661191]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1013\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.91      0.95      0.93       990\n",
      "           3       0.91      0.91      0.91      1011\n",
      "           4       0.95      0.94      0.95       992\n",
      "           5       0.91      0.93      0.92       875\n",
      "           6       0.96      0.94      0.95       973\n",
      "           7       0.93      0.93      0.93      1026\n",
      "           8       0.94      0.90      0.92      1011\n",
      "           9       0.91      0.95      0.93       974\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 21: 9376 / 10000\n",
      "Accuracy = 93.76%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9501992  0.97966401 0.93836978 0.91015625 0.94427558 0.93150685\n",
      " 0.93942505 0.93614931 0.91414141 0.93535354]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1004\n",
      "           1       0.98      0.98      0.98      1131\n",
      "           2       0.91      0.94      0.93      1006\n",
      "           3       0.92      0.91      0.92      1024\n",
      "           4       0.95      0.94      0.95       987\n",
      "           5       0.91      0.93      0.92       876\n",
      "           6       0.96      0.94      0.95       974\n",
      "           7       0.93      0.94      0.93      1018\n",
      "           8       0.93      0.91      0.92       990\n",
      "           9       0.92      0.94      0.93       990\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 22: 9385 / 10000\n",
      "Accuracy = 93.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95875252 0.96953873 0.93450635 0.91699605 0.94964029 0.93692661\n",
      " 0.91940299 0.93903638 0.92759706 0.93013972]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       994\n",
      "           1       0.98      0.97      0.98      1149\n",
      "           2       0.93      0.93      0.93      1023\n",
      "           3       0.92      0.92      0.92      1012\n",
      "           4       0.94      0.95      0.95       973\n",
      "           5       0.92      0.94      0.93       872\n",
      "           6       0.96      0.92      0.94      1005\n",
      "           7       0.93      0.94      0.93      1017\n",
      "           8       0.91      0.93      0.92       953\n",
      "           9       0.92      0.93      0.93      1002\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 23: 9387 / 10000\n",
      "Accuracy = 93.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94658754 0.9745614  0.94879518 0.91059281 0.94811801 0.94515753\n",
      " 0.92537313 0.94805195 0.91946993 0.9338014 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1011\n",
      "           1       0.98      0.97      0.98      1140\n",
      "           2       0.92      0.95      0.93       996\n",
      "           3       0.93      0.91      0.92      1029\n",
      "           4       0.95      0.95      0.95       983\n",
      "           5       0.91      0.95      0.93       857\n",
      "           6       0.97      0.93      0.95      1005\n",
      "           7       0.92      0.95      0.94      1001\n",
      "           8       0.93      0.92      0.92       981\n",
      "           9       0.92      0.93      0.93       997\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 24: 9404 / 10000\n",
      "Accuracy = 94.04%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94192913 0.97621145 0.94827586 0.92168675 0.94070352 0.93692661\n",
      " 0.93299492 0.93313953 0.89478859 0.94616977]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1016\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.91      0.95      0.93       986\n",
      "           3       0.91      0.92      0.92       996\n",
      "           4       0.95      0.94      0.95       995\n",
      "           5       0.92      0.94      0.93       872\n",
      "           6       0.96      0.93      0.95       985\n",
      "           7       0.94      0.93      0.93      1032\n",
      "           8       0.93      0.89      0.91      1017\n",
      "           9       0.91      0.95      0.93       966\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 25: 9377 / 10000\n",
      "Accuracy = 93.77%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94280079 0.9729021  0.94626866 0.90724638 0.95557851 0.93363844\n",
      " 0.92994924 0.93990148 0.92834891 0.93480441]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1014\n",
      "           1       0.98      0.97      0.98      1144\n",
      "           2       0.92      0.95      0.93      1005\n",
      "           3       0.93      0.91      0.92      1035\n",
      "           4       0.94      0.96      0.95       968\n",
      "           5       0.91      0.93      0.92       874\n",
      "           6       0.96      0.93      0.94       985\n",
      "           7       0.93      0.94      0.93      1015\n",
      "           8       0.92      0.93      0.92       963\n",
      "           9       0.92      0.93      0.93       997\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 26: 9396 / 10000\n",
      "Accuracy = 93.96%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.9410609  0.97122929 0.94059406 0.91757696 0.95131846 0.94117647\n",
      " 0.93394309 0.9410609  0.9158215  0.9457523 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1018\n",
      "           1       0.98      0.97      0.98      1147\n",
      "           2       0.92      0.94      0.93      1010\n",
      "           3       0.91      0.92      0.92      1007\n",
      "           4       0.96      0.95      0.95       986\n",
      "           5       0.91      0.94      0.93       867\n",
      "           6       0.96      0.93      0.95       984\n",
      "           7       0.93      0.94      0.94      1018\n",
      "           8       0.93      0.92      0.92       986\n",
      "           9       0.92      0.95      0.93       977\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 27: 9404 / 10000\n",
      "Accuracy = 94.04%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94466403 0.97125436 0.93978282 0.92345924 0.94822335 0.92905405\n",
      " 0.94879833 0.9307026  0.92600206 0.94586313]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1012\n",
      "           1       0.98      0.97      0.98      1148\n",
      "           2       0.92      0.94      0.93      1013\n",
      "           3       0.92      0.92      0.92      1006\n",
      "           4       0.95      0.95      0.95       985\n",
      "           5       0.92      0.93      0.93       888\n",
      "           6       0.95      0.95      0.95       957\n",
      "           7       0.94      0.93      0.94      1039\n",
      "           8       0.93      0.93      0.93       973\n",
      "           9       0.92      0.95      0.93       979\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 28: 9413 / 10000\n",
      "Accuracy = 94.13%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93548387 0.97877984 0.95040486 0.92107892 0.94635628 0.93401593\n",
      " 0.93756397 0.94280079 0.908      0.93293293]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1023\n",
      "           1       0.98      0.98      0.98      1131\n",
      "           2       0.91      0.95      0.93       988\n",
      "           3       0.91      0.92      0.92      1001\n",
      "           4       0.95      0.95      0.95       988\n",
      "           5       0.92      0.93      0.93       879\n",
      "           6       0.96      0.94      0.95       977\n",
      "           7       0.93      0.94      0.94      1014\n",
      "           8       0.93      0.91      0.92      1000\n",
      "           9       0.92      0.93      0.93       999\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 29: 9393 / 10000\n",
      "Accuracy = 93.93%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94846383 0.97038328 0.93867458 0.9104187  0.95389344 0.94192799\n",
      " 0.94895833 0.9439528  0.90990991 0.9375    ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1009\n",
      "           1       0.98      0.97      0.98      1148\n",
      "           2       0.92      0.94      0.93      1011\n",
      "           3       0.93      0.91      0.92      1027\n",
      "           4       0.95      0.95      0.95       976\n",
      "           5       0.91      0.94      0.93       861\n",
      "           6       0.95      0.95      0.95       960\n",
      "           7       0.93      0.94      0.94      1017\n",
      "           8       0.93      0.91      0.92       999\n",
      "           9       0.92      0.94      0.93       992\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 30: 9407 / 10000\n",
      "Accuracy = 94.07%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94187192 0.9695122  0.94240318 0.9246988  0.95301328 0.93614595\n",
      " 0.93858751 0.94736842 0.91117764 0.93850806]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1015\n",
      "           1       0.98      0.97      0.98      1148\n",
      "           2       0.92      0.94      0.93      1007\n",
      "           3       0.91      0.92      0.92       996\n",
      "           4       0.95      0.95      0.95       979\n",
      "           5       0.92      0.94      0.93       877\n",
      "           6       0.96      0.94      0.95       977\n",
      "           7       0.93      0.95      0.94      1007\n",
      "           8       0.94      0.91      0.92      1002\n",
      "           9       0.92      0.94      0.93       992\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 31: 9408 / 10000\n",
      "Accuracy = 94.08%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95879397 0.9745837  0.94805195 0.93279022 0.95015259 0.92290503\n",
      " 0.92864322 0.93604651 0.9049505  0.95134576]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       995\n",
      "           1       0.98      0.97      0.98      1141\n",
      "           2       0.92      0.95      0.93      1001\n",
      "           3       0.91      0.93      0.92       982\n",
      "           4       0.95      0.95      0.95       983\n",
      "           5       0.93      0.92      0.92       895\n",
      "           6       0.96      0.93      0.95       995\n",
      "           7       0.94      0.94      0.94      1032\n",
      "           8       0.94      0.90      0.92      1010\n",
      "           9       0.91      0.95      0.93       966\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 32: 9414 / 10000\n",
      "Accuracy = 94.14%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.955      0.9729021  0.94129353 0.9222333  0.94472362 0.93204983\n",
      " 0.94616977 0.93962999 0.90718563 0.94564103]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1000\n",
      "           1       0.98      0.97      0.98      1144\n",
      "           2       0.92      0.94      0.93      1005\n",
      "           3       0.92      0.92      0.92      1003\n",
      "           4       0.96      0.94      0.95       995\n",
      "           5       0.92      0.93      0.93       883\n",
      "           6       0.95      0.95      0.95       966\n",
      "           7       0.94      0.94      0.94      1027\n",
      "           8       0.93      0.91      0.92      1002\n",
      "           9       0.91      0.95      0.93       975\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 33: 9412 / 10000\n",
      "Accuracy = 94.12%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95309381 0.9745837  0.94605395 0.92338308 0.94747475 0.9382151\n",
      " 0.94547325 0.94695481 0.89442815 0.9486653 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1002\n",
      "           1       0.98      0.97      0.98      1141\n",
      "           2       0.92      0.95      0.93      1001\n",
      "           3       0.92      0.92      0.92      1005\n",
      "           4       0.96      0.95      0.95       990\n",
      "           5       0.92      0.94      0.93       874\n",
      "           6       0.96      0.95      0.95       972\n",
      "           7       0.94      0.95      0.94      1018\n",
      "           8       0.94      0.89      0.92      1023\n",
      "           9       0.92      0.95      0.93       974\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 34: 9422 / 10000\n",
      "Accuracy = 94.22%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96068548 0.976295   0.95266868 0.92807193 0.95589744 0.93107345\n",
      " 0.93807107 0.93695441 0.91348089 0.93233831]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       992\n",
      "           1       0.98      0.98      0.98      1139\n",
      "           2       0.92      0.95      0.93       993\n",
      "           3       0.92      0.93      0.92      1001\n",
      "           4       0.95      0.96      0.95       975\n",
      "           5       0.92      0.93      0.93       885\n",
      "           6       0.96      0.94      0.95       985\n",
      "           7       0.94      0.94      0.94      1031\n",
      "           8       0.93      0.91      0.92       994\n",
      "           9       0.93      0.93      0.93      1005\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 35: 9431 / 10000\n",
      "Accuracy = 94.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95883534 0.97460595 0.94974874 0.92353525 0.94848485 0.93227991\n",
      " 0.94650206 0.9459725  0.90628116 0.94046418]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       996\n",
      "           1       0.98      0.97      0.98      1142\n",
      "           2       0.92      0.95      0.93       995\n",
      "           3       0.92      0.92      0.92      1007\n",
      "           4       0.96      0.95      0.95       990\n",
      "           5       0.93      0.93      0.93       886\n",
      "           6       0.96      0.95      0.95       972\n",
      "           7       0.94      0.95      0.94      1018\n",
      "           8       0.93      0.91      0.92      1003\n",
      "           9       0.92      0.94      0.93       991\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 36: 9432 / 10000\n",
      "Accuracy = 94.32%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96367306 0.97550306 0.94251734 0.91568627 0.95320448 0.91906874\n",
      " 0.94159836 0.9495549  0.92016377 0.94331984]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       991\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.92      0.94      0.93      1009\n",
      "           3       0.92      0.92      0.92      1020\n",
      "           4       0.95      0.95      0.95       983\n",
      "           5       0.93      0.92      0.92       902\n",
      "           6       0.96      0.94      0.95       976\n",
      "           7       0.93      0.95      0.94      1011\n",
      "           8       0.92      0.92      0.92       977\n",
      "           9       0.92      0.94      0.93       988\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 37: 9431 / 10000\n",
      "Accuracy = 94.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93817468 0.98315603 0.94384236 0.93489318 0.95126904 0.93922018\n",
      " 0.94081633 0.9486166  0.90227048 0.93655589]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1019\n",
      "           1       0.98      0.98      0.98      1128\n",
      "           2       0.93      0.94      0.94      1015\n",
      "           3       0.91      0.93      0.92       983\n",
      "           4       0.95      0.95      0.95       985\n",
      "           5       0.92      0.94      0.93       872\n",
      "           6       0.96      0.94      0.95       980\n",
      "           7       0.93      0.95      0.94      1012\n",
      "           8       0.94      0.90      0.92      1013\n",
      "           9       0.92      0.94      0.93       993\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 38: 9424 / 10000\n",
      "Accuracy = 94.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.955      0.97460595 0.95348837 0.9148728  0.94848485 0.94131185\n",
      " 0.94840041 0.94721408 0.8996063  0.94693878]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1000\n",
      "           1       0.98      0.97      0.98      1142\n",
      "           2       0.91      0.95      0.93       989\n",
      "           3       0.93      0.91      0.92      1022\n",
      "           4       0.96      0.95      0.95       990\n",
      "           5       0.92      0.94      0.93       869\n",
      "           6       0.96      0.95      0.95       969\n",
      "           7       0.94      0.95      0.94      1023\n",
      "           8       0.94      0.90      0.92      1016\n",
      "           9       0.92      0.95      0.93       980\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 39: 9433 / 10000\n",
      "Accuracy = 94.33%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95883534 0.97635727 0.948      0.91756624 0.95585216 0.93552036\n",
      " 0.95228216 0.94341463 0.90927218 0.93856999]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       996\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.92      0.95      0.93      1000\n",
      "           3       0.93      0.92      0.92      1019\n",
      "           4       0.95      0.96      0.95       974\n",
      "           5       0.93      0.94      0.93       884\n",
      "           6       0.96      0.95      0.96       964\n",
      "           7       0.94      0.94      0.94      1025\n",
      "           8       0.94      0.91      0.92      1003\n",
      "           9       0.92      0.94      0.93       993\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 40: 9440 / 10000\n",
      "Accuracy = 94.40%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94747275 0.97801231 0.9510978  0.92537313 0.95015259 0.93552036\n",
      " 0.94807892 0.93719807 0.91291291 0.94303154]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1009\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.92      0.95      0.94      1002\n",
      "           3       0.92      0.93      0.92      1005\n",
      "           4       0.95      0.95      0.95       983\n",
      "           5       0.93      0.94      0.93       884\n",
      "           6       0.95      0.95      0.95       963\n",
      "           7       0.94      0.94      0.94      1035\n",
      "           8       0.94      0.91      0.92       999\n",
      "           9       0.92      0.94      0.93       983\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 41: 9434 / 10000\n",
      "Accuracy = 94.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95119522 0.97719298 0.94362018 0.92807193 0.94838057 0.94712644\n",
      " 0.95129534 0.95351137 0.90275049 0.93951613]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1004\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.92      0.94      0.93      1011\n",
      "           3       0.92      0.93      0.92      1001\n",
      "           4       0.95      0.95      0.95       988\n",
      "           5       0.92      0.95      0.94       870\n",
      "           6       0.96      0.95      0.95       965\n",
      "           7       0.94      0.95      0.95      1011\n",
      "           8       0.94      0.90      0.92      1018\n",
      "           9       0.92      0.94      0.93       992\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 42: 9446 / 10000\n",
      "Accuracy = 94.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.955      0.97297297 0.94285714 0.92193676 0.95674562 0.94057143\n",
      " 0.95134576 0.94335938 0.91590679 0.93020937]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1000\n",
      "           1       0.98      0.97      0.98      1147\n",
      "           2       0.93      0.94      0.94      1015\n",
      "           3       0.92      0.92      0.92      1012\n",
      "           4       0.95      0.96      0.95       971\n",
      "           5       0.92      0.94      0.93       875\n",
      "           6       0.96      0.95      0.96       966\n",
      "           7       0.94      0.94      0.94      1024\n",
      "           8       0.93      0.92      0.92       987\n",
      "           9       0.92      0.93      0.93      1003\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 43: 9435 / 10000\n",
      "Accuracy = 94.35%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95219124 0.97887324 0.95114656 0.93245968 0.95339412 0.93935927\n",
      " 0.95134576 0.93563881 0.90316206 0.94517766]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1004\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.92      0.95      0.94      1003\n",
      "           3       0.92      0.93      0.92       992\n",
      "           4       0.96      0.95      0.96       987\n",
      "           5       0.92      0.94      0.93       874\n",
      "           6       0.96      0.95      0.96       966\n",
      "           7       0.95      0.94      0.94      1041\n",
      "           8       0.94      0.90      0.92      1012\n",
      "           9       0.92      0.95      0.93       985\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 44: 9447 / 10000\n",
      "Accuracy = 94.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95787362 0.97807018 0.94778325 0.92254902 0.95422177 0.93771234\n",
      " 0.94855967 0.94536585 0.92573754 0.94501018]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       997\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.93      0.95      0.94      1015\n",
      "           3       0.93      0.92      0.93      1020\n",
      "           4       0.96      0.95      0.95       983\n",
      "           5       0.93      0.94      0.93       883\n",
      "           6       0.96      0.95      0.96       972\n",
      "           7       0.94      0.95      0.94      1025\n",
      "           8       0.93      0.93      0.93       983\n",
      "           9       0.92      0.95      0.93       982\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 45: 9468 / 10000\n",
      "Accuracy = 94.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95404595 0.97631579 0.94752475 0.92721834 0.94747475 0.93355856\n",
      " 0.94564103 0.9507874  0.9198783  0.93844601]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1001\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.93      0.95      0.94      1010\n",
      "           3       0.92      0.93      0.92      1003\n",
      "           4       0.96      0.95      0.95       990\n",
      "           5       0.93      0.93      0.93       888\n",
      "           6       0.96      0.95      0.95       975\n",
      "           7       0.94      0.95      0.95      1016\n",
      "           8       0.93      0.92      0.93       986\n",
      "           9       0.92      0.94      0.93       991\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 46: 9447 / 10000\n",
      "Accuracy = 94.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95413759 0.97807018 0.94581281 0.92552135 0.94763343 0.93446328\n",
      " 0.94467213 0.94731707 0.92441267 0.94779939]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1003\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.93      0.95      0.94      1015\n",
      "           3       0.92      0.93      0.92      1007\n",
      "           4       0.96      0.95      0.95       993\n",
      "           5       0.93      0.93      0.93       885\n",
      "           6       0.96      0.94      0.95       976\n",
      "           7       0.94      0.95      0.95      1025\n",
      "           8       0.93      0.92      0.93       979\n",
      "           9       0.92      0.95      0.93       977\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.94      0.94     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 47: 9456 / 10000\n",
      "Accuracy = 94.56%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95695696 0.97635727 0.93865628 0.92315271 0.94853683 0.93984109\n",
      " 0.94938017 0.94798822 0.92174797 0.94661191]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.93      0.94      0.94      1027\n",
      "           3       0.93      0.92      0.93      1015\n",
      "           4       0.96      0.95      0.95       991\n",
      "           5       0.93      0.94      0.93       881\n",
      "           6       0.96      0.95      0.95       968\n",
      "           7       0.94      0.95      0.94      1019\n",
      "           8       0.93      0.92      0.93       984\n",
      "           9       0.91      0.95      0.93       974\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 48: 9454 / 10000\n",
      "Accuracy = 94.54%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95883534 0.9797891  0.94945491 0.92027559 0.95417515 0.94785632\n",
      " 0.9457523  0.94547225 0.90918164 0.94040404]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       996\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.93      0.95      0.94      1009\n",
      "           3       0.93      0.92      0.92      1016\n",
      "           4       0.95      0.95      0.95       982\n",
      "           5       0.92      0.95      0.93       863\n",
      "           6       0.96      0.95      0.96       977\n",
      "           7       0.94      0.95      0.95      1027\n",
      "           8       0.94      0.91      0.92      1002\n",
      "           9       0.92      0.94      0.93       990\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.94      0.95      0.94     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 49: 9455 / 10000\n",
      "Accuracy = 94.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95029821 0.98148148 0.95314058 0.92322835 0.94578313 0.94077449\n",
      " 0.95134576 0.94655005 0.914      0.94855967]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1006\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.93      0.95      0.94      1003\n",
      "           3       0.93      0.92      0.93      1016\n",
      "           4       0.96      0.95      0.95       996\n",
      "           5       0.93      0.94      0.93       878\n",
      "           6       0.96      0.95      0.96       966\n",
      "           7       0.95      0.95      0.95      1029\n",
      "           8       0.94      0.91      0.93      1000\n",
      "           9       0.91      0.95      0.93       972\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 50: 9460 / 10000\n",
      "Accuracy = 94.60%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95409182 0.97975352 0.94768016 0.92792793 0.94561934 0.93863636\n",
      " 0.94552929 0.9410058  0.92323439 0.93756294]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1002\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.93      0.95      0.94      1013\n",
      "           3       0.92      0.93      0.92       999\n",
      "           4       0.96      0.95      0.95       993\n",
      "           5       0.93      0.94      0.93       880\n",
      "           6       0.96      0.95      0.95       973\n",
      "           7       0.95      0.94      0.94      1034\n",
      "           8       0.93      0.92      0.92       977\n",
      "           9       0.92      0.94      0.93       993\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 51: 9447 / 10000\n",
      "Accuracy = 94.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95691383 0.97721297 0.95134062 0.92885772 0.95315682 0.94043528\n",
      " 0.94845361 0.93840231 0.91082164 0.93762575]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       998\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.93      0.95      0.94      1007\n",
      "           3       0.92      0.93      0.92       998\n",
      "           4       0.95      0.95      0.95       982\n",
      "           5       0.92      0.94      0.93       873\n",
      "           6       0.96      0.95      0.95       970\n",
      "           7       0.95      0.94      0.94      1039\n",
      "           8       0.93      0.91      0.92       998\n",
      "           9       0.92      0.94      0.93       994\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.95      0.94      0.94     10000\n",
      "\n",
      "Epoch 52: 9448 / 10000\n",
      "Accuracy = 94.48%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95228628 0.98059965 0.94591937 0.92864322 0.95510204 0.93243243\n",
      " 0.95036194 0.94460641 0.91382766 0.94117647]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1006\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.93      0.95      0.94      1017\n",
      "           3       0.91      0.93      0.92       995\n",
      "           4       0.95      0.96      0.95       980\n",
      "           5       0.93      0.93      0.93       888\n",
      "           6       0.96      0.95      0.95       967\n",
      "           7       0.95      0.94      0.95      1029\n",
      "           8       0.94      0.91      0.92       998\n",
      "           9       0.92      0.94      0.93       986\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 53: 9451 / 10000\n",
      "Accuracy = 94.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95409182 0.97971781 0.94685039 0.92110454 0.95325203 0.94579008\n",
      " 0.94370522 0.94563107 0.91566265 0.94489796]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1002\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.93      0.95      0.94      1016\n",
      "           3       0.92      0.92      0.92      1014\n",
      "           4       0.96      0.95      0.95       984\n",
      "           5       0.92      0.95      0.93       867\n",
      "           6       0.96      0.94      0.95       977\n",
      "           7       0.95      0.95      0.95      1030\n",
      "           8       0.94      0.92      0.93       996\n",
      "           9       0.92      0.94      0.93       980\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.94      0.95      0.94     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 54: 9455 / 10000\n",
      "Accuracy = 94.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.956      0.97889182 0.9486166  0.93172691 0.95505618 0.93497758\n",
      " 0.94932782 0.94444444 0.91959799 0.93373494]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.93      0.95      0.94      1012\n",
      "           3       0.92      0.93      0.93       996\n",
      "           4       0.95      0.96      0.95       979\n",
      "           5       0.93      0.93      0.93       892\n",
      "           6       0.96      0.95      0.95       967\n",
      "           7       0.94      0.94      0.94      1026\n",
      "           8       0.94      0.92      0.93       995\n",
      "           9       0.92      0.93      0.93       996\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 55: 9458 / 10000\n",
      "Accuracy = 94.58%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95687061 0.98315603 0.93968872 0.92871486 0.94035785 0.93340858\n",
      " 0.94742268 0.95093229 0.91943605 0.94882293]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       997\n",
      "           1       0.98      0.98      0.98      1128\n",
      "           2       0.94      0.94      0.94      1028\n",
      "           3       0.92      0.93      0.92       996\n",
      "           4       0.96      0.94      0.95      1006\n",
      "           5       0.93      0.93      0.93       886\n",
      "           6       0.96      0.95      0.95       970\n",
      "           7       0.94      0.95      0.95      1019\n",
      "           8       0.94      0.92      0.93       993\n",
      "           9       0.92      0.95      0.93       977\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.94      0.94     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 56: 9455 / 10000\n",
      "Accuracy = 94.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95228628 0.97721297 0.95214357 0.92201382 0.95334686 0.94495413\n",
      " 0.94855967 0.95112414 0.91591592 0.94213198]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1006\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.93      0.95      0.94      1003\n",
      "           3       0.92      0.92      0.92      1013\n",
      "           4       0.96      0.95      0.96       986\n",
      "           5       0.92      0.94      0.93       872\n",
      "           6       0.96      0.95      0.96       972\n",
      "           7       0.95      0.95      0.95      1023\n",
      "           8       0.94      0.92      0.93       999\n",
      "           9       0.92      0.94      0.93       985\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 57: 9464 / 10000\n",
      "Accuracy = 94.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95318725 0.97977133 0.95114656 0.92644135 0.94848485 0.93686584\n",
      " 0.95129534 0.94911937 0.918429   0.93554884]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1004\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.92      0.95      0.94      1003\n",
      "           3       0.92      0.93      0.92      1006\n",
      "           4       0.96      0.95      0.95       990\n",
      "           5       0.93      0.94      0.93       887\n",
      "           6       0.96      0.95      0.95       965\n",
      "           7       0.94      0.95      0.95      1022\n",
      "           8       0.94      0.92      0.93       993\n",
      "           9       0.92      0.94      0.93       993\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 58: 9456 / 10000\n",
      "Accuracy = 94.56%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95608782 0.97891037 0.95104895 0.92232055 0.95607763 0.95443925\n",
      " 0.95159629 0.94911937 0.90078585 0.93574297]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.92      0.95      0.94      1001\n",
      "           3       0.93      0.92      0.93      1017\n",
      "           4       0.95      0.96      0.95       979\n",
      "           5       0.92      0.95      0.93       856\n",
      "           6       0.96      0.95      0.96       971\n",
      "           7       0.94      0.95      0.95      1022\n",
      "           8       0.94      0.90      0.92      1018\n",
      "           9       0.92      0.94      0.93       996\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 59: 9458 / 10000\n",
      "Accuracy = 94.58%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95975855 0.97801231 0.94856578 0.93072289 0.94578313 0.93072626\n",
      " 0.94467213 0.94747082 0.9172553  0.94569672]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       994\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.93      0.95      0.94      1011\n",
      "           3       0.92      0.93      0.92       996\n",
      "           4       0.96      0.95      0.95       996\n",
      "           5       0.93      0.93      0.93       895\n",
      "           6       0.96      0.94      0.95       976\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.93      0.92      0.93       991\n",
      "           9       0.91      0.95      0.93       976\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.94      0.94     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 60: 9455 / 10000\n",
      "Accuracy = 94.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96072508 0.9771529  0.94700687 0.9265144  0.94858871 0.93581081\n",
      " 0.94747683 0.94294004 0.92528147 0.94495413]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       993\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.94      0.95      0.94      1019\n",
      "           3       0.92      0.93      0.93      1007\n",
      "           4       0.96      0.95      0.95       992\n",
      "           5       0.93      0.94      0.93       888\n",
      "           6       0.96      0.95      0.95       971\n",
      "           7       0.95      0.94      0.95      1034\n",
      "           8       0.93      0.93      0.93       977\n",
      "           9       0.92      0.94      0.93       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 61: 9462 / 10000\n",
      "Accuracy = 94.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95595596 0.97805092 0.95044599 0.92828685 0.94949495 0.92502756\n",
      " 0.93985729 0.95200784 0.93004115 0.94580777]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       999\n",
      "           1       0.98      0.98      0.98      1139\n",
      "           2       0.93      0.95      0.94      1009\n",
      "           3       0.92      0.93      0.93      1004\n",
      "           4       0.96      0.95      0.95       990\n",
      "           5       0.94      0.93      0.93       907\n",
      "           6       0.96      0.94      0.95       981\n",
      "           7       0.95      0.95      0.95      1021\n",
      "           8       0.93      0.93      0.93       972\n",
      "           9       0.92      0.95      0.93       978\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 62: 9462 / 10000\n",
      "Accuracy = 94.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95691383 0.98318584 0.95153314 0.92179863 0.95625636 0.94004525\n",
      " 0.94461538 0.94578896 0.92653061 0.94404883]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       998\n",
      "           1       0.98      0.98      0.98      1130\n",
      "           2       0.93      0.95      0.94      1011\n",
      "           3       0.93      0.92      0.93      1023\n",
      "           4       0.96      0.96      0.96       983\n",
      "           5       0.93      0.94      0.94       884\n",
      "           6       0.96      0.94      0.95       975\n",
      "           7       0.95      0.95      0.95      1033\n",
      "           8       0.93      0.93      0.93       980\n",
      "           9       0.92      0.94      0.93       983\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 63: 9476 / 10000\n",
      "Accuracy = 94.76%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95418327 0.97633655 0.95158103 0.92133727 0.95339412 0.93176734\n",
      " 0.94845361 0.952895   0.93451143 0.93561368]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1004\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.93      0.95      0.94      1012\n",
      "           3       0.93      0.92      0.92      1017\n",
      "           4       0.96      0.95      0.96       987\n",
      "           5       0.93      0.93      0.93       894\n",
      "           6       0.96      0.95      0.95       970\n",
      "           7       0.94      0.95      0.95      1019\n",
      "           8       0.92      0.93      0.93       962\n",
      "           9       0.92      0.94      0.93       994\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 64: 9466 / 10000\n",
      "Accuracy = 94.66%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95791583 0.9806338  0.94705882 0.92772277 0.95146613 0.94815668\n",
      " 0.94683027 0.95940594 0.91080278 0.94501018]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       998\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.94      0.95      0.94      1020\n",
      "           3       0.93      0.93      0.93      1010\n",
      "           4       0.96      0.95      0.95       989\n",
      "           5       0.92      0.95      0.94       868\n",
      "           6       0.97      0.95      0.96       978\n",
      "           7       0.94      0.96      0.95      1010\n",
      "           8       0.94      0.91      0.93      1009\n",
      "           9       0.92      0.95      0.93       982\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 65: 9479 / 10000\n",
      "Accuracy = 94.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95891784 0.97973568 0.95323383 0.92383778 0.95816327 0.93483146\n",
      " 0.94948454 0.94747082 0.91919192 0.93856999]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       998\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.93      0.95      0.94      1005\n",
      "           3       0.92      0.92      0.92      1011\n",
      "           4       0.96      0.96      0.96       980\n",
      "           5       0.93      0.93      0.93       890\n",
      "           6       0.96      0.95      0.96       970\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.93      0.92      0.93       990\n",
      "           9       0.92      0.94      0.93       993\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 66: 9469 / 10000\n",
      "Accuracy = 94.69%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95687061 0.98148148 0.95247525 0.92254902 0.95625636 0.94090909\n",
      " 0.94467213 0.94123314 0.92512821 0.94427558]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       997\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.93      0.95      0.94      1010\n",
      "           3       0.93      0.92      0.93      1020\n",
      "           4       0.96      0.96      0.96       983\n",
      "           5       0.93      0.94      0.93       880\n",
      "           6       0.96      0.94      0.95       976\n",
      "           7       0.95      0.94      0.95      1038\n",
      "           8       0.93      0.93      0.93       975\n",
      "           9       0.92      0.94      0.93       987\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 67: 9471 / 10000\n",
      "Accuracy = 94.71%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95134062 0.9806338  0.95049505 0.92914172 0.95918367 0.92769744\n",
      " 0.95119418 0.9502439  0.9235474  0.93881645]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1007\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.93      0.95      0.94      1010\n",
      "           3       0.92      0.93      0.93      1002\n",
      "           4       0.96      0.96      0.96       980\n",
      "           5       0.93      0.93      0.93       899\n",
      "           6       0.96      0.95      0.95       963\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.93      0.92      0.93       981\n",
      "           9       0.93      0.94      0.93       997\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 68: 9469 / 10000\n",
      "Accuracy = 94.69%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95704296 0.98144876 0.95522388 0.93027888 0.95055499 0.92992214\n",
      " 0.95036194 0.95205479 0.91343284 0.9476386 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.98      0.98      0.98      1132\n",
      "           2       0.93      0.96      0.94      1005\n",
      "           3       0.92      0.93      0.93      1004\n",
      "           4       0.96      0.95      0.95       991\n",
      "           5       0.94      0.93      0.93       899\n",
      "           6       0.96      0.95      0.95       967\n",
      "           7       0.95      0.95      0.95      1022\n",
      "           8       0.94      0.91      0.93      1005\n",
      "           9       0.91      0.95      0.93       974\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 69: 9474 / 10000\n",
      "Accuracy = 94.74%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96084337 0.9797891  0.95395395 0.92254902 0.95431472 0.93146067\n",
      " 0.95139607 0.95107632 0.91708797 0.93963783]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.92      0.95      0.94       999\n",
      "           3       0.93      0.92      0.93      1020\n",
      "           4       0.96      0.95      0.96       985\n",
      "           5       0.93      0.93      0.93       890\n",
      "           6       0.96      0.95      0.96       967\n",
      "           7       0.95      0.95      0.95      1022\n",
      "           8       0.93      0.92      0.92       989\n",
      "           9       0.93      0.94      0.93       994\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 70: 9468 / 10000\n",
      "Accuracy = 94.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95891784 0.98314108 0.95341923 0.93106893 0.95621181 0.92849162\n",
      " 0.94661191 0.94310511 0.92020202 0.94326241]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       998\n",
      "           1       0.98      0.98      0.98      1127\n",
      "           2       0.93      0.95      0.94      1009\n",
      "           3       0.92      0.93      0.93      1001\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.93      0.93      0.93       895\n",
      "           6       0.96      0.95      0.95       974\n",
      "           7       0.95      0.94      0.95      1037\n",
      "           8       0.94      0.92      0.93       990\n",
      "           9       0.92      0.94      0.93       987\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 71: 9471 / 10000\n",
      "Accuracy = 94.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95887663 0.97975352 0.95162883 0.92413793 0.9516129  0.93905192\n",
      " 0.94861254 0.94834308 0.92004049 0.94661191]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.93      0.95      0.94      1013\n",
      "           3       0.93      0.92      0.93      1015\n",
      "           4       0.96      0.95      0.96       992\n",
      "           5       0.93      0.94      0.94       886\n",
      "           6       0.96      0.95      0.96       973\n",
      "           7       0.95      0.95      0.95      1026\n",
      "           8       0.93      0.92      0.93       988\n",
      "           9       0.91      0.95      0.93       974\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 72: 9474 / 10000\n",
      "Accuracy = 94.74%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95143707 0.98058252 0.95304695 0.91894531 0.94869215 0.94501718\n",
      " 0.94677584 0.95298727 0.92292089 0.94399185]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1009\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.92      0.95      0.94      1001\n",
      "           3       0.93      0.92      0.93      1024\n",
      "           4       0.96      0.95      0.95       994\n",
      "           5       0.92      0.95      0.93       873\n",
      "           6       0.97      0.95      0.96       977\n",
      "           7       0.95      0.95      0.95      1021\n",
      "           8       0.93      0.92      0.93       986\n",
      "           9       0.92      0.94      0.93       982\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 73: 9469 / 10000\n",
      "Accuracy = 94.69%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.958      0.97971781 0.95318725 0.93467337 0.94864048 0.92538976\n",
      " 0.94829369 0.94752187 0.916      0.94489796]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.93      0.95      0.94      1004\n",
      "           3       0.92      0.93      0.93       995\n",
      "           4       0.96      0.95      0.95       993\n",
      "           5       0.93      0.93      0.93       898\n",
      "           6       0.96      0.95      0.95       967\n",
      "           7       0.95      0.95      0.95      1029\n",
      "           8       0.94      0.92      0.93      1000\n",
      "           9       0.92      0.94      0.93       980\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 74: 9463 / 10000\n",
      "Accuracy = 94.63%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95895896 0.97803163 0.95323383 0.92141454 0.95820591 0.92769744\n",
      " 0.94742268 0.9539667  0.92410256 0.93863179]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.93      0.95      0.94      1005\n",
      "           3       0.93      0.92      0.93      1018\n",
      "           4       0.96      0.96      0.96       981\n",
      "           5       0.93      0.93      0.93       899\n",
      "           6       0.96      0.95      0.95       970\n",
      "           7       0.95      0.95      0.95      1021\n",
      "           8       0.93      0.92      0.92       975\n",
      "           9       0.92      0.94      0.93       994\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 75: 9468 / 10000\n",
      "Accuracy = 94.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.959      0.98146514 0.95233366 0.929      0.95146613 0.93250844\n",
      " 0.94948454 0.95369458 0.91540785 0.93326693]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.93      0.95      0.94      1007\n",
      "           3       0.92      0.93      0.92      1000\n",
      "           4       0.96      0.95      0.95       989\n",
      "           5       0.93      0.93      0.93       889\n",
      "           6       0.96      0.95      0.96       970\n",
      "           7       0.94      0.95      0.95      1015\n",
      "           8       0.93      0.92      0.92       993\n",
      "           9       0.93      0.93      0.93      1004\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 76: 9464 / 10000\n",
      "Accuracy = 94.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95233366 0.97973568 0.95162883 0.91878669 0.95247725 0.93814433\n",
      " 0.94661191 0.95117188 0.91845056 0.94399185]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1007\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.93      0.95      0.94      1013\n",
      "           3       0.93      0.92      0.92      1022\n",
      "           4       0.96      0.95      0.96       989\n",
      "           5       0.92      0.94      0.93       873\n",
      "           6       0.96      0.95      0.95       974\n",
      "           7       0.95      0.95      0.95      1024\n",
      "           8       0.93      0.92      0.92       981\n",
      "           9       0.92      0.94      0.93       982\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 77: 9459 / 10000\n",
      "Accuracy = 94.59%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96464646 0.98146514 0.95427435 0.92497532 0.94583751 0.93468468\n",
      " 0.94655704 0.94936709 0.91497976 0.94213198]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       990\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.93      0.95      0.94      1006\n",
      "           3       0.93      0.92      0.93      1013\n",
      "           4       0.96      0.95      0.95       997\n",
      "           5       0.93      0.93      0.93       888\n",
      "           6       0.96      0.95      0.95       973\n",
      "           7       0.95      0.95      0.95      1027\n",
      "           8       0.93      0.91      0.92       988\n",
      "           9       0.92      0.94      0.93       985\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 78: 9465 / 10000\n",
      "Accuracy = 94.65%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96273917 0.97971781 0.95341923 0.92164545 0.94773869 0.93863636\n",
      " 0.94758479 0.95121951 0.91506572 0.9459735 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       993\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.93      0.95      0.94      1009\n",
      "           3       0.93      0.92      0.93      1021\n",
      "           4       0.96      0.95      0.95       995\n",
      "           5       0.93      0.94      0.93       880\n",
      "           6       0.96      0.95      0.95       973\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.93      0.92      0.92       989\n",
      "           9       0.92      0.95      0.93       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 79: 9469 / 10000\n",
      "Accuracy = 94.69%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96270161 0.97977133 0.95242815 0.93554884 0.94673367 0.93679458\n",
      " 0.94219067 0.9548577  0.91491491 0.94512195]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       992\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.93      0.95      0.94      1009\n",
      "           3       0.92      0.94      0.93       993\n",
      "           4       0.96      0.95      0.95       995\n",
      "           5       0.93      0.94      0.93       886\n",
      "           6       0.97      0.94      0.96       986\n",
      "           7       0.95      0.95      0.95      1019\n",
      "           8       0.94      0.91      0.93       999\n",
      "           9       0.92      0.95      0.93       984\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 80: 9477 / 10000\n",
      "Accuracy = 94.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95708583 0.97891037 0.95328032 0.92610837 0.95621181 0.93693694\n",
      " 0.94758479 0.9556213  0.92198582 0.93969849]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.93      0.95      0.94      1006\n",
      "           3       0.93      0.93      0.93      1015\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.93      0.94      0.93       888\n",
      "           6       0.96      0.95      0.95       973\n",
      "           7       0.94      0.96      0.95      1014\n",
      "           8       0.93      0.92      0.93       987\n",
      "           9       0.93      0.94      0.93       995\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 81: 9479 / 10000\n",
      "Accuracy = 94.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95891784 0.98059965 0.95256917 0.92871287 0.95532995 0.93303571\n",
      " 0.94564103 0.95210166 0.92370295 0.94817073]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       998\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.93      0.95      0.94      1012\n",
      "           3       0.93      0.93      0.93      1010\n",
      "           4       0.96      0.96      0.96       985\n",
      "           5       0.94      0.93      0.94       896\n",
      "           6       0.96      0.95      0.95       975\n",
      "           7       0.95      0.95      0.95      1023\n",
      "           8       0.93      0.92      0.93       983\n",
      "           9       0.92      0.95      0.94       984\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 82: 9485 / 10000\n",
      "Accuracy = 94.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96288867 0.98143236 0.95242815 0.931      0.95238095 0.92572062\n",
      " 0.94871795 0.96318408 0.90900099 0.94201424]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.98      0.98      0.98      1131\n",
      "           2       0.93      0.95      0.94      1009\n",
      "           3       0.92      0.93      0.93      1000\n",
      "           4       0.96      0.95      0.95       987\n",
      "           5       0.94      0.93      0.93       902\n",
      "           6       0.97      0.95      0.96       975\n",
      "           7       0.94      0.96      0.95      1005\n",
      "           8       0.94      0.91      0.93      1011\n",
      "           9       0.92      0.94      0.93       983\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 83: 9475 / 10000\n",
      "Accuracy = 94.75%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.959      0.97631579 0.95436508 0.92428712 0.94964753 0.93161435\n",
      " 0.94958848 0.95570866 0.92065107 0.94586313]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.93      0.95      0.94      1008\n",
      "           3       0.93      0.92      0.93      1017\n",
      "           4       0.96      0.95      0.95       993\n",
      "           5       0.93      0.93      0.93       892\n",
      "           6       0.96      0.95      0.96       972\n",
      "           7       0.94      0.96      0.95      1016\n",
      "           8       0.93      0.92      0.92       983\n",
      "           9       0.92      0.95      0.93       979\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 84: 9473 / 10000\n",
      "Accuracy = 94.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96       0.98056537 0.95422886 0.92779426 0.94294294 0.93446328\n",
      " 0.9457523  0.95200784 0.91465863 0.9476386 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.98      0.98      1132\n",
      "           2       0.93      0.95      0.94      1005\n",
      "           3       0.93      0.93      0.93      1011\n",
      "           4       0.96      0.94      0.95       999\n",
      "           5       0.93      0.93      0.93       885\n",
      "           6       0.96      0.95      0.96       977\n",
      "           7       0.95      0.95      0.95      1021\n",
      "           8       0.94      0.91      0.92       996\n",
      "           9       0.91      0.95      0.93       974\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 85: 9466 / 10000\n",
      "Accuracy = 94.66%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95708583 0.97883598 0.95436508 0.92673267 0.94383149 0.93877551\n",
      " 0.94845361 0.94849368 0.9185336  0.94320487]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.93      0.95      0.94      1008\n",
      "           3       0.93      0.93      0.93      1010\n",
      "           4       0.96      0.94      0.95       997\n",
      "           5       0.93      0.94      0.93       882\n",
      "           6       0.96      0.95      0.95       970\n",
      "           7       0.95      0.95      0.95      1029\n",
      "           8       0.93      0.92      0.92       982\n",
      "           9       0.92      0.94      0.93       986\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 86: 9464 / 10000\n",
      "Accuracy = 94.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95422886 0.98058252 0.95256917 0.93186373 0.94959677 0.93265993\n",
      " 0.94840041 0.95205479 0.91946993 0.93781344]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1005\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.93      0.95      0.94      1012\n",
      "           3       0.92      0.93      0.93       998\n",
      "           4       0.96      0.95      0.95       992\n",
      "           5       0.93      0.93      0.93       891\n",
      "           6       0.96      0.95      0.95       969\n",
      "           7       0.95      0.95      0.95      1022\n",
      "           8       0.93      0.92      0.92       981\n",
      "           9       0.93      0.94      0.93       997\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 87: 9466 / 10000\n",
      "Accuracy = 94.66%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95895896 0.98058252 0.94871795 0.9260355  0.95701126 0.93468468\n",
      " 0.95238095 0.9456838  0.92057026 0.937751  ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.93      0.95      0.94      1014\n",
      "           3       0.93      0.93      0.93      1014\n",
      "           4       0.95      0.96      0.95       977\n",
      "           5       0.93      0.93      0.93       888\n",
      "           6       0.96      0.95      0.96       966\n",
      "           7       0.95      0.95      0.95      1031\n",
      "           8       0.93      0.92      0.92       982\n",
      "           9       0.93      0.94      0.93       996\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 88: 9468 / 10000\n",
      "Accuracy = 94.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9637827  0.98143236 0.95323383 0.93220339 0.94673367 0.92087912\n",
      " 0.94938017 0.9503408  0.92118731 0.94242424]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.98      0.98      0.98      1131\n",
      "           2       0.93      0.95      0.94      1005\n",
      "           3       0.93      0.93      0.93      1003\n",
      "           4       0.96      0.95      0.95       995\n",
      "           5       0.94      0.92      0.93       910\n",
      "           6       0.96      0.95      0.95       968\n",
      "           7       0.95      0.95      0.95      1027\n",
      "           8       0.92      0.92      0.92       977\n",
      "           9       0.92      0.94      0.93       990\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 89: 9469 / 10000\n",
      "Accuracy = 94.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96092184 0.98056537 0.95337302 0.92074364 0.94217348 0.9375\n",
      " 0.9476386  0.94931774 0.92197125 0.94506612]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       998\n",
      "           1       0.98      0.98      0.98      1132\n",
      "           2       0.93      0.95      0.94      1008\n",
      "           3       0.93      0.92      0.93      1022\n",
      "           4       0.96      0.94      0.95      1003\n",
      "           5       0.92      0.94      0.93       880\n",
      "           6       0.96      0.95      0.96       974\n",
      "           7       0.95      0.95      0.95      1026\n",
      "           8       0.92      0.92      0.92       974\n",
      "           9       0.92      0.95      0.93       983\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 90: 9465 / 10000\n",
      "Accuracy = 94.65%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95904096 0.98058252 0.955      0.93574297 0.95905834 0.93169093\n",
      " 0.94472876 0.9503408  0.90954274 0.94343434]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.93      0.95      0.94      1000\n",
      "           3       0.92      0.94      0.93       996\n",
      "           4       0.95      0.96      0.96       977\n",
      "           5       0.93      0.93      0.93       893\n",
      "           6       0.96      0.94      0.95       977\n",
      "           7       0.95      0.95      0.95      1027\n",
      "           8       0.94      0.91      0.92      1006\n",
      "           9       0.93      0.94      0.93       990\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 91: 9475 / 10000\n",
      "Accuracy = 94.75%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95708583 0.97885463 0.95341923 0.92800789 0.95050505 0.93686584\n",
      " 0.9504644  0.95210166 0.92173018 0.937     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.93      0.95      0.94      1009\n",
      "           3       0.93      0.93      0.93      1014\n",
      "           4       0.96      0.95      0.95       990\n",
      "           5       0.93      0.94      0.93       887\n",
      "           6       0.96      0.95      0.96       969\n",
      "           7       0.95      0.95      0.95      1023\n",
      "           8       0.92      0.92      0.92       971\n",
      "           9       0.93      0.94      0.93      1000\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 92: 9472 / 10000\n",
      "Accuracy = 94.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95708583 0.97801231 0.95422886 0.935      0.943      0.92699115\n",
      " 0.95129534 0.95378564 0.92032686 0.9394551 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.93      0.95      0.94      1005\n",
      "           3       0.93      0.94      0.93      1000\n",
      "           4       0.96      0.94      0.95      1000\n",
      "           5       0.94      0.93      0.93       904\n",
      "           6       0.96      0.95      0.95       965\n",
      "           7       0.94      0.95      0.95      1017\n",
      "           8       0.93      0.92      0.92       979\n",
      "           9       0.92      0.94      0.93       991\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 93: 9466 / 10000\n",
      "Accuracy = 94.66%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96       0.97969991 0.95049505 0.92716535 0.95060484 0.92841163\n",
      " 0.95341615 0.95019531 0.91573604 0.94591837]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.93      0.95      0.94      1010\n",
      "           3       0.93      0.93      0.93      1016\n",
      "           4       0.96      0.95      0.96       992\n",
      "           5       0.93      0.93      0.93       894\n",
      "           6       0.96      0.95      0.96       966\n",
      "           7       0.95      0.95      0.95      1024\n",
      "           8       0.93      0.92      0.92       985\n",
      "           9       0.92      0.95      0.93       980\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 94: 9468 / 10000\n",
      "Accuracy = 94.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95808383 0.98053097 0.95059289 0.93213573 0.95238095 0.93273543\n",
      " 0.94958848 0.95463511 0.91616162 0.93693694]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.98      0.98      0.98      1130\n",
      "           2       0.93      0.95      0.94      1012\n",
      "           3       0.92      0.93      0.93      1002\n",
      "           4       0.96      0.95      0.95       987\n",
      "           5       0.93      0.93      0.93       892\n",
      "           6       0.96      0.95      0.96       972\n",
      "           7       0.94      0.95      0.95      1014\n",
      "           8       0.93      0.92      0.92       990\n",
      "           9       0.93      0.94      0.93       999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 95: 9470 / 10000\n",
      "Accuracy = 94.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95517928 0.97885463 0.94995093 0.93020937 0.94858871 0.92849162\n",
      " 0.95124481 0.95742574 0.9178499  0.93951613]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1004\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.94      0.95      0.94      1019\n",
      "           3       0.92      0.93      0.93      1003\n",
      "           4       0.96      0.95      0.95       992\n",
      "           5       0.93      0.93      0.93       895\n",
      "           6       0.96      0.95      0.95       964\n",
      "           7       0.94      0.96      0.95      1010\n",
      "           8       0.93      0.92      0.92       986\n",
      "           9       0.92      0.94      0.93       992\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 96: 9464 / 10000\n",
      "Accuracy = 94.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95604396 0.97887324 0.95172414 0.93393393 0.95060484 0.93370787\n",
      " 0.95041322 0.94752187 0.91801619 0.94602851]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.94      0.95      0.94      1015\n",
      "           3       0.92      0.93      0.93       999\n",
      "           4       0.96      0.95      0.96       992\n",
      "           5       0.93      0.93      0.93       890\n",
      "           6       0.96      0.95      0.96       968\n",
      "           7       0.95      0.95      0.95      1029\n",
      "           8       0.93      0.92      0.92       988\n",
      "           9       0.92      0.95      0.93       982\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 97: 9473 / 10000\n",
      "Accuracy = 94.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96475327 0.97711268 0.956      0.92262488 0.94394394 0.93220339\n",
      " 0.95139607 0.94767442 0.91521961 0.94433198]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       993\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.93      0.96      0.94      1000\n",
      "           3       0.93      0.92      0.93      1021\n",
      "           4       0.96      0.94      0.95       999\n",
      "           5       0.92      0.93      0.93       885\n",
      "           6       0.96      0.95      0.96       967\n",
      "           7       0.95      0.95      0.95      1032\n",
      "           8       0.92      0.92      0.92       979\n",
      "           9       0.92      0.94      0.93       988\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 98: 9461 / 10000\n",
      "Accuracy = 94.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.9637827  0.9822695  0.95167653 0.92991115 0.94488978 0.93977273\n",
      " 0.94758479 0.95019531 0.9126506  0.94795918]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.98      0.98      0.98      1128\n",
      "           2       0.94      0.95      0.94      1014\n",
      "           3       0.93      0.93      0.93      1013\n",
      "           4       0.96      0.94      0.95       998\n",
      "           5       0.93      0.94      0.93       880\n",
      "           6       0.96      0.95      0.95       973\n",
      "           7       0.95      0.95      0.95      1024\n",
      "           8       0.93      0.91      0.92       996\n",
      "           9       0.92      0.95      0.93       980\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 99: 9476 / 10000\n",
      "Accuracy = 94.76%\n"
     ]
    }
   ],
   "source": [
    "net = network.Network([784, 30, 10])\n",
    "net.SGD(training_data, 100, 10, 0.5, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.91918208 0.95603448 0.9        0.87231969 0.87099903 0.8486917\n",
      " 0.9047619  0.91699605 0.89050279 0.88708037]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1027\n",
      "           1       0.98      0.96      0.97      1160\n",
      "           2       0.87      0.90      0.89      1000\n",
      "           3       0.89      0.87      0.88      1026\n",
      "           4       0.91      0.87      0.89      1031\n",
      "           5       0.84      0.85      0.84       879\n",
      "           6       0.93      0.90      0.92       987\n",
      "           7       0.90      0.92      0.91      1012\n",
      "           8       0.82      0.89      0.85       895\n",
      "           9       0.86      0.89      0.88       983\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 0: 8982 / 10000\n",
      "Accuracy = 89.82%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9295499  0.96858639 0.92697769 0.91794872 0.87321258 0.88333333\n",
      " 0.9185336  0.91321119 0.91028446 0.88978766]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1022\n",
      "           1       0.98      0.97      0.97      1146\n",
      "           2       0.89      0.93      0.91       986\n",
      "           3       0.89      0.92      0.90       975\n",
      "           4       0.93      0.87      0.90      1049\n",
      "           5       0.89      0.88      0.89       900\n",
      "           6       0.94      0.92      0.93       982\n",
      "           7       0.92      0.91      0.92      1037\n",
      "           8       0.85      0.91      0.88       914\n",
      "           9       0.87      0.89      0.88       989\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.91      0.91     10000\n",
      "\n",
      "Epoch 1: 9141 / 10000\n",
      "Accuracy = 91.41%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93365854 0.97120419 0.91658584 0.90818363 0.91683367 0.9212691\n",
      " 0.94899044 0.92585366 0.86600985 0.92546584]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1025\n",
      "           1       0.98      0.97      0.98      1146\n",
      "           2       0.92      0.92      0.92      1031\n",
      "           3       0.90      0.91      0.90      1002\n",
      "           4       0.93      0.92      0.92       998\n",
      "           5       0.88      0.92      0.90       851\n",
      "           6       0.93      0.95      0.94       941\n",
      "           7       0.92      0.93      0.92      1025\n",
      "           8       0.90      0.87      0.88      1015\n",
      "           9       0.89      0.93      0.91       966\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Epoch 2: 9239 / 10000\n",
      "Accuracy = 92.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94466403 0.9720524  0.90728477 0.92980671 0.94708423 0.89900111\n",
      " 0.94692144 0.92307692 0.90466321 0.89407191]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1012\n",
      "           1       0.98      0.97      0.98      1145\n",
      "           2       0.93      0.91      0.92      1057\n",
      "           3       0.90      0.93      0.92       983\n",
      "           4       0.89      0.95      0.92       926\n",
      "           5       0.91      0.90      0.90       901\n",
      "           6       0.93      0.95      0.94       942\n",
      "           7       0.93      0.92      0.93      1040\n",
      "           8       0.90      0.90      0.90       965\n",
      "           9       0.91      0.89      0.90      1029\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 3: 9274 / 10000\n",
      "Accuracy = 92.74%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95204795 0.9788173  0.94111776 0.92354125 0.92517695 0.95024272\n",
      " 0.92959184 0.90909091 0.86781609 0.92960663]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1001\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.91      0.94      0.93      1002\n",
      "           3       0.91      0.92      0.92       994\n",
      "           4       0.93      0.93      0.93       989\n",
      "           5       0.88      0.95      0.91       824\n",
      "           6       0.95      0.93      0.94       980\n",
      "           7       0.94      0.91      0.93      1067\n",
      "           8       0.93      0.87      0.90      1044\n",
      "           9       0.89      0.93      0.91       966\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 4: 9306 / 10000\n",
      "Accuracy = 93.06%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95039683 0.97132928 0.91858238 0.93421053 0.93904959 0.89666308\n",
      " 0.95430393 0.94610778 0.92099792 0.91459782]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1008\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.93      0.92      0.92      1044\n",
      "           3       0.91      0.93      0.92       988\n",
      "           4       0.93      0.94      0.93       968\n",
      "           5       0.93      0.90      0.91       929\n",
      "           6       0.94      0.95      0.95       941\n",
      "           7       0.92      0.95      0.93      1002\n",
      "           8       0.91      0.92      0.92       962\n",
      "           9       0.91      0.91      0.91      1007\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 5: 9353 / 10000\n",
      "Accuracy = 93.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96130346 0.97382199 0.93811395 0.93561368 0.92678034 0.92247191\n",
      " 0.91150442 0.91721543 0.9345301  0.94714588]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       982\n",
      "           1       0.98      0.97      0.98      1146\n",
      "           2       0.93      0.94      0.93      1018\n",
      "           3       0.92      0.94      0.93       994\n",
      "           4       0.94      0.93      0.93       997\n",
      "           5       0.92      0.92      0.92       890\n",
      "           6       0.97      0.91      0.94      1017\n",
      "           7       0.95      0.92      0.93      1063\n",
      "           8       0.91      0.93      0.92       947\n",
      "           9       0.89      0.95      0.92       946\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 6: 9373 / 10000\n",
      "Accuracy = 93.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94187192 0.97135417 0.93542074 0.94484168 0.91159136 0.9261745\n",
      " 0.93387589 0.93103448 0.92715921 0.94849785]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1015\n",
      "           1       0.99      0.97      0.98      1152\n",
      "           2       0.93      0.94      0.93      1022\n",
      "           3       0.92      0.94      0.93       979\n",
      "           4       0.95      0.91      0.93      1018\n",
      "           5       0.93      0.93      0.93       894\n",
      "           6       0.96      0.93      0.95       983\n",
      "           7       0.95      0.93      0.94      1044\n",
      "           8       0.91      0.93      0.92       961\n",
      "           9       0.88      0.95      0.91       932\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 7: 9377 / 10000\n",
      "Accuracy = 93.77%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93945312 0.97637795 0.94041708 0.92552135 0.95373291 0.92721165\n",
      " 0.93380855 0.94083414 0.93236212 0.92407592]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1024\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.92      0.94      0.93      1007\n",
      "           3       0.92      0.93      0.92      1007\n",
      "           4       0.92      0.95      0.94       951\n",
      "           5       0.93      0.93      0.93       893\n",
      "           6       0.96      0.93      0.95       982\n",
      "           7       0.94      0.94      0.94      1031\n",
      "           8       0.92      0.93      0.93       961\n",
      "           9       0.92      0.92      0.92      1001\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 8: 9400 / 10000\n",
      "Accuracy = 94.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94238281 0.97637795 0.9396637  0.92210321 0.92655936 0.95321637\n",
      " 0.93679918 0.95608782 0.91313131 0.9311408 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1024\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.92      0.94      0.93      1011\n",
      "           3       0.94      0.92      0.93      1027\n",
      "           4       0.94      0.93      0.93       994\n",
      "           5       0.91      0.95      0.93       855\n",
      "           6       0.96      0.94      0.95       981\n",
      "           7       0.93      0.96      0.94      1002\n",
      "           8       0.93      0.91      0.92       990\n",
      "           9       0.90      0.93      0.91       973\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 9: 9401 / 10000\n",
      "Accuracy = 94.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92226488 0.97727273 0.93972332 0.93718843 0.92445328 0.95925495\n",
      " 0.9454171  0.92761905 0.93677555 0.94190871]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1042\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.94      0.93      1012\n",
      "           3       0.93      0.94      0.93      1003\n",
      "           4       0.95      0.92      0.94      1006\n",
      "           5       0.92      0.96      0.94       859\n",
      "           6       0.96      0.95      0.95       971\n",
      "           7       0.95      0.93      0.94      1050\n",
      "           8       0.91      0.94      0.92       949\n",
      "           9       0.90      0.94      0.92       964\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 10: 9413 / 10000\n",
      "Accuracy = 94.13%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93792435 0.97727273 0.94047619 0.93818544 0.95258166 0.94959908\n",
      " 0.94709544 0.94960474 0.91717172 0.91325536]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1031\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.92      0.94      0.93      1008\n",
      "           3       0.93      0.94      0.93      1003\n",
      "           4       0.92      0.95      0.94       949\n",
      "           5       0.93      0.95      0.94       873\n",
      "           6       0.95      0.95      0.95       964\n",
      "           7       0.93      0.95      0.94      1012\n",
      "           8       0.93      0.92      0.92       990\n",
      "           9       0.93      0.91      0.92      1026\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 11: 9426 / 10000\n",
      "Accuracy = 94.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95252226 0.97142857 0.94664032 0.91795367 0.93340061 0.94318182\n",
      " 0.94341564 0.95364892 0.94099052 0.93367347]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1011\n",
      "           1       0.99      0.97      0.98      1155\n",
      "           2       0.93      0.95      0.94      1012\n",
      "           3       0.94      0.92      0.93      1036\n",
      "           4       0.94      0.93      0.94       991\n",
      "           5       0.93      0.94      0.94       880\n",
      "           6       0.96      0.94      0.95       972\n",
      "           7       0.94      0.95      0.95      1014\n",
      "           8       0.92      0.94      0.93       949\n",
      "           9       0.91      0.93      0.92       980\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 12: 9441 / 10000\n",
      "Accuracy = 94.41%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94031311 0.97476066 0.9441675  0.94170854 0.95056643 0.9537037\n",
      " 0.95005203 0.93422307 0.91851107 0.93447581]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1022\n",
      "           1       0.99      0.97      0.98      1149\n",
      "           2       0.92      0.94      0.93      1003\n",
      "           3       0.93      0.94      0.93       995\n",
      "           4       0.94      0.95      0.95       971\n",
      "           5       0.92      0.95      0.94       864\n",
      "           6       0.95      0.95      0.95       961\n",
      "           7       0.95      0.93      0.94      1049\n",
      "           8       0.94      0.92      0.93       994\n",
      "           9       0.92      0.93      0.93       992\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 13: 9445 / 10000\n",
      "Accuracy = 94.45%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95355731 0.96974935 0.92748092 0.95092025 0.95383001 0.94954128\n",
      " 0.9423275  0.9436346  0.93032787 0.9252988 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1012\n",
      "           1       0.99      0.97      0.98      1157\n",
      "           2       0.94      0.93      0.93      1048\n",
      "           3       0.92      0.95      0.94       978\n",
      "           4       0.93      0.95      0.94       953\n",
      "           5       0.93      0.95      0.94       872\n",
      "           6       0.96      0.94      0.95       971\n",
      "           7       0.94      0.94      0.94      1029\n",
      "           8       0.93      0.93      0.93       976\n",
      "           9       0.92      0.93      0.92      1004\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.95      0.94      0.95     10000\n",
      "\n",
      "Epoch 14: 9449 / 10000\n",
      "Accuracy = 94.49%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93695441 0.96649485 0.94736842 0.94111776 0.93591048 0.96041909\n",
      " 0.94279877 0.95252226 0.9382199  0.9246779 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1031\n",
      "           1       0.99      0.97      0.98      1164\n",
      "           2       0.92      0.95      0.94      1007\n",
      "           3       0.93      0.94      0.94      1002\n",
      "           4       0.94      0.94      0.94       983\n",
      "           5       0.92      0.96      0.94       859\n",
      "           6       0.96      0.94      0.95       979\n",
      "           7       0.94      0.95      0.94      1011\n",
      "           8       0.92      0.94      0.93       955\n",
      "           9       0.92      0.92      0.92      1009\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.95      0.94      0.94     10000\n",
      "\n",
      "Epoch 15: 9448 / 10000\n",
      "Accuracy = 94.48%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95069034 0.97558849 0.94238281 0.92934249 0.94917012 0.92240437\n",
      " 0.9539749  0.94482091 0.95171674 0.92871486]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1014\n",
      "           1       0.99      0.98      0.98      1147\n",
      "           2       0.94      0.94      0.94      1024\n",
      "           3       0.94      0.93      0.93      1019\n",
      "           4       0.93      0.95      0.94       964\n",
      "           5       0.95      0.92      0.93       915\n",
      "           6       0.95      0.95      0.95       956\n",
      "           7       0.95      0.94      0.95      1033\n",
      "           8       0.91      0.95      0.93       932\n",
      "           9       0.92      0.93      0.92       996\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 16: 9454 / 10000\n",
      "Accuracy = 94.54%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94335938 0.97727273 0.94129159 0.94094094 0.94129555 0.95591647\n",
      " 0.96459227 0.94225217 0.91351889 0.93699187]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1024\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.93      0.94      0.94      1022\n",
      "           3       0.93      0.94      0.94       999\n",
      "           4       0.95      0.94      0.94       988\n",
      "           5       0.92      0.96      0.94       862\n",
      "           6       0.94      0.96      0.95       932\n",
      "           7       0.95      0.94      0.95      1039\n",
      "           8       0.94      0.91      0.93      1006\n",
      "           9       0.91      0.94      0.93       984\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 17: 9459 / 10000\n",
      "Accuracy = 94.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95341923 0.97132928 0.953      0.93743693 0.95661376 0.92572062\n",
      " 0.95502092 0.95270936 0.92944785 0.90123457]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1009\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.92      0.95      0.94      1000\n",
      "           3       0.92      0.94      0.93       991\n",
      "           4       0.92      0.96      0.94       945\n",
      "           5       0.94      0.93      0.93       902\n",
      "           6       0.95      0.96      0.95       956\n",
      "           7       0.94      0.95      0.95      1015\n",
      "           8       0.93      0.93      0.93       978\n",
      "           9       0.94      0.90      0.92      1053\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 18: 9439 / 10000\n",
      "Accuracy = 94.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96374622 0.96810345 0.92857143 0.9526749  0.94189602 0.94031532\n",
      " 0.94438723 0.94990177 0.94160584 0.92857143]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       993\n",
      "           1       0.99      0.97      0.98      1160\n",
      "           2       0.94      0.93      0.94      1050\n",
      "           3       0.92      0.95      0.93       972\n",
      "           4       0.94      0.94      0.94       981\n",
      "           5       0.94      0.94      0.94       888\n",
      "           6       0.96      0.94      0.95       971\n",
      "           7       0.94      0.95      0.95      1018\n",
      "           8       0.93      0.94      0.93       959\n",
      "           9       0.93      0.93      0.93      1008\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 19: 9463 / 10000\n",
      "Accuracy = 94.63%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95059289 0.97560976 0.94856578 0.93523062 0.95511482 0.94256757\n",
      " 0.95886076 0.93467819 0.91691692 0.94057377]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1012\n",
      "           1       0.99      0.98      0.98      1148\n",
      "           2       0.93      0.95      0.94      1011\n",
      "           3       0.94      0.94      0.94      1019\n",
      "           4       0.93      0.96      0.94       958\n",
      "           5       0.94      0.94      0.94       888\n",
      "           6       0.95      0.96      0.95       948\n",
      "           7       0.95      0.93      0.94      1041\n",
      "           8       0.94      0.92      0.93       999\n",
      "           9       0.91      0.94      0.92       976\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 20: 9462 / 10000\n",
      "Accuracy = 94.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.957      0.97725284 0.94406281 0.9526749  0.92193676 0.94130926\n",
      " 0.94747683 0.94711068 0.91226321 0.9331963 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.93      0.94      0.94      1019\n",
      "           3       0.92      0.95      0.93       972\n",
      "           4       0.95      0.92      0.94      1012\n",
      "           5       0.93      0.94      0.94       886\n",
      "           6       0.96      0.95      0.95       971\n",
      "           7       0.94      0.95      0.94      1021\n",
      "           8       0.94      0.91      0.93      1003\n",
      "           9       0.90      0.93      0.92       973\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 21: 9439 / 10000\n",
      "Accuracy = 94.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9488189  0.97727273 0.94871795 0.92878049 0.95802728 0.94469526\n",
      " 0.9524302  0.94385286 0.94392523 0.93393393]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1016\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.93      0.95      0.94      1014\n",
      "           3       0.94      0.93      0.94      1025\n",
      "           4       0.93      0.96      0.94       953\n",
      "           5       0.94      0.94      0.94       886\n",
      "           6       0.96      0.95      0.96       967\n",
      "           7       0.95      0.94      0.95      1033\n",
      "           8       0.93      0.94      0.94       963\n",
      "           9       0.92      0.93      0.93       999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 22: 9484 / 10000\n",
      "Accuracy = 94.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95341923 0.97735192 0.94705882 0.93557978 0.94580777 0.94982896\n",
      " 0.95746888 0.94660194 0.93911249 0.93574297]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1009\n",
      "           1       0.99      0.98      0.98      1148\n",
      "           2       0.94      0.95      0.94      1020\n",
      "           3       0.93      0.94      0.94      1009\n",
      "           4       0.94      0.95      0.94       978\n",
      "           5       0.93      0.95      0.94       877\n",
      "           6       0.96      0.96      0.96       964\n",
      "           7       0.95      0.95      0.95      1030\n",
      "           8       0.93      0.94      0.94       969\n",
      "           9       0.92      0.94      0.93       996\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 23: 9492 / 10000\n",
      "Accuracy = 94.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95522388 0.97476066 0.94346979 0.92898833 0.94105691 0.94677237\n",
      " 0.96206533 0.93942308 0.95440085 0.93454179]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1005\n",
      "           1       0.99      0.97      0.98      1149\n",
      "           2       0.94      0.94      0.94      1026\n",
      "           3       0.95      0.93      0.94      1028\n",
      "           4       0.94      0.94      0.94       984\n",
      "           5       0.94      0.95      0.94       883\n",
      "           6       0.95      0.96      0.96       949\n",
      "           7       0.95      0.94      0.94      1040\n",
      "           8       0.92      0.95      0.94       943\n",
      "           9       0.92      0.93      0.93       993\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 24: 9483 / 10000\n",
      "Accuracy = 94.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95332671 0.97816594 0.94243902 0.94322709 0.94455852 0.94851259\n",
      " 0.94758479 0.95459033 0.91616766 0.93997965]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1007\n",
      "           1       0.99      0.98      0.98      1145\n",
      "           2       0.94      0.94      0.94      1025\n",
      "           3       0.94      0.94      0.94      1004\n",
      "           4       0.94      0.94      0.94       974\n",
      "           5       0.93      0.95      0.94       874\n",
      "           6       0.96      0.95      0.95       973\n",
      "           7       0.94      0.95      0.95      1013\n",
      "           8       0.94      0.92      0.93      1002\n",
      "           9       0.92      0.94      0.93       983\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 25: 9473 / 10000\n",
      "Accuracy = 94.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95059289 0.98068481 0.94664032 0.9473151  0.91723466 0.92982456\n",
      " 0.96202532 0.94891945 0.92588832 0.946875  ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1012\n",
      "           1       0.98      0.98      0.98      1139\n",
      "           2       0.93      0.95      0.94      1012\n",
      "           3       0.93      0.95      0.94       987\n",
      "           4       0.96      0.92      0.94      1027\n",
      "           5       0.95      0.93      0.94       912\n",
      "           6       0.95      0.96      0.96       948\n",
      "           7       0.94      0.95      0.94      1018\n",
      "           8       0.94      0.93      0.93       985\n",
      "           9       0.90      0.95      0.92       960\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 26: 9461 / 10000\n",
      "Accuracy = 94.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96277666 0.97896582 0.95770393 0.92130518 0.94611399 0.95319635\n",
      " 0.96008403 0.9510284  0.92690355 0.91367604]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.92      0.96      0.94       993\n",
      "           3       0.95      0.92      0.94      1042\n",
      "           4       0.93      0.95      0.94       965\n",
      "           5       0.94      0.95      0.94       876\n",
      "           6       0.95      0.96      0.96       952\n",
      "           7       0.94      0.95      0.95      1021\n",
      "           8       0.94      0.93      0.93       985\n",
      "           9       0.93      0.91      0.92      1031\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 27: 9473 / 10000\n",
      "Accuracy = 94.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95039683 0.97731239 0.9459725  0.95252838 0.93825911 0.93541203\n",
      " 0.95346432 0.92401501 0.93340164 0.94709544]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1008\n",
      "           1       0.99      0.98      0.98      1146\n",
      "           2       0.93      0.95      0.94      1018\n",
      "           3       0.91      0.95      0.93       969\n",
      "           4       0.94      0.94      0.94       988\n",
      "           5       0.94      0.94      0.94       898\n",
      "           6       0.96      0.95      0.96       967\n",
      "           7       0.96      0.92      0.94      1066\n",
      "           8       0.94      0.93      0.93       976\n",
      "           9       0.90      0.95      0.93       964\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 28: 9462 / 10000\n",
      "Accuracy = 94.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96285141 0.97648084 0.93804453 0.93781344 0.94111675 0.94909502\n",
      " 0.96398305 0.95       0.9331963  0.92254902]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.99      0.98      0.98      1148\n",
      "           2       0.94      0.94      0.94      1033\n",
      "           3       0.93      0.94      0.93       997\n",
      "           4       0.94      0.94      0.94       985\n",
      "           5       0.94      0.95      0.94       884\n",
      "           6       0.95      0.96      0.96       944\n",
      "           7       0.94      0.95      0.95      1020\n",
      "           8       0.93      0.93      0.93       973\n",
      "           9       0.93      0.92      0.93      1020\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 29: 9478 / 10000\n",
      "Accuracy = 94.78%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95721393 0.97643979 0.94266278 0.95097038 0.93649194 0.94288914\n",
      " 0.95811518 0.94401544 0.9195171  0.94747683]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1005\n",
      "           1       0.99      0.98      0.98      1146\n",
      "           2       0.94      0.94      0.94      1029\n",
      "           3       0.92      0.95      0.94       979\n",
      "           4       0.95      0.94      0.94       992\n",
      "           5       0.94      0.94      0.94       893\n",
      "           6       0.96      0.96      0.96       955\n",
      "           7       0.95      0.94      0.95      1036\n",
      "           8       0.94      0.92      0.93       994\n",
      "           9       0.91      0.95      0.93       971\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 30: 9480 / 10000\n",
      "Accuracy = 94.80%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95904096 0.97222222 0.94330401 0.94326241 0.94871795 0.93645485\n",
      " 0.95828989 0.94573643 0.94654088 0.92352941]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.99      0.97      0.98      1152\n",
      "           2       0.94      0.94      0.94      1023\n",
      "           3       0.92      0.94      0.93       987\n",
      "           4       0.94      0.95      0.95       975\n",
      "           5       0.94      0.94      0.94       897\n",
      "           6       0.96      0.96      0.96       959\n",
      "           7       0.95      0.95      0.95      1032\n",
      "           8       0.93      0.95      0.94       954\n",
      "           9       0.93      0.92      0.93      1020\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 31: 9481 / 10000\n",
      "Accuracy = 94.81%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95054402 0.97311362 0.942607   0.94182548 0.9590766  0.95727483\n",
      " 0.95738046 0.95107632 0.93538462 0.91771539]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1011\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.94      0.94      0.94      1028\n",
      "           3       0.93      0.94      0.94       997\n",
      "           4       0.93      0.96      0.94       953\n",
      "           5       0.93      0.96      0.94       866\n",
      "           6       0.96      0.96      0.96       962\n",
      "           7       0.95      0.95      0.95      1022\n",
      "           8       0.94      0.94      0.94       975\n",
      "           9       0.94      0.92      0.93      1033\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 32: 9487 / 10000\n",
      "Accuracy = 94.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95721393 0.96804836 0.94618395 0.93418468 0.932      0.96082949\n",
      " 0.9662803  0.94044188 0.95348837 0.93353474]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1005\n",
      "           1       0.99      0.97      0.98      1158\n",
      "           2       0.94      0.95      0.94      1022\n",
      "           3       0.94      0.93      0.94      1018\n",
      "           4       0.95      0.93      0.94      1000\n",
      "           5       0.93      0.96      0.95       868\n",
      "           6       0.96      0.97      0.96       949\n",
      "           7       0.95      0.94      0.95      1041\n",
      "           8       0.93      0.95      0.94       946\n",
      "           9       0.92      0.93      0.93       993\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 33: 9492 / 10000\n",
      "Accuracy = 94.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.957      0.97224631 0.93557692 0.94657258 0.94242424 0.94314381\n",
      " 0.95459236 0.94757282 0.95638298 0.93731041]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.94      0.94      0.94      1040\n",
      "           3       0.93      0.95      0.94       992\n",
      "           4       0.95      0.94      0.95       990\n",
      "           5       0.95      0.94      0.95       897\n",
      "           6       0.97      0.95      0.96       969\n",
      "           7       0.95      0.95      0.95      1030\n",
      "           8       0.92      0.96      0.94       940\n",
      "           9       0.92      0.94      0.93       989\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 34: 9496 / 10000\n",
      "Accuracy = 94.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96767677 0.97145329 0.93288591 0.94934144 0.93951613 0.93122271\n",
      " 0.9640592  0.94762367 0.95233051 0.93567839]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       990\n",
      "           1       0.99      0.97      0.98      1156\n",
      "           2       0.94      0.93      0.94      1043\n",
      "           3       0.93      0.95      0.94       987\n",
      "           4       0.95      0.94      0.94       992\n",
      "           5       0.96      0.93      0.94       916\n",
      "           6       0.95      0.96      0.96       946\n",
      "           7       0.95      0.95      0.95      1031\n",
      "           8       0.92      0.95      0.94       944\n",
      "           9       0.92      0.94      0.93       995\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 35: 9495 / 10000\n",
      "Accuracy = 94.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95895896 0.97478261 0.95261599 0.94023904 0.94421907 0.95647194\n",
      " 0.95652174 0.9414025  0.93367347 0.93724696]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.99      0.97      0.98      1150\n",
      "           2       0.94      0.95      0.94      1013\n",
      "           3       0.93      0.94      0.94      1004\n",
      "           4       0.95      0.94      0.95       986\n",
      "           5       0.94      0.96      0.95       873\n",
      "           6       0.96      0.96      0.96       966\n",
      "           7       0.95      0.94      0.95      1041\n",
      "           8       0.94      0.93      0.94       980\n",
      "           9       0.92      0.94      0.93       988\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 36: 9499 / 10000\n",
      "Accuracy = 94.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95712861 0.96974935 0.94422701 0.95174538 0.95020747 0.94683258\n",
      " 0.96020942 0.94026975 0.92439516 0.9297725 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1003\n",
      "           1       0.99      0.97      0.98      1157\n",
      "           2       0.94      0.94      0.94      1022\n",
      "           3       0.92      0.95      0.93       974\n",
      "           4       0.93      0.95      0.94       964\n",
      "           5       0.94      0.95      0.94       884\n",
      "           6       0.96      0.96      0.96       955\n",
      "           7       0.95      0.94      0.94      1038\n",
      "           8       0.94      0.92      0.93       992\n",
      "           9       0.93      0.93      0.93      1011\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 37: 9477 / 10000\n",
      "Accuracy = 94.77%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95808383 0.97480452 0.94623656 0.94641052 0.94591837 0.95130238\n",
      " 0.95850622 0.93942308 0.9392379  0.93079238]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.94      0.95      0.94      1023\n",
      "           3       0.93      0.95      0.94       989\n",
      "           4       0.94      0.95      0.94       980\n",
      "           5       0.94      0.95      0.95       883\n",
      "           6       0.96      0.96      0.96       964\n",
      "           7       0.95      0.94      0.94      1040\n",
      "           8       0.94      0.94      0.94       971\n",
      "           9       0.92      0.93      0.93       997\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 38: 9494 / 10000\n",
      "Accuracy = 94.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95337302 0.97807018 0.95337302 0.942      0.93034826 0.94432071\n",
      " 0.95548654 0.95746785 0.93279022 0.93991853]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1008\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.93      0.95      0.94      1008\n",
      "           3       0.93      0.94      0.94      1000\n",
      "           4       0.95      0.93      0.94      1005\n",
      "           5       0.95      0.94      0.95       898\n",
      "           6       0.96      0.96      0.96       966\n",
      "           7       0.94      0.96      0.95      1011\n",
      "           8       0.94      0.93      0.94       982\n",
      "           9       0.91      0.94      0.93       982\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 39: 9492 / 10000\n",
      "Accuracy = 94.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96088265 0.97478261 0.94563107 0.93924303 0.93781344 0.94512878\n",
      " 0.95850622 0.94660194 0.9477534  0.94171779]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.99      0.97      0.98      1150\n",
      "           2       0.94      0.95      0.94      1030\n",
      "           3       0.93      0.94      0.94      1004\n",
      "           4       0.95      0.94      0.94       997\n",
      "           5       0.95      0.95      0.95       893\n",
      "           6       0.96      0.96      0.96       964\n",
      "           7       0.95      0.95      0.95      1030\n",
      "           8       0.93      0.95      0.94       957\n",
      "           9       0.91      0.94      0.93       978\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 40: 9502 / 10000\n",
      "Accuracy = 95.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95704296 0.97061366 0.95445545 0.93096647 0.94758479 0.93384785\n",
      " 0.9625     0.94854369 0.96030043 0.9261811 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.99      0.97      0.98      1157\n",
      "           2       0.93      0.95      0.94      1010\n",
      "           3       0.93      0.93      0.93      1014\n",
      "           4       0.94      0.95      0.94       973\n",
      "           5       0.95      0.93      0.94       907\n",
      "           6       0.96      0.96      0.96       960\n",
      "           7       0.95      0.95      0.95      1030\n",
      "           8       0.92      0.96      0.94       932\n",
      "           9       0.93      0.93      0.93      1016\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 41: 9495 / 10000\n",
      "Accuracy = 94.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96356275 0.97814685 0.94726562 0.93836978 0.9402229  0.93687708\n",
      " 0.95950156 0.93948127 0.95440085 0.92807193]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       988\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.94      0.95      0.94      1024\n",
      "           3       0.93      0.94      0.94      1006\n",
      "           4       0.95      0.94      0.94       987\n",
      "           5       0.95      0.94      0.94       903\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.95      0.94      0.95      1041\n",
      "           8       0.92      0.95      0.94       943\n",
      "           9       0.92      0.93      0.92      1001\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 42: 9490 / 10000\n",
      "Accuracy = 94.90%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96461072 0.98075241 0.95167653 0.93333333 0.93838384 0.95727483\n",
      " 0.95539419 0.94439024 0.91791792 0.93034826]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       989\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.94      0.95      0.94      1014\n",
      "           3       0.93      0.93      0.93      1005\n",
      "           4       0.95      0.94      0.94       990\n",
      "           5       0.93      0.96      0.94       866\n",
      "           6       0.96      0.96      0.96       964\n",
      "           7       0.94      0.94      0.94      1025\n",
      "           8       0.94      0.92      0.93       999\n",
      "           9       0.93      0.93      0.93      1005\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 43: 9477 / 10000\n",
      "Accuracy = 94.77%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96003996 0.97476066 0.9436346  0.94752775 0.94892748 0.95238095\n",
      " 0.95760083 0.93869732 0.93551689 0.94495413]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.99      0.97      0.98      1149\n",
      "           2       0.94      0.94      0.94      1029\n",
      "           3       0.93      0.95      0.94       991\n",
      "           4       0.95      0.95      0.95       979\n",
      "           5       0.94      0.95      0.95       882\n",
      "           6       0.97      0.96      0.96       967\n",
      "           7       0.95      0.94      0.95      1044\n",
      "           8       0.94      0.94      0.94       977\n",
      "           9       0.92      0.94      0.93       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 44: 9507 / 10000\n",
      "Accuracy = 95.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95054402 0.97814685 0.93840231 0.94944388 0.93141153 0.95542857\n",
      " 0.96041667 0.94423077 0.93654043 0.95099062]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1011\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.94      0.94      0.94      1039\n",
      "           3       0.93      0.95      0.94       989\n",
      "           4       0.95      0.93      0.94      1006\n",
      "           5       0.94      0.96      0.95       875\n",
      "           6       0.96      0.96      0.96       960\n",
      "           7       0.96      0.94      0.95      1040\n",
      "           8       0.94      0.94      0.94       977\n",
      "           9       0.90      0.95      0.93       959\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 45: 9498 / 10000\n",
      "Accuracy = 94.98%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96374622 0.97480452 0.9436346  0.94242424 0.94958848 0.94400896\n",
      " 0.95272354 0.95191364 0.93942505 0.93141153]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       993\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.94      0.94      0.94      1029\n",
      "           3       0.92      0.94      0.93       990\n",
      "           4       0.94      0.95      0.94       972\n",
      "           5       0.95      0.94      0.94       893\n",
      "           6       0.97      0.95      0.96       973\n",
      "           7       0.94      0.95      0.95      1019\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.93      0.93      0.93      1006\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 46: 9498 / 10000\n",
      "Accuracy = 94.98%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95427435 0.97393571 0.95238095 0.91819057 0.95426195 0.95717593\n",
      " 0.94964029 0.9325736  0.94942044 0.93467337]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1006\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.93      0.95      0.94      1008\n",
      "           3       0.94      0.92      0.93      1039\n",
      "           4       0.93      0.95      0.94       962\n",
      "           5       0.93      0.96      0.94       864\n",
      "           6       0.96      0.95      0.96       973\n",
      "           7       0.96      0.93      0.94      1053\n",
      "           8       0.93      0.95      0.94       949\n",
      "           9       0.92      0.93      0.93       995\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 47: 9477 / 10000\n",
      "Accuracy = 94.77%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96767677 0.97731239 0.94439024 0.91899711 0.94785276 0.95189003\n",
      " 0.95282051 0.95014663 0.94786236 0.93963783]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       990\n",
      "           1       0.99      0.98      0.98      1146\n",
      "           2       0.94      0.94      0.94      1025\n",
      "           3       0.94      0.92      0.93      1037\n",
      "           4       0.94      0.95      0.95       978\n",
      "           5       0.93      0.95      0.94       873\n",
      "           6       0.97      0.95      0.96       975\n",
      "           7       0.95      0.95      0.95      1023\n",
      "           8       0.93      0.95      0.94       959\n",
      "           9       0.93      0.94      0.93       994\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 48: 9501 / 10000\n",
      "Accuracy = 95.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96281407 0.97395833 0.9407767  0.9445005  0.92443572 0.9481398\n",
      " 0.95760083 0.9456838  0.9468196  0.94427245]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       995\n",
      "           1       0.99      0.97      0.98      1152\n",
      "           2       0.94      0.94      0.94      1030\n",
      "           3       0.93      0.94      0.94       991\n",
      "           4       0.96      0.92      0.94      1019\n",
      "           5       0.94      0.95      0.95       887\n",
      "           6       0.97      0.96      0.96       967\n",
      "           7       0.95      0.95      0.95      1031\n",
      "           8       0.93      0.95      0.94       959\n",
      "           9       0.91      0.94      0.93       969\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 49: 9492 / 10000\n",
      "Accuracy = 94.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96084337 0.97902098 0.94525904 0.94331984 0.93606394 0.93267108\n",
      " 0.95841996 0.94741967 0.94008264 0.93705584]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.94      0.95      0.94      1023\n",
      "           3       0.92      0.94      0.93       988\n",
      "           4       0.95      0.94      0.95      1001\n",
      "           5       0.95      0.93      0.94       906\n",
      "           6       0.96      0.96      0.96       962\n",
      "           7       0.95      0.95      0.95      1027\n",
      "           8       0.93      0.94      0.94       968\n",
      "           9       0.91      0.94      0.93       985\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 50: 9486 / 10000\n",
      "Accuracy = 94.86%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96385542 0.97227036 0.94449854 0.93806194 0.95793901 0.94400896\n",
      " 0.95454545 0.94379845 0.94979079 0.92074364]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.99      0.97      0.98      1154\n",
      "           2       0.94      0.94      0.94      1027\n",
      "           3       0.93      0.94      0.93      1001\n",
      "           4       0.93      0.96      0.94       951\n",
      "           5       0.95      0.94      0.94       893\n",
      "           6       0.96      0.95      0.96       968\n",
      "           7       0.95      0.94      0.95      1032\n",
      "           8       0.93      0.95      0.94       956\n",
      "           9       0.93      0.92      0.93      1022\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 51: 9492 / 10000\n",
      "Accuracy = 94.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96478873 0.97309028 0.94705882 0.93287266 0.94887526 0.94282511\n",
      " 0.95833333 0.94916911 0.9458897  0.92750745]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.99      0.97      0.98      1152\n",
      "           2       0.94      0.95      0.94      1020\n",
      "           3       0.94      0.93      0.93      1013\n",
      "           4       0.95      0.95      0.95       978\n",
      "           5       0.94      0.94      0.94       892\n",
      "           6       0.96      0.96      0.96       960\n",
      "           7       0.94      0.95      0.95      1023\n",
      "           8       0.93      0.95      0.94       961\n",
      "           9       0.93      0.93      0.93      1007\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 52: 9494 / 10000\n",
      "Accuracy = 94.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96582915 0.97563098 0.94644596 0.94619289 0.94591837 0.9369469\n",
      " 0.95945946 0.94767442 0.94220846 0.9327984 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       995\n",
      "           1       0.99      0.98      0.98      1149\n",
      "           2       0.94      0.95      0.94      1027\n",
      "           3       0.92      0.95      0.93       985\n",
      "           4       0.94      0.95      0.94       980\n",
      "           5       0.95      0.94      0.94       904\n",
      "           6       0.96      0.96      0.96       962\n",
      "           7       0.95      0.95      0.95      1032\n",
      "           8       0.94      0.94      0.94       969\n",
      "           9       0.92      0.93      0.93       997\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 53: 9504 / 10000\n",
      "Accuracy = 95.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.961      0.97896582 0.95544554 0.91980676 0.94360524 0.95727483\n",
      " 0.96029258 0.95307918 0.93995859 0.92765114]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.94      0.96      0.95      1010\n",
      "           3       0.94      0.92      0.93      1035\n",
      "           4       0.95      0.94      0.95       993\n",
      "           5       0.93      0.96      0.94       866\n",
      "           6       0.96      0.96      0.96       957\n",
      "           7       0.95      0.95      0.95      1023\n",
      "           8       0.93      0.94      0.94       966\n",
      "           9       0.93      0.93      0.93      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 54: 9499 / 10000\n",
      "Accuracy = 94.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96007984 0.97733217 0.9436346  0.937251   0.93881645 0.94808126\n",
      " 0.95742471 0.94487427 0.94160584 0.94075587]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.99      0.98      0.98      1147\n",
      "           2       0.94      0.94      0.94      1029\n",
      "           3       0.93      0.94      0.93      1004\n",
      "           4       0.95      0.94      0.95       997\n",
      "           5       0.94      0.95      0.94       886\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.95      0.94      0.95      1034\n",
      "           8       0.93      0.94      0.93       959\n",
      "           9       0.91      0.94      0.93       979\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 55: 9494 / 10000\n",
      "Accuracy = 94.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95904096 0.96724138 0.94449854 0.92563601 0.9477459  0.95896835\n",
      " 0.95454545 0.94294004 0.9468196  0.936     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.99      0.97      0.98      1160\n",
      "           2       0.94      0.94      0.94      1027\n",
      "           3       0.94      0.93      0.93      1022\n",
      "           4       0.94      0.95      0.94       976\n",
      "           5       0.92      0.96      0.94       853\n",
      "           6       0.96      0.95      0.96       968\n",
      "           7       0.95      0.94      0.95      1034\n",
      "           8       0.93      0.95      0.94       959\n",
      "           9       0.93      0.94      0.93      1000\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 56: 9484 / 10000\n",
      "Accuracy = 94.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.959      0.97224631 0.94736842 0.94523327 0.94661191 0.95016988\n",
      " 0.95755694 0.94332373 0.94392523 0.92757937]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.94      0.95      0.94      1026\n",
      "           3       0.92      0.95      0.93       986\n",
      "           4       0.94      0.95      0.94       974\n",
      "           5       0.94      0.95      0.95       883\n",
      "           6       0.97      0.96      0.96       966\n",
      "           7       0.96      0.94      0.95      1041\n",
      "           8       0.93      0.94      0.94       963\n",
      "           9       0.93      0.93      0.93      1008\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 57: 9496 / 10000\n",
      "Accuracy = 94.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96096096 0.97311362 0.94015444 0.94444444 0.95041322 0.9478458\n",
      " 0.95828989 0.95088409 0.94208893 0.9192607 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.94      0.94      0.94      1036\n",
      "           3       0.93      0.94      0.93       990\n",
      "           4       0.94      0.95      0.94       968\n",
      "           5       0.94      0.95      0.94       882\n",
      "           6       0.96      0.96      0.96       959\n",
      "           7       0.94      0.95      0.95      1018\n",
      "           8       0.94      0.94      0.94       967\n",
      "           9       0.94      0.92      0.93      1028\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 58: 9490 / 10000\n",
      "Accuracy = 94.90%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96770938 0.9730669  0.94731707 0.93830846 0.94195519 0.94295302\n",
      " 0.95174538 0.95307918 0.94154489 0.93781344]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       991\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.94      0.95      0.94      1025\n",
      "           3       0.93      0.94      0.94      1005\n",
      "           4       0.94      0.94      0.94       982\n",
      "           5       0.95      0.94      0.94       894\n",
      "           6       0.97      0.95      0.96       974\n",
      "           7       0.95      0.95      0.95      1023\n",
      "           8       0.93      0.94      0.93       958\n",
      "           9       0.93      0.94      0.93       997\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 59: 9500 / 10000\n",
      "Accuracy = 95.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96292585 0.97812773 0.94089147 0.93280632 0.94779939 0.94713161\n",
      " 0.95755694 0.95121951 0.94858342 0.93432836]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       998\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.94      0.94      0.94      1032\n",
      "           3       0.93      0.93      0.93      1012\n",
      "           4       0.94      0.95      0.95       977\n",
      "           5       0.94      0.95      0.95       889\n",
      "           6       0.97      0.96      0.96       966\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.93      0.95      0.94       953\n",
      "           9       0.93      0.93      0.93      1005\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 60: 9505 / 10000\n",
      "Accuracy = 95.05%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9582505  0.97393571 0.94731707 0.94461229 0.93787575 0.94363021\n",
      " 0.96230366 0.9360687  0.93904959 0.94427245]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1006\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.94      0.95      0.94      1025\n",
      "           3       0.93      0.94      0.94       993\n",
      "           4       0.95      0.94      0.95       998\n",
      "           5       0.94      0.94      0.94       887\n",
      "           6       0.96      0.96      0.96       955\n",
      "           7       0.95      0.94      0.95      1048\n",
      "           8       0.93      0.94      0.94       968\n",
      "           9       0.91      0.94      0.93       969\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 61: 9491 / 10000\n",
      "Accuracy = 94.91%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96572581 0.97646033 0.94552529 0.94005994 0.94159114 0.94576271\n",
      " 0.95950156 0.94762367 0.9411157  0.93649194]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       992\n",
      "           1       0.99      0.98      0.98      1147\n",
      "           2       0.94      0.95      0.94      1028\n",
      "           3       0.93      0.94      0.94      1001\n",
      "           4       0.95      0.94      0.95       993\n",
      "           5       0.94      0.95      0.94       885\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.95      0.95      0.95      1031\n",
      "           8       0.94      0.94      0.94       968\n",
      "           9       0.92      0.94      0.93       992\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 62: 9504 / 10000\n",
      "Accuracy = 95.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96767677 0.97391304 0.94277401 0.94337715 0.93957704 0.93854749\n",
      " 0.95945946 0.95557749 0.93505155 0.9285005 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       990\n",
      "           1       0.99      0.97      0.98      1150\n",
      "           2       0.94      0.94      0.94      1031\n",
      "           3       0.92      0.94      0.93       989\n",
      "           4       0.95      0.94      0.94       993\n",
      "           5       0.94      0.94      0.94       895\n",
      "           6       0.96      0.96      0.96       962\n",
      "           7       0.94      0.96      0.95      1013\n",
      "           8       0.93      0.94      0.93       970\n",
      "           9       0.93      0.93      0.93      1007\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 63: 9489 / 10000\n",
      "Accuracy = 94.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95908184 0.9730669  0.94736842 0.9320197  0.93768844 0.95016988\n",
      " 0.95950156 0.94916911 0.94369135 0.94201424]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.94      0.95      0.94      1026\n",
      "           3       0.94      0.93      0.93      1015\n",
      "           4       0.95      0.94      0.94       995\n",
      "           5       0.94      0.95      0.95       883\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.94      0.95      0.95      1023\n",
      "           8       0.93      0.94      0.94       959\n",
      "           9       0.92      0.94      0.93       983\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 64: 9497 / 10000\n",
      "Accuracy = 94.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96576032 0.97554585 0.94449854 0.92752204 0.93963783 0.95298165\n",
      " 0.95751295 0.959285   0.93075356 0.93762575]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       993\n",
      "           1       0.98      0.98      0.98      1145\n",
      "           2       0.94      0.94      0.94      1027\n",
      "           3       0.94      0.93      0.93      1021\n",
      "           4       0.95      0.94      0.95       994\n",
      "           5       0.93      0.95      0.94       872\n",
      "           6       0.96      0.96      0.96       965\n",
      "           7       0.94      0.96      0.95      1007\n",
      "           8       0.94      0.93      0.93       982\n",
      "           9       0.92      0.94      0.93       994\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 65: 9494 / 10000\n",
      "Accuracy = 94.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96188566 0.97727273 0.94660194 0.93912176 0.9494324  0.94500561\n",
      " 0.9623431  0.94829268 0.93163265 0.93439364]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.99      0.98      0.98      1144\n",
      "           2       0.94      0.95      0.95      1030\n",
      "           3       0.93      0.94      0.94      1002\n",
      "           4       0.94      0.95      0.94       969\n",
      "           5       0.94      0.95      0.94       891\n",
      "           6       0.96      0.96      0.96       956\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.94      0.93      0.93       980\n",
      "           9       0.93      0.93      0.93      1006\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 66: 9500 / 10000\n",
      "Accuracy = 95.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95812562 0.96969697 0.94374394 0.94259819 0.94421907 0.94044944\n",
      " 0.96402116 0.94563107 0.93698347 0.93593594]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1003\n",
      "           1       0.99      0.97      0.98      1155\n",
      "           2       0.94      0.94      0.94      1031\n",
      "           3       0.93      0.94      0.93       993\n",
      "           4       0.95      0.94      0.95       986\n",
      "           5       0.94      0.94      0.94       890\n",
      "           6       0.95      0.96      0.96       945\n",
      "           7       0.95      0.95      0.95      1030\n",
      "           8       0.93      0.94      0.93       968\n",
      "           9       0.93      0.94      0.93       999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 67: 9485 / 10000\n",
      "Accuracy = 94.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96767677 0.97227036 0.95167653 0.92998028 0.93606394 0.93875278\n",
      " 0.95674562 0.94980315 0.94852941 0.94141414]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       990\n",
      "           1       0.99      0.97      0.98      1154\n",
      "           2       0.94      0.95      0.94      1014\n",
      "           3       0.93      0.93      0.93      1014\n",
      "           4       0.95      0.94      0.95      1001\n",
      "           5       0.95      0.94      0.94       898\n",
      "           6       0.97      0.96      0.96       971\n",
      "           7       0.94      0.95      0.94      1016\n",
      "           8       0.93      0.95      0.94       952\n",
      "           9       0.92      0.94      0.93       990\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 68: 9497 / 10000\n",
      "Accuracy = 94.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96478873 0.9730669  0.94731707 0.93280632 0.9402229  0.93721973\n",
      " 0.96029258 0.94936709 0.94258873 0.93580742]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.94      0.95      0.94      1025\n",
      "           3       0.93      0.93      0.93      1012\n",
      "           4       0.95      0.94      0.94       987\n",
      "           5       0.94      0.94      0.94       892\n",
      "           6       0.96      0.96      0.96       957\n",
      "           7       0.95      0.95      0.95      1027\n",
      "           8       0.93      0.94      0.93       958\n",
      "           9       0.92      0.94      0.93       997\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 69: 9488 / 10000\n",
      "Accuracy = 94.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95904096 0.96888505 0.94557823 0.94383149 0.94693878 0.94582393\n",
      " 0.95454545 0.93959732 0.946875   0.94484168]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.99      0.97      0.98      1157\n",
      "           2       0.94      0.95      0.94      1029\n",
      "           3       0.93      0.94      0.94       997\n",
      "           4       0.95      0.95      0.95       980\n",
      "           5       0.94      0.95      0.94       886\n",
      "           6       0.96      0.95      0.96       968\n",
      "           7       0.95      0.94      0.95      1043\n",
      "           8       0.93      0.95      0.94       960\n",
      "           9       0.92      0.94      0.93       979\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 70: 9499 / 10000\n",
      "Accuracy = 94.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96096096 0.97053726 0.94731707 0.93545184 0.93512974 0.95298165\n",
      " 0.95751295 0.95895896 0.93237705 0.93406593]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.99      0.97      0.98      1154\n",
      "           2       0.94      0.95      0.94      1025\n",
      "           3       0.93      0.94      0.93      1007\n",
      "           4       0.95      0.94      0.94      1002\n",
      "           5       0.93      0.95      0.94       872\n",
      "           6       0.96      0.96      0.96       965\n",
      "           7       0.93      0.96      0.95       999\n",
      "           8       0.93      0.93      0.93       976\n",
      "           9       0.93      0.93      0.93      1001\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 71: 9488 / 10000\n",
      "Accuracy = 94.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95808383 0.97051171 0.95729891 0.9214355  0.93737374 0.95113636\n",
      " 0.95742471 0.95355731 0.94258873 0.93027888]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.93      0.96      0.95      1007\n",
      "           3       0.94      0.92      0.93      1031\n",
      "           4       0.95      0.94      0.94       990\n",
      "           5       0.94      0.95      0.94       880\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.94      0.95      0.95      1012\n",
      "           8       0.93      0.94      0.93       958\n",
      "           9       0.93      0.93      0.93      1004\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 72: 9482 / 10000\n",
      "Accuracy = 94.82%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96478873 0.96977547 0.94117647 0.94194194 0.93668342 0.9406495\n",
      " 0.96335079 0.95205479 0.9475341  0.93762575]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.99      0.97      0.98      1158\n",
      "           2       0.95      0.94      0.94      1037\n",
      "           3       0.93      0.94      0.94       999\n",
      "           4       0.95      0.94      0.94       995\n",
      "           5       0.94      0.94      0.94       893\n",
      "           6       0.96      0.96      0.96       955\n",
      "           7       0.95      0.95      0.95      1022\n",
      "           8       0.93      0.95      0.94       953\n",
      "           9       0.92      0.94      0.93       994\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 73: 9499 / 10000\n",
      "Accuracy = 94.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96277666 0.97560976 0.94466019 0.9437751  0.94058409 0.93384785\n",
      " 0.95553257 0.95360316 0.946875   0.93951613]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.99      0.98      0.98      1148\n",
      "           2       0.94      0.94      0.94      1030\n",
      "           3       0.93      0.94      0.94       996\n",
      "           4       0.95      0.94      0.95       993\n",
      "           5       0.95      0.93      0.94       907\n",
      "           6       0.96      0.96      0.96       967\n",
      "           7       0.94      0.95      0.95      1013\n",
      "           8       0.93      0.95      0.94       960\n",
      "           9       0.92      0.94      0.93       992\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 74: 9502 / 10000\n",
      "Accuracy = 95.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95704296 0.97222222 0.93576222 0.95746888 0.93674699 0.93952968\n",
      " 0.95945946 0.94906954 0.93156282 0.93933266]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.99      0.97      0.98      1152\n",
      "           2       0.95      0.94      0.94      1043\n",
      "           3       0.91      0.96      0.94       964\n",
      "           4       0.95      0.94      0.94       996\n",
      "           5       0.94      0.94      0.94       893\n",
      "           6       0.96      0.96      0.96       962\n",
      "           7       0.94      0.95      0.95      1021\n",
      "           8       0.94      0.93      0.93       979\n",
      "           9       0.92      0.94      0.93       989\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 75: 9482 / 10000\n",
      "Accuracy = 94.82%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95904096 0.97391304 0.94282946 0.93906094 0.94195519 0.93875278\n",
      " 0.96529968 0.94849368 0.95132275 0.93076162]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.99      0.97      0.98      1150\n",
      "           2       0.94      0.94      0.94      1032\n",
      "           3       0.93      0.94      0.93      1001\n",
      "           4       0.94      0.94      0.94       982\n",
      "           5       0.95      0.94      0.94       898\n",
      "           6       0.96      0.97      0.96       951\n",
      "           7       0.95      0.95      0.95      1029\n",
      "           8       0.92      0.95      0.94       945\n",
      "           9       0.93      0.93      0.93      1011\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 76: 9495 / 10000\n",
      "Accuracy = 94.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96281407 0.97476066 0.95205479 0.93936382 0.9535124  0.93548387\n",
      " 0.96129707 0.94747082 0.94427245 0.93253968]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       995\n",
      "           1       0.99      0.97      0.98      1149\n",
      "           2       0.94      0.95      0.95      1022\n",
      "           3       0.94      0.94      0.94      1006\n",
      "           4       0.94      0.95      0.95       968\n",
      "           5       0.94      0.94      0.94       899\n",
      "           6       0.96      0.96      0.96       956\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.94      0.94      0.94       969\n",
      "           9       0.93      0.93      0.93      1008\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 77: 9508 / 10000\n",
      "Accuracy = 95.08%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96288867 0.97140381 0.93930636 0.93366337 0.95041322 0.94375703\n",
      " 0.9537037  0.94980315 0.94496366 0.94058409]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.99      0.97      0.98      1154\n",
      "           2       0.94      0.94      0.94      1038\n",
      "           3       0.93      0.93      0.93      1010\n",
      "           4       0.94      0.95      0.94       968\n",
      "           5       0.94      0.94      0.94       889\n",
      "           6       0.97      0.95      0.96       972\n",
      "           7       0.94      0.95      0.94      1016\n",
      "           8       0.93      0.94      0.94       963\n",
      "           9       0.93      0.94      0.93       993\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 78: 9494 / 10000\n",
      "Accuracy = 94.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95712861 0.97556719 0.95083579 0.9223301  0.94753086 0.9382716\n",
      " 0.96518987 0.94965449 0.94479167 0.9245098 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1003\n",
      "           1       0.99      0.98      0.98      1146\n",
      "           2       0.94      0.95      0.94      1017\n",
      "           3       0.94      0.92      0.93      1030\n",
      "           4       0.94      0.95      0.94       972\n",
      "           5       0.94      0.94      0.94       891\n",
      "           6       0.96      0.97      0.96       948\n",
      "           7       0.94      0.95      0.94      1013\n",
      "           8       0.93      0.94      0.94       960\n",
      "           9       0.93      0.92      0.93      1020\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 79: 9479 / 10000\n",
      "Accuracy = 94.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96184739 0.97222222 0.94191675 0.93247269 0.94672131 0.94217687\n",
      " 0.95449845 0.95054402 0.94202899 0.93168317]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.99      0.97      0.98      1152\n",
      "           2       0.94      0.94      0.94      1033\n",
      "           3       0.93      0.93      0.93      1007\n",
      "           4       0.94      0.95      0.94       976\n",
      "           5       0.93      0.94      0.94       882\n",
      "           6       0.96      0.95      0.96       967\n",
      "           7       0.93      0.95      0.94      1011\n",
      "           8       0.93      0.94      0.94       966\n",
      "           9       0.93      0.93      0.93      1010\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 80: 9480 / 10000\n",
      "Accuracy = 94.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96173212 0.97556719 0.94547225 0.93564356 0.93762575 0.94369369\n",
      " 0.95933264 0.94573643 0.9411157  0.93997965]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       993\n",
      "           1       0.99      0.98      0.98      1146\n",
      "           2       0.94      0.95      0.94      1027\n",
      "           3       0.94      0.94      0.94      1010\n",
      "           4       0.95      0.94      0.94       994\n",
      "           5       0.94      0.94      0.94       888\n",
      "           6       0.96      0.96      0.96       959\n",
      "           7       0.95      0.95      0.95      1032\n",
      "           8       0.94      0.94      0.94       968\n",
      "           9       0.92      0.94      0.93       983\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 81: 9490 / 10000\n",
      "Accuracy = 94.90%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96288867 0.97560976 0.94921875 0.92419825 0.94147326 0.94736842\n",
      " 0.95841996 0.95369458 0.94490644 0.93787575]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.99      0.98      0.98      1148\n",
      "           2       0.94      0.95      0.95      1024\n",
      "           3       0.94      0.92      0.93      1029\n",
      "           4       0.95      0.94      0.95       991\n",
      "           5       0.93      0.95      0.94       874\n",
      "           6       0.96      0.96      0.96       962\n",
      "           7       0.94      0.95      0.95      1015\n",
      "           8       0.93      0.94      0.94       962\n",
      "           9       0.93      0.94      0.93       998\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 82: 9499 / 10000\n",
      "Accuracy = 94.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95995996 0.97733217 0.9494655  0.93011811 0.94550959 0.94683258\n",
      " 0.96041667 0.95038911 0.95068206 0.94259819]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.99      0.98      0.98      1147\n",
      "           2       0.95      0.95      0.95      1029\n",
      "           3       0.94      0.93      0.93      1016\n",
      "           4       0.95      0.95      0.95       991\n",
      "           5       0.94      0.95      0.94       884\n",
      "           6       0.96      0.96      0.96       960\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.93      0.95      0.94       953\n",
      "           9       0.93      0.94      0.94       993\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 83: 9517 / 10000\n",
      "Accuracy = 95.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96096096 0.97056277 0.9436346  0.93452381 0.94613821 0.9476082\n",
      " 0.95459236 0.94896958 0.94479167 0.93693694]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.99      0.97      0.98      1155\n",
      "           2       0.94      0.94      0.94      1029\n",
      "           3       0.93      0.93      0.93      1008\n",
      "           4       0.95      0.95      0.95       984\n",
      "           5       0.93      0.95      0.94       878\n",
      "           6       0.97      0.95      0.96       969\n",
      "           7       0.94      0.95      0.94      1019\n",
      "           8       0.93      0.94      0.94       960\n",
      "           9       0.93      0.94      0.93       999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 84: 9492 / 10000\n",
      "Accuracy = 94.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96196196 0.97384481 0.94202899 0.94094094 0.94393476 0.93743017\n",
      " 0.96020942 0.95073892 0.93634497 0.934     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.98      0.97      0.98      1147\n",
      "           2       0.94      0.94      0.94      1035\n",
      "           3       0.93      0.94      0.94       999\n",
      "           4       0.94      0.94      0.94       981\n",
      "           5       0.94      0.94      0.94       895\n",
      "           6       0.96      0.96      0.96       955\n",
      "           7       0.94      0.95      0.94      1015\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.93      0.93      0.93      1000\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 85: 9486 / 10000\n",
      "Accuracy = 94.86%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96292585 0.97309028 0.94357977 0.93405512 0.9413549  0.94863014\n",
      " 0.9565667  0.94649805 0.94577685 0.94123607]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       998\n",
      "           1       0.99      0.97      0.98      1152\n",
      "           2       0.94      0.94      0.94      1028\n",
      "           3       0.94      0.93      0.94      1016\n",
      "           4       0.95      0.94      0.94       989\n",
      "           5       0.93      0.95      0.94       876\n",
      "           6       0.97      0.96      0.96       967\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.93      0.95      0.94       959\n",
      "           9       0.92      0.94      0.93       987\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 86: 9497 / 10000\n",
      "Accuracy = 94.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95717131 0.97137901 0.94767442 0.94211577 0.94795918 0.95\n",
      " 0.95548654 0.94752187 0.94973822 0.93893894]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1004\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.95      0.95      0.95      1032\n",
      "           3       0.93      0.94      0.94      1002\n",
      "           4       0.95      0.95      0.95       980\n",
      "           5       0.94      0.95      0.94       880\n",
      "           6       0.96      0.96      0.96       966\n",
      "           7       0.95      0.95      0.95      1029\n",
      "           8       0.93      0.95      0.94       955\n",
      "           9       0.93      0.94      0.93       999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 87: 9511 / 10000\n",
      "Accuracy = 95.11%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96285141 0.97222222 0.94021215 0.93353175 0.94882293 0.9382716\n",
      " 0.95742471 0.94829268 0.95042194 0.93619143]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.99      0.97      0.98      1152\n",
      "           2       0.94      0.94      0.94      1037\n",
      "           3       0.93      0.93      0.93      1008\n",
      "           4       0.94      0.95      0.95       977\n",
      "           5       0.94      0.94      0.94       891\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.93      0.95      0.94       948\n",
      "           9       0.93      0.94      0.93      1003\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 88: 9492 / 10000\n",
      "Accuracy = 94.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96192385 0.97222222 0.94819159 0.93644489 0.94834711 0.93480663\n",
      " 0.95950156 0.94649805 0.94099379 0.93939394]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       998\n",
      "           1       0.99      0.97      0.98      1152\n",
      "           2       0.94      0.95      0.94      1023\n",
      "           3       0.93      0.94      0.94      1007\n",
      "           4       0.93      0.95      0.94       968\n",
      "           5       0.95      0.93      0.94       905\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.93      0.94      0.94       966\n",
      "           9       0.92      0.94      0.93       990\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 89: 9493 / 10000\n",
      "Accuracy = 94.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96385542 0.96640827 0.93600764 0.94271357 0.94399185 0.94256757\n",
      " 0.95548654 0.95418327 0.94659686 0.92942346]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.99      0.97      0.98      1161\n",
      "           2       0.95      0.94      0.94      1047\n",
      "           3       0.93      0.94      0.94       995\n",
      "           4       0.94      0.94      0.94       982\n",
      "           5       0.94      0.94      0.94       888\n",
      "           6       0.96      0.96      0.96       966\n",
      "           7       0.93      0.95      0.94      1004\n",
      "           8       0.93      0.95      0.94       955\n",
      "           9       0.93      0.93      0.93      1006\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 90: 9484 / 10000\n",
      "Accuracy = 94.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95431976 0.9738676  0.95224172 0.93117011 0.94506612 0.94343891\n",
      " 0.95850622 0.94716243 0.94659686 0.93963783]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1007\n",
      "           1       0.99      0.97      0.98      1148\n",
      "           2       0.95      0.95      0.95      1026\n",
      "           3       0.94      0.93      0.93      1017\n",
      "           4       0.95      0.95      0.95       983\n",
      "           5       0.93      0.94      0.94       884\n",
      "           6       0.96      0.96      0.96       964\n",
      "           7       0.94      0.95      0.94      1022\n",
      "           8       0.93      0.95      0.94       955\n",
      "           9       0.93      0.94      0.93       994\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 91: 9496 / 10000\n",
      "Accuracy = 94.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95912263 0.97473868 0.94747082 0.93619143 0.94602851 0.94224236\n",
      " 0.96045786 0.94634146 0.94123711 0.93781344]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1003\n",
      "           1       0.99      0.97      0.98      1148\n",
      "           2       0.94      0.95      0.95      1028\n",
      "           3       0.93      0.94      0.93      1003\n",
      "           4       0.95      0.95      0.95       982\n",
      "           5       0.93      0.94      0.94       883\n",
      "           6       0.96      0.96      0.96       961\n",
      "           7       0.94      0.95      0.94      1025\n",
      "           8       0.94      0.94      0.94       970\n",
      "           9       0.93      0.94      0.93       997\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 92: 9496 / 10000\n",
      "Accuracy = 94.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96389168 0.97393571 0.94032724 0.92927308 0.94314721 0.94282511\n",
      " 0.96033403 0.94911937 0.95207668 0.93593594]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.95      0.94      0.94      1039\n",
      "           3       0.94      0.93      0.93      1018\n",
      "           4       0.95      0.94      0.94       985\n",
      "           5       0.94      0.94      0.94       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.94      0.95      0.95      1022\n",
      "           8       0.92      0.95      0.93       939\n",
      "           9       0.93      0.94      0.93       999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 93: 9494 / 10000\n",
      "Accuracy = 94.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96288867 0.9730669  0.94563107 0.9295499  0.93519442 0.94324631\n",
      " 0.95247934 0.95098039 0.9483667  0.94382022]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.94      0.95      0.94      1030\n",
      "           3       0.94      0.93      0.94      1022\n",
      "           4       0.96      0.94      0.95      1003\n",
      "           5       0.93      0.94      0.94       881\n",
      "           6       0.96      0.95      0.96       968\n",
      "           7       0.94      0.95      0.95      1020\n",
      "           8       0.92      0.95      0.94       949\n",
      "           9       0.92      0.94      0.93       979\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 94: 9489 / 10000\n",
      "Accuracy = 94.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96676737 0.9672696  0.94117647 0.93644489 0.94586313 0.93652561\n",
      " 0.95945946 0.95266272 0.94670846 0.94254032]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       993\n",
      "           1       0.99      0.97      0.98      1161\n",
      "           2       0.95      0.94      0.94      1037\n",
      "           3       0.93      0.94      0.94      1007\n",
      "           4       0.94      0.95      0.94       979\n",
      "           5       0.94      0.94      0.94       898\n",
      "           6       0.96      0.96      0.96       962\n",
      "           7       0.94      0.95      0.95      1014\n",
      "           8       0.93      0.95      0.94       957\n",
      "           9       0.93      0.94      0.93       992\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 95: 9499 / 10000\n",
      "Accuracy = 94.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96871847 0.97140381 0.93852065 0.92759295 0.94790603 0.93932584\n",
      " 0.95929019 0.95167653 0.94456067 0.94070352]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       991\n",
      "           1       0.99      0.97      0.98      1154\n",
      "           2       0.95      0.94      0.94      1041\n",
      "           3       0.94      0.93      0.93      1022\n",
      "           4       0.95      0.95      0.95       979\n",
      "           5       0.94      0.94      0.94       890\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.94      0.95      0.95      1014\n",
      "           8       0.93      0.94      0.94       956\n",
      "           9       0.93      0.94      0.93       995\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 96: 9493 / 10000\n",
      "Accuracy = 94.93%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96485944 0.96893874 0.94089147 0.93032385 0.94244604 0.95287356\n",
      " 0.95449845 0.94711068 0.94659686 0.92956349]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.99      0.97      0.98      1159\n",
      "           2       0.94      0.94      0.94      1032\n",
      "           3       0.94      0.93      0.93      1019\n",
      "           4       0.93      0.94      0.94       973\n",
      "           5       0.93      0.95      0.94       870\n",
      "           6       0.96      0.95      0.96       967\n",
      "           7       0.94      0.95      0.94      1021\n",
      "           8       0.93      0.95      0.94       955\n",
      "           9       0.93      0.93      0.93      1008\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 97: 9480 / 10000\n",
      "Accuracy = 94.80%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96572581 0.97140381 0.93743985 0.93215339 0.94141414 0.94545455\n",
      " 0.95553257 0.94736842 0.94736842 0.94314721]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       992\n",
      "           1       0.99      0.97      0.98      1154\n",
      "           2       0.94      0.94      0.94      1039\n",
      "           3       0.94      0.93      0.94      1017\n",
      "           4       0.95      0.94      0.95       990\n",
      "           5       0.93      0.95      0.94       880\n",
      "           6       0.96      0.96      0.96       967\n",
      "           7       0.95      0.95      0.95      1026\n",
      "           8       0.92      0.95      0.94       950\n",
      "           9       0.92      0.94      0.93       985\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 98: 9490 / 10000\n",
      "Accuracy = 94.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96489468 0.97219809 0.93840231 0.92752204 0.96300211 0.94772727\n",
      " 0.958159   0.95059289 0.93595041 0.92330097]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.94      0.94      0.94      1039\n",
      "           3       0.94      0.93      0.93      1021\n",
      "           4       0.93      0.96      0.95       946\n",
      "           5       0.93      0.95      0.94       880\n",
      "           6       0.96      0.96      0.96       956\n",
      "           7       0.94      0.95      0.94      1012\n",
      "           8       0.93      0.94      0.93       968\n",
      "           9       0.94      0.92      0.93      1030\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 99: 9483 / 10000\n",
      "Accuracy = 94.83%\n"
     ]
    }
   ],
   "source": [
    "net = network.Network([784, 30, 10])\n",
    "net.SGD(training_data, 100, 10, 1.5, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.91475096 0.94952951 0.9632107  0.83970856 0.87778855 0.94270123\n",
      " 0.91446029 0.917154   0.84984985 0.86973555]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1044\n",
      "           1       0.98      0.95      0.96      1169\n",
      "           2       0.84      0.96      0.90       897\n",
      "           3       0.91      0.84      0.87      1098\n",
      "           4       0.92      0.88      0.90      1031\n",
      "           5       0.77      0.94      0.85       733\n",
      "           6       0.94      0.91      0.93       982\n",
      "           7       0.92      0.92      0.92      1026\n",
      "           8       0.87      0.85      0.86       999\n",
      "           9       0.88      0.87      0.87      1021\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 0: 9023 / 10000\n",
      "Accuracy = 90.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9395122  0.96847636 0.89784442 0.91769547 0.88720379 0.92071006\n",
      " 0.9299691  0.91969407 0.90070922 0.95280899]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1025\n",
      "           1       0.97      0.97      0.97      1142\n",
      "           2       0.93      0.90      0.91      1067\n",
      "           3       0.88      0.92      0.90       972\n",
      "           4       0.95      0.89      0.92      1055\n",
      "           5       0.87      0.92      0.90       845\n",
      "           6       0.94      0.93      0.94       971\n",
      "           7       0.94      0.92      0.93      1046\n",
      "           8       0.91      0.90      0.91       987\n",
      "           9       0.84      0.95      0.89       890\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.92      0.92     10000\n",
      "\n",
      "Epoch 1: 9235 / 10000\n",
      "Accuracy = 92.35%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94227006 0.95965665 0.93313668 0.90801187 0.91552063 0.8992333\n",
      " 0.91927346 0.94285714 0.93704092 0.95977654]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1022\n",
      "           1       0.99      0.96      0.97      1165\n",
      "           2       0.92      0.93      0.93      1017\n",
      "           3       0.91      0.91      0.91      1011\n",
      "           4       0.95      0.92      0.93      1018\n",
      "           5       0.92      0.90      0.91       913\n",
      "           6       0.95      0.92      0.93       991\n",
      "           7       0.93      0.94      0.94      1015\n",
      "           8       0.92      0.94      0.93       953\n",
      "           9       0.85      0.96      0.90       895\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Epoch 2: 9321 / 10000\n",
      "Accuracy = 93.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95318725 0.9745614  0.92829457 0.93898656 0.93819656 0.91255605\n",
      " 0.92749245 0.95708583 0.90606061 0.93454179]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1004\n",
      "           1       0.98      0.97      0.98      1140\n",
      "           2       0.93      0.93      0.93      1032\n",
      "           3       0.90      0.94      0.92       967\n",
      "           4       0.94      0.94      0.94       987\n",
      "           5       0.91      0.91      0.91       892\n",
      "           6       0.96      0.93      0.94       993\n",
      "           7       0.93      0.96      0.94      1002\n",
      "           8       0.92      0.91      0.91       990\n",
      "           9       0.92      0.93      0.93       993\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 3: 9379 / 10000\n",
      "Accuracy = 93.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96551724 0.98660714 0.95276382 0.93597561 0.90114068 0.91814159\n",
      " 0.93522267 0.94504416 0.89773845 0.94438503]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       986\n",
      "           1       0.97      0.99      0.98      1120\n",
      "           2       0.92      0.95      0.94       995\n",
      "           3       0.91      0.94      0.92       984\n",
      "           4       0.97      0.90      0.93      1052\n",
      "           5       0.93      0.92      0.92       904\n",
      "           6       0.96      0.94      0.95       988\n",
      "           7       0.94      0.95      0.94      1019\n",
      "           8       0.94      0.90      0.92      1017\n",
      "           9       0.88      0.94      0.91       935\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 4: 9387 / 10000\n",
      "Accuracy = 93.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9551346  0.97889182 0.9565667  0.88345865 0.95720251 0.96287129\n",
      " 0.93360161 0.93998064 0.9029703  0.92105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1003\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.90      0.96      0.93       967\n",
      "           3       0.93      0.88      0.91      1064\n",
      "           4       0.93      0.96      0.95       958\n",
      "           5       0.87      0.96      0.92       808\n",
      "           6       0.97      0.93      0.95       994\n",
      "           7       0.94      0.94      0.94      1033\n",
      "           8       0.94      0.90      0.92      1010\n",
      "           9       0.94      0.92      0.93      1026\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 5: 9387 / 10000\n",
      "Accuracy = 93.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.959285   0.97375328 0.92564347 0.94497354 0.94613821 0.90899242\n",
      " 0.95459345 0.9494655  0.92385787 0.94534413]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      1007\n",
      "           1       0.98      0.97      0.98      1143\n",
      "           2       0.94      0.93      0.93      1049\n",
      "           3       0.88      0.94      0.91       945\n",
      "           4       0.95      0.95      0.95       984\n",
      "           5       0.94      0.91      0.92       923\n",
      "           6       0.94      0.95      0.95       947\n",
      "           7       0.95      0.95      0.95      1029\n",
      "           8       0.93      0.92      0.93       985\n",
      "           9       0.93      0.95      0.94       988\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Epoch 6: 9438 / 10000\n",
      "Accuracy = 94.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9459725  0.97725284 0.9395122  0.92262488 0.96458333 0.9143798\n",
      " 0.94855967 0.95944609 0.96467991 0.9196515 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1018\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.93      0.94      0.94      1025\n",
      "           3       0.93      0.92      0.93      1021\n",
      "           4       0.94      0.96      0.95       960\n",
      "           5       0.93      0.91      0.92       911\n",
      "           6       0.96      0.95      0.96       972\n",
      "           7       0.94      0.96      0.95      1011\n",
      "           8       0.90      0.96      0.93       906\n",
      "           9       0.94      0.92      0.93      1033\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 7: 9460 / 10000\n",
      "Accuracy = 94.60%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96023857 0.98312611 0.95095095 0.92610837 0.94763343 0.94130926\n",
      " 0.96838778 0.96506986 0.90569745 0.93240557]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      1006\n",
      "           1       0.98      0.98      0.98      1126\n",
      "           2       0.92      0.95      0.94       999\n",
      "           3       0.93      0.93      0.93      1015\n",
      "           4       0.96      0.95      0.95       993\n",
      "           5       0.93      0.94      0.94       886\n",
      "           6       0.96      0.97      0.96       949\n",
      "           7       0.94      0.97      0.95      1002\n",
      "           8       0.95      0.91      0.93      1018\n",
      "           9       0.93      0.93      0.93      1006\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 8: 9484 / 10000\n",
      "Accuracy = 94.84%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95441031 0.9814978  0.95247525 0.90900474 0.96480331 0.94889663\n",
      " 0.94416244 0.94980695 0.94196891 0.94683027]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1009\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.93      0.95      0.94      1010\n",
      "           3       0.95      0.91      0.93      1055\n",
      "           4       0.95      0.96      0.96       966\n",
      "           5       0.92      0.95      0.93       861\n",
      "           6       0.97      0.94      0.96       985\n",
      "           7       0.96      0.95      0.95      1036\n",
      "           8       0.93      0.94      0.94       965\n",
      "           9       0.92      0.95      0.93       978\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 9: 9496 / 10000\n",
      "Accuracy = 94.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94851485 0.96956522 0.94282946 0.94552929 0.94322709 0.94773519\n",
      " 0.95356037 0.963      0.92477432 0.937251  ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1010\n",
      "           1       0.98      0.97      0.98      1150\n",
      "           2       0.94      0.94      0.94      1032\n",
      "           3       0.91      0.95      0.93       973\n",
      "           4       0.96      0.94      0.95      1004\n",
      "           5       0.91      0.95      0.93       861\n",
      "           6       0.96      0.95      0.96       969\n",
      "           7       0.94      0.96      0.95      1000\n",
      "           8       0.95      0.92      0.94       997\n",
      "           9       0.93      0.94      0.93      1004\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 10: 9479 / 10000\n",
      "Accuracy = 94.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95904096 0.96459413 0.96728016 0.9345887  0.93897638 0.95586527\n",
      " 0.95760083 0.95853899 0.90677134 0.94989775]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.98      0.96      0.97      1158\n",
      "           2       0.92      0.97      0.94       978\n",
      "           3       0.93      0.93      0.93      1009\n",
      "           4       0.97      0.94      0.95      1016\n",
      "           5       0.92      0.96      0.94       861\n",
      "           6       0.97      0.96      0.96       967\n",
      "           7       0.94      0.96      0.95      1013\n",
      "           8       0.95      0.91      0.93      1019\n",
      "           9       0.92      0.95      0.94       978\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 11: 9493 / 10000\n",
      "Accuracy = 94.93%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95337302 0.96964441 0.9406037  0.91899711 0.94969819 0.95454545\n",
      " 0.95076923 0.94346979 0.95610278 0.94129555]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1008\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.94      0.94      0.94      1027\n",
      "           3       0.94      0.92      0.93      1037\n",
      "           4       0.96      0.95      0.96       994\n",
      "           5       0.92      0.95      0.94       858\n",
      "           6       0.97      0.95      0.96       975\n",
      "           7       0.94      0.94      0.94      1026\n",
      "           8       0.92      0.96      0.94       934\n",
      "           9       0.92      0.94      0.93       988\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 12: 9479 / 10000\n",
      "Accuracy = 94.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.97025641 0.98405669 0.96738022 0.8983209  0.96865204 0.93007769\n",
      " 0.94399185 0.96273917 0.93326489 0.91119691]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       975\n",
      "           1       0.98      0.98      0.98      1129\n",
      "           2       0.92      0.97      0.94       981\n",
      "           3       0.95      0.90      0.93      1072\n",
      "           4       0.94      0.97      0.96       957\n",
      "           5       0.94      0.93      0.93       901\n",
      "           6       0.97      0.94      0.96       982\n",
      "           7       0.93      0.96      0.95       993\n",
      "           8       0.93      0.93      0.93       974\n",
      "           9       0.94      0.91      0.92      1036\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 13: 9470 / 10000\n",
      "Accuracy = 94.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96941896 0.98323036 0.9275635  0.90462701 0.98399146 0.95522388\n",
      " 0.93306693 0.96111665 0.95628998 0.93096647]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       981\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.96      0.93      0.94      1063\n",
      "           3       0.95      0.90      0.93      1059\n",
      "           4       0.94      0.98      0.96       937\n",
      "           5       0.93      0.96      0.94       871\n",
      "           6       0.97      0.93      0.95      1001\n",
      "           7       0.94      0.96      0.95      1003\n",
      "           8       0.92      0.96      0.94       938\n",
      "           9       0.94      0.93      0.93      1014\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 14: 9502 / 10000\n",
      "Accuracy = 95.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93768257 0.97803163 0.94214079 0.94523327 0.96020408 0.92417582\n",
      " 0.95733611 0.96115538 0.93082401 0.9486653 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1027\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.95      0.94      0.94      1037\n",
      "           3       0.92      0.95      0.93       986\n",
      "           4       0.96      0.96      0.96       980\n",
      "           5       0.94      0.92      0.93       910\n",
      "           6       0.96      0.96      0.96       961\n",
      "           7       0.94      0.96      0.95      1004\n",
      "           8       0.94      0.93      0.94       983\n",
      "           9       0.92      0.95      0.93       974\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 15: 9491 / 10000\n",
      "Accuracy = 94.91%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94581281 0.96626298 0.95177165 0.94035785 0.97274633 0.9498861\n",
      " 0.95081967 0.95067698 0.93124368 0.95389344]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1015\n",
      "           1       0.98      0.97      0.98      1156\n",
      "           2       0.94      0.95      0.94      1016\n",
      "           3       0.94      0.94      0.94      1006\n",
      "           4       0.95      0.97      0.96       954\n",
      "           5       0.93      0.95      0.94       878\n",
      "           6       0.97      0.95      0.96       976\n",
      "           7       0.96      0.95      0.95      1034\n",
      "           8       0.95      0.93      0.94       989\n",
      "           9       0.92      0.95      0.94       976\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 16: 9515 / 10000\n",
      "Accuracy = 95.15%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95360316 0.97550306 0.96115538 0.9271137  0.96032553 0.96069364\n",
      " 0.9490316  0.9382716  0.95183246 0.95482546]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1013\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.94      0.96      0.95      1004\n",
      "           3       0.94      0.93      0.94      1029\n",
      "           4       0.96      0.96      0.96       983\n",
      "           5       0.93      0.96      0.95       865\n",
      "           6       0.97      0.95      0.96       981\n",
      "           7       0.96      0.94      0.95      1053\n",
      "           8       0.93      0.95      0.94       955\n",
      "           9       0.92      0.95      0.94       974\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 17: 9533 / 10000\n",
      "Accuracy = 95.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94970414 0.97968198 0.959285   0.95213319 0.93879566 0.91675676\n",
      " 0.94201424 0.94782609 0.93191057 0.96088795]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1014\n",
      "           1       0.98      0.98      0.98      1132\n",
      "           2       0.94      0.96      0.95      1007\n",
      "           3       0.91      0.95      0.93       961\n",
      "           4       0.97      0.94      0.95      1013\n",
      "           5       0.95      0.92      0.93       925\n",
      "           6       0.97      0.94      0.95       983\n",
      "           7       0.95      0.95      0.95      1035\n",
      "           8       0.94      0.93      0.94       984\n",
      "           9       0.90      0.96      0.93       946\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 18: 9485 / 10000\n",
      "Accuracy = 94.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94346979 0.97807018 0.95833333 0.93066406 0.96300103 0.96470588\n",
      " 0.95539419 0.9352381  0.94142259 0.93062438]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      1026\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.94      0.96      0.95      1008\n",
      "           3       0.94      0.93      0.94      1024\n",
      "           4       0.95      0.96      0.96       973\n",
      "           5       0.92      0.96      0.94       850\n",
      "           6       0.96      0.96      0.96       964\n",
      "           7       0.96      0.94      0.95      1050\n",
      "           8       0.92      0.94      0.93       956\n",
      "           9       0.93      0.93      0.93      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 19: 9501 / 10000\n",
      "Accuracy = 95.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95059289 0.96542783 0.94680851 0.93203883 0.95395395 0.95842956\n",
      " 0.9524302  0.95298727 0.95263158 0.9626556 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1012\n",
      "           1       0.98      0.97      0.97      1157\n",
      "           2       0.95      0.95      0.95      1034\n",
      "           3       0.95      0.93      0.94      1030\n",
      "           4       0.97      0.95      0.96       999\n",
      "           5       0.93      0.96      0.94       866\n",
      "           6       0.96      0.95      0.96       967\n",
      "           7       0.95      0.95      0.95      1021\n",
      "           8       0.93      0.95      0.94       950\n",
      "           9       0.92      0.96      0.94       964\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 20: 9528 / 10000\n",
      "Accuracy = 95.28%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96468214 0.97797357 0.95112414 0.92042186 0.96322778 0.96499417\n",
      " 0.92935323 0.95126706 0.94962487 0.93650794]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       991\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.94      0.95      0.95      1023\n",
      "           3       0.95      0.92      0.94      1043\n",
      "           4       0.96      0.96      0.96       979\n",
      "           5       0.93      0.96      0.95       857\n",
      "           6       0.97      0.93      0.95      1005\n",
      "           7       0.95      0.95      0.95      1026\n",
      "           8       0.91      0.95      0.93       933\n",
      "           9       0.94      0.94      0.94      1008\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 21: 9509 / 10000\n",
      "Accuracy = 95.09%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93774319 0.96376186 0.95759369 0.93164062 0.95195195 0.95532646\n",
      " 0.95850622 0.95392157 0.95449735 0.95893224]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1028\n",
      "           1       0.98      0.96      0.97      1159\n",
      "           2       0.94      0.96      0.95      1014\n",
      "           3       0.94      0.93      0.94      1024\n",
      "           4       0.97      0.95      0.96       999\n",
      "           5       0.93      0.96      0.95       873\n",
      "           6       0.96      0.96      0.96       964\n",
      "           7       0.95      0.95      0.95      1020\n",
      "           8       0.93      0.95      0.94       945\n",
      "           9       0.93      0.96      0.94       974\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 22: 9524 / 10000\n",
      "Accuracy = 95.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95630586 0.97051171 0.95019531 0.90601504 0.96236012 0.9594438\n",
      " 0.95277207 0.95392157 0.966046   0.94094094]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1007\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.94      0.95      0.95      1024\n",
      "           3       0.95      0.91      0.93      1064\n",
      "           4       0.96      0.96      0.96       983\n",
      "           5       0.93      0.96      0.94       863\n",
      "           6       0.97      0.95      0.96       974\n",
      "           7       0.95      0.95      0.95      1020\n",
      "           8       0.91      0.97      0.93       913\n",
      "           9       0.93      0.94      0.94       999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 23: 9516 / 10000\n",
      "Accuracy = 95.16%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94243902 0.97467249 0.96396396 0.93431373 0.96714579 0.94394619\n",
      " 0.94877049 0.94680851 0.95638298 0.95175879]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1025\n",
      "           1       0.98      0.97      0.98      1145\n",
      "           2       0.93      0.96      0.95       999\n",
      "           3       0.94      0.93      0.94      1020\n",
      "           4       0.96      0.97      0.96       974\n",
      "           5       0.94      0.94      0.94       892\n",
      "           6       0.97      0.95      0.96       976\n",
      "           7       0.95      0.95      0.95      1034\n",
      "           8       0.92      0.96      0.94       940\n",
      "           9       0.94      0.95      0.95       995\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 24: 9533 / 10000\n",
      "Accuracy = 95.33%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95355731 0.97377622 0.95019531 0.94023904 0.96255061 0.95632184\n",
      " 0.9625     0.94898941 0.92424242 0.9628483 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1012\n",
      "           1       0.98      0.97      0.98      1144\n",
      "           2       0.94      0.95      0.95      1024\n",
      "           3       0.93      0.94      0.94      1004\n",
      "           4       0.97      0.96      0.97       988\n",
      "           5       0.93      0.96      0.94       870\n",
      "           6       0.96      0.96      0.96       960\n",
      "           7       0.96      0.95      0.95      1039\n",
      "           8       0.94      0.92      0.93       990\n",
      "           9       0.92      0.96      0.94       969\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 25: 9537 / 10000\n",
      "Accuracy = 95.37%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95409182 0.97546012 0.95136187 0.93817468 0.96728016 0.96853147\n",
      " 0.94410569 0.95091434 0.93299492 0.96273292]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1002\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.95      0.95      0.95      1028\n",
      "           3       0.95      0.94      0.94      1019\n",
      "           4       0.96      0.97      0.97       978\n",
      "           5       0.93      0.97      0.95       858\n",
      "           6       0.97      0.94      0.96       984\n",
      "           7       0.96      0.95      0.96      1039\n",
      "           8       0.94      0.93      0.94       985\n",
      "           9       0.92      0.96      0.94       966\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 26: 9546 / 10000\n",
      "Accuracy = 95.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94400786 0.97465035 0.94956353 0.93774704 0.95841785 0.95216401\n",
      " 0.95638629 0.96165192 0.94318182 0.9491353 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1018\n",
      "           1       0.98      0.97      0.98      1144\n",
      "           2       0.95      0.95      0.95      1031\n",
      "           3       0.94      0.94      0.94      1012\n",
      "           4       0.96      0.96      0.96       986\n",
      "           5       0.94      0.95      0.94       878\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.95      0.96      0.96      1017\n",
      "           8       0.94      0.94      0.94       968\n",
      "           9       0.92      0.95      0.94       983\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 27: 9530 / 10000\n",
      "Accuracy = 95.30%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93871595 0.9745837  0.94236311 0.94194194 0.96833504 0.97810219\n",
      " 0.95139607 0.95472441 0.91141732 0.94752775]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1028\n",
      "           1       0.98      0.97      0.98      1141\n",
      "           2       0.95      0.94      0.95      1041\n",
      "           3       0.93      0.94      0.94       999\n",
      "           4       0.97      0.97      0.97       979\n",
      "           5       0.90      0.98      0.94       822\n",
      "           6       0.96      0.95      0.96       967\n",
      "           7       0.94      0.95      0.95      1016\n",
      "           8       0.95      0.91      0.93      1016\n",
      "           9       0.93      0.95      0.94       991\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 28: 9506 / 10000\n",
      "Accuracy = 95.06%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95422886 0.98066784 0.95178399 0.91889313 0.96236012 0.96266044\n",
      " 0.94501018 0.95583906 0.95127119 0.9473151 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1005\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.96      0.95      0.95      1037\n",
      "           3       0.95      0.92      0.94      1048\n",
      "           4       0.96      0.96      0.96       983\n",
      "           5       0.92      0.96      0.94       857\n",
      "           6       0.97      0.95      0.96       982\n",
      "           7       0.95      0.96      0.95      1019\n",
      "           8       0.92      0.95      0.94       944\n",
      "           9       0.93      0.95      0.94       987\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 29: 9531 / 10000\n",
      "Accuracy = 95.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95531281 0.96961806 0.94869313 0.94187192 0.95850202 0.95238095\n",
      " 0.95755694 0.95494613 0.95173137 0.95015259]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1007\n",
      "           1       0.98      0.97      0.98      1152\n",
      "           2       0.95      0.95      0.95      1033\n",
      "           3       0.95      0.94      0.94      1015\n",
      "           4       0.96      0.96      0.96       988\n",
      "           5       0.94      0.95      0.95       882\n",
      "           6       0.97      0.96      0.96       966\n",
      "           7       0.95      0.95      0.95      1021\n",
      "           8       0.93      0.95      0.94       953\n",
      "           9       0.93      0.95      0.94       983\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 30: 9543 / 10000\n",
      "Accuracy = 95.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96551724 0.97709251 0.96830266 0.91897045 0.9691358  0.97159763\n",
      " 0.94236603 0.95763547 0.91818182 0.91642651]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       986\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.92      0.97      0.94       978\n",
      "           3       0.95      0.92      0.94      1049\n",
      "           4       0.96      0.97      0.96       972\n",
      "           5       0.92      0.97      0.95       845\n",
      "           6       0.97      0.94      0.96       989\n",
      "           7       0.95      0.96      0.95      1015\n",
      "           8       0.93      0.92      0.93       990\n",
      "           9       0.95      0.92      0.93      1041\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 31: 9502 / 10000\n",
      "Accuracy = 95.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94866732 0.97539543 0.96023857 0.9120983  0.94094488 0.96702002\n",
      " 0.96342738 0.9460501  0.93667007 0.96934461]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1013\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.94      0.96      0.95      1006\n",
      "           3       0.96      0.91      0.93      1058\n",
      "           4       0.97      0.94      0.96      1016\n",
      "           5       0.92      0.97      0.94       849\n",
      "           6       0.96      0.96      0.96       957\n",
      "           7       0.96      0.95      0.95      1038\n",
      "           8       0.94      0.94      0.94       979\n",
      "           9       0.91      0.97      0.94       946\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 32: 9517 / 10000\n",
      "Accuracy = 95.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94705882 0.97717296 0.963      0.90601504 0.95175879 0.96702002\n",
      " 0.95751295 0.95579568 0.94184839 0.94630193]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1020\n",
      "           1       0.98      0.98      0.98      1139\n",
      "           2       0.93      0.96      0.95      1000\n",
      "           3       0.95      0.91      0.93      1064\n",
      "           4       0.96      0.95      0.96       995\n",
      "           5       0.92      0.97      0.94       849\n",
      "           6       0.96      0.96      0.96       965\n",
      "           7       0.95      0.96      0.95      1018\n",
      "           8       0.93      0.94      0.94       963\n",
      "           9       0.93      0.95      0.94       987\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 33: 9512 / 10000\n",
      "Accuracy = 95.12%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96572581 0.9721497  0.95117188 0.93009709 0.96060606 0.93939394\n",
      " 0.95724713 0.95155039 0.9439834  0.95975232]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       992\n",
      "           1       0.98      0.97      0.98      1149\n",
      "           2       0.94      0.95      0.95      1024\n",
      "           3       0.95      0.93      0.94      1030\n",
      "           4       0.97      0.96      0.96       990\n",
      "           5       0.94      0.94      0.94       891\n",
      "           6       0.96      0.96      0.96       959\n",
      "           7       0.96      0.95      0.95      1032\n",
      "           8       0.93      0.94      0.94       964\n",
      "           9       0.92      0.96      0.94       969\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 34: 9535 / 10000\n",
      "Accuracy = 95.35%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95418327 0.97207679 0.95924453 0.92478303 0.96615385 0.97037915\n",
      " 0.94602851 0.94721689 0.93698347 0.94578313]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1004\n",
      "           1       0.98      0.97      0.98      1146\n",
      "           2       0.94      0.96      0.95      1006\n",
      "           3       0.95      0.92      0.94      1037\n",
      "           4       0.96      0.97      0.96       975\n",
      "           5       0.92      0.97      0.94       844\n",
      "           6       0.97      0.95      0.96       982\n",
      "           7       0.96      0.95      0.95      1042\n",
      "           8       0.93      0.94      0.93       968\n",
      "           9       0.93      0.95      0.94       996\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 35: 9522 / 10000\n",
      "Accuracy = 95.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95148515 0.97554585 0.95503421 0.92603266 0.95943205 0.96292005\n",
      " 0.96747114 0.94017094 0.94190871 0.96153846]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1010\n",
      "           1       0.98      0.98      0.98      1145\n",
      "           2       0.95      0.96      0.95      1023\n",
      "           3       0.95      0.93      0.94      1041\n",
      "           4       0.96      0.96      0.96       986\n",
      "           5       0.93      0.96      0.95       863\n",
      "           6       0.96      0.97      0.96       953\n",
      "           7       0.96      0.94      0.95      1053\n",
      "           8       0.93      0.94      0.94       964\n",
      "           9       0.92      0.96      0.94       962\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 36: 9541 / 10000\n",
      "Accuracy = 95.41%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95436508 0.9780894  0.96403596 0.91714286 0.96731359 0.9478458\n",
      " 0.95081967 0.94433781 0.95435244 0.95199183]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1008\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.94      0.96      0.95      1001\n",
      "           3       0.95      0.92      0.93      1050\n",
      "           4       0.96      0.97      0.97       979\n",
      "           5       0.94      0.95      0.94       882\n",
      "           6       0.97      0.95      0.96       976\n",
      "           7       0.96      0.94      0.95      1042\n",
      "           8       0.92      0.95      0.94       942\n",
      "           9       0.92      0.95      0.94       979\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 37: 9532 / 10000\n",
      "Accuracy = 95.32%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95034757 0.97548161 0.94849368 0.93411996 0.95761857 0.94880546\n",
      " 0.95746888 0.96496496 0.93103448 0.94827586]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1007\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.95      0.95      0.95      1029\n",
      "           3       0.94      0.93      0.94      1017\n",
      "           4       0.97      0.96      0.96       991\n",
      "           5       0.93      0.95      0.94       879\n",
      "           6       0.96      0.96      0.96       964\n",
      "           7       0.94      0.96      0.95       999\n",
      "           8       0.94      0.93      0.94       986\n",
      "           9       0.93      0.95      0.94       986\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 38: 9520 / 10000\n",
      "Accuracy = 95.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95595596 0.97122929 0.94798822 0.92100193 0.97379455 0.96041909\n",
      " 0.94619289 0.95920398 0.9246988  0.94088176]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       999\n",
      "           1       0.98      0.97      0.98      1147\n",
      "           2       0.94      0.95      0.94      1019\n",
      "           3       0.95      0.92      0.93      1038\n",
      "           4       0.95      0.97      0.96       954\n",
      "           5       0.92      0.96      0.94       859\n",
      "           6       0.97      0.95      0.96       985\n",
      "           7       0.94      0.96      0.95      1005\n",
      "           8       0.95      0.92      0.94       996\n",
      "           9       0.93      0.94      0.94       998\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 39: 9501 / 10000\n",
      "Accuracy = 95.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.962      0.97465035 0.94337812 0.92403846 0.97395833 0.96507567\n",
      " 0.95867769 0.96414343 0.93839836 0.9345887 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.97      0.98      1144\n",
      "           2       0.95      0.94      0.95      1042\n",
      "           3       0.95      0.92      0.94      1040\n",
      "           4       0.95      0.97      0.96       960\n",
      "           5       0.93      0.97      0.95       859\n",
      "           6       0.97      0.96      0.96       968\n",
      "           7       0.94      0.96      0.95      1004\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.93      0.93      0.93      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 40: 9538 / 10000\n",
      "Accuracy = 95.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95508982 0.96302666 0.94615385 0.93891626 0.96319018 0.95532646\n",
      " 0.96257796 0.95874263 0.95449735 0.94422311]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.99      0.96      0.97      1163\n",
      "           2       0.95      0.95      0.95      1040\n",
      "           3       0.94      0.94      0.94      1015\n",
      "           4       0.96      0.96      0.96       978\n",
      "           5       0.93      0.96      0.95       873\n",
      "           6       0.97      0.96      0.96       962\n",
      "           7       0.95      0.96      0.95      1018\n",
      "           8       0.93      0.95      0.94       945\n",
      "           9       0.94      0.94      0.94      1004\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 41: 9542 / 10000\n",
      "Accuracy = 95.42%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95621891 0.97803163 0.95414634 0.93915604 0.94930417 0.95876289\n",
      " 0.95846314 0.96267191 0.93621399 0.95412844]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1005\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.95      0.95      0.95      1025\n",
      "           3       0.95      0.94      0.94      1019\n",
      "           4       0.97      0.95      0.96      1006\n",
      "           5       0.94      0.96      0.95       873\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.95      0.96      0.96      1018\n",
      "           8       0.93      0.94      0.94       972\n",
      "           9       0.93      0.95      0.94       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.96     10000\n",
      "\n",
      "Epoch 42: 9550 / 10000\n",
      "Accuracy = 95.50%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96468214 0.98323036 0.95592556 0.95837563 0.94836147 0.95681818\n",
      " 0.94343434 0.93389991 0.94045175 0.95      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       991\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.95      0.96      0.95      1021\n",
      "           3       0.93      0.96      0.95       985\n",
      "           4       0.97      0.95      0.96      1007\n",
      "           5       0.94      0.96      0.95       880\n",
      "           6       0.97      0.94      0.96       990\n",
      "           7       0.96      0.93      0.95      1059\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.90      0.95      0.93       960\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 43: 9538 / 10000\n",
      "Accuracy = 95.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95517928 0.97546012 0.95392157 0.9488978  0.94994995 0.96744186\n",
      " 0.94416244 0.9502439  0.91940299 0.95534787]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1004\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.94      0.95      0.95      1020\n",
      "           3       0.94      0.95      0.94       998\n",
      "           4       0.97      0.95      0.96       999\n",
      "           5       0.93      0.97      0.95       860\n",
      "           6       0.97      0.94      0.96       985\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.95      0.92      0.93      1005\n",
      "           9       0.91      0.96      0.93       963\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 44: 9521 / 10000\n",
      "Accuracy = 95.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94482759 0.96796537 0.95605469 0.95431472 0.95854398 0.9587156\n",
      " 0.95647668 0.95150339 0.94507772 0.94394394]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1015\n",
      "           1       0.99      0.97      0.98      1155\n",
      "           2       0.95      0.96      0.95      1024\n",
      "           3       0.93      0.95      0.94       985\n",
      "           4       0.97      0.96      0.96       989\n",
      "           5       0.94      0.96      0.95       872\n",
      "           6       0.96      0.96      0.96       965\n",
      "           7       0.95      0.95      0.95      1031\n",
      "           8       0.94      0.95      0.94       965\n",
      "           9       0.93      0.94      0.94       999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 45: 9539 / 10000\n",
      "Accuracy = 95.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95912263 0.97554585 0.95410156 0.9288499  0.97701149 0.94576271\n",
      " 0.95       0.95776031 0.93883792 0.95310907]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1003\n",
      "           1       0.98      0.98      0.98      1145\n",
      "           2       0.95      0.95      0.95      1024\n",
      "           3       0.94      0.93      0.94      1026\n",
      "           4       0.95      0.98      0.96       957\n",
      "           5       0.94      0.95      0.94       885\n",
      "           6       0.97      0.95      0.96       980\n",
      "           7       0.95      0.96      0.95      1018\n",
      "           8       0.95      0.94      0.94       981\n",
      "           9       0.93      0.95      0.94       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 46: 9543 / 10000\n",
      "Accuracy = 95.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96003996 0.97637795 0.95512195 0.93170732 0.96048632 0.96403712\n",
      " 0.95       0.9540567  0.94226804 0.94918699]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.98      0.98      0.98      1143\n",
      "           2       0.95      0.96      0.95      1025\n",
      "           3       0.95      0.93      0.94      1025\n",
      "           4       0.97      0.96      0.96       987\n",
      "           5       0.93      0.96      0.95       862\n",
      "           6       0.97      0.95      0.96       980\n",
      "           7       0.95      0.95      0.95      1023\n",
      "           8       0.94      0.94      0.94       970\n",
      "           9       0.93      0.95      0.94       984\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 47: 9545 / 10000\n",
      "Accuracy = 95.45%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95816733 0.9738676  0.93904762 0.93463415 0.96594427 0.95091324\n",
      " 0.95174538 0.97082495 0.96099675 0.91899711]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1004\n",
      "           1       0.99      0.97      0.98      1148\n",
      "           2       0.96      0.94      0.95      1050\n",
      "           3       0.95      0.93      0.94      1025\n",
      "           4       0.95      0.97      0.96       969\n",
      "           5       0.93      0.95      0.94       876\n",
      "           6       0.97      0.95      0.96       974\n",
      "           7       0.94      0.97      0.95       994\n",
      "           8       0.91      0.96      0.94       923\n",
      "           9       0.94      0.92      0.93      1037\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 48: 9525 / 10000\n",
      "Accuracy = 95.25%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96003996 0.9763986  0.96078431 0.93009709 0.95395395 0.96849475\n",
      " 0.95482546 0.95512195 0.93306288 0.95539419]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.98      0.98      0.98      1144\n",
      "           2       0.95      0.96      0.96      1020\n",
      "           3       0.95      0.93      0.94      1030\n",
      "           4       0.97      0.95      0.96       999\n",
      "           5       0.93      0.97      0.95       857\n",
      "           6       0.97      0.95      0.96       974\n",
      "           7       0.95      0.96      0.95      1025\n",
      "           8       0.94      0.93      0.94       986\n",
      "           9       0.91      0.96      0.93       964\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.95     10000\n",
      "\n",
      "Epoch 49: 9549 / 10000\n",
      "Accuracy = 95.49%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.958      0.97713281 0.9556213  0.92168099 0.96322778 0.96962617\n",
      " 0.9490316  0.94926829 0.93156282 0.9490835 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.94      0.96      0.95      1014\n",
      "           3       0.96      0.92      0.94      1047\n",
      "           4       0.96      0.96      0.96       979\n",
      "           5       0.93      0.97      0.95       856\n",
      "           6       0.97      0.95      0.96       981\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.94      0.93      0.93       979\n",
      "           9       0.92      0.95      0.94       982\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 50: 9524 / 10000\n",
      "Accuracy = 95.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96       0.97046047 0.96329365 0.90780809 0.968107   0.94582393\n",
      " 0.95257732 0.95566502 0.95238095 0.94343434]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.97      0.98      1151\n",
      "           2       0.94      0.96      0.95      1008\n",
      "           3       0.96      0.91      0.93      1063\n",
      "           4       0.96      0.97      0.96       972\n",
      "           5       0.94      0.95      0.94       886\n",
      "           6       0.96      0.95      0.96       970\n",
      "           7       0.94      0.96      0.95      1015\n",
      "           8       0.92      0.95      0.94       945\n",
      "           9       0.93      0.94      0.93       990\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 51: 9520 / 10000\n",
      "Accuracy = 95.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95441031 0.97971781 0.94534995 0.92940039 0.96322778 0.95351474\n",
      " 0.96342738 0.9593254  0.94450154 0.95412844]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1009\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.96      0.95      0.95      1043\n",
      "           3       0.95      0.93      0.94      1034\n",
      "           4       0.96      0.96      0.96       979\n",
      "           5       0.94      0.95      0.95       882\n",
      "           6       0.96      0.96      0.96       957\n",
      "           7       0.94      0.96      0.95      1008\n",
      "           8       0.94      0.94      0.94       973\n",
      "           9       0.93      0.95      0.94       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.95     10000\n",
      "\n",
      "Epoch 52: 9549 / 10000\n",
      "Accuracy = 95.49%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9667003  0.97891037 0.95592556 0.92628516 0.96724667 0.96721311\n",
      " 0.95384615 0.95686275 0.92871486 0.93981946]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       991\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.95      0.96      0.95      1021\n",
      "           3       0.95      0.93      0.94      1031\n",
      "           4       0.96      0.97      0.96       977\n",
      "           5       0.93      0.97      0.95       854\n",
      "           6       0.97      0.95      0.96       975\n",
      "           7       0.95      0.96      0.95      1020\n",
      "           8       0.95      0.93      0.94       996\n",
      "           9       0.93      0.94      0.93       997\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 53: 9542 / 10000\n",
      "Accuracy = 95.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96569122 0.96883117 0.96403596 0.92628516 0.9510978  0.95428571\n",
      " 0.94608342 0.95520935 0.93558282 0.96238245]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       991\n",
      "           1       0.99      0.97      0.98      1155\n",
      "           2       0.94      0.96      0.95      1001\n",
      "           3       0.95      0.93      0.94      1031\n",
      "           4       0.97      0.95      0.96      1002\n",
      "           5       0.94      0.95      0.95       875\n",
      "           6       0.97      0.95      0.96       983\n",
      "           7       0.95      0.96      0.95      1027\n",
      "           8       0.94      0.94      0.94       978\n",
      "           9       0.91      0.96      0.94       957\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 54: 9531 / 10000\n",
      "Accuracy = 95.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95883534 0.97635727 0.95476893 0.944334   0.91515729 0.93875278\n",
      " 0.94704684 0.94247363 0.94780793 0.97469747]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       996\n",
      "           1       0.98      0.98      0.98      1142\n",
      "           2       0.94      0.95      0.95      1017\n",
      "           3       0.94      0.94      0.94      1006\n",
      "           4       0.98      0.92      0.95      1049\n",
      "           5       0.95      0.94      0.94       898\n",
      "           6       0.97      0.95      0.96       982\n",
      "           7       0.96      0.94      0.95      1043\n",
      "           8       0.93      0.95      0.94       958\n",
      "           9       0.88      0.97      0.92       909\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 55: 9501 / 10000\n",
      "Accuracy = 95.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95504496 0.9806338  0.96031746 0.92425695 0.96813977 0.9595843\n",
      " 0.95454545 0.93726236 0.94075587 0.95174538]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.94      0.96      0.95      1008\n",
      "           3       0.95      0.92      0.94      1043\n",
      "           4       0.96      0.97      0.96       973\n",
      "           5       0.93      0.96      0.95       866\n",
      "           6       0.96      0.95      0.96       968\n",
      "           7       0.96      0.94      0.95      1052\n",
      "           8       0.95      0.94      0.94       979\n",
      "           9       0.92      0.95      0.93       974\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 56: 9533 / 10000\n",
      "Accuracy = 95.33%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95630586 0.97633655 0.95053346 0.94037146 0.96341463 0.9675174\n",
      " 0.95863495 0.95776031 0.94250513 0.93957704]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1007\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.95      0.95      0.95      1031\n",
      "           3       0.95      0.94      0.95      1023\n",
      "           4       0.97      0.96      0.96       984\n",
      "           5       0.93      0.97      0.95       862\n",
      "           6       0.97      0.96      0.96       967\n",
      "           7       0.95      0.96      0.95      1018\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.92      0.94      0.93       993\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.95      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "Epoch 57: 9554 / 10000\n",
      "Accuracy = 95.54%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95812562 0.97462817 0.94439118 0.94549058 0.95573441 0.94288914\n",
      " 0.95449845 0.95048544 0.94947368 0.95144628]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1003\n",
      "           1       0.98      0.97      0.98      1143\n",
      "           2       0.95      0.94      0.95      1043\n",
      "           3       0.94      0.95      0.95      1009\n",
      "           4       0.97      0.96      0.96       994\n",
      "           5       0.94      0.94      0.94       893\n",
      "           6       0.96      0.95      0.96       967\n",
      "           7       0.95      0.95      0.95      1030\n",
      "           8       0.93      0.95      0.94       950\n",
      "           9       0.91      0.95      0.93       968\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 58: 9531 / 10000\n",
      "Accuracy = 95.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95887663 0.97889182 0.93584906 0.92072588 0.95947315 0.96153846\n",
      " 0.9591195  0.95476893 0.94665272 0.94224924]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.98      0.98      0.98      1137\n",
      "           2       0.96      0.94      0.95      1060\n",
      "           3       0.95      0.92      0.94      1047\n",
      "           4       0.96      0.96      0.96       987\n",
      "           5       0.92      0.96      0.94       858\n",
      "           6       0.96      0.96      0.96       954\n",
      "           7       0.94      0.95      0.95      1017\n",
      "           8       0.93      0.95      0.94       956\n",
      "           9       0.92      0.94      0.93       987\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 59: 9518 / 10000\n",
      "Accuracy = 95.18%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9551346  0.97975352 0.94615385 0.94135189 0.95963673 0.92880613\n",
      " 0.95755694 0.95592556 0.9556962  0.95286885]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1003\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.95      0.95      0.95      1040\n",
      "           3       0.94      0.94      0.94      1006\n",
      "           4       0.97      0.96      0.96       991\n",
      "           5       0.95      0.93      0.94       913\n",
      "           6       0.97      0.96      0.96       966\n",
      "           7       0.95      0.96      0.95      1021\n",
      "           8       0.93      0.96      0.94       948\n",
      "           9       0.92      0.95      0.94       976\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 60: 9538 / 10000\n",
      "Accuracy = 95.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96196196 0.97302002 0.95635306 0.9372549  0.97512953 0.95113636\n",
      " 0.95194274 0.95357834 0.94502075 0.95306122]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.99      0.97      0.98      1149\n",
      "           2       0.96      0.96      0.96      1031\n",
      "           3       0.95      0.94      0.94      1020\n",
      "           4       0.96      0.98      0.97       965\n",
      "           5       0.94      0.95      0.94       880\n",
      "           6       0.97      0.95      0.96       978\n",
      "           7       0.96      0.95      0.96      1034\n",
      "           8       0.94      0.95      0.94       964\n",
      "           9       0.93      0.95      0.94       980\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "Epoch 61: 9561 / 10000\n",
      "Accuracy = 95.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96576032 0.97471665 0.956905   0.93542074 0.96625767 0.95\n",
      " 0.94720812 0.95414634 0.95449735 0.93824701]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       993\n",
      "           1       0.99      0.97      0.98      1147\n",
      "           2       0.95      0.96      0.95      1021\n",
      "           3       0.95      0.94      0.94      1022\n",
      "           4       0.96      0.97      0.96       978\n",
      "           5       0.94      0.95      0.94       880\n",
      "           6       0.97      0.95      0.96       985\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.93      0.95      0.94       945\n",
      "           9       0.93      0.94      0.94      1004\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 62: 9546 / 10000\n",
      "Accuracy = 95.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95908184 0.97982456 0.95401174 0.93879566 0.95582329 0.94176932\n",
      " 0.96041667 0.96142433 0.94507772 0.94188377]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.94      0.95      0.95      1022\n",
      "           3       0.94      0.94      0.94      1013\n",
      "           4       0.97      0.96      0.96       996\n",
      "           5       0.94      0.94      0.94       893\n",
      "           6       0.96      0.96      0.96       960\n",
      "           7       0.95      0.96      0.95      1011\n",
      "           8       0.94      0.95      0.94       965\n",
      "           9       0.93      0.94      0.94       998\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 63: 9543 / 10000\n",
      "Accuracy = 95.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96281407 0.96964441 0.95307918 0.92822502 0.96048632 0.94407159\n",
      " 0.94801223 0.96859169 0.93942505 0.95076923]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       995\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.94      0.95      0.95      1023\n",
      "           3       0.95      0.93      0.94      1031\n",
      "           4       0.97      0.96      0.96       987\n",
      "           5       0.95      0.94      0.95       894\n",
      "           6       0.97      0.95      0.96       981\n",
      "           7       0.93      0.97      0.95       987\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.92      0.95      0.93       975\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 64: 9528 / 10000\n",
      "Accuracy = 95.28%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96088265 0.97384481 0.94225217 0.92850242 0.95577889 0.96189376\n",
      " 0.95440415 0.9518664  0.9423275  0.9524302 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.98      0.97      0.98      1147\n",
      "           2       0.95      0.94      0.95      1039\n",
      "           3       0.95      0.93      0.94      1035\n",
      "           4       0.97      0.96      0.96       995\n",
      "           5       0.93      0.96      0.95       866\n",
      "           6       0.96      0.95      0.96       965\n",
      "           7       0.94      0.95      0.95      1018\n",
      "           8       0.94      0.94      0.94       971\n",
      "           9       0.91      0.95      0.93       967\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 65: 9525 / 10000\n",
      "Accuracy = 95.25%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.958      0.97453907 0.94731801 0.95714286 0.97113402 0.9481982\n",
      " 0.94984647 0.9507722  0.92828283 0.95286885]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.97      0.98      1139\n",
      "           2       0.96      0.95      0.95      1044\n",
      "           3       0.93      0.96      0.94       980\n",
      "           4       0.96      0.97      0.97       970\n",
      "           5       0.94      0.95      0.95       888\n",
      "           6       0.97      0.95      0.96       977\n",
      "           7       0.96      0.95      0.95      1036\n",
      "           8       0.94      0.93      0.94       990\n",
      "           9       0.92      0.95      0.94       976\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 66: 9541 / 10000\n",
      "Accuracy = 95.41%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96072508 0.96964441 0.94145873 0.92635659 0.96604938 0.96631823\n",
      " 0.95850622 0.94599807 0.94496366 0.94608342]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       993\n",
      "           1       0.99      0.97      0.98      1153\n",
      "           2       0.95      0.94      0.95      1042\n",
      "           3       0.95      0.93      0.94      1032\n",
      "           4       0.96      0.97      0.96       972\n",
      "           5       0.93      0.97      0.95       861\n",
      "           6       0.96      0.96      0.96       964\n",
      "           7       0.95      0.95      0.95      1037\n",
      "           8       0.93      0.94      0.94       963\n",
      "           9       0.92      0.95      0.93       983\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 67: 9525 / 10000\n",
      "Accuracy = 95.25%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.959      0.9721497  0.96520875 0.9303675  0.96236012 0.95995423\n",
      " 0.94349142 0.95601173 0.95735608 0.93912176]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.97      0.98      1149\n",
      "           2       0.94      0.97      0.95      1006\n",
      "           3       0.95      0.93      0.94      1034\n",
      "           4       0.96      0.96      0.96       983\n",
      "           5       0.94      0.96      0.95       874\n",
      "           6       0.98      0.94      0.96       991\n",
      "           7       0.95      0.96      0.95      1023\n",
      "           8       0.92      0.96      0.94       938\n",
      "           9       0.93      0.94      0.94      1002\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 68: 9546 / 10000\n",
      "Accuracy = 95.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95725646 0.98324515 0.95631068 0.93016489 0.96345178 0.96941176\n",
      " 0.94923858 0.95242718 0.94008264 0.9459735 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1006\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.95      0.96      0.96      1030\n",
      "           3       0.95      0.93      0.94      1031\n",
      "           4       0.97      0.96      0.96       985\n",
      "           5       0.92      0.97      0.95       850\n",
      "           6       0.98      0.95      0.96       985\n",
      "           7       0.95      0.95      0.95      1030\n",
      "           8       0.93      0.94      0.94       968\n",
      "           9       0.92      0.95      0.93       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.95     10000\n",
      "\n",
      "Epoch 69: 9549 / 10000\n",
      "Accuracy = 95.49%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96177062 0.9763986  0.95086705 0.93897638 0.96348884 0.9543379\n",
      " 0.95661157 0.95780177 0.95435244 0.93117011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.98      0.98      0.98      1144\n",
      "           2       0.96      0.95      0.95      1038\n",
      "           3       0.94      0.94      0.94      1016\n",
      "           4       0.97      0.96      0.97       986\n",
      "           5       0.94      0.95      0.95       876\n",
      "           6       0.97      0.96      0.96       968\n",
      "           7       0.95      0.96      0.95      1019\n",
      "           8       0.92      0.95      0.94       942\n",
      "           9       0.94      0.93      0.93      1017\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 70: 9548 / 10000\n",
      "Accuracy = 95.48%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95621891 0.97377622 0.95614035 0.93418468 0.97271773 0.95438997\n",
      " 0.9535124  0.95857988 0.94654088 0.91258405]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1005\n",
      "           1       0.98      0.97      0.98      1144\n",
      "           2       0.95      0.96      0.95      1026\n",
      "           3       0.94      0.93      0.94      1018\n",
      "           4       0.94      0.97      0.96       953\n",
      "           5       0.94      0.95      0.95       877\n",
      "           6       0.96      0.95      0.96       968\n",
      "           7       0.95      0.96      0.95      1014\n",
      "           8       0.93      0.95      0.94       954\n",
      "           9       0.94      0.91      0.93      1041\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 71: 9519 / 10000\n",
      "Accuracy = 95.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96084337 0.97719298 0.94550669 0.93627451 0.95862765 0.95852535\n",
      " 0.95360825 0.95414634 0.94467641 0.94929006]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.98      0.98      0.98      1140\n",
      "           2       0.96      0.95      0.95      1046\n",
      "           3       0.95      0.94      0.94      1020\n",
      "           4       0.97      0.96      0.96       991\n",
      "           5       0.93      0.96      0.95       868\n",
      "           6       0.97      0.95      0.96       970\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.93      0.94      0.94       958\n",
      "           9       0.93      0.95      0.94       986\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 72: 9541 / 10000\n",
      "Accuracy = 95.41%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96184739 0.97125436 0.95503421 0.92628516 0.96597938 0.95423341\n",
      " 0.94354839 0.95360316 0.93518519 0.9490316 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.98      0.97      0.98      1148\n",
      "           2       0.95      0.96      0.95      1023\n",
      "           3       0.95      0.93      0.94      1031\n",
      "           4       0.95      0.97      0.96       970\n",
      "           5       0.93      0.95      0.94       874\n",
      "           6       0.98      0.94      0.96       992\n",
      "           7       0.94      0.95      0.95      1013\n",
      "           8       0.93      0.94      0.93       972\n",
      "           9       0.92      0.95      0.94       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 73: 9518 / 10000\n",
      "Accuracy = 95.18%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95531281 0.9738676  0.94792671 0.94642857 0.96523517 0.9481982\n",
      " 0.95652174 0.95596869 0.94611399 0.95107034]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1007\n",
      "           1       0.99      0.97      0.98      1148\n",
      "           2       0.95      0.95      0.95      1037\n",
      "           3       0.94      0.95      0.95      1008\n",
      "           4       0.96      0.97      0.96       978\n",
      "           5       0.94      0.95      0.95       888\n",
      "           6       0.96      0.96      0.96       966\n",
      "           7       0.95      0.96      0.95      1022\n",
      "           8       0.94      0.95      0.94       965\n",
      "           9       0.92      0.95      0.94       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.96     10000\n",
      "\n",
      "Epoch 74: 9550 / 10000\n",
      "Accuracy = 95.50%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96177062 0.97552448 0.94889103 0.94742063 0.95959596 0.95558087\n",
      " 0.9526749  0.95490196 0.94014448 0.94838057]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.98      0.98      0.98      1144\n",
      "           2       0.95      0.95      0.95      1037\n",
      "           3       0.95      0.95      0.95      1008\n",
      "           4       0.97      0.96      0.96       990\n",
      "           5       0.94      0.96      0.95       878\n",
      "           6       0.97      0.95      0.96       972\n",
      "           7       0.95      0.95      0.95      1020\n",
      "           8       0.94      0.94      0.94       969\n",
      "           9       0.93      0.95      0.94       988\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 75: 9548 / 10000\n",
      "Accuracy = 95.48%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95621891 0.97633655 0.95596869 0.93682132 0.95209581 0.94825647\n",
      " 0.95473251 0.94951456 0.94715026 0.96149844]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1005\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.95      0.96      0.95      1022\n",
      "           3       0.94      0.94      0.94      1013\n",
      "           4       0.97      0.95      0.96      1002\n",
      "           5       0.95      0.95      0.95       889\n",
      "           6       0.97      0.95      0.96       972\n",
      "           7       0.95      0.95      0.95      1030\n",
      "           8       0.94      0.95      0.94       965\n",
      "           9       0.92      0.96      0.94       961\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 76: 9542 / 10000\n",
      "Accuracy = 95.42%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96184739 0.97046047 0.93965517 0.9380531  0.96424923 0.95319635\n",
      " 0.95463918 0.9612326  0.9377551  0.95005097]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.98      0.97      0.98      1151\n",
      "           2       0.95      0.94      0.95      1044\n",
      "           3       0.94      0.94      0.94      1017\n",
      "           4       0.96      0.96      0.96       979\n",
      "           5       0.94      0.95      0.94       876\n",
      "           6       0.97      0.95      0.96       970\n",
      "           7       0.94      0.96      0.95      1006\n",
      "           8       0.94      0.94      0.94       980\n",
      "           9       0.92      0.95      0.94       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 77: 9533 / 10000\n",
      "Accuracy = 95.33%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94140625 0.97471665 0.95169082 0.9395441  0.95290581 0.96499417\n",
      " 0.96141814 0.9552964  0.94879833 0.95431472]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1024\n",
      "           1       0.99      0.97      0.98      1147\n",
      "           2       0.95      0.95      0.95      1035\n",
      "           3       0.94      0.94      0.94      1009\n",
      "           4       0.97      0.95      0.96       998\n",
      "           5       0.93      0.96      0.95       857\n",
      "           6       0.96      0.96      0.96       959\n",
      "           7       0.96      0.96      0.96      1029\n",
      "           8       0.93      0.95      0.94       957\n",
      "           9       0.93      0.95      0.94       985\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 78: 9546 / 10000\n",
      "Accuracy = 95.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95708583 0.9721497  0.94555874 0.93281402 0.96337742 0.95852535\n",
      " 0.94699286 0.96314741 0.95147679 0.9445005 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1002\n",
      "           1       0.98      0.97      0.98      1149\n",
      "           2       0.96      0.95      0.95      1047\n",
      "           3       0.95      0.93      0.94      1027\n",
      "           4       0.96      0.96      0.96       983\n",
      "           5       0.93      0.96      0.95       868\n",
      "           6       0.97      0.95      0.96       981\n",
      "           7       0.94      0.96      0.95      1004\n",
      "           8       0.93      0.95      0.94       948\n",
      "           9       0.93      0.94      0.94       991\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 79: 9537 / 10000\n",
      "Accuracy = 95.37%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96003996 0.97297297 0.96245059 0.93399015 0.95281124 0.95578231\n",
      " 0.94795918 0.96059113 0.94409938 0.94726166]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.98      0.97      0.98      1147\n",
      "           2       0.94      0.96      0.95      1012\n",
      "           3       0.94      0.93      0.94      1015\n",
      "           4       0.97      0.95      0.96       996\n",
      "           5       0.95      0.96      0.95       882\n",
      "           6       0.97      0.95      0.96       980\n",
      "           7       0.95      0.96      0.95      1015\n",
      "           8       0.94      0.94      0.94       966\n",
      "           9       0.93      0.95      0.94       986\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 80: 9541 / 10000\n",
      "Accuracy = 95.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95613161 0.97132928 0.93667297 0.95790554 0.96220633 0.94920993\n",
      " 0.95036194 0.94269341 0.9411157  0.95346432]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1003\n",
      "           1       0.99      0.97      0.98      1151\n",
      "           2       0.96      0.94      0.95      1058\n",
      "           3       0.92      0.96      0.94       974\n",
      "           4       0.96      0.96      0.96       979\n",
      "           5       0.94      0.95      0.95       886\n",
      "           6       0.96      0.95      0.95       967\n",
      "           7       0.96      0.94      0.95      1047\n",
      "           8       0.94      0.94      0.94       968\n",
      "           9       0.91      0.95      0.93       967\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 81: 9523 / 10000\n",
      "Accuracy = 95.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95346535 0.97040905 0.94792671 0.9380531  0.9645749  0.95747126\n",
      " 0.95846314 0.95956607 0.94135802 0.95408163]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1010\n",
      "           1       0.98      0.97      0.98      1149\n",
      "           2       0.95      0.95      0.95      1037\n",
      "           3       0.94      0.94      0.94      1017\n",
      "           4       0.97      0.96      0.97       988\n",
      "           5       0.93      0.96      0.95       870\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.95      0.96      0.95      1014\n",
      "           8       0.94      0.94      0.94       972\n",
      "           9       0.93      0.95      0.94       980\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 82: 9547 / 10000\n",
      "Accuracy = 95.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94783465 0.97299652 0.93667297 0.93523062 0.96813977 0.94653015\n",
      " 0.95530146 0.95849802 0.95940171 0.93981946]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1016\n",
      "           1       0.98      0.97      0.98      1148\n",
      "           2       0.96      0.94      0.95      1058\n",
      "           3       0.94      0.94      0.94      1019\n",
      "           4       0.96      0.97      0.96       973\n",
      "           5       0.93      0.95      0.94       879\n",
      "           6       0.96      0.96      0.96       962\n",
      "           7       0.94      0.96      0.95      1012\n",
      "           8       0.92      0.96      0.94       936\n",
      "           9       0.93      0.94      0.93       997\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 83: 9522 / 10000\n",
      "Accuracy = 95.22%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.961      0.97384481 0.95432459 0.93177388 0.95665323 0.9481982\n",
      " 0.95282051 0.95224172 0.94032922 0.96507937]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.97      0.98      1147\n",
      "           2       0.95      0.95      0.95      1029\n",
      "           3       0.95      0.93      0.94      1026\n",
      "           4       0.97      0.96      0.96       992\n",
      "           5       0.94      0.95      0.95       888\n",
      "           6       0.97      0.95      0.96       975\n",
      "           7       0.95      0.95      0.95      1026\n",
      "           8       0.94      0.94      0.94       972\n",
      "           9       0.90      0.97      0.93       945\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 84: 9539 / 10000\n",
      "Accuracy = 95.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95436508 0.97891037 0.96055227 0.94263106 0.94815553 0.95537757\n",
      " 0.95833333 0.95507812 0.92462312 0.95272354]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1008\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.94      0.96      0.95      1014\n",
      "           3       0.94      0.94      0.94      1011\n",
      "           4       0.97      0.95      0.96      1003\n",
      "           5       0.94      0.96      0.95       874\n",
      "           6       0.96      0.96      0.96       960\n",
      "           7       0.95      0.96      0.95      1024\n",
      "           8       0.94      0.92      0.93       995\n",
      "           9       0.92      0.95      0.94       973\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 85: 9534 / 10000\n",
      "Accuracy = 95.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96288867 0.9720524  0.94807692 0.94280079 0.95943205 0.95771429\n",
      " 0.94501018 0.95592556 0.94496366 0.95291709]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.98      0.97      0.98      1145\n",
      "           2       0.96      0.95      0.95      1040\n",
      "           3       0.95      0.94      0.94      1014\n",
      "           4       0.96      0.96      0.96       986\n",
      "           5       0.94      0.96      0.95       875\n",
      "           6       0.97      0.95      0.96       982\n",
      "           7       0.95      0.96      0.95      1021\n",
      "           8       0.93      0.94      0.94       963\n",
      "           9       0.92      0.95      0.94       977\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 86: 9544 / 10000\n",
      "Accuracy = 95.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95054402 0.97633655 0.95303327 0.92122959 0.95656566 0.95068807\n",
      " 0.95841996 0.95210166 0.93654043 0.95317378]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1011\n",
      "           1       0.98      0.98      0.98      1141\n",
      "           2       0.94      0.95      0.95      1022\n",
      "           3       0.95      0.92      0.94      1041\n",
      "           4       0.96      0.96      0.96       990\n",
      "           5       0.93      0.95      0.94       872\n",
      "           6       0.96      0.96      0.96       962\n",
      "           7       0.95      0.95      0.95      1023\n",
      "           8       0.94      0.94      0.94       977\n",
      "           9       0.91      0.95      0.93       961\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 87: 9511 / 10000\n",
      "Accuracy = 95.11%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95346535 0.97382199 0.95776031 0.93418468 0.951      0.95011338\n",
      " 0.95638629 0.94908742 0.94709544 0.95720251]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1010\n",
      "           1       0.98      0.97      0.98      1146\n",
      "           2       0.94      0.96      0.95      1018\n",
      "           3       0.94      0.93      0.94      1018\n",
      "           4       0.97      0.95      0.96      1000\n",
      "           5       0.94      0.95      0.94       882\n",
      "           6       0.96      0.96      0.96       963\n",
      "           7       0.96      0.95      0.96      1041\n",
      "           8       0.94      0.95      0.94       964\n",
      "           9       0.91      0.96      0.93       958\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 88: 9533 / 10000\n",
      "Accuracy = 95.33%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.959      0.96707106 0.95081967 0.9488978  0.96435845 0.94196429\n",
      " 0.95454545 0.95618306 0.94513458 0.95781893]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.98      0.97      0.98      1154\n",
      "           2       0.96      0.95      0.95      1037\n",
      "           3       0.94      0.95      0.94       998\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.95      0.94      0.94       896\n",
      "           6       0.96      0.95      0.96       968\n",
      "           7       0.96      0.96      0.96      1027\n",
      "           8       0.94      0.95      0.94       966\n",
      "           9       0.92      0.96      0.94       972\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.95     10000\n",
      "\n",
      "Epoch 89: 9549 / 10000\n",
      "Accuracy = 95.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96666667 0.97368421 0.9548577  0.94223108 0.95190381 0.95028249\n",
      " 0.95473251 0.95317073 0.92936428 0.94979508]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       990\n",
      "           1       0.98      0.97      0.98      1140\n",
      "           2       0.94      0.95      0.95      1019\n",
      "           3       0.94      0.94      0.94      1004\n",
      "           4       0.97      0.95      0.96       998\n",
      "           5       0.94      0.95      0.95       885\n",
      "           6       0.97      0.95      0.96       972\n",
      "           7       0.95      0.95      0.95      1025\n",
      "           8       0.95      0.93      0.94       991\n",
      "           9       0.92      0.95      0.93       976\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 90: 9530 / 10000\n",
      "Accuracy = 95.30%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95526839 0.97212544 0.95238095 0.94356436 0.95939086 0.94713161\n",
      " 0.94779939 0.95583906 0.94306418 0.95365602]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1006\n",
      "           1       0.98      0.97      0.98      1148\n",
      "           2       0.95      0.95      0.95      1029\n",
      "           3       0.94      0.94      0.94      1010\n",
      "           4       0.96      0.96      0.96       985\n",
      "           5       0.94      0.95      0.95       889\n",
      "           6       0.97      0.95      0.96       977\n",
      "           7       0.95      0.96      0.95      1019\n",
      "           8       0.94      0.94      0.94       966\n",
      "           9       0.92      0.95      0.94       971\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 91: 9534 / 10000\n",
      "Accuracy = 95.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96188566 0.9763986  0.94534995 0.9380531  0.95850202 0.95642202\n",
      " 0.95056643 0.956905   0.94153846 0.95679012]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.98      0.98      0.98      1144\n",
      "           2       0.96      0.95      0.95      1043\n",
      "           3       0.94      0.94      0.94      1017\n",
      "           4       0.96      0.96      0.96       988\n",
      "           5       0.93      0.96      0.95       872\n",
      "           6       0.96      0.95      0.96       971\n",
      "           7       0.95      0.96      0.95      1021\n",
      "           8       0.94      0.94      0.94       975\n",
      "           9       0.92      0.96      0.94       972\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 92: 9545 / 10000\n",
      "Accuracy = 95.45%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95995996 0.97125436 0.95622568 0.94129353 0.95943205 0.94506726\n",
      " 0.94795918 0.95499022 0.94153846 0.95440415]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.98      0.97      0.98      1148\n",
      "           2       0.95      0.96      0.95      1028\n",
      "           3       0.94      0.94      0.94      1005\n",
      "           4       0.96      0.96      0.96       986\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.97      0.95      0.96       980\n",
      "           7       0.95      0.95      0.95      1022\n",
      "           8       0.94      0.94      0.94       975\n",
      "           9       0.91      0.95      0.93       965\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 93: 9536 / 10000\n",
      "Accuracy = 95.36%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96288867 0.97382199 0.95117188 0.91714286 0.96130346 0.96252927\n",
      " 0.94613821 0.95755183 0.95675105 0.94011976]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       997\n",
      "           1       0.98      0.97      0.98      1146\n",
      "           2       0.94      0.95      0.95      1024\n",
      "           3       0.95      0.92      0.93      1050\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.92      0.96      0.94       854\n",
      "           6       0.97      0.95      0.96       984\n",
      "           7       0.94      0.96      0.95      1013\n",
      "           8       0.93      0.96      0.94       948\n",
      "           9       0.93      0.94      0.94      1002\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 94: 9529 / 10000\n",
      "Accuracy = 95.29%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95721393 0.97046047 0.95251938 0.93867458 0.95190381 0.95742232\n",
      " 0.95252838 0.94869313 0.95238095 0.95962733]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1005\n",
      "           1       0.98      0.97      0.98      1151\n",
      "           2       0.95      0.95      0.95      1032\n",
      "           3       0.94      0.94      0.94      1011\n",
      "           4       0.97      0.95      0.96       998\n",
      "           5       0.93      0.96      0.94       869\n",
      "           6       0.96      0.95      0.96       969\n",
      "           7       0.95      0.95      0.95      1033\n",
      "           8       0.94      0.95      0.95       966\n",
      "           9       0.92      0.96      0.94       966\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 95: 9543 / 10000\n",
      "Accuracy = 95.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96103896 0.9679098  0.95878312 0.94521912 0.95748988 0.95475113\n",
      " 0.94989775 0.95583906 0.94244604 0.95107034]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1001\n",
      "           1       0.98      0.97      0.98      1153\n",
      "           2       0.95      0.96      0.95      1019\n",
      "           3       0.94      0.95      0.94      1004\n",
      "           4       0.96      0.96      0.96       988\n",
      "           5       0.95      0.95      0.95       884\n",
      "           6       0.97      0.95      0.96       978\n",
      "           7       0.95      0.96      0.95      1019\n",
      "           8       0.94      0.94      0.94       973\n",
      "           9       0.92      0.95      0.94       981\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 96: 9547 / 10000\n",
      "Accuracy = 95.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94980315 0.96788194 0.95494613 0.92621359 0.96138211 0.95227273\n",
      " 0.95548654 0.95494613 0.95440085 0.9473151 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1016\n",
      "           1       0.98      0.97      0.98      1152\n",
      "           2       0.94      0.95      0.95      1021\n",
      "           3       0.94      0.93      0.94      1030\n",
      "           4       0.96      0.96      0.96       984\n",
      "           5       0.94      0.95      0.95       880\n",
      "           6       0.96      0.96      0.96       966\n",
      "           7       0.95      0.95      0.95      1021\n",
      "           8       0.92      0.95      0.94       943\n",
      "           9       0.93      0.95      0.94       987\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 97: 9526 / 10000\n",
      "Accuracy = 95.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95895896 0.97377622 0.95173745 0.94071146 0.96212897 0.95752009\n",
      " 0.94969199 0.9469112  0.94484912 0.94343434]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       999\n",
      "           1       0.98      0.97      0.98      1144\n",
      "           2       0.96      0.95      0.95      1036\n",
      "           3       0.94      0.94      0.94      1012\n",
      "           4       0.96      0.96      0.96       977\n",
      "           5       0.93      0.96      0.95       871\n",
      "           6       0.97      0.95      0.96       974\n",
      "           7       0.95      0.95      0.95      1036\n",
      "           8       0.93      0.94      0.94       961\n",
      "           9       0.93      0.94      0.93       990\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 98: 9532 / 10000\n",
      "Accuracy = 95.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.9637827  0.97212544 0.94874275 0.93873518 0.95669688 0.95823666\n",
      " 0.94790603 0.95575221 0.94353183 0.95136778]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       994\n",
      "           1       0.98      0.97      0.98      1148\n",
      "           2       0.95      0.95      0.95      1034\n",
      "           3       0.94      0.94      0.94      1012\n",
      "           4       0.97      0.96      0.96       993\n",
      "           5       0.93      0.96      0.94       862\n",
      "           6       0.97      0.95      0.96       979\n",
      "           7       0.95      0.96      0.95      1017\n",
      "           8       0.94      0.94      0.94       974\n",
      "           9       0.93      0.95      0.94       987\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Epoch 99: 9539 / 10000\n",
      "Accuracy = 95.39%\n"
     ]
    }
   ],
   "source": [
    "net = network.Network([784, 30, 10])\n",
    "net.SGD(training_data, 100, 10, 3.0, test_data=test_data) #training_data, epochs, mini_batch_size, eta, test_data=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os resultados demonstram, um aumento na taxa de aprendizagem tende a um aumento na performance do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste momento, varia-se o tamanho da rede para observar o seu comportamento no desempenho do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.89793282 0.96813496 0.56785714 0.74006445 0.68654971 0.34485349\n",
      " 0.94744318 0.85211268 0.38778055 0.55758157]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       774\n",
      "           1       0.91      0.97      0.94      1067\n",
      "           2       0.46      0.57      0.51       840\n",
      "           3       0.68      0.74      0.71       931\n",
      "           4       0.60      0.69      0.64       855\n",
      "           5       0.51      0.34      0.41      1331\n",
      "           6       0.70      0.95      0.80       704\n",
      "           7       0.71      0.85      0.77       852\n",
      "           8       0.64      0.39      0.48      1604\n",
      "           9       0.58      0.56      0.57      1042\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     10000\n",
      "   macro avg       0.65      0.70      0.66     10000\n",
      "weighted avg       0.65      0.65      0.64     10000\n",
      "\n",
      "Epoch 0: 6536 / 10000\n",
      "Accuracy = 65.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "network.py:149: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.76646707 0.65567981 0.90311419 0.89473684 0.43347874 0.5\n",
      " 0.72176309 0.70642978 0.60039761 0.55125285]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83      1169\n",
      "           1       0.98      0.66      0.79      1699\n",
      "           2       0.51      0.90      0.65       578\n",
      "           3       0.52      0.89      0.66       589\n",
      "           4       0.81      0.43      0.56      1834\n",
      "           5       0.51      0.50      0.51       918\n",
      "           6       0.82      0.72      0.77      1089\n",
      "           7       0.81      0.71      0.76      1182\n",
      "           8       0.31      0.60      0.41       503\n",
      "           9       0.24      0.55      0.33       439\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     10000\n",
      "   macro avg       0.64      0.67      0.63     10000\n",
      "weighted avg       0.74      0.65      0.67     10000\n",
      "\n",
      "Epoch 1: 6478 / 10000\n",
      "Accuracy = 64.78%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93766234 0.90977444 0.87205882 0.64649682 0.48       0.36912281\n",
      " 0.57915058 0.         0.16115261 0.29716486]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.94      0.53       385\n",
      "           1       0.85      0.91      0.88      1064\n",
      "           2       0.57      0.87      0.69       680\n",
      "           3       0.80      0.65      0.72      1256\n",
      "           4       0.05      0.48      0.09       100\n",
      "           5       0.59      0.37      0.45      1425\n",
      "           6       0.78      0.58      0.67      1295\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.16      0.16      0.16       937\n",
      "           9       0.84      0.30      0.44      2857\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     10000\n",
      "   macro avg       0.50      0.53      0.46     10000\n",
      "weighted avg       0.69      0.51      0.54     10000\n",
      "\n",
      "Epoch 2: 5058 / 10000\n",
      "Accuracy = 50.58%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.57731305 0.75811001 0.61167748 0.27913199 0.25558476        nan\n",
      "        nan        nan 0.11934552        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.58      0.71      1578\n",
      "           1       0.95      0.76      0.84      1418\n",
      "           2       0.64      0.61      0.63      1079\n",
      "           3       0.93      0.28      0.43      3364\n",
      "           4       0.40      0.26      0.31      1522\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.13      0.12      0.12      1039\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.41      0.41      0.41     10000\n",
      "   macro avg       0.40      0.26      0.30     10000\n",
      "weighted avg       0.74      0.41      0.50     10000\n",
      "\n",
      "Epoch 3: 4098 / 10000\n",
      "Accuracy = 40.98%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.33333333 0.48945518 0.27064969 0.86666667 0.6875            nan\n",
      "        nan 0.15539226        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.33      0.00         3\n",
      "           1       0.98      0.49      0.65      2276\n",
      "           2       0.80      0.27      0.40      3063\n",
      "           3       0.01      0.87      0.03        15\n",
      "           4       0.01      0.69      0.02        16\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.70      0.16      0.25      4627\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.27      0.27      0.27     10000\n",
      "   macro avg       0.25      0.28      0.14     10000\n",
      "weighted avg       0.79      0.27      0.39     10000\n",
      "\n",
      "Epoch 4: 2687 / 10000\n",
      "Accuracy = 26.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan 0.79009901 0.21557719 0.85185185 0.65853659 0.13719614\n",
      "        nan 0.33021807        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.70      0.79      0.74      1010\n",
      "           2       0.90      0.22      0.35      4314\n",
      "           3       0.02      0.85      0.04        27\n",
      "           4       0.03      0.66      0.05        41\n",
      "           5       0.46      0.14      0.21      3003\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.52      0.33      0.40      1605\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.27      0.27      0.27     10000\n",
      "   macro avg       0.26      0.30      0.18     10000\n",
      "weighted avg       0.68      0.27      0.35     10000\n",
      "\n",
      "Epoch 5: 2720 / 10000\n",
      "Accuracy = 27.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan 0.94266917 0.15722543 0.69078947 0.66666667 0.14490786\n",
      "        nan 0.27272727        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.88      0.94      0.91      1064\n",
      "           2       0.53      0.16      0.24      3460\n",
      "           3       0.21      0.69      0.32       304\n",
      "           4       0.00      0.67      0.01         6\n",
      "           5       0.84      0.14      0.25      5155\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.27      0.01        11\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.25      0.25      0.25     10000\n",
      "   macro avg       0.25      0.29      0.17     10000\n",
      "weighted avg       0.71      0.25      0.32     10000\n",
      "\n",
      "Epoch 6: 2511 / 10000\n",
      "Accuracy = 25.11%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan 1.         0.40742857        nan 0.18053375        nan\n",
      "        nan 0.18248319        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.01      1.00      0.01         7\n",
      "           2       0.69      0.41      0.51      1750\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.59      0.18      0.28      3185\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.90      0.18      0.30      5058\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.22      0.22      0.22     10000\n",
      "   macro avg       0.22      0.18      0.11     10000\n",
      "weighted avg       0.76      0.22      0.33     10000\n",
      "\n",
      "Epoch 7: 2218 / 10000\n",
      "Accuracy = 22.18%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan 0.91226097 0.20316223        nan 0.03149606 0.07892204\n",
      " 0.64262821 0.5               nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.71      0.91      0.80       889\n",
      "           2       0.91      0.20      0.33      4617\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.03      0.01       127\n",
      "           5       0.28      0.08      0.12      3117\n",
      "           6       0.84      0.64      0.73      1248\n",
      "           7       0.00      0.50      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.28      0.28      0.28     10000\n",
      "   macro avg       0.27      0.24      0.20     10000\n",
      "weighted avg       0.67      0.28      0.35     10000\n",
      "\n",
      "Epoch 8: 2802 / 10000\n",
      "Accuracy = 28.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[1.         0.75019455 0.43482741 0.4653706  0.20441676 0.\n",
      " 0.11570844 0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         1\n",
      "           1       0.85      0.75      0.80      1285\n",
      "           2       0.82      0.43      0.57      1941\n",
      "           3       0.38      0.47      0.42       823\n",
      "           4       0.37      0.20      0.26      1766\n",
      "           5       0.00      0.00      0.00        23\n",
      "           6       0.50      0.12      0.19      4157\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.30      0.30      0.30     10000\n",
      "   macro avg       0.29      0.30      0.22     10000\n",
      "weighted avg       0.57      0.30      0.37     10000\n",
      "\n",
      "Epoch 9: 3034 / 10000\n",
      "Accuracy = 30.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[       nan 0.75817923 0.16071717        nan 0.07135399 0.07359307\n",
      "        nan 0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.47      0.76      0.58       703\n",
      "           2       0.96      0.16      0.28      6191\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.21      0.07      0.11      2873\n",
      "           5       0.02      0.07      0.03       231\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.17      0.17      0.17     10000\n",
      "   macro avg       0.17      0.11      0.10     10000\n",
      "weighted avg       0.69      0.17      0.24     10000\n",
      "\n",
      "Epoch 10: 1750 / 10000\n",
      "Accuracy = 17.50%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan 0.30849825        nan 0.11665824 0.10810811\n",
      "        nan        nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.51      0.31      0.39      1718\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.94      0.12      0.21      7912\n",
      "           5       0.04      0.11      0.06       370\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.15      0.15      0.15     10000\n",
      "   macro avg       0.15      0.05      0.07     10000\n",
      "weighted avg       0.83      0.15      0.23     10000\n",
      "\n",
      "Epoch 11: 1493 / 10000\n",
      "Accuracy = 14.93%\n",
      "\n",
      "Accuracy for each class\n",
      "[1.         0.86892489 0.26219726 0.13564406 0.09027778 0.21621622\n",
      "        nan        nan        nan 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         1\n",
      "           1       0.52      0.87      0.65       679\n",
      "           2       0.72      0.26      0.38      2849\n",
      "           3       0.81      0.14      0.23      6001\n",
      "           4       0.04      0.09      0.06       432\n",
      "           5       0.01      0.22      0.02        37\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.22      0.22      0.22     10000\n",
      "   macro avg       0.21      0.26      0.13     10000\n",
      "weighted avg       0.73      0.22      0.30     10000\n",
      "\n",
      "Epoch 12: 2199 / 10000\n",
      "Accuracy = 21.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[1.         0.54010695 0.36082877        nan 0.15303006 0.18333333\n",
      "        nan        nan        nan 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      1.00      0.07        38\n",
      "           1       0.53      0.54      0.54      1122\n",
      "           2       0.89      0.36      0.51      2558\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.97      0.15      0.26      6221\n",
      "           5       0.01      0.18      0.02        60\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.25      0.25      0.25     10000\n",
      "   macro avg       0.24      0.22      0.14     10000\n",
      "weighted avg       0.89      0.25      0.36     10000\n",
      "\n",
      "Epoch 13: 2530 / 10000\n",
      "Accuracy = 25.30%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.         0.41252372 0.18106509 0.13479195 0.21695402 0.\n",
      "        nan        nan        nan 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      0.41      0.58      2635\n",
      "           2       0.15      0.18      0.16       845\n",
      "           3       0.68      0.13      0.23      5119\n",
      "           4       0.31      0.22      0.25      1392\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.22      0.22      0.22     10000\n",
      "   macro avg       0.21      0.09      0.12     10000\n",
      "weighted avg       0.66      0.22      0.32     10000\n",
      "\n",
      "Epoch 14: 2232 / 10000\n",
      "Accuracy = 22.32%\n",
      "\n",
      "Accuracy for each class\n",
      "[1.         0.77426471 0.50985915 0.16897196 0.29774614 0.33333333\n",
      " 0.32625884        nan        nan 0.24742268]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         1\n",
      "           1       0.93      0.77      0.84      1360\n",
      "           2       0.88      0.51      0.64      1775\n",
      "           3       0.45      0.17      0.25      2675\n",
      "           4       0.51      0.30      0.38      1686\n",
      "           5       0.00      0.33      0.00         3\n",
      "           6       0.82      0.33      0.47      2403\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.02      0.25      0.04        97\n",
      "\n",
      "   micro avg       0.37      0.37      0.37     10000\n",
      "   macro avg       0.36      0.37      0.26     10000\n",
      "weighted avg       0.68      0.37      0.47     10000\n",
      "\n",
      "Epoch 15: 3722 / 10000\n",
      "Accuracy = 37.22%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan 0.25       0.09517895        nan\n",
      " 0.73722628 0.89285714        nan 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.25      0.00         4\n",
      "           4       0.86      0.10      0.17      8857\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.84      0.74      0.79      1096\n",
      "           7       0.02      0.89      0.05        28\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00        15\n",
      "\n",
      "   micro avg       0.17      0.17      0.17     10000\n",
      "   macro avg       0.17      0.20      0.10     10000\n",
      "weighted avg       0.85      0.17      0.24     10000\n",
      "\n",
      "Epoch 16: 1677 / 10000\n",
      "Accuracy = 16.77%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.10037817        nan\n",
      " 0.88888889 0.60054348        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.95      0.10      0.18      9255\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.01      0.89      0.02         9\n",
      "           7       0.43      0.60      0.50       736\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.14      0.14      0.14     10000\n",
      "   macro avg       0.14      0.16      0.07     10000\n",
      "weighted avg       0.91      0.14      0.20     10000\n",
      "\n",
      "Epoch 17: 1379 / 10000\n",
      "Accuracy = 13.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.10446224        nan\n",
      " 0.94117647 0.54660529        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.93      0.10      0.19      8740\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.38      0.94      0.55       391\n",
      "           7       0.46      0.55      0.50       869\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.18      0.18      0.18     10000\n",
      "   macro avg       0.18      0.16      0.12     10000\n",
      "weighted avg       0.87      0.18      0.23     10000\n",
      "\n",
      "Epoch 18: 1756 / 10000\n",
      "Accuracy = 17.56%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.09795878 0.\n",
      "        nan 0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      0.10      0.18      9994\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.01      0.02     10000\n",
      "weighted avg       1.00      0.10      0.18     10000\n",
      "\n",
      "Epoch 19: 979 / 10000\n",
      "Accuracy = 9.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.09820982 0.\n",
      "        nan        nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      0.10      0.18      9999\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.01      0.02     10000\n",
      "weighted avg       1.00      0.10      0.18     10000\n",
      "\n",
      "Epoch 20: 982 / 10000\n",
      "Accuracy = 9.82%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.10061802 0.\n",
      "        nan 0.62628866        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.95      0.10      0.18      9223\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.47      0.63      0.54       776\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.14      0.14      0.14     10000\n",
      "   macro avg       0.14      0.07      0.07     10000\n",
      "weighted avg       0.91      0.14      0.21     10000\n",
      "\n",
      "Epoch 21: 1414 / 10000\n",
      "Accuracy = 14.14%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.09798819        nan\n",
      "        nan 0.5               nan 0.14285714]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      0.10      0.18      9991\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.50      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.14      0.00         7\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.07      0.02     10000\n",
      "weighted avg       1.00      0.10      0.18     10000\n",
      "\n",
      "Epoch 22: 981 / 10000\n",
      "Accuracy = 9.81%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.95238095        nan\n",
      "        nan 0.10500511        nan 0.00529101]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.02      0.95      0.04        21\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       1.00      0.11      0.19      9790\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.01      0.00       189\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.11      0.02     10000\n",
      "weighted avg       0.98      0.10      0.19     10000\n",
      "\n",
      "Epoch 23: 1049 / 10000\n",
      "Accuracy = 10.49%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.89655172        nan\n",
      "        nan 0.10528472        nan 0.01449275]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.03      0.90      0.05        29\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       1.00      0.11      0.19      9764\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.01      0.00       207\n",
      "\n",
      "   micro avg       0.11      0.11      0.11     10000\n",
      "   macro avg       0.10      0.10      0.02     10000\n",
      "weighted avg       0.98      0.11      0.19     10000\n",
      "\n",
      "Epoch 24: 1057 / 10000\n",
      "Accuracy = 10.57%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.90909091        nan\n",
      "        nan 0.10511247        nan 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.03      0.91      0.06        33\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       1.00      0.11      0.19      9780\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00       187\n",
      "\n",
      "   micro avg       0.11      0.11      0.11     10000\n",
      "   macro avg       0.10      0.10      0.02     10000\n",
      "weighted avg       0.98      0.11      0.19     10000\n",
      "\n",
      "Epoch 25: 1058 / 10000\n",
      "Accuracy = 10.58%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.81084489        nan\n",
      "        nan 0.11281598        nan 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.65      0.81      0.72       793\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.99      0.11      0.20      9059\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00       148\n",
      "\n",
      "   micro avg       0.17      0.17      0.17     10000\n",
      "   macro avg       0.16      0.09      0.09     10000\n",
      "weighted avg       0.95      0.17      0.24     10000\n",
      "\n",
      "Epoch 26: 1665 / 10000\n",
      "Accuracy = 16.65%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.74756098        nan\n",
      "        nan 0.11569966        nan 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.62      0.75      0.68       820\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.99      0.12      0.21      8790\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00       390\n",
      "\n",
      "   micro avg       0.16      0.16      0.16     10000\n",
      "   macro avg       0.16      0.09      0.09     10000\n",
      "weighted avg       0.92      0.16      0.24     10000\n",
      "\n",
      "Epoch 27: 1630 / 10000\n",
      "Accuracy = 16.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.66666667        nan\n",
      "        nan 0.10620932        nan 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.67      0.00         3\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       1.00      0.11      0.19      9679\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00       318\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.08      0.02     10000\n",
      "weighted avg       0.97      0.10      0.19     10000\n",
      "\n",
      "Epoch 28: 1030 / 10000\n",
      "Accuracy = 10.30%\n",
      "\n",
      "Accuracy for each class\n",
      "[       nan        nan        nan        nan 0.55844156        nan\n",
      "        nan 0.10977199        nan 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.18      0.56      0.27       308\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.98      0.11      0.20      9210\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00       482\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     10000\n",
      "   macro avg       0.12      0.07      0.05     10000\n",
      "weighted avg       0.91      0.12      0.19     10000\n",
      "\n",
      "Epoch 29: 1183 / 10000\n",
      "Accuracy = 11.83%\n"
     ]
    }
   ],
   "source": [
    "net = network.Network([784, 30, 30, 10])\n",
    "net.SGD(training_data, 30, 1, 3.0, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.71492205 0.69887077 0.74       0.40675403 0.46142093 0.29947917\n",
      " 0.40292486 0.70814273 0.56666667 0.39670932]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.71      0.45       449\n",
      "           1       0.98      0.70      0.82      1594\n",
      "           2       0.04      0.74      0.07        50\n",
      "           3       0.80      0.41      0.54      1984\n",
      "           4       0.62      0.46      0.53      1309\n",
      "           5       0.13      0.30      0.18       384\n",
      "           6       0.83      0.40      0.54      1983\n",
      "           7       0.75      0.71      0.73      1093\n",
      "           8       0.03      0.57      0.07        60\n",
      "           9       0.43      0.40      0.41      1094\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     10000\n",
      "   macro avg       0.49      0.54      0.43     10000\n",
      "weighted avg       0.71      0.50      0.57     10000\n",
      "\n",
      "Epoch 0: 5039 / 10000\n",
      "Accuracy = 50.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81704782 0.76125512 0.90225564 0.57378223 0.53653295 0.55958549\n",
      " 0.6784831  0.84575026 0.73937153 0.5369863 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       962\n",
      "           1       0.98      0.76      0.86      1466\n",
      "           2       0.35      0.90      0.50       399\n",
      "           3       0.79      0.57      0.67      1396\n",
      "           4       0.76      0.54      0.63      1396\n",
      "           5       0.36      0.56      0.44       579\n",
      "           6       0.86      0.68      0.76      1213\n",
      "           7       0.78      0.85      0.81       953\n",
      "           8       0.41      0.74      0.53       541\n",
      "           9       0.58      0.54      0.56      1095\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.67      0.70      0.66     10000\n",
      "weighted avg       0.74      0.68      0.69     10000\n",
      "\n",
      "Epoch 1: 6753 / 10000\n",
      "Accuracy = 67.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82889734 0.82740741 0.91376451 0.67202029 0.59653092 0.7375\n",
      " 0.78256795 0.87526205 0.76773296 0.5851602 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1052\n",
      "           1       0.98      0.83      0.90      1350\n",
      "           2       0.53      0.91      0.67       603\n",
      "           3       0.79      0.67      0.73      1183\n",
      "           4       0.81      0.60      0.69      1326\n",
      "           5       0.46      0.74      0.57       560\n",
      "           6       0.87      0.78      0.82      1067\n",
      "           7       0.81      0.88      0.84       954\n",
      "           8       0.57      0.77      0.65       719\n",
      "           9       0.69      0.59      0.63      1186\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.74      0.76      0.74     10000\n",
      "weighted avg       0.78      0.75      0.75     10000\n",
      "\n",
      "Epoch 2: 7455 / 10000\n",
      "Accuracy = 74.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8470255  0.87607843 0.92972182 0.73170732 0.64581704 0.81153846\n",
      " 0.82910156 0.88       0.76904762 0.61389338]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88      1059\n",
      "           1       0.98      0.88      0.93      1275\n",
      "           2       0.62      0.93      0.74       683\n",
      "           3       0.80      0.73      0.77      1107\n",
      "           4       0.84      0.65      0.73      1279\n",
      "           5       0.47      0.81      0.60       520\n",
      "           6       0.89      0.83      0.86      1024\n",
      "           7       0.83      0.88      0.86       975\n",
      "           8       0.66      0.77      0.71       840\n",
      "           9       0.75      0.61      0.68      1238\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.79      0.77     10000\n",
      "weighted avg       0.81      0.78      0.79     10000\n",
      "\n",
      "Epoch 3: 7820 / 10000\n",
      "Accuracy = 78.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82553957 0.90056589 0.94514768 0.77887463 0.71318493 0.83600713\n",
      " 0.85155466 0.89925769 0.77237569 0.62084257]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88      1112\n",
      "           1       0.98      0.90      0.94      1237\n",
      "           2       0.65      0.95      0.77       711\n",
      "           3       0.78      0.78      0.78      1013\n",
      "           4       0.85      0.71      0.77      1168\n",
      "           5       0.53      0.84      0.65       561\n",
      "           6       0.89      0.85      0.87       997\n",
      "           7       0.82      0.90      0.86       943\n",
      "           8       0.72      0.77      0.74       905\n",
      "           9       0.83      0.62      0.71      1353\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.81      0.80     10000\n",
      "weighted avg       0.82      0.80      0.81     10000\n",
      "\n",
      "Epoch 4: 8031 / 10000\n",
      "Accuracy = 80.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83800905 0.91824938 0.95348837 0.80668016 0.75765766 0.86021505\n",
      " 0.85458167 0.90811966 0.76690947 0.63467049]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89      1105\n",
      "           1       0.98      0.92      0.95      1211\n",
      "           2       0.68      0.95      0.79       731\n",
      "           3       0.79      0.81      0.80       988\n",
      "           4       0.86      0.76      0.80      1110\n",
      "           5       0.54      0.86      0.66       558\n",
      "           6       0.90      0.85      0.87      1004\n",
      "           7       0.83      0.91      0.87       936\n",
      "           8       0.76      0.77      0.76       961\n",
      "           9       0.88      0.63      0.74      1396\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.81      0.83      0.81     10000\n",
      "weighted avg       0.84      0.82      0.82     10000\n",
      "\n",
      "Epoch 5: 8184 / 10000\n",
      "Accuracy = 81.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84377838 0.93176074 0.95739015 0.82186235 0.76224399 0.88311688\n",
      " 0.86639676 0.92197802 0.75416259 0.64152299]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89      1101\n",
      "           1       0.97      0.93      0.95      1187\n",
      "           2       0.70      0.96      0.81       751\n",
      "           3       0.80      0.82      0.81       988\n",
      "           4       0.87      0.76      0.81      1123\n",
      "           5       0.53      0.88      0.67       539\n",
      "           6       0.89      0.87      0.88       988\n",
      "           7       0.82      0.92      0.87       910\n",
      "           8       0.79      0.75      0.77      1021\n",
      "           9       0.89      0.64      0.74      1392\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.82      0.84      0.82     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "Epoch 6: 8256 / 10000\n",
      "Accuracy = 82.56%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8426259  0.93254637 0.96271638 0.83197556 0.7748227  0.89292196\n",
      " 0.87031408 0.93095768 0.76597837 0.65057637]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90      1112\n",
      "           1       0.97      0.93      0.95      1186\n",
      "           2       0.70      0.96      0.81       751\n",
      "           3       0.81      0.83      0.82       982\n",
      "           4       0.89      0.77      0.83      1128\n",
      "           5       0.55      0.89      0.68       551\n",
      "           6       0.90      0.87      0.88       987\n",
      "           7       0.81      0.93      0.87       898\n",
      "           8       0.80      0.77      0.78      1017\n",
      "           9       0.89      0.65      0.75      1388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.85      0.83     10000\n",
      "weighted avg       0.85      0.83      0.83     10000\n",
      "\n",
      "Epoch 7: 8326 / 10000\n",
      "Accuracy = 83.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84886878 0.94520548 0.96648794 0.83604888 0.78507993 0.89043478\n",
      " 0.87309645 0.92399566 0.76140684 0.67313433]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      1105\n",
      "           1       0.97      0.95      0.96      1168\n",
      "           2       0.70      0.97      0.81       746\n",
      "           3       0.81      0.84      0.82       982\n",
      "           4       0.90      0.79      0.84      1126\n",
      "           5       0.57      0.89      0.70       575\n",
      "           6       0.90      0.87      0.89       985\n",
      "           7       0.83      0.92      0.87       921\n",
      "           8       0.82      0.76      0.79      1052\n",
      "           9       0.89      0.67      0.77      1340\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.85      0.83     10000\n",
      "weighted avg       0.86      0.84      0.84     10000\n",
      "\n",
      "Epoch 8: 8394 / 10000\n",
      "Accuracy = 83.94%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.8438061  0.94596913 0.96679947 0.84536082 0.78798587 0.89630931\n",
      " 0.87234043 0.93756968 0.76253548 0.67232472]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90      1114\n",
      "           1       0.97      0.95      0.96      1166\n",
      "           2       0.71      0.97      0.82       753\n",
      "           3       0.81      0.85      0.83       970\n",
      "           4       0.91      0.79      0.84      1132\n",
      "           5       0.57      0.90      0.70       569\n",
      "           6       0.90      0.87      0.89       987\n",
      "           7       0.82      0.94      0.87       897\n",
      "           8       0.83      0.76      0.79      1057\n",
      "           9       0.90      0.67      0.77      1355\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.85      0.84     10000\n",
      "weighted avg       0.86      0.84      0.84     10000\n",
      "\n",
      "Epoch 9: 8412 / 10000\n",
      "Accuracy = 84.12%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84333035 0.95090439 0.96774194 0.83919598 0.7876652  0.9118705\n",
      " 0.87704918 0.93986637 0.76704545 0.67107195]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90      1117\n",
      "           1       0.97      0.95      0.96      1161\n",
      "           2       0.70      0.97      0.81       744\n",
      "           3       0.83      0.84      0.83       995\n",
      "           4       0.91      0.79      0.84      1135\n",
      "           5       0.57      0.91      0.70       556\n",
      "           6       0.89      0.88      0.89       976\n",
      "           7       0.82      0.94      0.88       898\n",
      "           8       0.83      0.77      0.80      1056\n",
      "           9       0.91      0.67      0.77      1362\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.86      0.84     10000\n",
      "weighted avg       0.86      0.84      0.84     10000\n",
      "\n",
      "Epoch 10: 8426 / 10000\n",
      "Accuracy = 84.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84196429 0.94995686 0.96854522 0.84068136 0.80428954 0.92167577\n",
      " 0.87841945 0.94039735 0.76394052 0.69085412]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90      1120\n",
      "           1       0.97      0.95      0.96      1159\n",
      "           2       0.72      0.97      0.82       763\n",
      "           3       0.83      0.84      0.84       998\n",
      "           4       0.92      0.80      0.86      1119\n",
      "           5       0.57      0.92      0.70       549\n",
      "           6       0.91      0.88      0.89       987\n",
      "           7       0.83      0.94      0.88       906\n",
      "           8       0.84      0.76      0.80      1076\n",
      "           9       0.91      0.69      0.78      1323\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.84      0.86      0.84     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 11: 8483 / 10000\n",
      "Accuracy = 84.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84450402 0.95004307 0.97082228 0.84545455 0.79911894 0.93333333\n",
      " 0.88374486 0.94630872 0.74621549 0.69512195]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90      1119\n",
      "           1       0.97      0.95      0.96      1161\n",
      "           2       0.71      0.97      0.82       754\n",
      "           3       0.83      0.85      0.84       990\n",
      "           4       0.92      0.80      0.86      1135\n",
      "           5       0.57      0.93      0.70       540\n",
      "           6       0.90      0.88      0.89       972\n",
      "           7       0.82      0.95      0.88       894\n",
      "           8       0.86      0.75      0.80      1123\n",
      "           9       0.90      0.70      0.79      1312\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.84      0.86      0.84     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 12: 8483 / 10000\n",
      "Accuracy = 84.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84870188 0.95250432 0.9772423  0.85817061 0.80625    0.93014706\n",
      " 0.88774459 0.94432071 0.74336283 0.68554396]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90      1117\n",
      "           1       0.97      0.95      0.96      1158\n",
      "           2       0.71      0.98      0.82       747\n",
      "           3       0.83      0.86      0.84       973\n",
      "           4       0.92      0.81      0.86      1120\n",
      "           5       0.57      0.93      0.70       544\n",
      "           6       0.90      0.89      0.89       971\n",
      "           7       0.82      0.94      0.88       898\n",
      "           8       0.86      0.74      0.80      1130\n",
      "           9       0.91      0.69      0.78      1342\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.86      0.84     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 13: 8495 / 10000\n",
      "Accuracy = 84.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84946237 0.95       0.97860963 0.86034659 0.80427046 0.93984962\n",
      " 0.89648033 0.94425864 0.73224979 0.6993114 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90      1116\n",
      "           1       0.97      0.95      0.96      1160\n",
      "           2       0.71      0.98      0.82       748\n",
      "           3       0.84      0.86      0.85       981\n",
      "           4       0.92      0.80      0.86      1124\n",
      "           5       0.56      0.94      0.70       532\n",
      "           6       0.90      0.90      0.90       966\n",
      "           7       0.82      0.94      0.88       897\n",
      "           8       0.88      0.73      0.80      1169\n",
      "           9       0.91      0.70      0.79      1307\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 14: 8513 / 10000\n",
      "Accuracy = 85.13%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84656557 0.95324675 0.97631579 0.87240664 0.80676759 0.94074074\n",
      " 0.8902439  0.94555556 0.73557278 0.70743034]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90      1121\n",
      "           1       0.97      0.95      0.96      1155\n",
      "           2       0.72      0.98      0.83       760\n",
      "           3       0.83      0.87      0.85       964\n",
      "           4       0.92      0.81      0.86      1123\n",
      "           5       0.57      0.94      0.71       540\n",
      "           6       0.91      0.89      0.90       984\n",
      "           7       0.83      0.95      0.88       900\n",
      "           8       0.88      0.74      0.80      1161\n",
      "           9       0.91      0.71      0.79      1292\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.87      0.85      0.86     10000\n",
      "\n",
      "Epoch 15: 8542 / 10000\n",
      "Accuracy = 85.42%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85152057 0.95004307 0.97766097 0.86721144 0.80748663 0.94636015\n",
      " 0.89917695 0.94618834 0.73112807 0.70633694]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91      1118\n",
      "           1       0.97      0.95      0.96      1161\n",
      "           2       0.72      0.98      0.83       761\n",
      "           3       0.84      0.87      0.85       979\n",
      "           4       0.92      0.81      0.86      1122\n",
      "           5       0.55      0.95      0.70       522\n",
      "           6       0.91      0.90      0.91       972\n",
      "           7       0.82      0.95      0.88       892\n",
      "           8       0.89      0.73      0.80      1179\n",
      "           9       0.91      0.71      0.79      1294\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.87      0.85      0.86     10000\n",
      "\n",
      "Epoch 16: 8542 / 10000\n",
      "Accuracy = 85.42%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85701439 0.95238095 0.98023715 0.88117771 0.80567879 0.94227188\n",
      " 0.89430894 0.95248869 0.72433775 0.71317225]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      1112\n",
      "           1       0.97      0.95      0.96      1155\n",
      "           2       0.72      0.98      0.83       759\n",
      "           3       0.83      0.88      0.85       951\n",
      "           4       0.92      0.81      0.86      1127\n",
      "           5       0.57      0.94      0.71       537\n",
      "           6       0.92      0.89      0.91       984\n",
      "           7       0.82      0.95      0.88       884\n",
      "           8       0.90      0.72      0.80      1208\n",
      "           9       0.91      0.71      0.80      1283\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 17: 8561 / 10000\n",
      "Accuracy = 85.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.85496867 0.95415225 0.97891963 0.87295082 0.80636605 0.95183044\n",
      " 0.8968335  0.94831461 0.72674419 0.72025217]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91      1117\n",
      "           1       0.97      0.95      0.96      1156\n",
      "           2       0.72      0.98      0.83       759\n",
      "           3       0.84      0.87      0.86       976\n",
      "           4       0.93      0.81      0.86      1131\n",
      "           5       0.55      0.95      0.70       519\n",
      "           6       0.92      0.90      0.91       979\n",
      "           7       0.82      0.95      0.88       890\n",
      "           8       0.90      0.73      0.80      1204\n",
      "           9       0.91      0.72      0.80      1269\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 18: 8570 / 10000\n",
      "Accuracy = 85.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84929078 0.9573913  0.97771953 0.87706612 0.80650836 0.95542636\n",
      " 0.89846154 0.94920993 0.72405272 0.72288203]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1128\n",
      "           1       0.97      0.96      0.96      1150\n",
      "           2       0.72      0.98      0.83       763\n",
      "           3       0.84      0.88      0.86       968\n",
      "           4       0.93      0.81      0.87      1137\n",
      "           5       0.55      0.96      0.70       516\n",
      "           6       0.91      0.90      0.91       975\n",
      "           7       0.82      0.95      0.88       886\n",
      "           8       0.90      0.72      0.80      1214\n",
      "           9       0.90      0.72      0.80      1263\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 19: 8573 / 10000\n",
      "Accuracy = 85.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84628975 0.96066434 0.98021108 0.88655462 0.82046679 0.94980695\n",
      " 0.89318413 0.95238095 0.70630487 0.72468354]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1132\n",
      "           1       0.97      0.96      0.96      1144\n",
      "           2       0.72      0.98      0.83       758\n",
      "           3       0.84      0.89      0.86       952\n",
      "           4       0.93      0.82      0.87      1114\n",
      "           5       0.55      0.95      0.70       518\n",
      "           6       0.92      0.89      0.90       983\n",
      "           7       0.82      0.95      0.88       882\n",
      "           8       0.91      0.71      0.79      1253\n",
      "           9       0.91      0.72      0.81      1264\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 20: 8569 / 10000\n",
      "Accuracy = 85.69%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85433423 0.96231376 0.98054475 0.88078109 0.81107206 0.95533981\n",
      " 0.89191919 0.95083799 0.72532895 0.73429952]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1119\n",
      "           1       0.97      0.96      0.96      1141\n",
      "           2       0.73      0.98      0.84       771\n",
      "           3       0.85      0.88      0.86       973\n",
      "           4       0.94      0.81      0.87      1138\n",
      "           5       0.55      0.96      0.70       515\n",
      "           6       0.92      0.89      0.91       990\n",
      "           7       0.83      0.95      0.89       895\n",
      "           8       0.91      0.73      0.81      1216\n",
      "           9       0.90      0.73      0.81      1242\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.87      0.86     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 21: 8610 / 10000\n",
      "Accuracy = 86.10%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84615385 0.96403509 0.98167539 0.88333333 0.82506763 0.95816733\n",
      " 0.89918534 0.95296753 0.70150435 0.72850318]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1131\n",
      "           1       0.97      0.96      0.97      1140\n",
      "           2       0.73      0.98      0.84       764\n",
      "           3       0.84      0.88      0.86       960\n",
      "           4       0.93      0.83      0.88      1109\n",
      "           5       0.54      0.96      0.69       502\n",
      "           6       0.92      0.90      0.91       982\n",
      "           7       0.83      0.95      0.89       893\n",
      "           8       0.91      0.70      0.79      1263\n",
      "           9       0.91      0.73      0.81      1256\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 22: 8585 / 10000\n",
      "Accuracy = 85.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84690265 0.96563877 0.98036649 0.88586387 0.8206278  0.95694716\n",
      " 0.9011213  0.95485327 0.70913462 0.72      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1130\n",
      "           1       0.97      0.97      0.97      1135\n",
      "           2       0.73      0.98      0.83       764\n",
      "           3       0.84      0.89      0.86       955\n",
      "           4       0.93      0.82      0.87      1115\n",
      "           5       0.55      0.96      0.70       511\n",
      "           6       0.92      0.90      0.91       981\n",
      "           7       0.82      0.95      0.88       886\n",
      "           8       0.91      0.71      0.80      1248\n",
      "           9       0.91      0.72      0.80      1275\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 23: 8585 / 10000\n",
      "Accuracy = 85.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84466019 0.96312555 0.98046875 0.89451477 0.82549729 0.96761134\n",
      " 0.90593047 0.9559322  0.69585614 0.72362205]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91      1133\n",
      "           1       0.97      0.96      0.96      1139\n",
      "           2       0.73      0.98      0.84       768\n",
      "           3       0.84      0.89      0.87       948\n",
      "           4       0.93      0.83      0.87      1106\n",
      "           5       0.54      0.97      0.69       494\n",
      "           6       0.92      0.91      0.92       978\n",
      "           7       0.82      0.96      0.88       885\n",
      "           8       0.91      0.70      0.79      1279\n",
      "           9       0.91      0.72      0.81      1270\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.88      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 24: 8587 / 10000\n",
      "Accuracy = 85.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84751773 0.96646072 0.98069498 0.89330544 0.83608059 0.96975806\n",
      " 0.89919355 0.95573212 0.70070699 0.72327044]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1128\n",
      "           1       0.96      0.97      0.97      1133\n",
      "           2       0.74      0.98      0.84       777\n",
      "           3       0.85      0.89      0.87       956\n",
      "           4       0.93      0.84      0.88      1092\n",
      "           5       0.54      0.97      0.69       496\n",
      "           6       0.93      0.90      0.91       992\n",
      "           7       0.82      0.96      0.88       881\n",
      "           8       0.92      0.70      0.79      1273\n",
      "           9       0.91      0.72      0.81      1272\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.88      0.86     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 25: 8607 / 10000\n",
      "Accuracy = 86.07%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84676705 0.9664311  0.98036649 0.89259645 0.83076923 0.97346939\n",
      " 0.89919355 0.9556314  0.69781931 0.72590837]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1129\n",
      "           1       0.96      0.97      0.97      1132\n",
      "           2       0.73      0.98      0.83       764\n",
      "           3       0.85      0.89      0.87       959\n",
      "           4       0.93      0.83      0.88      1105\n",
      "           5       0.53      0.97      0.69       490\n",
      "           6       0.93      0.90      0.91       992\n",
      "           7       0.82      0.96      0.88       879\n",
      "           8       0.92      0.70      0.79      1284\n",
      "           9       0.91      0.73      0.81      1266\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.88      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 26: 8597 / 10000\n",
      "Accuracy = 85.97%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.83741259 0.96472663 0.98013245 0.8984127  0.83032491 0.97302905\n",
      " 0.9035533  0.95671982 0.69071374 0.72590837]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1144\n",
      "           1       0.96      0.96      0.96      1134\n",
      "           2       0.72      0.98      0.83       755\n",
      "           3       0.84      0.90      0.87       945\n",
      "           4       0.94      0.83      0.88      1108\n",
      "           5       0.53      0.97      0.68       482\n",
      "           6       0.93      0.90      0.92       985\n",
      "           7       0.82      0.96      0.88       878\n",
      "           8       0.92      0.69      0.79      1303\n",
      "           9       0.91      0.73      0.81      1266\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 27: 8579 / 10000\n",
      "Accuracy = 85.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84168865 0.96808511 0.97916667 0.90889603 0.82694023 0.97101449\n",
      " 0.90120968 0.95696489 0.68754775 0.73515249]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1137\n",
      "           1       0.96      0.97      0.97      1128\n",
      "           2       0.73      0.98      0.84       768\n",
      "           3       0.84      0.91      0.87       933\n",
      "           4       0.94      0.83      0.88      1121\n",
      "           5       0.53      0.97      0.68       483\n",
      "           6       0.93      0.90      0.92       992\n",
      "           7       0.82      0.96      0.88       883\n",
      "           8       0.92      0.69      0.79      1309\n",
      "           9       0.91      0.74      0.81      1246\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.88      0.85     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 28: 8600 / 10000\n",
      "Accuracy = 86.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83916084 0.96805679 0.98051948 0.90552017 0.83154122 0.97291667\n",
      " 0.90669371 0.95885714 0.68333333 0.73870968]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1144\n",
      "           1       0.96      0.97      0.96      1127\n",
      "           2       0.73      0.98      0.84       770\n",
      "           3       0.84      0.91      0.87       942\n",
      "           4       0.95      0.83      0.88      1116\n",
      "           5       0.52      0.97      0.68       480\n",
      "           6       0.93      0.91      0.92       986\n",
      "           7       0.82      0.96      0.88       875\n",
      "           8       0.93      0.68      0.79      1320\n",
      "           9       0.91      0.74      0.81      1240\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.88      0.85     10000\n",
      "weighted avg       0.89      0.86      0.86     10000\n",
      "\n",
      "Epoch 29: 8605 / 10000\n",
      "Accuracy = 86.05%\n"
     ]
    }
   ],
   "source": [
    "net = network_tanh.NetworkTanh([784, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 0.1, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.30907854 0.65428212 0.03225806 0.28417266 0.3967033  0.40298507\n",
      " 0.4852071  0.710199   0.32352941 0.39332914]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.31      0.46      2941\n",
      "           1       0.92      0.65      0.76      1588\n",
      "           2       0.00      0.03      0.00        31\n",
      "           3       0.08      0.28      0.12       278\n",
      "           4       0.37      0.40      0.38       910\n",
      "           5       0.06      0.40      0.11       134\n",
      "           6       0.77      0.49      0.60      1521\n",
      "           7       0.56      0.71      0.62       804\n",
      "           8       0.07      0.32      0.11       204\n",
      "           9       0.62      0.39      0.48      1589\n",
      "\n",
      "   micro avg       0.44      0.44      0.44     10000\n",
      "   macro avg       0.44      0.40      0.37     10000\n",
      "weighted avg       0.72      0.44      0.52     10000\n",
      "\n",
      "Epoch 0: 4443 / 10000\n",
      "Accuracy = 44.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.47400303 0.7697274  0.68412162 0.49426752 0.57317073 0.78461538\n",
      " 0.68006843 0.82096584 0.50114943 0.4989789 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.47      0.63      1981\n",
      "           1       0.95      0.77      0.85      1394\n",
      "           2       0.39      0.68      0.50       592\n",
      "           3       0.38      0.49      0.43       785\n",
      "           4       0.62      0.57      0.60      1066\n",
      "           5       0.23      0.78      0.35       260\n",
      "           6       0.83      0.68      0.75      1169\n",
      "           7       0.68      0.82      0.74       849\n",
      "           8       0.22      0.50      0.31       435\n",
      "           9       0.73      0.50      0.59      1469\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     10000\n",
      "   macro avg       0.60      0.63      0.58     10000\n",
      "weighted avg       0.72      0.61      0.63     10000\n",
      "\n",
      "Epoch 1: 6063 / 10000\n",
      "Accuracy = 60.63%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.6456477  0.84280156 0.79051819 0.69509595 0.72321429 0.85974026\n",
      " 0.77535545 0.85828571 0.6998672  0.59625468]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.65      0.77      1459\n",
      "           1       0.95      0.84      0.90      1285\n",
      "           2       0.69      0.79      0.74       907\n",
      "           3       0.65      0.70      0.67       938\n",
      "           4       0.74      0.72      0.73      1008\n",
      "           5       0.37      0.86      0.52       385\n",
      "           6       0.85      0.78      0.81      1055\n",
      "           7       0.73      0.86      0.79       875\n",
      "           8       0.54      0.70      0.61       753\n",
      "           9       0.79      0.60      0.68      1335\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.75      0.72     10000\n",
      "weighted avg       0.78      0.73      0.74     10000\n",
      "\n",
      "Epoch 2: 7346 / 10000\n",
      "Accuracy = 73.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.70208024 0.90325271 0.81628392 0.78716578 0.77502478 0.87695749\n",
      " 0.80232558 0.88901734 0.7206823  0.64830842]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81      1346\n",
      "           1       0.95      0.90      0.93      1199\n",
      "           2       0.76      0.82      0.79       958\n",
      "           3       0.73      0.79      0.76       935\n",
      "           4       0.80      0.78      0.79      1009\n",
      "           5       0.44      0.88      0.59       447\n",
      "           6       0.86      0.80      0.83      1032\n",
      "           7       0.75      0.89      0.81       865\n",
      "           8       0.69      0.72      0.71       938\n",
      "           9       0.82      0.65      0.72      1271\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.79      0.77     10000\n",
      "weighted avg       0.81      0.78      0.79     10000\n",
      "\n",
      "Epoch 3: 7817 / 10000\n",
      "Accuracy = 78.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.7309175  0.92570453 0.83747412 0.81276151 0.81628392 0.89852008\n",
      " 0.81756757 0.89886364 0.74406605 0.66383308]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.73      0.83      1297\n",
      "           1       0.96      0.93      0.94      1171\n",
      "           2       0.78      0.84      0.81       966\n",
      "           3       0.77      0.81      0.79       956\n",
      "           4       0.80      0.82      0.81       958\n",
      "           5       0.48      0.90      0.62       473\n",
      "           6       0.88      0.82      0.85      1036\n",
      "           7       0.77      0.90      0.83       880\n",
      "           8       0.74      0.74      0.74       969\n",
      "           9       0.85      0.66      0.75      1294\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.81      0.80     10000\n",
      "weighted avg       0.83      0.80      0.81     10000\n",
      "\n",
      "Epoch 4: 8043 / 10000\n",
      "Accuracy = 80.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.76267096 0.94076655 0.84876543 0.83050847 0.82755102 0.902\n",
      " 0.84630739 0.90857788 0.72814601 0.68380062]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85      1243\n",
      "           1       0.95      0.94      0.95      1148\n",
      "           2       0.80      0.85      0.82       972\n",
      "           3       0.78      0.83      0.80       944\n",
      "           4       0.83      0.83      0.83       980\n",
      "           5       0.51      0.90      0.65       500\n",
      "           6       0.89      0.85      0.87      1002\n",
      "           7       0.78      0.91      0.84       886\n",
      "           8       0.78      0.73      0.75      1041\n",
      "           9       0.87      0.68      0.77      1284\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.81      0.83      0.81     10000\n",
      "weighted avg       0.84      0.82      0.82     10000\n",
      "\n",
      "Epoch 5: 8188 / 10000\n",
      "Accuracy = 81.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.77235772 0.94454073 0.85353535 0.84199364 0.83350151 0.9194499\n",
      " 0.84744094 0.92533937 0.75343811 0.69960474]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.77      0.86      1230\n",
      "           1       0.96      0.94      0.95      1154\n",
      "           2       0.82      0.85      0.84       990\n",
      "           3       0.79      0.84      0.81       943\n",
      "           4       0.84      0.83      0.84       991\n",
      "           5       0.52      0.92      0.67       509\n",
      "           6       0.90      0.85      0.87      1016\n",
      "           7       0.80      0.93      0.86       884\n",
      "           8       0.79      0.75      0.77      1018\n",
      "           9       0.88      0.70      0.78      1265\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.84      0.82     10000\n",
      "weighted avg       0.85      0.83      0.83     10000\n",
      "\n",
      "Epoch 6: 8304 / 10000\n",
      "Accuracy = 83.04%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.77614379 0.95514512 0.86074672 0.8490566  0.8556594  0.91876209\n",
      " 0.86172345 0.92410714 0.74666667 0.70629921]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.86      1224\n",
      "           1       0.96      0.96      0.96      1137\n",
      "           2       0.83      0.86      0.84       991\n",
      "           3       0.80      0.85      0.82       954\n",
      "           4       0.84      0.86      0.85       963\n",
      "           5       0.53      0.92      0.67       517\n",
      "           6       0.90      0.86      0.88       998\n",
      "           7       0.81      0.92      0.86       896\n",
      "           8       0.80      0.75      0.77      1050\n",
      "           9       0.89      0.71      0.79      1270\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.83      0.85      0.83     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n",
      "Epoch 7: 8367 / 10000\n",
      "Accuracy = 83.67%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.78790389 0.95579134 0.86828774 0.86886994 0.84730539 0.92363636\n",
      " 0.85587364 0.92663657 0.75691134 0.72352466]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87      1207\n",
      "           1       0.95      0.96      0.95      1131\n",
      "           2       0.83      0.87      0.85       987\n",
      "           3       0.81      0.87      0.84       938\n",
      "           4       0.86      0.85      0.86      1002\n",
      "           5       0.57      0.92      0.70       550\n",
      "           6       0.91      0.86      0.88      1013\n",
      "           7       0.80      0.93      0.86       886\n",
      "           8       0.82      0.76      0.78      1049\n",
      "           9       0.89      0.72      0.80      1237\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.85      0.84     10000\n",
      "weighted avg       0.86      0.84      0.85     10000\n",
      "\n",
      "Epoch 8: 8438 / 10000\n",
      "Accuracy = 84.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.78453947 0.95594714 0.87922211 0.88038793 0.85273632 0.93173432\n",
      " 0.86739781 0.93431484 0.74408015 0.74196208]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.87      1216\n",
      "           1       0.96      0.96      0.96      1135\n",
      "           2       0.83      0.88      0.86       977\n",
      "           3       0.81      0.88      0.84       928\n",
      "           4       0.87      0.85      0.86      1005\n",
      "           5       0.57      0.93      0.70       542\n",
      "           6       0.91      0.87      0.89      1003\n",
      "           7       0.80      0.93      0.86       883\n",
      "           8       0.84      0.74      0.79      1098\n",
      "           9       0.89      0.74      0.81      1213\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.86      0.84     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "Epoch 9: 8489 / 10000\n",
      "Accuracy = 84.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.79384871 0.95851721 0.87918782 0.89154013 0.85133796 0.93451327\n",
      " 0.87274549 0.93884485 0.7518315  0.74545455]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87      1203\n",
      "           1       0.96      0.96      0.96      1133\n",
      "           2       0.84      0.88      0.86       985\n",
      "           3       0.81      0.89      0.85       922\n",
      "           4       0.87      0.85      0.86      1009\n",
      "           5       0.59      0.93      0.72       565\n",
      "           6       0.91      0.87      0.89       998\n",
      "           7       0.81      0.94      0.87       883\n",
      "           8       0.84      0.75      0.79      1092\n",
      "           9       0.89      0.75      0.81      1210\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.86      0.85     10000\n",
      "weighted avg       0.87      0.85      0.86     10000\n",
      "\n",
      "Epoch 10: 8539 / 10000\n",
      "Accuracy = 85.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.79866332 0.96362023 0.87586892 0.89565217 0.85842473 0.93381038\n",
      " 0.87687688 0.93281938 0.7559633  0.75714286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      1197\n",
      "           1       0.96      0.96      0.96      1127\n",
      "           2       0.85      0.88      0.87      1007\n",
      "           3       0.82      0.90      0.85       920\n",
      "           4       0.88      0.86      0.87      1003\n",
      "           5       0.59      0.93      0.72       559\n",
      "           6       0.91      0.88      0.90       999\n",
      "           7       0.82      0.93      0.87       908\n",
      "           8       0.85      0.76      0.80      1090\n",
      "           9       0.89      0.76      0.82      1190\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.86      0.85     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "Epoch 11: 8579 / 10000\n",
      "Accuracy = 85.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.79799666 0.96539485 0.882      0.89817792 0.86027944 0.93197279\n",
      " 0.87761194 0.94018059 0.78125    0.7526971 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      1198\n",
      "           1       0.96      0.97      0.96      1127\n",
      "           2       0.85      0.88      0.87      1000\n",
      "           3       0.83      0.90      0.86       933\n",
      "           4       0.88      0.86      0.87      1002\n",
      "           5       0.61      0.93      0.74       588\n",
      "           6       0.92      0.88      0.90      1005\n",
      "           7       0.81      0.94      0.87       886\n",
      "           8       0.85      0.78      0.81      1056\n",
      "           9       0.90      0.75      0.82      1205\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.87      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "Epoch 12: 8621 / 10000\n",
      "Accuracy = 86.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.79700499 0.96204766 0.89361702 0.91057797 0.859375   0.9380531\n",
      " 0.88293651 0.94276094 0.76065277 0.76923077]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      1202\n",
      "           1       0.96      0.96      0.96      1133\n",
      "           2       0.85      0.89      0.87       987\n",
      "           3       0.83      0.91      0.87       917\n",
      "           4       0.90      0.86      0.88      1024\n",
      "           5       0.59      0.94      0.73       565\n",
      "           6       0.93      0.88      0.91      1008\n",
      "           7       0.82      0.94      0.88       891\n",
      "           8       0.86      0.76      0.81      1103\n",
      "           9       0.89      0.77      0.83      1170\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.87      0.86     10000\n",
      "weighted avg       0.88      0.86      0.87     10000\n",
      "\n",
      "Epoch 13: 8644 / 10000\n",
      "Accuracy = 86.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81462585 0.96374889 0.89353234 0.91125541 0.86417323 0.94217687\n",
      " 0.89045226 0.94375703 0.7678245  0.76395939]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89      1176\n",
      "           1       0.96      0.96      0.96      1131\n",
      "           2       0.87      0.89      0.88      1005\n",
      "           3       0.83      0.91      0.87       924\n",
      "           4       0.89      0.86      0.88      1016\n",
      "           5       0.62      0.94      0.75       588\n",
      "           6       0.92      0.89      0.91       995\n",
      "           7       0.82      0.94      0.88       889\n",
      "           8       0.86      0.77      0.81      1094\n",
      "           9       0.89      0.76      0.82      1182\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.88      0.86     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "Epoch 14: 8688 / 10000\n",
      "Accuracy = 86.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81324278 0.96460177 0.89919355 0.91125541 0.85589942 0.94186047\n",
      " 0.89021956 0.94457014 0.77297794 0.77358491]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89      1178\n",
      "           1       0.96      0.96      0.96      1130\n",
      "           2       0.86      0.90      0.88       992\n",
      "           3       0.83      0.91      0.87       924\n",
      "           4       0.90      0.86      0.88      1034\n",
      "           5       0.64      0.94      0.76       602\n",
      "           6       0.93      0.89      0.91      1002\n",
      "           7       0.81      0.94      0.87       884\n",
      "           8       0.86      0.77      0.82      1088\n",
      "           9       0.89      0.77      0.83      1166\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.88      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "Epoch 15: 8704 / 10000\n",
      "Accuracy = 87.04%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81049069 0.96637168 0.90631365 0.91838955 0.87080868 0.94666667\n",
      " 0.89858012 0.94295302 0.76327633 0.7715736 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89      1182\n",
      "           1       0.96      0.97      0.96      1130\n",
      "           2       0.86      0.91      0.88       982\n",
      "           3       0.84      0.92      0.88       919\n",
      "           4       0.90      0.87      0.88      1014\n",
      "           5       0.64      0.95      0.76       600\n",
      "           6       0.92      0.90      0.91       986\n",
      "           7       0.82      0.94      0.88       894\n",
      "           8       0.87      0.76      0.81      1111\n",
      "           9       0.90      0.77      0.83      1182\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.88      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "Epoch 16: 8724 / 10000\n",
      "Accuracy = 87.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83015598 0.96719858 0.91179487 0.91965255 0.86143411 0.95\n",
      " 0.90374873 0.94019934 0.75197889 0.77644024]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1154\n",
      "           1       0.96      0.97      0.96      1128\n",
      "           2       0.86      0.91      0.89       975\n",
      "           3       0.84      0.92      0.88       921\n",
      "           4       0.91      0.86      0.88      1032\n",
      "           5       0.64      0.95      0.76       600\n",
      "           6       0.93      0.90      0.92       987\n",
      "           7       0.83      0.94      0.88       903\n",
      "           8       0.88      0.75      0.81      1137\n",
      "           9       0.89      0.78      0.83      1163\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.88      0.87     10000\n",
      "weighted avg       0.88      0.87      0.88     10000\n",
      "\n",
      "Epoch 17: 8743 / 10000\n",
      "Accuracy = 87.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.83507853 0.96816976 0.91038697 0.90899471 0.8631068  0.94918033\n",
      " 0.90374873 0.93832599 0.76784101 0.78509532]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1146\n",
      "           1       0.96      0.97      0.97      1131\n",
      "           2       0.87      0.91      0.89       982\n",
      "           3       0.85      0.91      0.88       945\n",
      "           4       0.91      0.86      0.88      1030\n",
      "           5       0.65      0.95      0.77       610\n",
      "           6       0.93      0.90      0.92       987\n",
      "           7       0.83      0.94      0.88       908\n",
      "           8       0.87      0.77      0.82      1107\n",
      "           9       0.90      0.79      0.84      1154\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.88      0.87     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 18: 8773 / 10000\n",
      "Accuracy = 87.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82815199 0.96891652 0.91260163 0.92207792 0.87106299 0.95737705\n",
      " 0.90211907 0.94400896 0.75728155 0.77939914]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1158\n",
      "           1       0.96      0.97      0.97      1126\n",
      "           2       0.87      0.91      0.89       984\n",
      "           3       0.84      0.92      0.88       924\n",
      "           4       0.90      0.87      0.89      1016\n",
      "           5       0.65      0.96      0.78       610\n",
      "           6       0.93      0.90      0.92       991\n",
      "           7       0.82      0.94      0.88       893\n",
      "           8       0.88      0.76      0.81      1133\n",
      "           9       0.90      0.78      0.84      1165\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.88      0.87     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 19: 8772 / 10000\n",
      "Accuracy = 87.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83015598 0.97140304 0.91010101 0.92524377 0.87996032 0.95772358\n",
      " 0.9040404  0.93956044 0.75795053 0.78688525]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1154\n",
      "           1       0.96      0.97      0.96      1119\n",
      "           2       0.87      0.91      0.89       990\n",
      "           3       0.85      0.93      0.88       923\n",
      "           4       0.90      0.88      0.89      1008\n",
      "           5       0.66      0.96      0.78       615\n",
      "           6       0.93      0.90      0.92       990\n",
      "           7       0.83      0.94      0.88       910\n",
      "           8       0.88      0.76      0.81      1132\n",
      "           9       0.90      0.79      0.84      1159\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.89      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 20: 8796 / 10000\n",
      "Accuracy = 87.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82943723 0.97227191 0.91203236 0.92077088 0.87747036 0.95631068\n",
      " 0.91056911 0.94241417 0.76287744 0.78639104]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1155\n",
      "           1       0.96      0.97      0.96      1118\n",
      "           2       0.87      0.91      0.89       989\n",
      "           3       0.85      0.92      0.88       934\n",
      "           4       0.90      0.88      0.89      1012\n",
      "           5       0.66      0.96      0.78       618\n",
      "           6       0.94      0.91      0.92       984\n",
      "           7       0.83      0.94      0.88       903\n",
      "           8       0.88      0.76      0.82      1126\n",
      "           9       0.90      0.79      0.84      1161\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.89      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 21: 8805 / 10000\n",
      "Accuracy = 88.05%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83814523 0.97145406 0.9118541  0.91825902 0.87254902 0.95268139\n",
      " 0.91975309 0.94860335 0.75720524 0.79491674]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1143\n",
      "           1       0.96      0.97      0.97      1121\n",
      "           2       0.87      0.91      0.89       987\n",
      "           3       0.86      0.92      0.89       942\n",
      "           4       0.91      0.87      0.89      1020\n",
      "           5       0.68      0.95      0.79       634\n",
      "           6       0.93      0.92      0.93       972\n",
      "           7       0.83      0.95      0.88       895\n",
      "           8       0.89      0.76      0.82      1145\n",
      "           9       0.90      0.79      0.84      1141\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.89      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 22: 8823 / 10000\n",
      "Accuracy = 88.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84256816 0.97145406 0.91649695 0.92332613 0.87196896 0.9553429\n",
      " 0.90770791 0.94701987 0.75195143 0.80106101]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91      1137\n",
      "           1       0.96      0.97      0.97      1121\n",
      "           2       0.87      0.92      0.89       982\n",
      "           3       0.85      0.92      0.88       926\n",
      "           4       0.92      0.87      0.89      1031\n",
      "           5       0.67      0.96      0.79       627\n",
      "           6       0.93      0.91      0.92       986\n",
      "           7       0.83      0.95      0.89       906\n",
      "           8       0.89      0.75      0.82      1153\n",
      "           9       0.90      0.80      0.85      1131\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.89      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 23: 8826 / 10000\n",
      "Accuracy = 88.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83376849 0.96975089 0.91820041 0.91923486 0.87988281 0.95761381\n",
      " 0.9106599  0.94609461 0.77018634 0.80461812]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1149\n",
      "           1       0.96      0.97      0.97      1124\n",
      "           2       0.87      0.92      0.89       978\n",
      "           3       0.86      0.92      0.89       941\n",
      "           4       0.92      0.88      0.90      1024\n",
      "           5       0.68      0.96      0.80       637\n",
      "           6       0.94      0.91      0.92       985\n",
      "           7       0.84      0.95      0.89       909\n",
      "           8       0.89      0.77      0.83      1127\n",
      "           9       0.90      0.80      0.85      1126\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.88      0.89      0.88     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 24: 8853 / 10000\n",
      "Accuracy = 88.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84021071 0.96808511 0.91658189 0.92192513 0.87988281 0.96025437\n",
      " 0.91437309 0.9449945  0.76725664 0.79947461]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1139\n",
      "           1       0.96      0.97      0.97      1128\n",
      "           2       0.87      0.92      0.89       983\n",
      "           3       0.85      0.92      0.89       935\n",
      "           4       0.92      0.88      0.90      1024\n",
      "           5       0.68      0.96      0.79       629\n",
      "           6       0.94      0.91      0.93       981\n",
      "           7       0.84      0.94      0.89       909\n",
      "           8       0.89      0.77      0.82      1130\n",
      "           9       0.90      0.80      0.85      1142\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.88      0.89      0.88     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 25: 8853 / 10000\n",
      "Accuracy = 88.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83873795 0.96805679 0.91845056 0.9181532  0.8763285  0.95918367\n",
      " 0.91344196 0.94835165 0.78026906 0.81054513]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1141\n",
      "           1       0.96      0.97      0.96      1127\n",
      "           2       0.87      0.92      0.90       981\n",
      "           3       0.87      0.92      0.89       953\n",
      "           4       0.92      0.88      0.90      1035\n",
      "           5       0.68      0.96      0.80       637\n",
      "           6       0.94      0.91      0.92       982\n",
      "           7       0.84      0.95      0.89       910\n",
      "           8       0.89      0.78      0.83      1115\n",
      "           9       0.90      0.81      0.85      1119\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 26: 8879 / 10000\n",
      "Accuracy = 88.79%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.83755459 0.97145406 0.91440081 0.91937173 0.87548263 0.95800933\n",
      " 0.9118541  0.95038589 0.78209765 0.81571816]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1145\n",
      "           1       0.96      0.97      0.97      1121\n",
      "           2       0.88      0.91      0.90       993\n",
      "           3       0.87      0.92      0.89       955\n",
      "           4       0.92      0.88      0.90      1036\n",
      "           5       0.69      0.96      0.80       643\n",
      "           6       0.94      0.91      0.93       987\n",
      "           7       0.84      0.95      0.89       907\n",
      "           8       0.89      0.78      0.83      1106\n",
      "           9       0.89      0.82      0.85      1107\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 27: 8887 / 10000\n",
      "Accuracy = 88.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83769634 0.9714795  0.91339376 0.91780822 0.88789683 0.95846154\n",
      " 0.92213115 0.95525727 0.78539225 0.79878578]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1146\n",
      "           1       0.96      0.97      0.97      1122\n",
      "           2       0.88      0.91      0.90       993\n",
      "           3       0.86      0.92      0.89       949\n",
      "           4       0.91      0.89      0.90      1008\n",
      "           5       0.70      0.96      0.81       650\n",
      "           6       0.94      0.92      0.93       976\n",
      "           7       0.83      0.96      0.89       894\n",
      "           8       0.89      0.79      0.84      1109\n",
      "           9       0.91      0.80      0.85      1153\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 28: 8892 / 10000\n",
      "Accuracy = 88.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83609416 0.96897163 0.91801619 0.91606218 0.88442703 0.95718654\n",
      " 0.9192229  0.95081967 0.79595588 0.81630824]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1147\n",
      "           1       0.96      0.97      0.97      1128\n",
      "           2       0.88      0.92      0.90       988\n",
      "           3       0.88      0.92      0.90       965\n",
      "           4       0.92      0.88      0.90      1021\n",
      "           5       0.70      0.96      0.81       654\n",
      "           6       0.94      0.92      0.93       978\n",
      "           7       0.85      0.95      0.90       915\n",
      "           8       0.89      0.80      0.84      1088\n",
      "           9       0.90      0.82      0.86      1116\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 29: 8918 / 10000\n",
      "Accuracy = 89.18%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84196664 0.96977778 0.91911021 0.91692627 0.8951049  0.9530303\n",
      " 0.91194332 0.95143488 0.79834254 0.80752406]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91      1139\n",
      "           1       0.96      0.97      0.97      1125\n",
      "           2       0.88      0.92      0.90       989\n",
      "           3       0.87      0.92      0.90       963\n",
      "           4       0.91      0.90      0.90      1001\n",
      "           5       0.71      0.95      0.81       660\n",
      "           6       0.94      0.91      0.93       988\n",
      "           7       0.84      0.95      0.89       906\n",
      "           8       0.89      0.80      0.84      1086\n",
      "           9       0.91      0.81      0.86      1143\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 30: 8920 / 10000\n",
      "Accuracy = 89.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84955752 0.96897163 0.918429   0.91796469 0.88910891 0.96\n",
      " 0.91286727 0.95138122 0.79042457 0.81632653]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1130\n",
      "           1       0.96      0.97      0.97      1128\n",
      "           2       0.88      0.92      0.90       993\n",
      "           3       0.88      0.92      0.90       963\n",
      "           4       0.91      0.89      0.90      1010\n",
      "           5       0.70      0.96      0.81       650\n",
      "           6       0.94      0.91      0.93       987\n",
      "           7       0.84      0.95      0.89       905\n",
      "           8       0.90      0.79      0.84      1107\n",
      "           9       0.91      0.82      0.86      1127\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 31: 8928 / 10000\n",
      "Accuracy = 89.28%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84298246 0.974084   0.92150866 0.91649485 0.88999009 0.95757576\n",
      " 0.91649695 0.95338513 0.791099   0.8117854 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91      1140\n",
      "           1       0.96      0.97      0.97      1119\n",
      "           2       0.88      0.92      0.90       981\n",
      "           3       0.88      0.92      0.90       970\n",
      "           4       0.91      0.89      0.90      1009\n",
      "           5       0.71      0.96      0.81       660\n",
      "           6       0.94      0.92      0.93       982\n",
      "           7       0.84      0.95      0.89       901\n",
      "           8       0.89      0.79      0.84      1101\n",
      "           9       0.91      0.81      0.86      1137\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 32: 8927 / 10000\n",
      "Accuracy = 89.27%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84507042 0.97497766 0.92252803 0.91649485 0.87996128 0.95488722\n",
      " 0.91658189 0.94868996 0.80166052 0.82210243]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1136\n",
      "           1       0.96      0.97      0.97      1119\n",
      "           2       0.88      0.92      0.90       981\n",
      "           3       0.88      0.92      0.90       970\n",
      "           4       0.93      0.88      0.90      1033\n",
      "           5       0.71      0.95      0.82       665\n",
      "           6       0.94      0.92      0.93       983\n",
      "           7       0.85      0.95      0.89       916\n",
      "           8       0.89      0.80      0.84      1084\n",
      "           9       0.91      0.82      0.86      1113\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 33: 8943 / 10000\n",
      "Accuracy = 89.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83637946 0.97244444 0.92630502 0.91830403 0.89317507 0.96101949\n",
      " 0.91632653 0.95103373 0.80110497 0.82484361]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      1149\n",
      "           1       0.96      0.97      0.97      1125\n",
      "           2       0.88      0.93      0.90       977\n",
      "           3       0.88      0.92      0.90       967\n",
      "           4       0.92      0.89      0.91      1011\n",
      "           5       0.72      0.96      0.82       667\n",
      "           6       0.94      0.92      0.93       980\n",
      "           7       0.85      0.95      0.90       919\n",
      "           8       0.89      0.80      0.84      1086\n",
      "           9       0.91      0.82      0.87      1119\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 34: 8957 / 10000\n",
      "Accuracy = 89.57%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84880637 0.97244444 0.92675483 0.91075051 0.88649706 0.96072508\n",
      " 0.92657704 0.94918919 0.79889807 0.82882883]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1131\n",
      "           1       0.96      0.97      0.97      1125\n",
      "           2       0.88      0.93      0.90       983\n",
      "           3       0.89      0.91      0.90       986\n",
      "           4       0.92      0.89      0.90      1022\n",
      "           5       0.71      0.96      0.82       662\n",
      "           6       0.94      0.93      0.93       967\n",
      "           7       0.85      0.95      0.90       925\n",
      "           8       0.89      0.80      0.84      1089\n",
      "           9       0.91      0.83      0.87      1110\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 35: 8969 / 10000\n",
      "Accuracy = 89.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.85333333 0.97326203 0.92747702 0.91308793 0.8970297  0.95933735\n",
      " 0.92032686 0.95191257 0.79673321 0.82238011]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1125\n",
      "           1       0.96      0.97      0.97      1122\n",
      "           2       0.88      0.93      0.90       979\n",
      "           3       0.88      0.91      0.90       978\n",
      "           4       0.92      0.90      0.91      1010\n",
      "           5       0.71      0.96      0.82       664\n",
      "           6       0.94      0.92      0.93       979\n",
      "           7       0.85      0.95      0.90       915\n",
      "           8       0.90      0.80      0.85      1102\n",
      "           9       0.92      0.82      0.87      1126\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 36: 8972 / 10000\n",
      "Accuracy = 89.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85854969 0.97419929 0.93505155 0.91335372 0.88660802 0.95864106\n",
      " 0.92569659 0.95005429 0.79908676 0.82368655]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.91      1117\n",
      "           1       0.96      0.97      0.97      1124\n",
      "           2       0.88      0.94      0.91       970\n",
      "           3       0.89      0.91      0.90       981\n",
      "           4       0.92      0.89      0.90      1023\n",
      "           5       0.73      0.96      0.83       677\n",
      "           6       0.94      0.93      0.93       969\n",
      "           7       0.85      0.95      0.90       921\n",
      "           8       0.90      0.80      0.85      1095\n",
      "           9       0.92      0.82      0.87      1123\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 37: 8985 / 10000\n",
      "Accuracy = 89.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85106383 0.97668161 0.92416582 0.91864058 0.89106968 0.95474453\n",
      " 0.91828396 0.95424837 0.80054895 0.83499547]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1128\n",
      "           1       0.96      0.98      0.97      1115\n",
      "           2       0.89      0.92      0.90       989\n",
      "           3       0.88      0.92      0.90       971\n",
      "           4       0.92      0.89      0.91      1019\n",
      "           5       0.73      0.95      0.83       685\n",
      "           6       0.94      0.92      0.93       979\n",
      "           7       0.85      0.95      0.90       918\n",
      "           8       0.90      0.80      0.85      1093\n",
      "           9       0.91      0.83      0.87      1103\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 38: 8988 / 10000\n",
      "Accuracy = 89.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86253369 0.97508897 0.9287169  0.9145473  0.88986355 0.95988113\n",
      " 0.92221085 0.95499451 0.80401094 0.82944345]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1113\n",
      "           1       0.97      0.98      0.97      1124\n",
      "           2       0.88      0.93      0.91       982\n",
      "           3       0.89      0.91      0.90       983\n",
      "           4       0.93      0.89      0.91      1026\n",
      "           5       0.72      0.96      0.83       673\n",
      "           6       0.94      0.92      0.93       977\n",
      "           7       0.85      0.95      0.90       911\n",
      "           8       0.91      0.80      0.85      1097\n",
      "           9       0.92      0.83      0.87      1114\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 39: 9003 / 10000\n",
      "Accuracy = 90.03%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85816236 0.97426797 0.93061224 0.91506572 0.890625   0.96035242\n",
      " 0.92032686 0.95429815 0.81750466 0.8363472 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1121\n",
      "           1       0.97      0.97      0.97      1127\n",
      "           2       0.88      0.93      0.91       980\n",
      "           3       0.90      0.92      0.91       989\n",
      "           4       0.93      0.89      0.91      1024\n",
      "           5       0.73      0.96      0.83       681\n",
      "           6       0.94      0.92      0.93       979\n",
      "           7       0.85      0.95      0.90       919\n",
      "           8       0.90      0.82      0.86      1074\n",
      "           9       0.92      0.84      0.87      1106\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 40: 9024 / 10000\n",
      "Accuracy = 90.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8588025  0.97684773 0.93149284 0.91037261 0.88662791 0.95710059\n",
      " 0.92953368 0.95609221 0.80695334 0.83153153]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1119\n",
      "           1       0.97      0.98      0.97      1123\n",
      "           2       0.88      0.93      0.91       978\n",
      "           3       0.90      0.91      0.90       993\n",
      "           4       0.93      0.89      0.91      1032\n",
      "           5       0.73      0.96      0.83       676\n",
      "           6       0.94      0.93      0.93       965\n",
      "           7       0.85      0.96      0.90       911\n",
      "           8       0.91      0.81      0.85      1093\n",
      "           9       0.91      0.83      0.87      1110\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 41: 9008 / 10000\n",
      "Accuracy = 90.08%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86098655 0.97682709 0.9361483  0.91203236 0.88546679 0.95434462\n",
      " 0.92672859 0.95310796 0.80656934 0.83590209]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1115\n",
      "           1       0.97      0.98      0.97      1122\n",
      "           2       0.88      0.94      0.91       971\n",
      "           3       0.89      0.91      0.90       989\n",
      "           4       0.94      0.89      0.91      1039\n",
      "           5       0.73      0.95      0.82       679\n",
      "           6       0.94      0.93      0.93       969\n",
      "           7       0.85      0.95      0.90       917\n",
      "           8       0.91      0.81      0.85      1096\n",
      "           9       0.91      0.84      0.87      1103\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 42: 9013 / 10000\n",
      "Accuracy = 90.13%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86086176 0.97597865 0.9372428  0.9137931  0.88728324 0.95620438\n",
      " 0.91768293 0.95444685 0.81348107 0.84432234]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1114\n",
      "           1       0.97      0.98      0.97      1124\n",
      "           2       0.88      0.94      0.91       972\n",
      "           3       0.89      0.91      0.90       986\n",
      "           4       0.94      0.89      0.91      1038\n",
      "           5       0.73      0.96      0.83       685\n",
      "           6       0.94      0.92      0.93       984\n",
      "           7       0.86      0.95      0.90       922\n",
      "           8       0.90      0.81      0.86      1083\n",
      "           9       0.91      0.84      0.88      1092\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 43: 9030 / 10000\n",
      "Accuracy = 90.30%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85867621 0.97686833 0.93333333 0.90936556 0.88888889 0.95335277\n",
      " 0.92126789 0.95424837 0.81625115 0.84587156]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1118\n",
      "           1       0.97      0.98      0.97      1124\n",
      "           2       0.88      0.93      0.91       975\n",
      "           3       0.89      0.91      0.90       993\n",
      "           4       0.94      0.89      0.91      1035\n",
      "           5       0.73      0.95      0.83       686\n",
      "           6       0.94      0.92      0.93       978\n",
      "           7       0.85      0.95      0.90       918\n",
      "           8       0.91      0.82      0.86      1083\n",
      "           9       0.91      0.85      0.88      1090\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 44: 9028 / 10000\n",
      "Accuracy = 90.28%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.85409253 0.97595726 0.93456033 0.92197125 0.89115646 0.95500726\n",
      " 0.92307692 0.95356371 0.8150874  0.84292237]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      1124\n",
      "           1       0.97      0.98      0.97      1123\n",
      "           2       0.89      0.93      0.91       978\n",
      "           3       0.89      0.92      0.91       974\n",
      "           4       0.93      0.89      0.91      1029\n",
      "           5       0.74      0.96      0.83       689\n",
      "           6       0.94      0.92      0.93       975\n",
      "           7       0.86      0.95      0.90       926\n",
      "           8       0.91      0.82      0.86      1087\n",
      "           9       0.91      0.84      0.88      1095\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 45: 9035 / 10000\n",
      "Accuracy = 90.35%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85714286 0.97767857 0.93177189 0.91573604 0.88856589 0.95375723\n",
      " 0.92458678 0.95737705 0.81877323 0.83423423]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.91      1120\n",
      "           1       0.96      0.98      0.97      1120\n",
      "           2       0.89      0.93      0.91       982\n",
      "           3       0.89      0.92      0.90       985\n",
      "           4       0.93      0.89      0.91      1032\n",
      "           5       0.74      0.95      0.83       692\n",
      "           6       0.93      0.92      0.93       968\n",
      "           7       0.85      0.96      0.90       915\n",
      "           8       0.90      0.82      0.86      1076\n",
      "           9       0.92      0.83      0.87      1110\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 46: 9027 / 10000\n",
      "Accuracy = 90.27%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85714286 0.97688889 0.93634497 0.91489362 0.89299611 0.94942197\n",
      " 0.92924037 0.95656895 0.81393217 0.83832879]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.91      1120\n",
      "           1       0.97      0.98      0.97      1125\n",
      "           2       0.88      0.94      0.91       974\n",
      "           3       0.89      0.91      0.90       987\n",
      "           4       0.93      0.89      0.91      1028\n",
      "           5       0.74      0.95      0.83       692\n",
      "           6       0.93      0.93      0.93       961\n",
      "           7       0.86      0.96      0.90       921\n",
      "           8       0.91      0.81      0.86      1091\n",
      "           9       0.91      0.84      0.87      1101\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n",
      "Epoch 47: 9034 / 10000\n",
      "Accuracy = 90.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86021505 0.9777382  0.92907801 0.91946993 0.89407191 0.95258621\n",
      " 0.92283951 0.95572354 0.82298424 0.84601283]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1116\n",
      "           1       0.97      0.98      0.97      1123\n",
      "           2       0.89      0.93      0.91       987\n",
      "           3       0.89      0.92      0.91       981\n",
      "           4       0.94      0.89      0.91      1029\n",
      "           5       0.74      0.95      0.84       696\n",
      "           6       0.94      0.92      0.93       972\n",
      "           7       0.86      0.96      0.91       926\n",
      "           8       0.91      0.82      0.87      1079\n",
      "           9       0.91      0.85      0.88      1091\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 48: 9053 / 10000\n",
      "Accuracy = 90.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86330935 0.97697077 0.93449335 0.91229839 0.89320388 0.95238095\n",
      " 0.92102564 0.95371367 0.82819795 0.84615385]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      1112\n",
      "           1       0.97      0.98      0.97      1129\n",
      "           2       0.88      0.93      0.91       977\n",
      "           3       0.90      0.91      0.90       992\n",
      "           4       0.94      0.89      0.91      1030\n",
      "           5       0.74      0.95      0.83       693\n",
      "           6       0.94      0.92      0.93       975\n",
      "           7       0.86      0.95      0.91       929\n",
      "           8       0.91      0.83      0.87      1071\n",
      "           9       0.92      0.85      0.88      1092\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Epoch 49: 9056 / 10000\n",
      "Accuracy = 90.56%\n"
     ]
    }
   ],
   "source": [
    "net = network_tanh.NetworkTanh([784, 30, 10])\n",
    "net.SGD(training_data, 50, 10, 0.1, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.4504008  0.64169788 0.36217211 0.10344828 0.49215923 0.42\n",
      " 0.0345098  0.76026273 0.13963329 0.42330383]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.45      0.60      1996\n",
      "           1       0.91      0.64      0.75      1602\n",
      "           2       0.76      0.36      0.49      2173\n",
      "           3       0.00      0.10      0.01        29\n",
      "           4       0.42      0.49      0.45       829\n",
      "           5       0.05      0.42      0.08       100\n",
      "           6       0.05      0.03      0.04      1275\n",
      "           7       0.45      0.76      0.57       609\n",
      "           8       0.10      0.14      0.12       709\n",
      "           9       0.28      0.42      0.34       678\n",
      "\n",
      "   micro avg       0.41      0.41      0.41     10000\n",
      "   macro avg       0.39      0.38      0.35     10000\n",
      "weighted avg       0.59      0.41      0.46     10000\n",
      "\n",
      "Epoch 0: 4060 / 10000\n",
      "Accuracy = 40.60%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.56474164 0.72037284 0.41785375 0.17948718 0.60053619 0.62130178\n",
      " 0.03489771 0.79908152 0.28639053 0.63230241]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.56      0.71      1645\n",
      "           1       0.95      0.72      0.82      1502\n",
      "           2       0.85      0.42      0.56      2106\n",
      "           3       0.01      0.18      0.01        39\n",
      "           4       0.68      0.60      0.64      1119\n",
      "           5       0.12      0.62      0.20       169\n",
      "           6       0.03      0.03      0.03       831\n",
      "           7       0.68      0.80      0.73       871\n",
      "           8       0.25      0.29      0.27       845\n",
      "           9       0.55      0.63      0.59       873\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     10000\n",
      "   macro avg       0.51      0.49      0.46     10000\n",
      "weighted avg       0.69      0.52      0.57     10000\n",
      "\n",
      "Epoch 1: 5194 / 10000\n",
      "Accuracy = 51.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.65220434 0.8243346  0.46169457 0.2972973  0.65397631 0.74086379\n",
      " 0.0317757  0.86877828 0.41816921 0.74668142]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.65      0.77      1429\n",
      "           1       0.96      0.82      0.88      1315\n",
      "           2       0.88      0.46      0.61      1971\n",
      "           3       0.01      0.30      0.02        37\n",
      "           4       0.79      0.65      0.71      1182\n",
      "           5       0.25      0.74      0.37       301\n",
      "           6       0.02      0.03      0.02       535\n",
      "           7       0.75      0.87      0.80       884\n",
      "           8       0.62      0.42      0.50      1442\n",
      "           9       0.67      0.75      0.71       904\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     10000\n",
      "   macro avg       0.59      0.57      0.54     10000\n",
      "weighted avg       0.75      0.60      0.65     10000\n",
      "\n",
      "Epoch 2: 5996 / 10000\n",
      "Accuracy = 59.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.68471105 0.84372594 0.47159091 0.47826087 0.70373588 0.79950495\n",
      " 0.04622871 0.89717514 0.46722907 0.77416073]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.68      0.80      1367\n",
      "           1       0.97      0.84      0.90      1299\n",
      "           2       0.88      0.47      0.62      1936\n",
      "           3       0.01      0.48      0.02        23\n",
      "           4       0.82      0.70      0.76      1151\n",
      "           5       0.36      0.80      0.50       404\n",
      "           6       0.02      0.05      0.03       411\n",
      "           7       0.77      0.90      0.83       885\n",
      "           8       0.74      0.47      0.57      1541\n",
      "           9       0.75      0.77      0.76       983\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     10000\n",
      "   macro avg       0.63      0.62      0.58     10000\n",
      "weighted avg       0.79      0.64      0.69     10000\n",
      "\n",
      "Epoch 3: 6383 / 10000\n",
      "Accuracy = 63.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.72094801 0.86740331 0.49299569 0.47826087 0.71366782 0.81818182\n",
      " 0.05167173 0.89967285 0.47513481 0.79740519]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.72      0.82      1308\n",
      "           1       0.97      0.87      0.92      1267\n",
      "           2       0.89      0.49      0.63      1856\n",
      "           3       0.01      0.48      0.02        23\n",
      "           4       0.84      0.71      0.77      1156\n",
      "           5       0.43      0.82      0.57       473\n",
      "           6       0.02      0.05      0.03       329\n",
      "           7       0.80      0.90      0.85       917\n",
      "           8       0.81      0.48      0.60      1669\n",
      "           9       0.79      0.80      0.79      1002\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.65      0.63      0.60     10000\n",
      "weighted avg       0.82      0.66      0.72     10000\n",
      "\n",
      "Epoch 4: 6614 / 10000\n",
      "Accuracy = 66.14%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.72201066 0.88727858 0.49252935 0.4375     0.71416667 0.81764706\n",
      " 0.06597222 0.92017738 0.49108205 0.82425488]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83      1313\n",
      "           1       0.97      0.89      0.93      1242\n",
      "           2       0.89      0.49      0.64      1874\n",
      "           3       0.01      0.44      0.01        16\n",
      "           4       0.87      0.71      0.79      1200\n",
      "           5       0.47      0.82      0.59       510\n",
      "           6       0.02      0.07      0.03       288\n",
      "           7       0.81      0.92      0.86       902\n",
      "           8       0.85      0.49      0.62      1682\n",
      "           9       0.79      0.82      0.81       973\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.66      0.64      0.61     10000\n",
      "weighted avg       0.84      0.67      0.73     10000\n",
      "\n",
      "Epoch 5: 6731 / 10000\n",
      "Accuracy = 67.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.74292453 0.89130435 0.49918434 0.42105263 0.70597738 0.8375\n",
      " 0.08786611 0.92527473 0.47968837 0.83817427]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.74      0.84      1272\n",
      "           1       0.98      0.89      0.93      1242\n",
      "           2       0.89      0.50      0.64      1839\n",
      "           3       0.01      0.42      0.02        19\n",
      "           4       0.89      0.71      0.79      1238\n",
      "           5       0.45      0.84      0.59       480\n",
      "           6       0.02      0.09      0.04       239\n",
      "           7       0.82      0.93      0.87       910\n",
      "           8       0.89      0.48      0.62      1797\n",
      "           9       0.80      0.84      0.82       964\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.67      0.64      0.61     10000\n",
      "weighted avg       0.85      0.68      0.74     10000\n",
      "\n",
      "Epoch 6: 6787 / 10000\n",
      "Accuracy = 67.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.74980143 0.89756098 0.50884956 0.41935484 0.71161657 0.85964912\n",
      " 0.11894273 0.93186813 0.47100271 0.82851446]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.75      0.84      1259\n",
      "           1       0.97      0.90      0.93      1230\n",
      "           2       0.89      0.51      0.65      1808\n",
      "           3       0.01      0.42      0.02        31\n",
      "           4       0.89      0.71      0.79      1231\n",
      "           5       0.44      0.86      0.58       456\n",
      "           6       0.03      0.12      0.05       227\n",
      "           7       0.82      0.93      0.88       910\n",
      "           8       0.89      0.47      0.62      1845\n",
      "           9       0.82      0.83      0.83      1003\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.67      0.65      0.62     10000\n",
      "weighted avg       0.85      0.68      0.74     10000\n",
      "\n",
      "Epoch 7: 6824 / 10000\n",
      "Accuracy = 68.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.76653061 0.90625    0.51046256 0.46774194 0.72123177 0.87608696\n",
      " 0.17596567 0.93137255 0.47198276 0.85102041]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.85      1225\n",
      "           1       0.97      0.91      0.94      1216\n",
      "           2       0.90      0.51      0.65      1816\n",
      "           3       0.03      0.47      0.05        62\n",
      "           4       0.91      0.72      0.80      1234\n",
      "           5       0.45      0.88      0.60       460\n",
      "           6       0.04      0.18      0.07       233\n",
      "           7       0.83      0.93      0.88       918\n",
      "           8       0.90      0.47      0.62      1856\n",
      "           9       0.83      0.85      0.84       980\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.68      0.67      0.63     10000\n",
      "weighted avg       0.86      0.69      0.74     10000\n",
      "\n",
      "Epoch 8: 6896 / 10000\n",
      "Accuracy = 68.96%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.79931682 0.91186161 0.62779661 0.7421875  0.81093605 0.94210526\n",
      " 0.76525199 0.93426724 0.50605886 0.83960396]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87      1171\n",
      "           1       0.98      0.91      0.94      1214\n",
      "           2       0.90      0.63      0.74      1475\n",
      "           3       0.19      0.74      0.30       256\n",
      "           4       0.89      0.81      0.85      1079\n",
      "           5       0.40      0.94      0.56       380\n",
      "           6       0.60      0.77      0.67       754\n",
      "           7       0.84      0.93      0.89       928\n",
      "           8       0.90      0.51      0.65      1733\n",
      "           9       0.84      0.84      0.84      1010\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.75      0.79      0.73     10000\n",
      "weighted avg       0.84      0.76      0.78     10000\n",
      "\n",
      "Epoch 9: 7561 / 10000\n",
      "Accuracy = 75.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8412132  0.92929293 0.70364742 0.87242026 0.83506126 0.96083551\n",
      " 0.82397408 0.93784079 0.56649283 0.84427032]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90      1121\n",
      "           1       0.97      0.93      0.95      1188\n",
      "           2       0.90      0.70      0.79      1316\n",
      "           3       0.46      0.87      0.60       533\n",
      "           4       0.90      0.84      0.87      1061\n",
      "           5       0.41      0.96      0.58       383\n",
      "           6       0.80      0.82      0.81       926\n",
      "           7       0.84      0.94      0.88       917\n",
      "           8       0.89      0.57      0.69      1534\n",
      "           9       0.85      0.84      0.85      1021\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.83      0.79     10000\n",
      "weighted avg       0.85      0.80      0.81     10000\n",
      "\n",
      "Epoch 10: 8046 / 10000\n",
      "Accuracy = 80.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85094851 0.93097643 0.72421875 0.87220447 0.84300666 0.97082228\n",
      " 0.83684211 0.94220284 0.58172115 0.85572139]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      1107\n",
      "           1       0.97      0.93      0.95      1188\n",
      "           2       0.90      0.72      0.80      1280\n",
      "           3       0.54      0.87      0.67       626\n",
      "           4       0.90      0.84      0.87      1051\n",
      "           5       0.41      0.97      0.58       377\n",
      "           6       0.83      0.84      0.83       950\n",
      "           7       0.84      0.94      0.89       917\n",
      "           8       0.90      0.58      0.71      1499\n",
      "           9       0.85      0.86      0.85      1005\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.81      0.84      0.81     10000\n",
      "weighted avg       0.86      0.82      0.82     10000\n",
      "\n",
      "Epoch 11: 8164 / 10000\n",
      "Accuracy = 81.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87025023 0.93638677 0.76767677 0.89176829 0.84938036 0.97540984\n",
      " 0.85579937 0.94245385 0.56120527 0.86067194]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      1079\n",
      "           1       0.97      0.94      0.95      1179\n",
      "           2       0.88      0.77      0.82      1188\n",
      "           3       0.58      0.89      0.70       656\n",
      "           4       0.91      0.85      0.88      1049\n",
      "           5       0.40      0.98      0.57       366\n",
      "           6       0.85      0.86      0.86       957\n",
      "           7       0.84      0.94      0.89       921\n",
      "           8       0.92      0.56      0.70      1593\n",
      "           9       0.86      0.86      0.86      1012\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.81     10000\n",
      "weighted avg       0.86      0.82      0.83     10000\n",
      "\n",
      "Epoch 12: 8240 / 10000\n",
      "Accuracy = 82.40%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86900369 0.93813559 0.77664975 0.87430939 0.84651601 0.98097826\n",
      " 0.86085151 0.9404117  0.58882236 0.85756677]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      1084\n",
      "           1       0.98      0.94      0.96      1180\n",
      "           2       0.89      0.78      0.83      1182\n",
      "           3       0.63      0.87      0.73       724\n",
      "           4       0.92      0.85      0.88      1062\n",
      "           5       0.40      0.98      0.57       368\n",
      "           6       0.87      0.86      0.86       963\n",
      "           7       0.84      0.94      0.89       923\n",
      "           8       0.91      0.59      0.71      1503\n",
      "           9       0.86      0.86      0.86      1011\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.85      0.82     10000\n",
      "weighted avg       0.87      0.83      0.84     10000\n",
      "\n",
      "Epoch 13: 8309 / 10000\n",
      "Accuracy = 83.09%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87698043 0.94278395 0.78431373 0.88508892 0.85       0.97883598\n",
      " 0.87604167 0.94004283 0.58398438 0.87906504]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      1073\n",
      "           1       0.97      0.94      0.96      1171\n",
      "           2       0.89      0.78      0.83      1173\n",
      "           3       0.64      0.89      0.74       731\n",
      "           4       0.92      0.85      0.88      1060\n",
      "           5       0.41      0.98      0.58       378\n",
      "           6       0.88      0.88      0.88       960\n",
      "           7       0.85      0.94      0.90       934\n",
      "           8       0.92      0.58      0.71      1536\n",
      "           9       0.86      0.88      0.87       984\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.83      0.86      0.83     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 14: 8364 / 10000\n",
      "Accuracy = 83.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8776645  0.94772922 0.78834619 0.88739946 0.85416667 0.98092643\n",
      " 0.88748686 0.94347826 0.58043758 0.87713998]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      1079\n",
      "           1       0.97      0.95      0.96      1167\n",
      "           2       0.89      0.79      0.84      1167\n",
      "           3       0.66      0.89      0.75       746\n",
      "           4       0.92      0.85      0.89      1056\n",
      "           5       0.40      0.98      0.57       367\n",
      "           6       0.88      0.89      0.88       951\n",
      "           7       0.84      0.94      0.89       920\n",
      "           8       0.93      0.58      0.71      1554\n",
      "           9       0.86      0.88      0.87       993\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.83      0.86      0.83     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 15: 8382 / 10000\n",
      "Accuracy = 83.82%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88235294 0.94619983 0.81200353 0.88974359 0.84351852 0.984\n",
      " 0.88773389 0.94307197 0.59681698 0.8776542 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      1071\n",
      "           1       0.98      0.95      0.96      1171\n",
      "           2       0.89      0.81      0.85      1133\n",
      "           3       0.69      0.89      0.78       780\n",
      "           4       0.93      0.84      0.88      1080\n",
      "           5       0.41      0.98      0.58       375\n",
      "           6       0.89      0.89      0.89       962\n",
      "           7       0.85      0.94      0.90       931\n",
      "           8       0.92      0.60      0.73      1508\n",
      "           9       0.86      0.88      0.87       989\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.88      0.84      0.85     10000\n",
      "\n",
      "Epoch 16: 8447 / 10000\n",
      "Accuracy = 84.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87825279 0.95017182 0.81915846 0.89209536 0.85876777 0.98644986\n",
      " 0.89468196 0.94325482 0.59141184 0.88608871]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      1076\n",
      "           1       0.97      0.95      0.96      1164\n",
      "           2       0.89      0.82      0.85      1117\n",
      "           3       0.70      0.89      0.79       797\n",
      "           4       0.92      0.86      0.89      1055\n",
      "           5       0.41      0.99      0.58       369\n",
      "           6       0.90      0.89      0.90       959\n",
      "           7       0.86      0.94      0.90       934\n",
      "           8       0.93      0.59      0.72      1537\n",
      "           9       0.87      0.89      0.88       992\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.88      0.85      0.85     10000\n",
      "\n",
      "Epoch 17: 8474 / 10000\n",
      "Accuracy = 84.74%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.88504673 0.95180723 0.81980375 0.91287386 0.86024551 0.98666667\n",
      " 0.90455992 0.94444444 0.58041958 0.88709677]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.92      1070\n",
      "           1       0.97      0.95      0.96      1162\n",
      "           2       0.89      0.82      0.85      1121\n",
      "           3       0.70      0.91      0.79       769\n",
      "           4       0.93      0.86      0.89      1059\n",
      "           5       0.41      0.99      0.58       375\n",
      "           6       0.89      0.90      0.90       943\n",
      "           7       0.86      0.94      0.90       936\n",
      "           8       0.94      0.58      0.72      1573\n",
      "           9       0.87      0.89      0.88       992\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.88      0.85      0.85     10000\n",
      "\n",
      "Epoch 18: 8485 / 10000\n",
      "Accuracy = 84.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88742964 0.95172414 0.82628263 0.90506329 0.84658041 0.9859944\n",
      " 0.90295359 0.9445629  0.57958148 0.89392379]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.92      1066\n",
      "           1       0.97      0.95      0.96      1160\n",
      "           2       0.89      0.83      0.86      1111\n",
      "           3       0.71      0.91      0.79       790\n",
      "           4       0.93      0.85      0.89      1082\n",
      "           5       0.39      0.99      0.56       357\n",
      "           6       0.89      0.90      0.90       948\n",
      "           7       0.86      0.94      0.90       938\n",
      "           8       0.94      0.58      0.72      1577\n",
      "           9       0.86      0.89      0.88       971\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.88      0.85      0.85     10000\n",
      "\n",
      "Epoch 19: 8475 / 10000\n",
      "Accuracy = 84.75%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89488636 0.95750217 0.83832879 0.89588378 0.8555452  0.98567335\n",
      " 0.8992731  0.94640943 0.58535032 0.89754098]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93      1056\n",
      "           1       0.97      0.96      0.97      1153\n",
      "           2       0.89      0.84      0.87      1101\n",
      "           3       0.73      0.90      0.81       826\n",
      "           4       0.93      0.86      0.89      1073\n",
      "           5       0.39      0.99      0.55       349\n",
      "           6       0.90      0.90      0.90       963\n",
      "           7       0.86      0.95      0.90       933\n",
      "           8       0.94      0.59      0.72      1570\n",
      "           9       0.87      0.90      0.88       976\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.88      0.84     10000\n",
      "weighted avg       0.89      0.85      0.86     10000\n",
      "\n",
      "Epoch 20: 8518 / 10000\n",
      "Accuracy = 85.18%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89339623 0.9543497  0.84234647 0.91304348 0.85674419 0.98879552\n",
      " 0.89968652 0.95053763 0.58154235 0.89613035]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1060\n",
      "           1       0.98      0.95      0.97      1161\n",
      "           2       0.89      0.84      0.87      1091\n",
      "           3       0.73      0.91      0.81       805\n",
      "           4       0.94      0.86      0.90      1075\n",
      "           5       0.40      0.99      0.57       357\n",
      "           6       0.90      0.90      0.90       957\n",
      "           7       0.86      0.95      0.90       930\n",
      "           8       0.94      0.58      0.72      1582\n",
      "           9       0.87      0.90      0.88       982\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.88      0.84     10000\n",
      "weighted avg       0.89      0.85      0.86     10000\n",
      "\n",
      "Epoch 21: 8528 / 10000\n",
      "Accuracy = 85.28%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89933523 0.95678479 0.84509624 0.9047619  0.85133887 0.98670213\n",
      " 0.89802289 0.94978632 0.60196078 0.90133607]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1053\n",
      "           1       0.98      0.96      0.97      1157\n",
      "           2       0.89      0.85      0.87      1091\n",
      "           3       0.75      0.90      0.82       840\n",
      "           4       0.94      0.85      0.89      1083\n",
      "           5       0.42      0.99      0.59       376\n",
      "           6       0.90      0.90      0.90       961\n",
      "           7       0.86      0.95      0.91       936\n",
      "           8       0.95      0.60      0.74      1530\n",
      "           9       0.87      0.90      0.88       973\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.89      0.86      0.86     10000\n",
      "\n",
      "Epoch 22: 8579 / 10000\n",
      "Accuracy = 85.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9002849  0.95844156 0.85041551 0.91411043 0.8637218  0.98915989\n",
      " 0.90346275 0.94989339 0.58312343 0.90325866]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1053\n",
      "           1       0.98      0.96      0.97      1155\n",
      "           2       0.89      0.85      0.87      1083\n",
      "           3       0.74      0.91      0.82       815\n",
      "           4       0.94      0.86      0.90      1064\n",
      "           5       0.41      0.99      0.58       369\n",
      "           6       0.90      0.90      0.90       953\n",
      "           7       0.87      0.95      0.91       938\n",
      "           8       0.95      0.58      0.72      1588\n",
      "           9       0.88      0.90      0.89       982\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.89      0.86      0.86     10000\n",
      "\n",
      "Epoch 23: 8570 / 10000\n",
      "Accuracy = 85.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90517241 0.96013865 0.84898711 0.90258216 0.8583411  0.98876404\n",
      " 0.8992731  0.95015907 0.59306804 0.90731205]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1044\n",
      "           1       0.98      0.96      0.97      1154\n",
      "           2       0.89      0.85      0.87      1086\n",
      "           3       0.76      0.90      0.83       852\n",
      "           4       0.94      0.86      0.90      1073\n",
      "           5       0.39      0.99      0.56       356\n",
      "           6       0.90      0.90      0.90       963\n",
      "           7       0.87      0.95      0.91       943\n",
      "           8       0.95      0.59      0.73      1558\n",
      "           9       0.87      0.91      0.89       971\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.89      0.86      0.86     10000\n",
      "\n",
      "Epoch 24: 8584 / 10000\n",
      "Accuracy = 85.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9        0.95847751 0.84770642 0.89953271 0.86074766 0.99101796\n",
      " 0.90605428 0.95202559 0.59067688 0.901222  ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1050\n",
      "           1       0.98      0.96      0.97      1156\n",
      "           2       0.90      0.85      0.87      1090\n",
      "           3       0.76      0.90      0.83       856\n",
      "           4       0.94      0.86      0.90      1070\n",
      "           5       0.37      0.99      0.54       334\n",
      "           6       0.91      0.91      0.91       958\n",
      "           7       0.87      0.95      0.91       938\n",
      "           8       0.95      0.59      0.73      1566\n",
      "           9       0.88      0.90      0.89       982\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.89      0.86      0.86     10000\n",
      "\n",
      "Epoch 25: 8570 / 10000\n",
      "Accuracy = 85.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.906641   0.95847751 0.85267035 0.89976959 0.86886792 0.98885794\n",
      " 0.91108787 0.95031712 0.59537572 0.91161357]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1039\n",
      "           1       0.98      0.96      0.97      1156\n",
      "           2       0.90      0.85      0.87      1086\n",
      "           3       0.77      0.90      0.83       868\n",
      "           4       0.94      0.87      0.90      1060\n",
      "           5       0.40      0.99      0.57       359\n",
      "           6       0.91      0.91      0.91       956\n",
      "           7       0.87      0.95      0.91       946\n",
      "           8       0.95      0.60      0.73      1557\n",
      "           9       0.88      0.91      0.90       973\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.88      0.85     10000\n",
      "weighted avg       0.89      0.86      0.87     10000\n",
      "\n",
      "Epoch 26: 8617 / 10000\n",
      "Accuracy = 86.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.9025788  0.9609375  0.85912882 0.90126292 0.86829727 0.98860399\n",
      " 0.90729167 0.95132275 0.59664948 0.90714286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1047\n",
      "           1       0.98      0.96      0.97      1152\n",
      "           2       0.90      0.86      0.88      1079\n",
      "           3       0.78      0.90      0.83       871\n",
      "           4       0.94      0.87      0.90      1063\n",
      "           5       0.39      0.99      0.56       351\n",
      "           6       0.91      0.91      0.91       960\n",
      "           7       0.87      0.95      0.91       945\n",
      "           8       0.95      0.60      0.73      1552\n",
      "           9       0.88      0.91      0.89       980\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.88      0.85     10000\n",
      "weighted avg       0.90      0.86      0.87     10000\n",
      "\n",
      "Epoch 27: 8619 / 10000\n",
      "Accuracy = 86.19%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90778098 0.96170583 0.8605948  0.89919817 0.86981132 0.98813056\n",
      " 0.90644491 0.95248152 0.58931977 0.90936864]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      1041\n",
      "           1       0.97      0.96      0.97      1149\n",
      "           2       0.90      0.86      0.88      1076\n",
      "           3       0.78      0.90      0.83       873\n",
      "           4       0.94      0.87      0.90      1060\n",
      "           5       0.37      0.99      0.54       337\n",
      "           6       0.91      0.91      0.91       962\n",
      "           7       0.88      0.95      0.91       947\n",
      "           8       0.95      0.59      0.73      1573\n",
      "           9       0.89      0.91      0.90       982\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.90      0.86      0.87     10000\n",
      "\n",
      "Epoch 28: 8610 / 10000\n",
      "Accuracy = 86.10%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90690979 0.96177237 0.8562212  0.89659091 0.85925926 0.98863636\n",
      " 0.91136601 0.95348837 0.60078023 0.91003102]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1042\n",
      "           1       0.98      0.96      0.97      1151\n",
      "           2       0.90      0.86      0.88      1085\n",
      "           3       0.78      0.90      0.83       880\n",
      "           4       0.95      0.86      0.90      1080\n",
      "           5       0.39      0.99      0.56       352\n",
      "           6       0.91      0.91      0.91       959\n",
      "           7       0.88      0.95      0.91       946\n",
      "           8       0.95      0.60      0.74      1538\n",
      "           9       0.87      0.91      0.89       967\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.88      0.85     10000\n",
      "weighted avg       0.90      0.86      0.87     10000\n",
      "\n",
      "Epoch 29: 8626 / 10000\n",
      "Accuracy = 86.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91400966 0.95840555 0.87193974 0.90657439 0.85767098 0.98873239\n",
      " 0.91277259 0.95541401 0.59062104 0.91164241]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1035\n",
      "           1       0.97      0.96      0.97      1154\n",
      "           2       0.90      0.87      0.88      1062\n",
      "           3       0.78      0.91      0.84       867\n",
      "           4       0.95      0.86      0.90      1082\n",
      "           5       0.39      0.99      0.56       355\n",
      "           6       0.92      0.91      0.92       963\n",
      "           7       0.88      0.96      0.91       942\n",
      "           8       0.96      0.59      0.73      1578\n",
      "           9       0.87      0.91      0.89       962\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.85     10000\n",
      "weighted avg       0.90      0.86      0.87     10000\n",
      "\n",
      "Epoch 30: 8631 / 10000\n",
      "Accuracy = 86.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91312741 0.9592721  0.868791   0.90689655 0.8633829  0.98882682\n",
      " 0.91422594 0.95744681 0.59325271 0.91255144]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1036\n",
      "           1       0.98      0.96      0.97      1154\n",
      "           2       0.90      0.87      0.88      1067\n",
      "           3       0.78      0.91      0.84       870\n",
      "           4       0.95      0.86      0.90      1076\n",
      "           5       0.40      0.99      0.57       358\n",
      "           6       0.91      0.91      0.91       956\n",
      "           7       0.88      0.96      0.91       940\n",
      "           8       0.96      0.59      0.73      1571\n",
      "           9       0.88      0.91      0.90       972\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.86      0.87     10000\n",
      "\n",
      "Epoch 31: 8645 / 10000\n",
      "Accuracy = 86.45%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91553398 0.96006944 0.87382298 0.89473684 0.86579683 0.98860399\n",
      " 0.91069574 0.95642933 0.59781911 0.90778689]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1030\n",
      "           1       0.97      0.96      0.97      1152\n",
      "           2       0.90      0.87      0.89      1062\n",
      "           3       0.79      0.89      0.84       893\n",
      "           4       0.95      0.87      0.90      1073\n",
      "           5       0.39      0.99      0.56       351\n",
      "           6       0.92      0.91      0.91       963\n",
      "           7       0.88      0.96      0.91       941\n",
      "           8       0.96      0.60      0.74      1559\n",
      "           9       0.88      0.91      0.89       976\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.85     10000\n",
      "weighted avg       0.90      0.86      0.87     10000\n",
      "\n",
      "Epoch 32: 8647 / 10000\n",
      "Accuracy = 86.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91828794 0.95847751 0.8754717  0.89497207 0.86728972 0.98860399\n",
      " 0.91040165 0.95478444 0.60154739 0.9131334 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1028\n",
      "           1       0.98      0.96      0.97      1156\n",
      "           2       0.90      0.88      0.89      1060\n",
      "           3       0.79      0.89      0.84       895\n",
      "           4       0.95      0.87      0.90      1070\n",
      "           5       0.39      0.99      0.56       351\n",
      "           6       0.92      0.91      0.92       971\n",
      "           7       0.88      0.95      0.92       951\n",
      "           8       0.96      0.60      0.74      1551\n",
      "           9       0.88      0.91      0.89       967\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.87     10000\n",
      "\n",
      "Epoch 33: 8664 / 10000\n",
      "Accuracy = 86.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92172211 0.96010408 0.87558907 0.89392265 0.86915888 0.98866856\n",
      " 0.91431557 0.95675105 0.59935897 0.91349125]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1022\n",
      "           1       0.98      0.96      0.97      1153\n",
      "           2       0.90      0.88      0.89      1061\n",
      "           3       0.80      0.89      0.84       905\n",
      "           4       0.95      0.87      0.91      1070\n",
      "           5       0.39      0.99      0.56       353\n",
      "           6       0.91      0.91      0.91       957\n",
      "           7       0.88      0.96      0.92       948\n",
      "           8       0.96      0.60      0.74      1560\n",
      "           9       0.88      0.91      0.90       971\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.87     10000\n",
      "\n",
      "Epoch 34: 8670 / 10000\n",
      "Accuracy = 86.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92458374 0.95685936 0.87962085 0.89281768 0.87288136 0.98870056\n",
      " 0.9122807  0.95473684 0.60154739 0.9137577 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1021\n",
      "           1       0.98      0.96      0.97      1159\n",
      "           2       0.90      0.88      0.89      1055\n",
      "           3       0.80      0.89      0.84       905\n",
      "           4       0.94      0.87      0.91      1062\n",
      "           5       0.39      0.99      0.56       354\n",
      "           6       0.92      0.91      0.92       969\n",
      "           7       0.88      0.95      0.92       950\n",
      "           8       0.96      0.60      0.74      1551\n",
      "           9       0.88      0.91      0.90       974\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.87     10000\n",
      "\n",
      "Epoch 35: 8680 / 10000\n",
      "Accuracy = 86.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.92458374 0.95934256 0.8754717  0.89643653 0.86778399 0.98873239\n",
      " 0.91606218 0.95574289 0.60232408 0.91161357]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1021\n",
      "           1       0.98      0.96      0.97      1156\n",
      "           2       0.90      0.88      0.89      1060\n",
      "           3       0.80      0.90      0.84       898\n",
      "           4       0.95      0.87      0.91      1074\n",
      "           5       0.39      0.99      0.56       355\n",
      "           6       0.92      0.92      0.92       965\n",
      "           7       0.88      0.96      0.92       949\n",
      "           8       0.96      0.60      0.74      1549\n",
      "           9       0.88      0.91      0.90       973\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.87     10000\n",
      "\n",
      "Epoch 36: 8680 / 10000\n",
      "Accuracy = 86.80%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92556317 0.95764909 0.88201713 0.88707926 0.87009346 0.98895028\n",
      " 0.91179487 0.95675105 0.61140236 0.91640867]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1021\n",
      "           1       0.98      0.96      0.97      1157\n",
      "           2       0.90      0.88      0.89      1051\n",
      "           3       0.81      0.89      0.85       921\n",
      "           4       0.95      0.87      0.91      1070\n",
      "           5       0.40      0.99      0.57       362\n",
      "           6       0.93      0.91      0.92       975\n",
      "           7       0.88      0.96      0.92       948\n",
      "           8       0.96      0.61      0.75      1526\n",
      "           9       0.88      0.92      0.90       969\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.88     10000\n",
      "\n",
      "Epoch 37: 8703 / 10000\n",
      "Accuracy = 87.03%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92322643 0.95764909 0.88140417 0.88876772 0.87724268 0.98876404\n",
      " 0.92203742 0.95670539 0.60767729 0.91344196]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95      1029\n",
      "           1       0.98      0.96      0.97      1157\n",
      "           2       0.90      0.88      0.89      1054\n",
      "           3       0.81      0.89      0.85       917\n",
      "           4       0.95      0.88      0.91      1059\n",
      "           5       0.39      0.99      0.56       356\n",
      "           6       0.93      0.92      0.92       962\n",
      "           7       0.88      0.96      0.92       947\n",
      "           8       0.96      0.61      0.74      1537\n",
      "           9       0.89      0.91      0.90       982\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.88     10000\n",
      "\n",
      "Epoch 38: 8707 / 10000\n",
      "Accuracy = 87.07%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92920354 0.96010408 0.87984863 0.88973799 0.86790698 0.98847262\n",
      " 0.91838843 0.95665962 0.60478655 0.90974359]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1017\n",
      "           1       0.98      0.96      0.97      1153\n",
      "           2       0.90      0.88      0.89      1057\n",
      "           3       0.81      0.89      0.85       916\n",
      "           4       0.95      0.87      0.91      1075\n",
      "           5       0.38      0.99      0.55       347\n",
      "           6       0.93      0.92      0.92       968\n",
      "           7       0.88      0.96      0.92       946\n",
      "           8       0.96      0.60      0.74      1546\n",
      "           9       0.88      0.91      0.89       975\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.87     10000\n",
      "\n",
      "Epoch 39: 8689 / 10000\n",
      "Accuracy = 86.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92822026 0.96177237 0.87488241 0.88602151 0.88185255 0.98876404\n",
      " 0.92203742 0.95877378 0.60793238 0.91624106]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1017\n",
      "           1       0.98      0.96      0.97      1151\n",
      "           2       0.90      0.87      0.89      1063\n",
      "           3       0.82      0.89      0.85       930\n",
      "           4       0.95      0.88      0.91      1058\n",
      "           5       0.39      0.99      0.56       356\n",
      "           6       0.93      0.92      0.92       962\n",
      "           7       0.88      0.96      0.92       946\n",
      "           8       0.96      0.61      0.74      1538\n",
      "           9       0.89      0.92      0.90       979\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.88     10000\n",
      "\n",
      "Epoch 40: 8716 / 10000\n",
      "Accuracy = 87.16%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92730845 0.95840555 0.87984863 0.88602151 0.8587156  0.98860399\n",
      " 0.9185567  0.95583596 0.61381579 0.91762252]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1018\n",
      "           1       0.97      0.96      0.97      1154\n",
      "           2       0.90      0.88      0.89      1057\n",
      "           3       0.82      0.89      0.85       930\n",
      "           4       0.95      0.86      0.90      1090\n",
      "           5       0.39      0.99      0.56       351\n",
      "           6       0.93      0.92      0.92       970\n",
      "           7       0.88      0.96      0.92       951\n",
      "           8       0.96      0.61      0.75      1520\n",
      "           9       0.87      0.92      0.89       959\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.88     10000\n",
      "\n",
      "Epoch 41: 8700 / 10000\n",
      "Accuracy = 87.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93004926 0.95682211 0.88645038 0.88900862 0.8728972  0.98853868\n",
      " 0.92061856 0.95978836 0.60700389 0.91794872]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1015\n",
      "           1       0.98      0.96      0.97      1158\n",
      "           2       0.90      0.89      0.89      1048\n",
      "           3       0.82      0.89      0.85       928\n",
      "           4       0.95      0.87      0.91      1070\n",
      "           5       0.39      0.99      0.56       349\n",
      "           6       0.93      0.92      0.93       970\n",
      "           7       0.88      0.96      0.92       945\n",
      "           8       0.96      0.61      0.74      1542\n",
      "           9       0.89      0.92      0.90       975\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.88     10000\n",
      "\n",
      "Epoch 42: 8716 / 10000\n",
      "Accuracy = 87.16%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92941176 0.95923677 0.88751192 0.88936627 0.87535145 0.98853868\n",
      " 0.92339545 0.95987328 0.60883691 0.91624106]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1020\n",
      "           1       0.97      0.96      0.97      1153\n",
      "           2       0.90      0.89      0.89      1049\n",
      "           3       0.82      0.89      0.85       931\n",
      "           4       0.95      0.88      0.91      1067\n",
      "           5       0.39      0.99      0.56       349\n",
      "           6       0.93      0.92      0.93       966\n",
      "           7       0.88      0.96      0.92       947\n",
      "           8       0.96      0.61      0.75      1539\n",
      "           9       0.89      0.92      0.90       979\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 43: 8727 / 10000\n",
      "Accuracy = 87.27%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92913386 0.96254355 0.88655863 0.89746417 0.86095764 0.98857143\n",
      " 0.92307692 0.95983087 0.59605598 0.91804979]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1016\n",
      "           1       0.97      0.96      0.97      1148\n",
      "           2       0.90      0.89      0.89      1049\n",
      "           3       0.81      0.90      0.85       907\n",
      "           4       0.95      0.86      0.90      1086\n",
      "           5       0.39      0.99      0.56       350\n",
      "           6       0.93      0.92      0.93       962\n",
      "           7       0.88      0.96      0.92       946\n",
      "           8       0.96      0.60      0.74      1572\n",
      "           9       0.88      0.92      0.90       964\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.90      0.87      0.87     10000\n",
      "\n",
      "Epoch 44: 8692 / 10000\n",
      "Accuracy = 86.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.93011811 0.96254355 0.88931298 0.8923913  0.88007554 0.9880597\n",
      " 0.92252066 0.95602094 0.60270444 0.91082164]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1016\n",
      "           1       0.97      0.96      0.97      1148\n",
      "           2       0.90      0.89      0.90      1048\n",
      "           3       0.81      0.89      0.85       920\n",
      "           4       0.95      0.88      0.91      1059\n",
      "           5       0.37      0.99      0.54       335\n",
      "           6       0.93      0.92      0.93       968\n",
      "           7       0.89      0.96      0.92       955\n",
      "           8       0.96      0.60      0.74      1553\n",
      "           9       0.90      0.91      0.91       998\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 45: 8717 / 10000\n",
      "Accuracy = 87.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93188549 0.96593886 0.88593156 0.89104639 0.87699531 0.98843931\n",
      " 0.92189106 0.96101159 0.60373711 0.9202454 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1013\n",
      "           1       0.97      0.97      0.97      1145\n",
      "           2       0.90      0.89      0.89      1052\n",
      "           3       0.82      0.89      0.85       927\n",
      "           4       0.95      0.88      0.91      1065\n",
      "           5       0.38      0.99      0.55       346\n",
      "           6       0.94      0.92      0.93       973\n",
      "           7       0.89      0.96      0.92       949\n",
      "           8       0.96      0.60      0.74      1552\n",
      "           9       0.89      0.92      0.91       978\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 46: 8730 / 10000\n",
      "Accuracy = 87.30%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92752204 0.95930736 0.88279773 0.89067524 0.87138863 0.98853868\n",
      " 0.92546584 0.95886076 0.61447368 0.91811668]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1021\n",
      "           1       0.98      0.96      0.97      1155\n",
      "           2       0.91      0.88      0.89      1058\n",
      "           3       0.82      0.89      0.86       933\n",
      "           4       0.95      0.87      0.91      1073\n",
      "           5       0.39      0.99      0.56       349\n",
      "           6       0.93      0.93      0.93       966\n",
      "           7       0.88      0.96      0.92       948\n",
      "           8       0.96      0.61      0.75      1520\n",
      "           9       0.89      0.92      0.90       977\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 47: 8734 / 10000\n",
      "Accuracy = 87.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92934249 0.96512642 0.89037178 0.88783069 0.87535145 0.98870056\n",
      " 0.92738589 0.95711297 0.61782178 0.91971545]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1019\n",
      "           1       0.98      0.97      0.97      1147\n",
      "           2       0.91      0.89      0.90      1049\n",
      "           3       0.83      0.89      0.86       945\n",
      "           4       0.95      0.88      0.91      1067\n",
      "           5       0.39      0.99      0.56       354\n",
      "           6       0.93      0.93      0.93       964\n",
      "           7       0.89      0.96      0.92       956\n",
      "           8       0.96      0.62      0.75      1515\n",
      "           9       0.90      0.92      0.91       984\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 48: 8761 / 10000\n",
      "Accuracy = 87.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92397661 0.96509599 0.88952381 0.88782051 0.87045666 0.99120235\n",
      " 0.92252066 0.95715778 0.61121983 0.92164948]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95      1026\n",
      "           1       0.97      0.97      0.97      1146\n",
      "           2       0.91      0.89      0.90      1050\n",
      "           3       0.82      0.89      0.85       936\n",
      "           4       0.95      0.87      0.91      1073\n",
      "           5       0.38      0.99      0.55       341\n",
      "           6       0.93      0.92      0.93       968\n",
      "           7       0.89      0.96      0.92       957\n",
      "           8       0.96      0.61      0.75      1533\n",
      "           9       0.89      0.92      0.90       970\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 49: 8731 / 10000\n",
      "Accuracy = 87.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93452381 0.96177237 0.88772598 0.8934338  0.87301587 0.99109792\n",
      " 0.92347466 0.95807128 0.6029601  0.9202454 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1008\n",
      "           1       0.98      0.96      0.97      1151\n",
      "           2       0.90      0.89      0.90      1051\n",
      "           3       0.82      0.89      0.86       929\n",
      "           4       0.95      0.87      0.91      1071\n",
      "           5       0.37      0.99      0.54       337\n",
      "           6       0.93      0.92      0.93       967\n",
      "           7       0.89      0.96      0.92       954\n",
      "           8       0.96      0.60      0.74      1554\n",
      "           9       0.89      0.92      0.91       978\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 50: 8725 / 10000\n",
      "Accuracy = 87.25%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92829077 0.96512642 0.89111748 0.8913738  0.8807947  0.99107143\n",
      " 0.92554292 0.96210526 0.60335917 0.91624622]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1018\n",
      "           1       0.98      0.97      0.97      1147\n",
      "           2       0.90      0.89      0.90      1047\n",
      "           3       0.83      0.89      0.86       939\n",
      "           4       0.95      0.88      0.91      1057\n",
      "           5       0.37      0.99      0.54       336\n",
      "           6       0.93      0.93      0.93       967\n",
      "           7       0.89      0.96      0.92       950\n",
      "           8       0.96      0.60      0.74      1548\n",
      "           9       0.90      0.92      0.91       991\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 51: 8737 / 10000\n",
      "Accuracy = 87.37%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93731343 0.9609375  0.89217557 0.88204593 0.8787594  0.99093656\n",
      " 0.92761117 0.96109359 0.60737387 0.92433538]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1005\n",
      "           1       0.98      0.96      0.97      1152\n",
      "           2       0.91      0.89      0.90      1048\n",
      "           3       0.84      0.88      0.86       958\n",
      "           4       0.95      0.88      0.91      1064\n",
      "           5       0.37      0.99      0.54       331\n",
      "           6       0.94      0.93      0.93       967\n",
      "           7       0.89      0.96      0.92       951\n",
      "           8       0.96      0.61      0.75      1546\n",
      "           9       0.90      0.92      0.91       978\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 52: 8746 / 10000\n",
      "Accuracy = 87.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93465347 0.96177237 0.89292543 0.89006342 0.87628866 0.99085366\n",
      " 0.92842324 0.96012592 0.60348162 0.91971545]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1010\n",
      "           1       0.98      0.96      0.97      1151\n",
      "           2       0.91      0.89      0.90      1046\n",
      "           3       0.83      0.89      0.86       946\n",
      "           4       0.95      0.88      0.91      1067\n",
      "           5       0.36      0.99      0.53       328\n",
      "           6       0.93      0.93      0.93       964\n",
      "           7       0.89      0.96      0.92       953\n",
      "           8       0.96      0.60      0.74      1551\n",
      "           9       0.90      0.92      0.91       984\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 53: 8738 / 10000\n",
      "Accuracy = 87.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.93018682 0.96341463 0.88793922 0.89289502 0.87711069 0.99104478\n",
      " 0.92938733 0.96202532 0.60686528 0.92268566]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1017\n",
      "           1       0.97      0.96      0.97      1148\n",
      "           2       0.91      0.89      0.90      1053\n",
      "           3       0.83      0.89      0.86       943\n",
      "           4       0.95      0.88      0.91      1066\n",
      "           5       0.37      0.99      0.54       335\n",
      "           6       0.93      0.93      0.93       963\n",
      "           7       0.89      0.96      0.92       948\n",
      "           8       0.96      0.61      0.74      1544\n",
      "           9       0.90      0.92      0.91       983\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 54: 8747 / 10000\n",
      "Accuracy = 87.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9345887  0.96006944 0.89238095 0.89064143 0.87546816 0.99142857\n",
      " 0.92584964 0.96402116 0.61791831 0.9198783 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1009\n",
      "           1       0.97      0.96      0.97      1152\n",
      "           2       0.91      0.89      0.90      1050\n",
      "           3       0.84      0.89      0.86       951\n",
      "           4       0.95      0.88      0.91      1068\n",
      "           5       0.39      0.99      0.56       350\n",
      "           6       0.94      0.93      0.93       971\n",
      "           7       0.89      0.96      0.92       945\n",
      "           8       0.96      0.62      0.75      1518\n",
      "           9       0.90      0.92      0.91       986\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 55: 8770 / 10000\n",
      "Accuracy = 87.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92822026 0.95757576 0.89142857 0.89384289 0.87864534 0.99112426\n",
      " 0.93110647 0.96402116 0.60776699 0.92097264]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1017\n",
      "           1       0.97      0.96      0.97      1155\n",
      "           2       0.91      0.89      0.90      1050\n",
      "           3       0.83      0.89      0.86       942\n",
      "           4       0.95      0.88      0.91      1063\n",
      "           5       0.38      0.99      0.54       338\n",
      "           6       0.93      0.93      0.93       958\n",
      "           7       0.89      0.96      0.92       945\n",
      "           8       0.96      0.61      0.75      1545\n",
      "           9       0.90      0.92      0.91       987\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 56: 8748 / 10000\n",
      "Accuracy = 87.48%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93706294 0.95844156 0.89312977 0.88095238 0.8787594  0.99096386\n",
      " 0.92783505 0.96004206 0.61377049 0.91801619]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1001\n",
      "           1       0.98      0.96      0.97      1155\n",
      "           2       0.91      0.89      0.90      1048\n",
      "           3       0.84      0.88      0.86       966\n",
      "           4       0.95      0.88      0.91      1064\n",
      "           5       0.37      0.99      0.54       332\n",
      "           6       0.94      0.93      0.93       970\n",
      "           7       0.89      0.96      0.92       951\n",
      "           8       0.96      0.61      0.75      1525\n",
      "           9       0.90      0.92      0.91       988\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 57: 8752 / 10000\n",
      "Accuracy = 87.52%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93083004 0.96010408 0.89408397 0.89229145 0.87581699 0.99104478\n",
      " 0.92924037 0.96315789 0.61042345 0.92004049]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1012\n",
      "           1       0.98      0.96      0.97      1153\n",
      "           2       0.91      0.89      0.90      1048\n",
      "           3       0.84      0.89      0.86       947\n",
      "           4       0.96      0.88      0.91      1071\n",
      "           5       0.37      0.99      0.54       335\n",
      "           6       0.93      0.93      0.93       961\n",
      "           7       0.89      0.96      0.93       950\n",
      "           8       0.96      0.61      0.75      1535\n",
      "           9       0.90      0.92      0.91       988\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 58: 8755 / 10000\n",
      "Accuracy = 87.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93812375 0.95438898 0.89408397 0.88485477 0.8787594  0.99053628\n",
      " 0.92982456 0.96016771 0.60977199 0.92385787]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1002\n",
      "           1       0.98      0.95      0.97      1162\n",
      "           2       0.91      0.89      0.90      1048\n",
      "           3       0.84      0.88      0.86       964\n",
      "           4       0.95      0.88      0.91      1064\n",
      "           5       0.35      0.99      0.52       317\n",
      "           6       0.94      0.93      0.94       969\n",
      "           7       0.89      0.96      0.92       954\n",
      "           8       0.96      0.61      0.75      1535\n",
      "           9       0.90      0.92      0.91       985\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 59: 8751 / 10000\n",
      "Accuracy = 87.51%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93893894 0.95431034 0.89731286 0.88669439 0.87969925 0.99122807\n",
      " 0.92967942 0.96016771 0.61629435 0.92206478]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       999\n",
      "           1       0.98      0.95      0.96      1160\n",
      "           2       0.91      0.90      0.90      1042\n",
      "           3       0.84      0.89      0.87       962\n",
      "           4       0.95      0.88      0.91      1064\n",
      "           5       0.38      0.99      0.55       342\n",
      "           6       0.94      0.93      0.93       967\n",
      "           7       0.89      0.96      0.92       954\n",
      "           8       0.96      0.62      0.75      1522\n",
      "           9       0.90      0.92      0.91       988\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 60: 8772 / 10000\n",
      "Accuracy = 87.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93712575 0.95757576 0.89741131 0.88645833 0.87969925 0.99107143\n",
      " 0.92975207 0.96315789 0.61024643 0.9255102 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1002\n",
      "           1       0.97      0.96      0.97      1155\n",
      "           2       0.91      0.90      0.90      1043\n",
      "           3       0.84      0.89      0.86       960\n",
      "           4       0.95      0.88      0.91      1064\n",
      "           5       0.37      0.99      0.54       336\n",
      "           6       0.94      0.93      0.93       968\n",
      "           7       0.89      0.96      0.93       950\n",
      "           8       0.97      0.61      0.75      1542\n",
      "           9       0.90      0.93      0.91       980\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 61: 8764 / 10000\n",
      "Accuracy = 87.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94082247 0.95592048 0.89980732 0.89052632 0.86839666 0.99041534\n",
      " 0.92695473 0.96230366 0.60359205 0.91734694]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       997\n",
      "           1       0.97      0.96      0.97      1157\n",
      "           2       0.91      0.90      0.90      1038\n",
      "           3       0.84      0.89      0.86       950\n",
      "           4       0.95      0.87      0.91      1079\n",
      "           5       0.35      0.99      0.51       313\n",
      "           6       0.94      0.93      0.93       972\n",
      "           7       0.89      0.96      0.93       955\n",
      "           8       0.97      0.60      0.74      1559\n",
      "           9       0.89      0.92      0.90       980\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 62: 8731 / 10000\n",
      "Accuracy = 87.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.92998028 0.95431034 0.8970448  0.8855359  0.87383178 0.99041534\n",
      " 0.92783505 0.96222455 0.61071195 0.92441267]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1014\n",
      "           1       0.98      0.95      0.96      1160\n",
      "           2       0.91      0.90      0.90      1049\n",
      "           3       0.84      0.89      0.86       961\n",
      "           4       0.95      0.87      0.91      1070\n",
      "           5       0.35      0.99      0.51       313\n",
      "           6       0.94      0.93      0.93       970\n",
      "           7       0.89      0.96      0.93       953\n",
      "           8       0.96      0.61      0.75      1531\n",
      "           9       0.90      0.92      0.91       979\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.87      0.88     10000\n",
      "\n",
      "Epoch 63: 8744 / 10000\n",
      "Accuracy = 87.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93545184 0.95356836 0.89468691 0.88556701 0.89016237 0.99088146\n",
      " 0.92710472 0.96439791 0.62135279 0.9204431 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1007\n",
      "           1       0.98      0.95      0.97      1163\n",
      "           2       0.91      0.89      0.90      1054\n",
      "           3       0.85      0.89      0.87       970\n",
      "           4       0.95      0.89      0.92      1047\n",
      "           5       0.37      0.99      0.53       329\n",
      "           6       0.94      0.93      0.93       974\n",
      "           7       0.90      0.96      0.93       955\n",
      "           8       0.96      0.62      0.76      1508\n",
      "           9       0.91      0.92      0.91       993\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.89     10000\n",
      "\n",
      "Epoch 64: 8786 / 10000\n",
      "Accuracy = 87.86%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94088176 0.95521102 0.89363723 0.89039666 0.88146754 0.99376947\n",
      " 0.92820513 0.96327387 0.61357702 0.9198783 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       998\n",
      "           1       0.98      0.96      0.97      1161\n",
      "           2       0.91      0.89      0.90      1053\n",
      "           3       0.84      0.89      0.87       958\n",
      "           4       0.95      0.88      0.92      1063\n",
      "           5       0.36      0.99      0.53       321\n",
      "           6       0.94      0.93      0.94       975\n",
      "           7       0.89      0.96      0.93       953\n",
      "           8       0.97      0.61      0.75      1532\n",
      "           9       0.90      0.92      0.91       986\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 65: 8768 / 10000\n",
      "Accuracy = 87.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93987976 0.95184867 0.89866157 0.88865979 0.87734082 0.99038462\n",
      " 0.92346939 0.96327387 0.61397779 0.92441267]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       998\n",
      "           1       0.98      0.95      0.96      1163\n",
      "           2       0.91      0.90      0.90      1046\n",
      "           3       0.85      0.89      0.87       970\n",
      "           4       0.95      0.88      0.91      1068\n",
      "           5       0.35      0.99      0.51       312\n",
      "           6       0.94      0.92      0.93       980\n",
      "           7       0.89      0.96      0.93       953\n",
      "           8       0.97      0.61      0.75      1531\n",
      "           9       0.90      0.92      0.91       979\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 66: 8761 / 10000\n",
      "Accuracy = 87.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94188377 0.95274914 0.90028763 0.88842975 0.87981221 0.99371069\n",
      " 0.92638037 0.96331237 0.61442623 0.92299899]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       998\n",
      "           1       0.98      0.95      0.96      1164\n",
      "           2       0.91      0.90      0.91      1043\n",
      "           3       0.85      0.89      0.87       968\n",
      "           4       0.95      0.88      0.92      1065\n",
      "           5       0.35      0.99      0.52       318\n",
      "           6       0.95      0.93      0.94       978\n",
      "           7       0.89      0.96      0.93       954\n",
      "           8       0.96      0.61      0.75      1525\n",
      "           9       0.90      0.92      0.91       987\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 67: 8774 / 10000\n",
      "Accuracy = 87.74%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94182548 0.95103093 0.90637066 0.89164087 0.87839102 0.99375\n",
      " 0.92717949 0.96424816 0.61237785 0.92479675]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       997\n",
      "           1       0.98      0.95      0.96      1164\n",
      "           2       0.91      0.91      0.91      1036\n",
      "           3       0.86      0.89      0.87       969\n",
      "           4       0.96      0.88      0.92      1069\n",
      "           5       0.36      0.99      0.52       320\n",
      "           6       0.94      0.93      0.94       975\n",
      "           7       0.89      0.96      0.93       951\n",
      "           8       0.97      0.61      0.75      1535\n",
      "           9       0.90      0.92      0.91       984\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 68: 8777 / 10000\n",
      "Accuracy = 87.77%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94182548 0.95025729 0.89895138 0.89130435 0.87418453 0.99367089\n",
      " 0.92528147 0.96617336 0.61183355 0.92798354]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       997\n",
      "           1       0.98      0.95      0.96      1166\n",
      "           2       0.91      0.90      0.91      1049\n",
      "           3       0.85      0.89      0.87       966\n",
      "           4       0.96      0.87      0.91      1073\n",
      "           5       0.35      0.99      0.52       316\n",
      "           6       0.94      0.93      0.93       977\n",
      "           7       0.89      0.97      0.93       946\n",
      "           8       0.97      0.61      0.75      1538\n",
      "           9       0.89      0.93      0.91       972\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 69: 8764 / 10000\n",
      "Accuracy = 87.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93993994 0.95189003 0.90239234 0.89511942 0.88075117 0.99378882\n",
      " 0.92717949 0.9624609  0.61720289 0.92385787]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       999\n",
      "           1       0.98      0.95      0.96      1164\n",
      "           2       0.91      0.90      0.91      1045\n",
      "           3       0.85      0.90      0.87       963\n",
      "           4       0.96      0.88      0.92      1065\n",
      "           5       0.36      0.99      0.53       322\n",
      "           6       0.94      0.93      0.94       975\n",
      "           7       0.90      0.96      0.93       959\n",
      "           8       0.97      0.62      0.75      1523\n",
      "           9       0.90      0.92      0.91       985\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.89     10000\n",
      "\n",
      "Epoch 70: 8787 / 10000\n",
      "Accuracy = 87.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94271357 0.95111492 0.90412272 0.89164087 0.87049029 0.99369085\n",
      " 0.9283521  0.96507937 0.61227154 0.92410256]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       995\n",
      "           1       0.98      0.95      0.96      1166\n",
      "           2       0.91      0.90      0.91      1043\n",
      "           3       0.86      0.89      0.87       969\n",
      "           4       0.96      0.87      0.91      1081\n",
      "           5       0.35      0.99      0.52       317\n",
      "           6       0.95      0.93      0.94       977\n",
      "           7       0.89      0.97      0.92       945\n",
      "           8       0.96      0.61      0.75      1532\n",
      "           9       0.89      0.92      0.91       975\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 71: 8768 / 10000\n",
      "Accuracy = 87.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94371859 0.94867408 0.90229885 0.88786952 0.88490566 0.99382716\n",
      " 0.92747702 0.96428571 0.6205298  0.92393509]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       995\n",
      "           1       0.98      0.95      0.96      1169\n",
      "           2       0.91      0.90      0.91      1044\n",
      "           3       0.86      0.89      0.87       981\n",
      "           4       0.96      0.88      0.92      1060\n",
      "           5       0.36      0.99      0.53       324\n",
      "           6       0.95      0.93      0.94       979\n",
      "           7       0.89      0.96      0.93       952\n",
      "           8       0.96      0.62      0.75      1510\n",
      "           9       0.90      0.92      0.91       986\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.89     10000\n",
      "\n",
      "Epoch 72: 8795 / 10000\n",
      "Accuracy = 87.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94466801 0.95184867 0.90403071 0.89719626 0.88323917 0.99371069\n",
      " 0.92638037 0.96522655 0.60880829 0.92502533]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       994\n",
      "           1       0.98      0.95      0.96      1163\n",
      "           2       0.91      0.90      0.91      1042\n",
      "           3       0.86      0.90      0.88       963\n",
      "           4       0.96      0.88      0.92      1062\n",
      "           5       0.35      0.99      0.52       318\n",
      "           6       0.95      0.93      0.94       978\n",
      "           7       0.89      0.97      0.93       949\n",
      "           8       0.97      0.61      0.75      1544\n",
      "           9       0.90      0.93      0.91       987\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.88     10000\n",
      "\n",
      "Epoch 73: 8781 / 10000\n",
      "Accuracy = 87.81%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94929006 0.94867408 0.90480769 0.89230769 0.88075117 0.99361022\n",
      " 0.92456677 0.96439791 0.61357702 0.92682927]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       986\n",
      "           1       0.98      0.95      0.96      1169\n",
      "           2       0.91      0.90      0.91      1040\n",
      "           3       0.86      0.89      0.88       975\n",
      "           4       0.96      0.88      0.92      1065\n",
      "           5       0.35      0.99      0.52       313\n",
      "           6       0.95      0.92      0.94       981\n",
      "           7       0.90      0.96      0.93       955\n",
      "           8       0.97      0.61      0.75      1532\n",
      "           9       0.90      0.93      0.92       984\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 74: 8785 / 10000\n",
      "Accuracy = 87.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93993994 0.94790777 0.90334928 0.88821138 0.87581699 0.99365079\n",
      " 0.92166836 0.96226415 0.61986755 0.93181818]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       999\n",
      "           1       0.98      0.95      0.96      1171\n",
      "           2       0.91      0.90      0.91      1045\n",
      "           3       0.87      0.89      0.88       984\n",
      "           4       0.96      0.88      0.91      1071\n",
      "           5       0.35      0.99      0.52       315\n",
      "           6       0.95      0.92      0.93       983\n",
      "           7       0.89      0.96      0.93       954\n",
      "           8       0.96      0.62      0.75      1510\n",
      "           9       0.89      0.93      0.91       968\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.89     10000\n",
      "\n",
      "Epoch 75: 8780 / 10000\n",
      "Accuracy = 87.80%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94188377 0.94790777 0.9025788  0.88990826 0.88490566 0.99373041\n",
      " 0.92543412 0.96230366 0.62300532 0.92494929]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       998\n",
      "           1       0.98      0.95      0.96      1171\n",
      "           2       0.92      0.90      0.91      1047\n",
      "           3       0.86      0.89      0.88       981\n",
      "           4       0.96      0.88      0.92      1060\n",
      "           5       0.36      0.99      0.52       319\n",
      "           6       0.95      0.93      0.94       979\n",
      "           7       0.89      0.96      0.93       955\n",
      "           8       0.96      0.62      0.76      1504\n",
      "           9       0.90      0.92      0.91       986\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 76: 8797 / 10000\n",
      "Accuracy = 87.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94182548 0.94871795 0.9050815  0.88843813 0.88312912 0.99348534\n",
      " 0.92362525 0.96413502 0.6146789  0.92755102]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       997\n",
      "           1       0.98      0.95      0.96      1170\n",
      "           2       0.91      0.91      0.91      1043\n",
      "           3       0.87      0.89      0.88       986\n",
      "           4       0.95      0.88      0.92      1061\n",
      "           5       0.34      0.99      0.51       307\n",
      "           6       0.95      0.92      0.94       982\n",
      "           7       0.89      0.96      0.93       948\n",
      "           8       0.96      0.61      0.75      1526\n",
      "           9       0.90      0.93      0.91       980\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 77: 8779 / 10000\n",
      "Accuracy = 87.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94277108 0.94709898 0.89990467 0.89322382 0.89408397 0.99384615\n",
      " 0.92331288 0.96327387 0.62234043 0.92107892]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       996\n",
      "           1       0.98      0.95      0.96      1172\n",
      "           2       0.91      0.90      0.91      1049\n",
      "           3       0.86      0.89      0.88       974\n",
      "           4       0.95      0.89      0.92      1048\n",
      "           5       0.36      0.99      0.53       325\n",
      "           6       0.94      0.92      0.93       978\n",
      "           7       0.89      0.96      0.93       953\n",
      "           8       0.96      0.62      0.76      1504\n",
      "           9       0.91      0.92      0.92      1001\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.89     10000\n",
      "\n",
      "Epoch 78: 8802 / 10000\n",
      "Accuracy = 88.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9445005  0.94790777 0.90393852 0.89114954 0.89655172 0.99367089\n",
      " 0.92150866 0.9625     0.61710526 0.92749245]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       991\n",
      "           1       0.98      0.95      0.96      1171\n",
      "           2       0.91      0.90      0.91      1041\n",
      "           3       0.87      0.89      0.88       983\n",
      "           4       0.95      0.90      0.92      1044\n",
      "           5       0.35      0.99      0.52       316\n",
      "           6       0.94      0.92      0.93       981\n",
      "           7       0.90      0.96      0.93       960\n",
      "           8       0.96      0.62      0.75      1520\n",
      "           9       0.91      0.93      0.92       993\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 79: 8800 / 10000\n",
      "Accuracy = 88.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94556452 0.94307562 0.90316395 0.8984456  0.88563327 0.99373041\n",
      " 0.92433538 0.96421053 0.6146789  0.92439516]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       992\n",
      "           1       0.98      0.94      0.96      1177\n",
      "           2       0.91      0.90      0.91      1043\n",
      "           3       0.86      0.90      0.88       965\n",
      "           4       0.95      0.89      0.92      1058\n",
      "           5       0.36      0.99      0.52       319\n",
      "           6       0.94      0.92      0.93       978\n",
      "           7       0.89      0.96      0.93       950\n",
      "           8       0.96      0.61      0.75      1526\n",
      "           9       0.91      0.92      0.92       992\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.89     10000\n",
      "\n",
      "Epoch 80: 8786 / 10000\n",
      "Accuracy = 87.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.9473151  0.94382979 0.90926641 0.89907312 0.88323917 0.99367089\n",
      " 0.92252803 0.9625     0.6130719  0.92769857]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       987\n",
      "           1       0.98      0.94      0.96      1175\n",
      "           2       0.91      0.91      0.91      1036\n",
      "           3       0.86      0.90      0.88       971\n",
      "           4       0.96      0.88      0.92      1062\n",
      "           5       0.35      0.99      0.52       316\n",
      "           6       0.94      0.92      0.93       981\n",
      "           7       0.90      0.96      0.93       960\n",
      "           8       0.96      0.61      0.75      1530\n",
      "           9       0.90      0.93      0.92       982\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 81: 8789 / 10000\n",
      "Accuracy = 87.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94188377 0.94468085 0.90682037 0.89783282 0.88407163 0.99348534\n",
      " 0.92687951 0.96331237 0.60988296 0.92697769]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       998\n",
      "           1       0.98      0.94      0.96      1175\n",
      "           2       0.91      0.91      0.91      1041\n",
      "           3       0.86      0.90      0.88       969\n",
      "           4       0.96      0.88      0.92      1061\n",
      "           5       0.34      0.99      0.51       307\n",
      "           6       0.94      0.93      0.93       971\n",
      "           7       0.89      0.96      0.93       954\n",
      "           8       0.96      0.61      0.75      1538\n",
      "           9       0.91      0.93      0.92       986\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 82: 8778 / 10000\n",
      "Accuracy = 87.78%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94094094 0.94709898 0.90944123 0.88832998 0.89132507 0.99371069\n",
      " 0.92346939 0.96242171 0.62167553 0.92712551]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       999\n",
      "           1       0.98      0.95      0.96      1172\n",
      "           2       0.91      0.91      0.91      1038\n",
      "           3       0.87      0.89      0.88       994\n",
      "           4       0.95      0.89      0.92      1049\n",
      "           5       0.35      0.99      0.52       318\n",
      "           6       0.94      0.92      0.93       980\n",
      "           7       0.90      0.96      0.93       958\n",
      "           8       0.96      0.62      0.75      1504\n",
      "           9       0.91      0.93      0.92       988\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 83: 8806 / 10000\n",
      "Accuracy = 88.06%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94271357 0.94952951 0.91031823 0.8891129  0.89142857 0.99378882\n",
      " 0.92520492 0.96342738 0.61961564 0.92547835]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       995\n",
      "           1       0.98      0.95      0.96      1169\n",
      "           2       0.91      0.91      0.91      1037\n",
      "           3       0.87      0.89      0.88       992\n",
      "           4       0.95      0.89      0.92      1050\n",
      "           5       0.36      0.99      0.53       322\n",
      "           6       0.94      0.93      0.93       976\n",
      "           7       0.90      0.96      0.93       957\n",
      "           8       0.96      0.62      0.75      1509\n",
      "           9       0.91      0.93      0.92       993\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 84: 8809 / 10000\n",
      "Accuracy = 88.09%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94742164 0.94307562 0.90751445 0.89134809 0.88973384 0.99375\n",
      " 0.91995947 0.96242171 0.62474916 0.92525253]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       989\n",
      "           1       0.98      0.94      0.96      1177\n",
      "           2       0.91      0.91      0.91      1038\n",
      "           3       0.88      0.89      0.88       994\n",
      "           4       0.95      0.89      0.92      1052\n",
      "           5       0.36      0.99      0.52       320\n",
      "           6       0.95      0.92      0.93       987\n",
      "           7       0.90      0.96      0.93       958\n",
      "           8       0.96      0.62      0.76      1495\n",
      "           9       0.91      0.93      0.92       990\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 85: 8809 / 10000\n",
      "Accuracy = 88.09%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94539939 0.94307562 0.90926641 0.90238837 0.88731061 0.99376947\n",
      " 0.92346939 0.96338912 0.61201829 0.92532795]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       989\n",
      "           1       0.98      0.94      0.96      1177\n",
      "           2       0.91      0.91      0.91      1036\n",
      "           3       0.86      0.90      0.88       963\n",
      "           4       0.95      0.89      0.92      1056\n",
      "           5       0.36      0.99      0.53       321\n",
      "           6       0.94      0.92      0.93       980\n",
      "           7       0.90      0.96      0.93       956\n",
      "           8       0.96      0.61      0.75      1531\n",
      "           9       0.91      0.93      0.92       991\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.89     10000\n",
      "\n",
      "Epoch 86: 8792 / 10000\n",
      "Accuracy = 87.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94176707 0.94387755 0.91111111 0.89602446 0.88229755 0.99376947\n",
      " 0.9198783  0.96432319 0.62126246 0.9248731 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       996\n",
      "           1       0.98      0.94      0.96      1176\n",
      "           2       0.91      0.91      0.91      1035\n",
      "           3       0.87      0.90      0.88       981\n",
      "           4       0.95      0.88      0.92      1062\n",
      "           5       0.36      0.99      0.53       321\n",
      "           6       0.95      0.92      0.93       986\n",
      "           7       0.89      0.96      0.93       953\n",
      "           8       0.96      0.62      0.75      1505\n",
      "           9       0.90      0.92      0.91       985\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 87: 8798 / 10000\n",
      "Accuracy = 87.98%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94176707 0.94468085 0.91040462 0.89137056 0.8905804  0.99337748\n",
      " 0.92166836 0.96436059 0.6129666  0.92618807]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       996\n",
      "           1       0.98      0.94      0.96      1175\n",
      "           2       0.92      0.91      0.91      1038\n",
      "           3       0.87      0.89      0.88       985\n",
      "           4       0.95      0.89      0.92      1051\n",
      "           5       0.34      0.99      0.50       302\n",
      "           6       0.95      0.92      0.93       983\n",
      "           7       0.89      0.96      0.93       954\n",
      "           8       0.96      0.61      0.75      1527\n",
      "           9       0.91      0.93      0.92       989\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 88: 8785 / 10000\n",
      "Accuracy = 87.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94182548 0.94302721 0.90717703 0.89137056 0.89068441 0.99335548\n",
      " 0.92543412 0.96424816 0.61578947 0.92354125]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       997\n",
      "           1       0.98      0.94      0.96      1176\n",
      "           2       0.92      0.91      0.91      1045\n",
      "           3       0.87      0.89      0.88       985\n",
      "           4       0.95      0.89      0.92      1052\n",
      "           5       0.34      0.99      0.50       301\n",
      "           6       0.95      0.93      0.94       979\n",
      "           7       0.89      0.96      0.93       951\n",
      "           8       0.96      0.62      0.75      1520\n",
      "           9       0.91      0.92      0.92       994\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 89: 8787 / 10000\n",
      "Accuracy = 87.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94277108 0.94302721 0.91023166 0.88665998 0.88731061 0.99315068\n",
      " 0.91809909 0.96424816 0.61477573 0.92330979]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       996\n",
      "           1       0.98      0.94      0.96      1176\n",
      "           2       0.91      0.91      0.91      1036\n",
      "           3       0.88      0.89      0.88       997\n",
      "           4       0.95      0.89      0.92      1056\n",
      "           5       0.33      0.99      0.49       292\n",
      "           6       0.95      0.92      0.93       989\n",
      "           7       0.89      0.96      0.93       951\n",
      "           8       0.96      0.61      0.75      1516\n",
      "           9       0.91      0.92      0.91       991\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.86     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 90: 8774 / 10000\n",
      "Accuracy = 87.74%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94461229 0.942226   0.90856593 0.89307536 0.89248335 0.99369085\n",
      " 0.92236977 0.96432319 0.6193634  0.92207792]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       993\n",
      "           1       0.98      0.94      0.96      1177\n",
      "           2       0.91      0.91      0.91      1039\n",
      "           3       0.87      0.89      0.88       982\n",
      "           4       0.96      0.89      0.92      1051\n",
      "           5       0.35      0.99      0.52       317\n",
      "           6       0.94      0.92      0.93       979\n",
      "           7       0.89      0.96      0.93       953\n",
      "           8       0.96      0.62      0.75      1508\n",
      "           9       0.91      0.92      0.92      1001\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 91: 8800 / 10000\n",
      "Accuracy = 88.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94539939 0.942226   0.9025788  0.89318413 0.89068441 0.99361022\n",
      " 0.92339122 0.96432319 0.61721854 0.9227683 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       989\n",
      "           1       0.98      0.94      0.96      1177\n",
      "           2       0.92      0.90      0.91      1047\n",
      "           3       0.87      0.89      0.88       983\n",
      "           4       0.95      0.89      0.92      1052\n",
      "           5       0.35      0.99      0.52       313\n",
      "           6       0.94      0.92      0.93       979\n",
      "           7       0.89      0.96      0.93       953\n",
      "           8       0.96      0.62      0.75      1510\n",
      "           9       0.91      0.92      0.92       997\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.91      0.88      0.89     10000\n",
      "\n",
      "Epoch 92: 8790 / 10000\n",
      "Accuracy = 87.90%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94277108 0.942226   0.90891659 0.88956434 0.9017341  0.99350649\n",
      " 0.92260692 0.96526316 0.61543536 0.92123629]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       996\n",
      "           1       0.98      0.94      0.96      1177\n",
      "           2       0.92      0.91      0.91      1043\n",
      "           3       0.87      0.89      0.88       987\n",
      "           4       0.95      0.90      0.93      1038\n",
      "           5       0.34      0.99      0.51       308\n",
      "           6       0.95      0.92      0.93       982\n",
      "           7       0.89      0.97      0.93       950\n",
      "           8       0.96      0.62      0.75      1516\n",
      "           9       0.92      0.92      0.92      1003\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 93: 8796 / 10000\n",
      "Accuracy = 87.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94556452 0.94147583 0.9154519  0.88453815 0.88563327 0.99356913\n",
      " 0.92174797 0.9662803  0.61788079 0.92137097]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       992\n",
      "           1       0.98      0.94      0.96      1179\n",
      "           2       0.91      0.92      0.91      1029\n",
      "           3       0.87      0.88      0.88       996\n",
      "           4       0.95      0.89      0.92      1058\n",
      "           5       0.35      0.99      0.51       311\n",
      "           6       0.95      0.92      0.93       984\n",
      "           7       0.89      0.97      0.93       949\n",
      "           8       0.96      0.62      0.75      1510\n",
      "           9       0.91      0.92      0.91       992\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 94: 8788 / 10000\n",
      "Accuracy = 87.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94720812 0.94147583 0.91111111 0.90041068 0.90096154 0.99350649\n",
      " 0.9198783  0.96540881 0.60753736 0.923     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       985\n",
      "           1       0.98      0.94      0.96      1179\n",
      "           2       0.91      0.91      0.91      1035\n",
      "           3       0.87      0.90      0.88       974\n",
      "           4       0.95      0.90      0.93      1040\n",
      "           5       0.34      0.99      0.51       308\n",
      "           6       0.95      0.92      0.93       986\n",
      "           7       0.90      0.97      0.93       954\n",
      "           8       0.96      0.61      0.74      1539\n",
      "           9       0.91      0.92      0.92      1000\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 95: 8792 / 10000\n",
      "Accuracy = 87.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94923858 0.94387755 0.90926641 0.89602446 0.89645254 0.99365079\n",
      " 0.9198783  0.96537251 0.61235217 0.92123629]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       985\n",
      "           1       0.98      0.94      0.96      1176\n",
      "           2       0.91      0.91      0.91      1036\n",
      "           3       0.87      0.90      0.88       981\n",
      "           4       0.95      0.90      0.92      1043\n",
      "           5       0.35      0.99      0.52       315\n",
      "           6       0.95      0.92      0.93       986\n",
      "           7       0.89      0.97      0.93       953\n",
      "           8       0.96      0.61      0.75      1522\n",
      "           9       0.92      0.92      0.92      1003\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 96: 8797 / 10000\n",
      "Accuracy = 87.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94561934 0.94387755 0.91136802 0.88933602 0.89913545 0.99356913\n",
      " 0.92089249 0.96540881 0.61752988 0.92207792]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       993\n",
      "           1       0.98      0.94      0.96      1176\n",
      "           2       0.92      0.91      0.91      1038\n",
      "           3       0.88      0.89      0.88       994\n",
      "           4       0.95      0.90      0.93      1041\n",
      "           5       0.35      0.99      0.51       311\n",
      "           6       0.95      0.92      0.93       986\n",
      "           7       0.90      0.97      0.93       954\n",
      "           8       0.95      0.62      0.75      1506\n",
      "           9       0.91      0.92      0.92      1001\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 97: 8806 / 10000\n",
      "Accuracy = 88.06%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9437751  0.93908629 0.91400966 0.88465396 0.90009606 0.99337748\n",
      " 0.92081218 0.96439791 0.61850866 0.92039801]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       996\n",
      "           1       0.98      0.94      0.96      1182\n",
      "           2       0.92      0.91      0.92      1035\n",
      "           3       0.87      0.88      0.88       997\n",
      "           4       0.95      0.90      0.93      1041\n",
      "           5       0.34      0.99      0.50       302\n",
      "           6       0.95      0.92      0.93       985\n",
      "           7       0.90      0.96      0.93       955\n",
      "           8       0.95      0.62      0.75      1502\n",
      "           9       0.92      0.92      0.92      1005\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 98: 8797 / 10000\n",
      "Accuracy = 87.97%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94360524 0.93670886 0.91241578 0.89292929 0.88501414 0.99335548\n",
      " 0.91911021 0.96522655 0.61860465 0.92408907]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       993\n",
      "           1       0.98      0.94      0.96      1185\n",
      "           2       0.92      0.91      0.92      1039\n",
      "           3       0.88      0.89      0.88       990\n",
      "           4       0.96      0.89      0.92      1061\n",
      "           5       0.34      0.99      0.50       301\n",
      "           6       0.95      0.92      0.93       989\n",
      "           7       0.89      0.97      0.93       949\n",
      "           8       0.96      0.62      0.75      1505\n",
      "           9       0.90      0.92      0.91       988\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.92      0.88      0.89     10000\n",
      "\n",
      "Epoch 99: 8786 / 10000\n",
      "Accuracy = 87.86%\n"
     ]
    }
   ],
   "source": [
    "net = network_tanh.NetworkTanh([784, 30, 10])\n",
    "net.SGD(training_data, 100, 10, 0.1, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.90388769 0.94070796 0.93478261 0.85464334 0.93589744 0.46080306\n",
      " 0.63892909 0.89736842 0.55162659 0.84179104]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       926\n",
      "           1       0.94      0.94      0.94      1130\n",
      "           2       0.71      0.93      0.81       782\n",
      "           3       0.63      0.85      0.72       743\n",
      "           4       0.59      0.94      0.73       624\n",
      "           5       0.81      0.46      0.59      1569\n",
      "           6       0.92      0.64      0.75      1382\n",
      "           7       0.66      0.90      0.76       760\n",
      "           8       0.80      0.55      0.65      1414\n",
      "           9       0.56      0.84      0.67       670\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.80      0.75     10000\n",
      "weighted avg       0.78      0.75      0.74     10000\n",
      "\n",
      "Epoch 0: 7482 / 10000\n",
      "Accuracy = 74.82%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94719828 0.96363636 0.9631829  0.86237514 0.95590327 0.62304527\n",
      " 0.74750831 0.93277311 0.61555393 0.84412733]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       928\n",
      "           1       0.93      0.96      0.95      1100\n",
      "           2       0.79      0.96      0.87       842\n",
      "           3       0.77      0.86      0.81       901\n",
      "           4       0.68      0.96      0.80       703\n",
      "           5       0.85      0.62      0.72      1215\n",
      "           6       0.94      0.75      0.83      1204\n",
      "           7       0.76      0.93      0.84       833\n",
      "           8       0.86      0.62      0.72      1363\n",
      "           9       0.76      0.84      0.80       911\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.83     10000\n",
      "weighted avg       0.84      0.82      0.82     10000\n",
      "\n",
      "Epoch 1: 8241 / 10000\n",
      "Accuracy = 82.41%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95935829 0.97282609 0.96172249 0.84830339 0.95646259 0.73647984\n",
      " 0.80124777 0.9571263  0.65010799 0.85255767]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       935\n",
      "           1       0.95      0.97      0.96      1104\n",
      "           2       0.78      0.96      0.86       836\n",
      "           3       0.84      0.85      0.84      1002\n",
      "           4       0.72      0.96      0.82       735\n",
      "           5       0.84      0.74      0.78      1017\n",
      "           6       0.94      0.80      0.86      1122\n",
      "           7       0.80      0.96      0.87       863\n",
      "           8       0.93      0.65      0.76      1389\n",
      "           9       0.84      0.85      0.85       997\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.85      0.87      0.86     10000\n",
      "weighted avg       0.86      0.86      0.85     10000\n",
      "\n",
      "Epoch 2: 8555 / 10000\n",
      "Accuracy = 85.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9494324  0.97547684 0.96198157 0.87318087 0.95931759 0.7752809\n",
      " 0.80701754 0.97408716 0.64401982 0.87983281]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       969\n",
      "           1       0.95      0.98      0.96      1101\n",
      "           2       0.81      0.96      0.88       868\n",
      "           3       0.83      0.87      0.85       962\n",
      "           4       0.74      0.96      0.84       762\n",
      "           5       0.85      0.78      0.81       979\n",
      "           6       0.96      0.81      0.88      1140\n",
      "           7       0.80      0.97      0.88       849\n",
      "           8       0.93      0.64      0.76      1413\n",
      "           9       0.83      0.88      0.86       957\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.88      0.87     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 3: 8658 / 10000\n",
      "Accuracy = 86.58%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96346555 0.97716895 0.95388076 0.8808554  0.97275204 0.79854621\n",
      " 0.84166667 0.97011494 0.6490113  0.86969398]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       958\n",
      "           1       0.94      0.98      0.96      1095\n",
      "           2       0.82      0.95      0.88       889\n",
      "           3       0.86      0.88      0.87       982\n",
      "           4       0.73      0.97      0.83       734\n",
      "           5       0.86      0.80      0.83       963\n",
      "           6       0.95      0.84      0.89      1080\n",
      "           7       0.82      0.97      0.89       870\n",
      "           8       0.94      0.65      0.77      1416\n",
      "           9       0.87      0.87      0.87      1013\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "Epoch 4: 8742 / 10000\n",
      "Accuracy = 87.42%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95820591 0.98039216 0.96469248 0.87586892 0.96962025 0.84280936\n",
      " 0.8556701  0.97456647 0.63436426 0.88372093]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       981\n",
      "           1       0.93      0.98      0.95      1071\n",
      "           2       0.82      0.96      0.89       878\n",
      "           3       0.87      0.88      0.87      1007\n",
      "           4       0.78      0.97      0.86       790\n",
      "           5       0.85      0.84      0.85       897\n",
      "           6       0.95      0.86      0.90      1067\n",
      "           7       0.82      0.97      0.89       865\n",
      "           8       0.95      0.63      0.76      1455\n",
      "           9       0.87      0.88      0.87       989\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.89      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 5: 8794 / 10000\n",
      "Accuracy = 87.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95625636 0.98137803 0.96825397 0.87536801 0.97358491 0.86321839\n",
      " 0.87106017 0.98354877 0.63679891 0.87217306]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       983\n",
      "           1       0.93      0.98      0.95      1074\n",
      "           2       0.83      0.97      0.89       882\n",
      "           3       0.88      0.88      0.88      1019\n",
      "           4       0.79      0.97      0.87       795\n",
      "           5       0.84      0.86      0.85       870\n",
      "           6       0.95      0.87      0.91      1047\n",
      "           7       0.81      0.98      0.89       851\n",
      "           8       0.96      0.64      0.76      1462\n",
      "           9       0.88      0.87      0.88      1017\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 6: 8832 / 10000\n",
      "Accuracy = 88.32%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95625636 0.98205855 0.96737908 0.86796117 0.96958637 0.88075561\n",
      " 0.87044146 0.9824356  0.62913014 0.89001009]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       983\n",
      "           1       0.92      0.98      0.95      1059\n",
      "           2       0.83      0.97      0.90       889\n",
      "           3       0.89      0.87      0.88      1030\n",
      "           4       0.81      0.97      0.88       822\n",
      "           5       0.84      0.88      0.86       847\n",
      "           6       0.95      0.87      0.91      1042\n",
      "           7       0.82      0.98      0.89       854\n",
      "           8       0.96      0.63      0.76      1483\n",
      "           9       0.87      0.89      0.88       991\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.89     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 7: 8838 / 10000\n",
      "Accuracy = 88.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94779116 0.98473282 0.97238205 0.85188679 0.96441281 0.88547816\n",
      " 0.8776699  0.98235294 0.62516824 0.89495366]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       996\n",
      "           1       0.91      0.98      0.95      1048\n",
      "           2       0.82      0.97      0.89       869\n",
      "           3       0.89      0.85      0.87      1060\n",
      "           4       0.83      0.96      0.89       843\n",
      "           5       0.84      0.89      0.86       847\n",
      "           6       0.94      0.88      0.91      1030\n",
      "           7       0.81      0.98      0.89       850\n",
      "           8       0.95      0.63      0.76      1486\n",
      "           9       0.86      0.89      0.88       971\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 8: 8824 / 10000\n",
      "Accuracy = 88.24%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94969819 0.98499062 0.96587031 0.84095064 0.97758406 0.90060606\n",
      " 0.89250493 0.98364486 0.64002732 0.88457711]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       994\n",
      "           1       0.93      0.98      0.95      1066\n",
      "           2       0.82      0.97      0.89       879\n",
      "           3       0.91      0.84      0.87      1094\n",
      "           4       0.80      0.98      0.88       803\n",
      "           5       0.83      0.90      0.87       825\n",
      "           6       0.94      0.89      0.92      1014\n",
      "           7       0.82      0.98      0.89       856\n",
      "           8       0.96      0.64      0.77      1464\n",
      "           9       0.88      0.88      0.88      1005\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.89      0.89      0.88     10000\n",
      "\n",
      "Epoch 9: 8864 / 10000\n",
      "Accuracy = 88.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94773869 0.98655139 0.97209302 0.84972171 0.9760101  0.9026764\n",
      " 0.8861629  0.98474178 0.60204734 0.89877301]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       995\n",
      "           1       0.90      0.99      0.94      1041\n",
      "           2       0.81      0.97      0.88       860\n",
      "           3       0.91      0.85      0.88      1078\n",
      "           4       0.79      0.98      0.87       792\n",
      "           5       0.83      0.90      0.87       822\n",
      "           6       0.94      0.89      0.91      1019\n",
      "           7       0.82      0.98      0.89       852\n",
      "           8       0.97      0.60      0.74      1563\n",
      "           9       0.87      0.90      0.88       978\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 10: 8799 / 10000\n",
      "Accuracy = 87.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.947      0.98543689 0.96674312 0.85205993 0.97607053 0.90842491\n",
      " 0.88292683 0.98576512 0.59481669 0.90692865]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1000\n",
      "           1       0.89      0.99      0.94      1030\n",
      "           2       0.82      0.97      0.89       872\n",
      "           3       0.90      0.85      0.88      1068\n",
      "           4       0.79      0.98      0.87       794\n",
      "           5       0.83      0.91      0.87       819\n",
      "           6       0.94      0.88      0.91      1025\n",
      "           7       0.81      0.99      0.89       843\n",
      "           8       0.97      0.59      0.74      1582\n",
      "           9       0.87      0.91      0.89       967\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 11: 8788 / 10000\n",
      "Accuracy = 87.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94959677 0.98653846 0.95725534 0.8440367  0.97471555 0.92220828\n",
      " 0.88596491 0.98578199 0.60051216 0.90402477]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       992\n",
      "           1       0.90      0.99      0.94      1040\n",
      "           2       0.82      0.96      0.89       889\n",
      "           3       0.91      0.84      0.88      1090\n",
      "           4       0.79      0.97      0.87       791\n",
      "           5       0.82      0.92      0.87       797\n",
      "           6       0.95      0.89      0.92      1026\n",
      "           7       0.81      0.99      0.89       844\n",
      "           8       0.96      0.60      0.74      1562\n",
      "           9       0.87      0.90      0.89       969\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 12: 8800 / 10000\n",
      "Accuracy = 88.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93307087 0.98729228 0.97334878 0.84095064 0.97752809 0.91949686\n",
      " 0.88671875 0.98500577 0.59961563 0.91631799]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1016\n",
      "           1       0.89      0.99      0.94      1023\n",
      "           2       0.81      0.97      0.89       863\n",
      "           3       0.91      0.84      0.87      1094\n",
      "           4       0.80      0.98      0.88       801\n",
      "           5       0.82      0.92      0.87       795\n",
      "           6       0.95      0.89      0.92      1024\n",
      "           7       0.83      0.99      0.90       867\n",
      "           8       0.96      0.60      0.74      1561\n",
      "           9       0.87      0.92      0.89       956\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 13: 8806 / 10000\n",
      "Accuracy = 88.06%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93608653 0.98705179 0.970964   0.86801541 0.97416974 0.9135201\n",
      " 0.89791873 0.98502304 0.58541147 0.90880829]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1017\n",
      "           1       0.87      0.99      0.93      1004\n",
      "           2       0.81      0.97      0.88       861\n",
      "           3       0.89      0.87      0.88      1038\n",
      "           4       0.81      0.97      0.88       813\n",
      "           5       0.84      0.91      0.88       821\n",
      "           6       0.95      0.90      0.92      1009\n",
      "           7       0.83      0.99      0.90       868\n",
      "           8       0.96      0.59      0.73      1604\n",
      "           9       0.87      0.91      0.89       965\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 14: 8799 / 10000\n",
      "Accuracy = 87.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94152626 0.98915187 0.96453089 0.84191509 0.97755611 0.91563275\n",
      " 0.90552764 0.98599767 0.59758423 0.91069574]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1009\n",
      "           1       0.88      0.99      0.93      1014\n",
      "           2       0.82      0.96      0.88       874\n",
      "           3       0.92      0.84      0.88      1107\n",
      "           4       0.80      0.98      0.88       802\n",
      "           5       0.83      0.92      0.87       806\n",
      "           6       0.94      0.91      0.92       995\n",
      "           7       0.82      0.99      0.90       857\n",
      "           8       0.97      0.60      0.74      1573\n",
      "           9       0.87      0.91      0.89       963\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 15: 8813 / 10000\n",
      "Accuracy = 88.13%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93780849 0.99006951 0.96878613 0.85410896 0.97546012 0.92211055\n",
      " 0.909      0.98509174 0.59303797 0.91021672]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      1013\n",
      "           1       0.88      0.99      0.93      1007\n",
      "           2       0.81      0.97      0.88       865\n",
      "           3       0.92      0.85      0.88      1083\n",
      "           4       0.81      0.98      0.88       815\n",
      "           5       0.82      0.92      0.87       796\n",
      "           6       0.95      0.91      0.93      1000\n",
      "           7       0.84      0.99      0.90       872\n",
      "           8       0.96      0.59      0.73      1580\n",
      "           9       0.87      0.91      0.89       969\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.89     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 16: 8826 / 10000\n",
      "Accuracy = 88.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94175716 0.98911968 0.96712018 0.8372093  0.97555012 0.9259724\n",
      " 0.91497976 0.98693587 0.61042345 0.89457831]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1013\n",
      "           1       0.88      0.99      0.93      1011\n",
      "           2       0.83      0.97      0.89       882\n",
      "           3       0.93      0.84      0.88      1118\n",
      "           4       0.81      0.98      0.89       818\n",
      "           5       0.83      0.93      0.87       797\n",
      "           6       0.94      0.91      0.93       988\n",
      "           7       0.81      0.99      0.89       842\n",
      "           8       0.96      0.61      0.75      1535\n",
      "           9       0.88      0.89      0.89       996\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.89     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 17: 8842 / 10000\n",
      "Accuracy = 88.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94251734 0.98982706 0.97176471 0.85188592 0.97665848 0.92079208\n",
      " 0.90772317 0.98734177 0.57572042 0.91911765]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1009\n",
      "           1       0.86      0.99      0.92       983\n",
      "           2       0.80      0.97      0.88       850\n",
      "           3       0.92      0.85      0.88      1087\n",
      "           4       0.81      0.98      0.89       814\n",
      "           5       0.83      0.92      0.88       808\n",
      "           6       0.94      0.91      0.93       997\n",
      "           7       0.83      0.99      0.90       869\n",
      "           8       0.96      0.58      0.72      1631\n",
      "           9       0.87      0.92      0.89       952\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 18: 8792 / 10000\n",
      "Accuracy = 87.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93990148 0.98990918 0.97212544 0.86685552 0.98106061 0.92307692\n",
      " 0.90881764 0.98598131 0.57142857 0.90174002]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1015\n",
      "           1       0.86      0.99      0.92       991\n",
      "           2       0.81      0.97      0.88       861\n",
      "           3       0.91      0.87      0.89      1059\n",
      "           4       0.79      0.98      0.88       792\n",
      "           5       0.83      0.92      0.88       806\n",
      "           6       0.95      0.91      0.93       998\n",
      "           7       0.82      0.99      0.90       856\n",
      "           8       0.97      0.57      0.72      1645\n",
      "           9       0.87      0.90      0.89       977\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 19: 8783 / 10000\n",
      "Accuracy = 87.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94378698 0.98965874 0.96959064 0.8664158  0.97349398 0.91849148\n",
      " 0.92535787 0.98722416 0.56987952 0.91368421]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1014\n",
      "           1       0.84      0.99      0.91       967\n",
      "           2       0.80      0.97      0.88       855\n",
      "           3       0.91      0.87      0.89      1063\n",
      "           4       0.82      0.97      0.89       830\n",
      "           5       0.85      0.92      0.88       822\n",
      "           6       0.94      0.93      0.93       978\n",
      "           7       0.83      0.99      0.90       861\n",
      "           8       0.97      0.57      0.72      1660\n",
      "           9       0.86      0.91      0.89       950\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.91      0.88     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 20: 8796 / 10000\n",
      "Accuracy = 87.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94296952 0.99034335 0.96962617 0.86085343 0.97149644 0.91625616\n",
      " 0.92252803 0.98824912 0.55164319 0.91693635]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1017\n",
      "           1       0.81      0.99      0.89       932\n",
      "           2       0.80      0.97      0.88       856\n",
      "           3       0.92      0.86      0.89      1078\n",
      "           4       0.83      0.97      0.90       842\n",
      "           5       0.83      0.92      0.87       812\n",
      "           6       0.94      0.92      0.93       981\n",
      "           7       0.82      0.99      0.90       851\n",
      "           8       0.97      0.55      0.70      1704\n",
      "           9       0.84      0.92      0.88       927\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.87      0.87     10000\n",
      "\n",
      "Epoch 21: 8738 / 10000\n",
      "Accuracy = 87.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94308145 0.99088146 0.96966161 0.84692029 0.97893432 0.92574257\n",
      " 0.9235474  0.98735632 0.57742134 0.90803383]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1019\n",
      "           1       0.86      0.99      0.92       987\n",
      "           2       0.81      0.97      0.88       857\n",
      "           3       0.93      0.85      0.88      1104\n",
      "           4       0.80      0.98      0.88       807\n",
      "           5       0.84      0.93      0.88       808\n",
      "           6       0.95      0.92      0.93       981\n",
      "           7       0.84      0.99      0.91       870\n",
      "           8       0.96      0.58      0.72      1621\n",
      "           9       0.85      0.91      0.88       946\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.91      0.89     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 22: 8803 / 10000\n",
      "Accuracy = 88.03%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94285714 0.98982706 0.96770473 0.86716558 0.97833935 0.9211165\n",
      " 0.91008991 0.9883856  0.57927205 0.92133621]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1015\n",
      "           1       0.86      0.99      0.92       983\n",
      "           2       0.81      0.97      0.88       867\n",
      "           3       0.92      0.87      0.89      1069\n",
      "           4       0.83      0.98      0.90       831\n",
      "           5       0.85      0.92      0.88       824\n",
      "           6       0.95      0.91      0.93      1001\n",
      "           7       0.83      0.99      0.90       861\n",
      "           8       0.96      0.58      0.72      1621\n",
      "           9       0.85      0.92      0.88       928\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.91      0.89     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 23: 8824 / 10000\n",
      "Accuracy = 88.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93847656 0.99081633 0.97297297 0.84490532 0.98108449 0.91605839\n",
      " 0.91809909 0.98614319 0.56571775 0.90382514]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1024\n",
      "           1       0.86      0.99      0.92       980\n",
      "           2       0.80      0.97      0.88       851\n",
      "           3       0.93      0.84      0.88      1109\n",
      "           4       0.79      0.98      0.88       793\n",
      "           5       0.84      0.92      0.88       822\n",
      "           6       0.95      0.92      0.93       989\n",
      "           7       0.83      0.99      0.90       866\n",
      "           8       0.96      0.57      0.71      1651\n",
      "           9       0.82      0.90      0.86       915\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 24: 8751 / 10000\n",
      "Accuracy = 87.51%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93560976 0.98961578 0.97420868 0.86524164 0.97929354 0.92009685\n",
      " 0.91491491 0.98942421 0.55621654 0.90939227]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1025\n",
      "           1       0.84      0.99      0.91       963\n",
      "           2       0.81      0.97      0.88       853\n",
      "           3       0.92      0.87      0.89      1076\n",
      "           4       0.82      0.98      0.89       821\n",
      "           5       0.85      0.92      0.88       826\n",
      "           6       0.95      0.91      0.93       999\n",
      "           7       0.82      0.99      0.90       851\n",
      "           8       0.96      0.56      0.70      1681\n",
      "           9       0.82      0.91      0.86       905\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 25: 8752 / 10000\n",
      "Accuracy = 87.52%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93378773 0.98966942 0.97206054 0.86136784 0.97859691 0.92401961\n",
      " 0.92020202 0.98942421 0.56650544 0.90570175]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1027\n",
      "           1       0.84      0.99      0.91       968\n",
      "           2       0.81      0.97      0.88       859\n",
      "           3       0.92      0.86      0.89      1082\n",
      "           4       0.84      0.98      0.90       841\n",
      "           5       0.85      0.92      0.88       816\n",
      "           6       0.95      0.92      0.94       990\n",
      "           7       0.82      0.99      0.90       851\n",
      "           8       0.96      0.57      0.71      1654\n",
      "           9       0.82      0.91      0.86       912\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 26: 8777 / 10000\n",
      "Accuracy = 87.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94037146 0.99186165 0.96697039 0.85414768 0.97919217 0.92307692\n",
      " 0.92028254 0.98835856 0.57414216 0.91564928]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1023\n",
      "           1       0.86      0.99      0.92       983\n",
      "           2       0.82      0.97      0.89       878\n",
      "           3       0.93      0.85      0.89      1097\n",
      "           4       0.81      0.98      0.89       817\n",
      "           5       0.85      0.92      0.88       819\n",
      "           6       0.95      0.92      0.94       991\n",
      "           7       0.83      0.99      0.90       859\n",
      "           8       0.96      0.57      0.72      1632\n",
      "           9       0.82      0.92      0.86       901\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.91      0.89     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 27: 8802 / 10000\n",
      "Accuracy = 88.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93391642 0.9907312  0.9739645  0.86190918 0.98014888 0.9165659\n",
      " 0.92456677 0.98723898 0.53638968 0.90175439]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1029\n",
      "           1       0.85      0.99      0.91       971\n",
      "           2       0.80      0.97      0.88       845\n",
      "           3       0.92      0.86      0.89      1079\n",
      "           4       0.80      0.98      0.88       806\n",
      "           5       0.85      0.92      0.88       827\n",
      "           6       0.95      0.92      0.94       981\n",
      "           7       0.83      0.99      0.90       862\n",
      "           8       0.96      0.54      0.69      1745\n",
      "           9       0.76      0.90      0.83       855\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.88     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 28: 8689 / 10000\n",
      "Accuracy = 86.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92760618 0.99076923 0.9741784  0.85245902 0.98029557 0.9252451\n",
      " 0.92166836 0.98831776 0.55111633 0.9045977 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1036\n",
      "           1       0.85      0.99      0.92       975\n",
      "           2       0.80      0.97      0.88       852\n",
      "           3       0.93      0.85      0.89      1098\n",
      "           4       0.81      0.98      0.89       812\n",
      "           5       0.85      0.93      0.88       816\n",
      "           6       0.95      0.92      0.93       983\n",
      "           7       0.82      0.99      0.90       856\n",
      "           8       0.96      0.55      0.70      1702\n",
      "           9       0.78      0.90      0.84       870\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.88     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "Epoch 29: 8721 / 10000\n",
      "Accuracy = 87.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93307468 0.99071207 0.97432905 0.86778399 0.98138958 0.93440594\n",
      " 0.92145015 0.98601399 0.54028986 0.88623436]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1031\n",
      "           1       0.85      0.99      0.91       969\n",
      "           2       0.81      0.97      0.88       857\n",
      "           3       0.92      0.87      0.89      1074\n",
      "           4       0.81      0.98      0.88       806\n",
      "           5       0.85      0.93      0.89       808\n",
      "           6       0.96      0.92      0.94       993\n",
      "           7       0.82      0.99      0.90       858\n",
      "           8       0.96      0.54      0.69      1725\n",
      "           9       0.77      0.89      0.83       879\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.88     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 30: 8707 / 10000\n",
      "Accuracy = 87.07%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92864031 0.99157007 0.97076023 0.85232452 0.97619048 0.92448234\n",
      " 0.93047035 0.9872093  0.54418605 0.90747331]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1037\n",
      "           1       0.83      0.99      0.90       949\n",
      "           2       0.80      0.97      0.88       855\n",
      "           3       0.93      0.85      0.89      1097\n",
      "           4       0.84      0.98      0.90       840\n",
      "           5       0.85      0.92      0.89       821\n",
      "           6       0.95      0.93      0.94       978\n",
      "           7       0.83      0.99      0.90       860\n",
      "           8       0.96      0.54      0.69      1720\n",
      "           9       0.76      0.91      0.83       843\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.88     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 31: 8708 / 10000\n",
      "Accuracy = 87.08%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92967245 0.99057592 0.97031963 0.86080586 0.97708082 0.92804878\n",
      " 0.9244898  0.98725377 0.54154561 0.90193705]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1038\n",
      "           1       0.83      0.99      0.91       955\n",
      "           2       0.82      0.97      0.89       876\n",
      "           3       0.93      0.86      0.89      1092\n",
      "           4       0.82      0.98      0.89       829\n",
      "           5       0.85      0.93      0.89       820\n",
      "           6       0.95      0.92      0.93       980\n",
      "           7       0.83      0.99      0.90       863\n",
      "           8       0.96      0.54      0.69      1721\n",
      "           9       0.74      0.90      0.81       826\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.88     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 32: 8707 / 10000\n",
      "Accuracy = 87.07%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93223621 0.9904963  0.97408716 0.86549165 0.98127341 0.91469194\n",
      " 0.9270298  0.98606272 0.50761697 0.90206186]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1033\n",
      "           1       0.83      0.99      0.90       947\n",
      "           2       0.80      0.97      0.88       849\n",
      "           3       0.92      0.87      0.89      1078\n",
      "           4       0.80      0.98      0.88       801\n",
      "           5       0.87      0.91      0.89       844\n",
      "           6       0.94      0.93      0.93       973\n",
      "           7       0.83      0.99      0.90       861\n",
      "           8       0.96      0.51      0.66      1838\n",
      "           9       0.69      0.90      0.78       776\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.90      0.87     10000\n",
      "weighted avg       0.88      0.86      0.85     10000\n",
      "\n",
      "Epoch 33: 8603 / 10000\n",
      "Accuracy = 86.03%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92514395 0.99076923 0.97219003 0.85416667 0.97222222 0.91606715\n",
      " 0.92581301 0.98505747 0.56360316 0.91230207]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1042\n",
      "           1       0.85      0.99      0.92       975\n",
      "           2       0.81      0.97      0.89       863\n",
      "           3       0.93      0.85      0.89      1104\n",
      "           4       0.86      0.97      0.91       864\n",
      "           5       0.86      0.92      0.89       834\n",
      "           6       0.95      0.93      0.94       984\n",
      "           7       0.83      0.99      0.90       870\n",
      "           8       0.95      0.56      0.71      1643\n",
      "           9       0.74      0.91      0.82       821\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.87     10000\n",
      "\n",
      "Epoch 34: 8759 / 10000\n",
      "Accuracy = 87.59%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93230174 0.98877551 0.97563805 0.86598891 0.97828709 0.9304878\n",
      " 0.92857143 0.98734177 0.52991453 0.89860583]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1034\n",
      "           1       0.85      0.99      0.92       980\n",
      "           2       0.81      0.98      0.89       862\n",
      "           3       0.93      0.87      0.90      1082\n",
      "           4       0.83      0.98      0.90       829\n",
      "           5       0.86      0.93      0.89       820\n",
      "           6       0.95      0.93      0.94       980\n",
      "           7       0.83      0.99      0.90       869\n",
      "           8       0.95      0.53      0.68      1755\n",
      "           9       0.70      0.90      0.79       789\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.88     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 35: 8692 / 10000\n",
      "Accuracy = 86.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.92685274 0.99068323 0.9738339  0.86815227 0.97746145 0.91795482\n",
      " 0.91967871 0.98716453 0.54384932 0.89165629]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1039\n",
      "           1       0.84      0.99      0.91       966\n",
      "           2       0.83      0.97      0.90       879\n",
      "           3       0.93      0.87      0.90      1077\n",
      "           4       0.84      0.98      0.90       843\n",
      "           5       0.87      0.92      0.89       841\n",
      "           6       0.96      0.92      0.94       996\n",
      "           7       0.82      0.99      0.90       857\n",
      "           8       0.95      0.54      0.69      1699\n",
      "           9       0.71      0.89      0.79       803\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.88     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 36: 8709 / 10000\n",
      "Accuracy = 87.09%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90951932 0.99055614 0.97325581 0.8650647  0.97652582 0.91577699\n",
      " 0.92588832 0.98819362 0.53526012 0.89580686]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95      1061\n",
      "           1       0.83      0.99      0.90       953\n",
      "           2       0.81      0.97      0.88       860\n",
      "           3       0.93      0.87      0.89      1082\n",
      "           4       0.85      0.98      0.91       852\n",
      "           5       0.87      0.92      0.89       843\n",
      "           6       0.95      0.93      0.94       985\n",
      "           7       0.81      0.99      0.89       847\n",
      "           8       0.95      0.54      0.68      1730\n",
      "           9       0.70      0.90      0.79       787\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 37: 8666 / 10000\n",
      "Accuracy = 86.66%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92692308 0.9907312  0.97266515 0.85987261 0.9744186  0.91795482\n",
      " 0.92494929 0.98820755 0.54985075 0.87905237]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1040\n",
      "           1       0.85      0.99      0.91       971\n",
      "           2       0.83      0.97      0.89       878\n",
      "           3       0.94      0.86      0.90      1099\n",
      "           4       0.85      0.97      0.91       860\n",
      "           5       0.87      0.92      0.89       841\n",
      "           6       0.95      0.92      0.94       986\n",
      "           7       0.82      0.99      0.89       848\n",
      "           8       0.95      0.55      0.70      1675\n",
      "           9       0.70      0.88      0.78       802\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.88     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "Epoch 38: 8711 / 10000\n",
      "Accuracy = 87.11%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92344498 0.99172699 0.97241379 0.85950413 0.97538101 0.90760234\n",
      " 0.92842536 0.99045346 0.53828171 0.88035264]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1045\n",
      "           1       0.84      0.99      0.91       967\n",
      "           2       0.82      0.97      0.89       870\n",
      "           3       0.93      0.86      0.89      1089\n",
      "           4       0.85      0.98      0.91       853\n",
      "           5       0.87      0.91      0.89       855\n",
      "           6       0.95      0.93      0.94       978\n",
      "           7       0.81      0.99      0.89       838\n",
      "           8       0.95      0.54      0.69      1711\n",
      "           9       0.69      0.88      0.78       794\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 39: 8672 / 10000\n",
      "Accuracy = 86.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92870906 0.98965874 0.97782964 0.8503156  0.970964   0.91795482\n",
      " 0.92857143 0.98941176 0.52853026 0.89501312]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1038\n",
      "           1       0.84      0.99      0.91       967\n",
      "           2       0.81      0.98      0.89       857\n",
      "           3       0.93      0.85      0.89      1109\n",
      "           4       0.85      0.97      0.91       861\n",
      "           5       0.87      0.92      0.89       841\n",
      "           6       0.95      0.93      0.94       980\n",
      "           7       0.82      0.99      0.90       850\n",
      "           8       0.94      0.53      0.68      1735\n",
      "           9       0.68      0.90      0.77       762\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 40: 8660 / 10000\n",
      "Accuracy = 86.60%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91730038 0.9908999  0.97359357 0.85766423 0.97420868 0.90962441\n",
      " 0.93099897 0.98928571 0.54443128 0.87563452]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1052\n",
      "           1       0.86      0.99      0.92       989\n",
      "           2       0.82      0.97      0.89       871\n",
      "           3       0.93      0.86      0.89      1096\n",
      "           4       0.85      0.97      0.91       853\n",
      "           5       0.87      0.91      0.89       852\n",
      "           6       0.94      0.93      0.94       971\n",
      "           7       0.81      0.99      0.89       840\n",
      "           8       0.94      0.54      0.69      1688\n",
      "           9       0.68      0.88      0.77       788\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 41: 8683 / 10000\n",
      "Accuracy = 86.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92514395 0.9919598  0.98030127 0.85144928 0.97176471 0.91283863\n",
      " 0.92292089 0.99171598 0.54431886 0.87643312]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1042\n",
      "           1       0.87      0.99      0.93       995\n",
      "           2       0.82      0.98      0.89       863\n",
      "           3       0.93      0.85      0.89      1104\n",
      "           4       0.84      0.97      0.90       850\n",
      "           5       0.87      0.91      0.89       849\n",
      "           6       0.95      0.92      0.94       986\n",
      "           7       0.82      0.99      0.89       845\n",
      "           8       0.94      0.54      0.69      1681\n",
      "           9       0.68      0.88      0.77       785\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.90      0.87     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 42: 8689 / 10000\n",
      "Accuracy = 86.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91920152 0.99144385 0.97777778 0.85094851 0.9712313  0.91547619\n",
      " 0.9255102  0.99159664 0.52951389 0.86516854]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1052\n",
      "           1       0.82      0.99      0.90       935\n",
      "           2       0.81      0.98      0.89       855\n",
      "           3       0.93      0.85      0.89      1107\n",
      "           4       0.86      0.97      0.91       869\n",
      "           5       0.86      0.92      0.89       840\n",
      "           6       0.95      0.93      0.94       980\n",
      "           7       0.80      0.99      0.89       833\n",
      "           8       0.94      0.53      0.68      1728\n",
      "           9       0.69      0.87      0.77       801\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.87     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 43: 8626 / 10000\n",
      "Accuracy = 86.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92080153 0.99288618 0.97869822 0.84892086 0.96907216 0.90559441\n",
      " 0.92622951 0.98604651 0.53243717 0.87994543]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1048\n",
      "           1       0.86      0.99      0.92       984\n",
      "           2       0.80      0.98      0.88       845\n",
      "           3       0.93      0.85      0.89      1112\n",
      "           4       0.86      0.97      0.91       873\n",
      "           5       0.87      0.91      0.89       858\n",
      "           6       0.94      0.93      0.93       976\n",
      "           7       0.82      0.99      0.90       860\n",
      "           8       0.94      0.53      0.68      1711\n",
      "           9       0.64      0.88      0.74       733\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.87      0.89      0.87     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 44: 8644 / 10000\n",
      "Accuracy = 86.44%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.91825095 0.99095477 0.98023256 0.85198556 0.97303634 0.91005917\n",
      " 0.92252803 0.99156627 0.54033215 0.86329114]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1052\n",
      "           1       0.87      0.99      0.93       995\n",
      "           2       0.82      0.98      0.89       860\n",
      "           3       0.93      0.85      0.89      1108\n",
      "           4       0.85      0.97      0.90       853\n",
      "           5       0.86      0.91      0.89       845\n",
      "           6       0.94      0.92      0.93       981\n",
      "           7       0.80      0.99      0.89       830\n",
      "           8       0.94      0.54      0.68      1686\n",
      "           9       0.68      0.86      0.76       790\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.87     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 45: 8659 / 10000\n",
      "Accuracy = 86.59%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91304348 0.99282787 0.98360656 0.85989011 0.97133028 0.8989547\n",
      " 0.92221085 0.98937426 0.52900232 0.87280108]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1058\n",
      "           1       0.85      0.99      0.92       976\n",
      "           2       0.81      0.98      0.89       854\n",
      "           3       0.93      0.86      0.89      1092\n",
      "           4       0.86      0.97      0.91       872\n",
      "           5       0.87      0.90      0.88       861\n",
      "           6       0.94      0.92      0.93       977\n",
      "           7       0.82      0.99      0.89       847\n",
      "           8       0.94      0.53      0.68      1724\n",
      "           9       0.64      0.87      0.74       739\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.87     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 46: 8631 / 10000\n",
      "Accuracy = 86.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92425695 0.99287169 0.97695853 0.86635945 0.97540984 0.89244851\n",
      " 0.92481977 0.99152542 0.52747253 0.85546875]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1043\n",
      "           1       0.86      0.99      0.92       982\n",
      "           2       0.82      0.98      0.89       868\n",
      "           3       0.93      0.87      0.90      1085\n",
      "           4       0.85      0.98      0.91       854\n",
      "           5       0.87      0.89      0.88       874\n",
      "           6       0.94      0.92      0.93       971\n",
      "           7       0.80      0.99      0.88       826\n",
      "           8       0.94      0.53      0.67      1729\n",
      "           9       0.65      0.86      0.74       768\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.87     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 47: 8626 / 10000\n",
      "Accuracy = 86.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91287879 0.99293643 0.97627119 0.86367795 0.97136312 0.89207807\n",
      " 0.92554292 0.99039616 0.55759804 0.85857322]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95      1056\n",
      "           1       0.87      0.99      0.93       991\n",
      "           2       0.84      0.98      0.90       885\n",
      "           3       0.93      0.86      0.90      1093\n",
      "           4       0.86      0.97      0.91       873\n",
      "           5       0.87      0.89      0.88       871\n",
      "           6       0.93      0.93      0.93       967\n",
      "           7       0.80      0.99      0.89       833\n",
      "           8       0.93      0.56      0.70      1632\n",
      "           9       0.68      0.86      0.76       799\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.87     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 48: 8697 / 10000\n",
      "Accuracy = 86.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91650854 0.99300699 0.97828571 0.86027397 0.97347174 0.89710983\n",
      " 0.92672859 0.99057715 0.52482679 0.86002886]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1054\n",
      "           1       0.88      0.99      0.93      1001\n",
      "           2       0.83      0.98      0.90       875\n",
      "           3       0.93      0.86      0.90      1095\n",
      "           4       0.86      0.97      0.91       867\n",
      "           5       0.87      0.90      0.88       865\n",
      "           6       0.94      0.93      0.93       969\n",
      "           7       0.82      0.99      0.90       849\n",
      "           8       0.93      0.52      0.67      1732\n",
      "           9       0.59      0.86      0.70       693\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.87     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 49: 8622 / 10000\n",
      "Accuracy = 86.22%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91825095 0.9929078  0.97803468 0.83731211 0.97048808 0.89443155\n",
      " 0.92768595 0.99166667 0.54114114 0.87182911]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1052\n",
      "           1       0.86      0.99      0.92       987\n",
      "           2       0.82      0.98      0.89       865\n",
      "           3       0.94      0.84      0.88      1131\n",
      "           4       0.87      0.97      0.92       881\n",
      "           5       0.86      0.89      0.88       862\n",
      "           6       0.94      0.93      0.93       968\n",
      "           7       0.81      0.99      0.89       840\n",
      "           8       0.93      0.54      0.68      1665\n",
      "           9       0.65      0.87      0.74       749\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.87      0.89      0.87     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 50: 8650 / 10000\n",
      "Accuracy = 86.50%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91737892 0.99297189 0.98050459 0.84252669 0.97479954 0.89220183\n",
      " 0.92229039 0.99166667 0.54887675 0.86979866]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1053\n",
      "           1       0.87      0.99      0.93       996\n",
      "           2       0.83      0.98      0.90       872\n",
      "           3       0.94      0.84      0.89      1124\n",
      "           4       0.87      0.97      0.92       873\n",
      "           5       0.87      0.89      0.88       872\n",
      "           6       0.94      0.92      0.93       978\n",
      "           7       0.81      0.99      0.89       840\n",
      "           8       0.93      0.55      0.69      1647\n",
      "           9       0.64      0.87      0.74       745\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.87     10000\n",
      "weighted avg       0.88      0.87      0.86     10000\n",
      "\n",
      "Epoch 51: 8673 / 10000\n",
      "Accuracy = 86.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90712946 0.99385875 0.97921478 0.84663677 0.97055493 0.88162345\n",
      " 0.92561983 0.99390987 0.51877527 0.86151603]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1066\n",
      "           1       0.86      0.99      0.92       977\n",
      "           2       0.82      0.98      0.89       866\n",
      "           3       0.93      0.85      0.89      1115\n",
      "           4       0.87      0.97      0.92       883\n",
      "           5       0.88      0.88      0.88       887\n",
      "           6       0.94      0.93      0.93       968\n",
      "           7       0.79      0.99      0.88       821\n",
      "           8       0.92      0.52      0.66      1731\n",
      "           9       0.59      0.86      0.70       686\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.87      0.86      0.85     10000\n",
      "\n",
      "Epoch 52: 8570 / 10000\n",
      "Accuracy = 85.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91382576 0.99276112 0.97818599 0.86876155 0.97068771 0.88348416\n",
      " 0.93125    0.99144254 0.50984806 0.82378223]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95      1056\n",
      "           1       0.85      0.99      0.91       967\n",
      "           2       0.83      0.98      0.90       871\n",
      "           3       0.93      0.87      0.90      1082\n",
      "           4       0.88      0.97      0.92       887\n",
      "           5       0.88      0.88      0.88       884\n",
      "           6       0.93      0.93      0.93       960\n",
      "           7       0.79      0.99      0.88       818\n",
      "           8       0.93      0.51      0.66      1777\n",
      "           9       0.57      0.82      0.67       698\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 53: 8545 / 10000\n",
      "Accuracy = 85.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.90977444 0.99320388 0.9785553  0.86623616 0.97171946 0.87486034\n",
      " 0.92611863 0.99509202 0.53020528 0.83431953]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1064\n",
      "           1       0.90      0.99      0.95      1030\n",
      "           2       0.84      0.98      0.90       886\n",
      "           3       0.93      0.87      0.90      1084\n",
      "           4       0.87      0.97      0.92       884\n",
      "           5       0.88      0.87      0.88       895\n",
      "           6       0.93      0.93      0.93       961\n",
      "           7       0.79      1.00      0.88       815\n",
      "           8       0.93      0.53      0.67      1705\n",
      "           9       0.56      0.83      0.67       676\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 54: 8608 / 10000\n",
      "Accuracy = 86.08%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91825095 0.99217986 0.97845805 0.85275519 0.96875    0.89028571\n",
      " 0.92371134 0.99030303 0.52561118 0.85276074]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1052\n",
      "           1       0.89      0.99      0.94      1023\n",
      "           2       0.84      0.98      0.90       882\n",
      "           3       0.93      0.85      0.89      1107\n",
      "           4       0.88      0.97      0.92       896\n",
      "           5       0.87      0.89      0.88       875\n",
      "           6       0.94      0.92      0.93       970\n",
      "           7       0.79      0.99      0.88       825\n",
      "           8       0.93      0.53      0.67      1718\n",
      "           9       0.55      0.85      0.67       652\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 55: 8607 / 10000\n",
      "Accuracy = 86.07%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90543071 0.99319728 0.98063781 0.84388938 0.97065463 0.88348416\n",
      " 0.92339545 0.98926014 0.53277712 0.8696319 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.94      1068\n",
      "           1       0.90      0.99      0.94      1029\n",
      "           2       0.83      0.98      0.90       878\n",
      "           3       0.94      0.84      0.89      1121\n",
      "           4       0.88      0.97      0.92       886\n",
      "           5       0.88      0.88      0.88       884\n",
      "           6       0.93      0.92      0.93       966\n",
      "           7       0.81      0.99      0.89       838\n",
      "           8       0.92      0.53      0.67      1678\n",
      "           9       0.56      0.87      0.68       652\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.87     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 56: 8619 / 10000\n",
      "Accuracy = 86.19%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90874882 0.99417476 0.98154556 0.84252669 0.97075366 0.87344633\n",
      " 0.91761071 0.99264706 0.51657941 0.83490566]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1063\n",
      "           1       0.90      0.99      0.95      1030\n",
      "           2       0.82      0.98      0.90       867\n",
      "           3       0.94      0.84      0.89      1124\n",
      "           4       0.88      0.97      0.92       889\n",
      "           5       0.87      0.87      0.87       885\n",
      "           6       0.93      0.92      0.92       971\n",
      "           7       0.79      0.99      0.88       816\n",
      "           8       0.91      0.52      0.66      1719\n",
      "           9       0.53      0.83      0.65       636\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.86      0.88      0.86     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 57: 8544 / 10000\n",
      "Accuracy = 85.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89879294 0.99236641 0.9753915  0.8410302  0.96770601 0.88201604\n",
      " 0.9253886  0.99145299 0.54511971 0.84649776]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1077\n",
      "           1       0.92      0.99      0.95      1048\n",
      "           2       0.84      0.98      0.91       894\n",
      "           3       0.94      0.84      0.89      1126\n",
      "           4       0.88      0.97      0.92       898\n",
      "           5       0.86      0.88      0.87       873\n",
      "           6       0.93      0.93      0.93       965\n",
      "           7       0.79      0.99      0.88       819\n",
      "           8       0.91      0.55      0.68      1629\n",
      "           9       0.56      0.85      0.68       671\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 58: 8627 / 10000\n",
      "Accuracy = 86.27%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90458372 0.99419167 0.97940503 0.84149599 0.9740991  0.88672769\n",
      " 0.92156863 0.99268293 0.52790974 0.82882883]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1069\n",
      "           1       0.90      0.99      0.95      1033\n",
      "           2       0.83      0.98      0.90       874\n",
      "           3       0.94      0.84      0.89      1123\n",
      "           4       0.88      0.97      0.93       888\n",
      "           5       0.87      0.89      0.88       874\n",
      "           6       0.93      0.92      0.93       969\n",
      "           7       0.79      0.99      0.88       820\n",
      "           8       0.91      0.53      0.67      1684\n",
      "           9       0.55      0.83      0.66       666\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.88      0.86      0.85     10000\n",
      "\n",
      "Epoch 59: 8583 / 10000\n",
      "Accuracy = 85.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91390728 0.99322362 0.97963801 0.83465259 0.97191011 0.87613636\n",
      " 0.92805005 0.99149453 0.51534453 0.83278689]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1057\n",
      "           1       0.90      0.99      0.95      1033\n",
      "           2       0.84      0.98      0.90       884\n",
      "           3       0.94      0.83      0.88      1137\n",
      "           4       0.88      0.97      0.92       890\n",
      "           5       0.86      0.88      0.87       880\n",
      "           6       0.93      0.93      0.93       959\n",
      "           7       0.79      0.99      0.88       823\n",
      "           8       0.91      0.52      0.66      1727\n",
      "           9       0.50      0.83      0.63       610\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.86      0.88      0.86     10000\n",
      "weighted avg       0.88      0.85      0.85     10000\n",
      "\n",
      "Epoch 60: 8547 / 10000\n",
      "Accuracy = 85.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90449438 0.99519693 0.97867565 0.82665505 0.97272727 0.87844037\n",
      " 0.91813472 0.99129353 0.5191289  0.81170886]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1068\n",
      "           1       0.91      1.00      0.95      1041\n",
      "           2       0.84      0.98      0.91       891\n",
      "           3       0.94      0.83      0.88      1148\n",
      "           4       0.87      0.97      0.92       880\n",
      "           5       0.86      0.88      0.87       872\n",
      "           6       0.92      0.92      0.92       965\n",
      "           7       0.78      0.99      0.87       804\n",
      "           8       0.91      0.52      0.66      1699\n",
      "           9       0.51      0.81      0.63       632\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 61: 8523 / 10000\n",
      "Accuracy = 85.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90883459 0.99429658 0.9767184  0.83612335 0.97098214 0.86222222\n",
      " 0.92299688 0.9927096  0.54314091 0.82469512]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1064\n",
      "           1       0.92      0.99      0.96      1052\n",
      "           2       0.85      0.98      0.91       902\n",
      "           3       0.94      0.84      0.88      1135\n",
      "           4       0.89      0.97      0.93       896\n",
      "           5       0.87      0.86      0.87       900\n",
      "           6       0.93      0.92      0.92       961\n",
      "           7       0.79      0.99      0.88       823\n",
      "           8       0.90      0.54      0.68      1611\n",
      "           9       0.54      0.82      0.65       656\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.88      0.86     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 62: 8609 / 10000\n",
      "Accuracy = 86.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.90055762 0.99510763 0.97747748 0.84498208 0.96899225 0.86607143\n",
      " 0.93157895 0.99388005 0.50455063 0.81707317]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1076\n",
      "           1       0.90      1.00      0.94      1022\n",
      "           2       0.84      0.98      0.90       888\n",
      "           3       0.93      0.84      0.89      1116\n",
      "           4       0.89      0.97      0.93       903\n",
      "           5       0.87      0.87      0.87       896\n",
      "           6       0.92      0.93      0.93       950\n",
      "           7       0.79      0.99      0.88       817\n",
      "           8       0.91      0.50      0.65      1758\n",
      "           9       0.46      0.82      0.59       574\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 63: 8501 / 10000\n",
      "Accuracy = 85.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89962825 0.99514563 0.97931034 0.82495667 0.97006652 0.86516854\n",
      " 0.92557652 0.99262899 0.51078717 0.81848739]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1076\n",
      "           1       0.90      1.00      0.95      1030\n",
      "           2       0.83      0.98      0.90       870\n",
      "           3       0.94      0.82      0.88      1154\n",
      "           4       0.89      0.97      0.93       902\n",
      "           5       0.86      0.87      0.86       890\n",
      "           6       0.92      0.93      0.92       954\n",
      "           7       0.79      0.99      0.88       814\n",
      "           8       0.90      0.51      0.65      1715\n",
      "           9       0.48      0.82      0.61       595\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 64: 8496 / 10000\n",
      "Accuracy = 84.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89381348 0.99517375 0.97757848 0.8115942  0.97078652 0.86312217\n",
      " 0.92387904 0.9936143  0.5236938  0.8058104 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      1083\n",
      "           1       0.91      1.00      0.95      1036\n",
      "           2       0.84      0.98      0.91       892\n",
      "           3       0.94      0.81      0.87      1173\n",
      "           4       0.88      0.97      0.92       890\n",
      "           5       0.86      0.86      0.86       884\n",
      "           6       0.92      0.92      0.92       959\n",
      "           7       0.76      0.99      0.86       783\n",
      "           8       0.89      0.52      0.66      1646\n",
      "           9       0.52      0.81      0.63       654\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 65: 8503 / 10000\n",
      "Accuracy = 85.03%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89144434 0.99424736 0.97566372 0.81732419 0.97094972 0.86230248\n",
      " 0.92267503 0.99242424 0.51402985 0.81176471]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      1087\n",
      "           1       0.91      0.99      0.95      1043\n",
      "           2       0.85      0.98      0.91       904\n",
      "           3       0.94      0.82      0.88      1166\n",
      "           4       0.88      0.97      0.93       895\n",
      "           5       0.86      0.86      0.86       886\n",
      "           6       0.92      0.92      0.92       957\n",
      "           7       0.76      0.99      0.86       792\n",
      "           8       0.88      0.51      0.65      1675\n",
      "           9       0.48      0.81      0.60       595\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 66: 8487 / 10000\n",
      "Accuracy = 84.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88736264 0.99430199 0.98087739 0.83911111 0.96788483 0.85462555\n",
      " 0.92348008 0.99371859 0.50992991 0.81161972]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      1092\n",
      "           1       0.92      0.99      0.96      1053\n",
      "           2       0.84      0.98      0.91       889\n",
      "           3       0.93      0.84      0.88      1125\n",
      "           4       0.89      0.97      0.93       903\n",
      "           5       0.87      0.85      0.86       908\n",
      "           6       0.92      0.92      0.92       954\n",
      "           7       0.77      0.99      0.87       796\n",
      "           8       0.90      0.51      0.65      1712\n",
      "           9       0.46      0.81      0.58       568\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 67: 8488 / 10000\n",
      "Accuracy = 84.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89814815 0.9941691  0.97653631 0.81452991 0.96892342 0.86833144\n",
      " 0.92283629 0.99253731 0.50824499 0.82332762]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1080\n",
      "           1       0.90      0.99      0.95      1029\n",
      "           2       0.85      0.98      0.91       895\n",
      "           3       0.94      0.81      0.87      1170\n",
      "           4       0.89      0.97      0.93       901\n",
      "           5       0.86      0.87      0.86       881\n",
      "           6       0.92      0.92      0.92       959\n",
      "           7       0.78      0.99      0.87       804\n",
      "           8       0.89      0.51      0.65      1698\n",
      "           9       0.48      0.82      0.60       583\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.88      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 68: 8484 / 10000\n",
      "Accuracy = 84.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88807339 0.99420849 0.97877095 0.80658784 0.96993318 0.86214689\n",
      " 0.92058516 0.99611902 0.50560472 0.7955707 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      1090\n",
      "           1       0.91      0.99      0.95      1036\n",
      "           2       0.85      0.98      0.91       895\n",
      "           3       0.95      0.81      0.87      1184\n",
      "           4       0.89      0.97      0.93       898\n",
      "           5       0.86      0.86      0.86       885\n",
      "           6       0.92      0.92      0.92       957\n",
      "           7       0.75      1.00      0.86       773\n",
      "           8       0.88      0.51      0.64      1695\n",
      "           9       0.46      0.80      0.59       587\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.87      0.85     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 69: 8438 / 10000\n",
      "Accuracy = 84.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88422972 0.99519231 0.97658863 0.82665505 0.96703297 0.85205784\n",
      " 0.92758253 0.99504337 0.51271437 0.80944056]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1097\n",
      "           1       0.91      1.00      0.95      1040\n",
      "           2       0.85      0.98      0.91       897\n",
      "           3       0.94      0.83      0.88      1148\n",
      "           4       0.90      0.97      0.93       910\n",
      "           5       0.86      0.85      0.86       899\n",
      "           6       0.91      0.93      0.92       939\n",
      "           7       0.78      1.00      0.88       807\n",
      "           8       0.89      0.51      0.65      1691\n",
      "           9       0.46      0.81      0.59       572\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 70: 8480 / 10000\n",
      "Accuracy = 84.80%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88391225 0.99422522 0.97762864 0.8238342  0.969129   0.84640884\n",
      " 0.92486772 0.99494949 0.5173445  0.80976431]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1094\n",
      "           1       0.91      0.99      0.95      1039\n",
      "           2       0.85      0.98      0.91       894\n",
      "           3       0.94      0.82      0.88      1158\n",
      "           4       0.90      0.97      0.93       907\n",
      "           5       0.86      0.85      0.85       905\n",
      "           6       0.91      0.92      0.92       945\n",
      "           7       0.77      0.99      0.87       792\n",
      "           8       0.89      0.52      0.65      1672\n",
      "           9       0.48      0.81      0.60       594\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.87      0.85      0.85     10000\n",
      "\n",
      "Epoch 71: 8481 / 10000\n",
      "Accuracy = 84.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.88090909 0.99522901 0.97750281 0.81143345 0.96692393 0.85300668\n",
      " 0.92667375 0.9974026  0.51125592 0.78705281]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1100\n",
      "           1       0.92      1.00      0.96      1048\n",
      "           2       0.84      0.98      0.90       889\n",
      "           3       0.94      0.81      0.87      1172\n",
      "           4       0.89      0.97      0.93       907\n",
      "           5       0.86      0.85      0.86       898\n",
      "           6       0.91      0.93      0.92       941\n",
      "           7       0.75      1.00      0.85       770\n",
      "           8       0.89      0.51      0.65      1688\n",
      "           9       0.46      0.79      0.58       587\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 72: 8440 / 10000\n",
      "Accuracy = 84.40%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88817599 0.99513619 0.97765363 0.82155172 0.9651036  0.85111111\n",
      " 0.92340426 0.99383477 0.50914454 0.80106572]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      1091\n",
      "           1       0.90      1.00      0.95      1028\n",
      "           2       0.85      0.98      0.91       895\n",
      "           3       0.94      0.82      0.88      1160\n",
      "           4       0.90      0.97      0.93       917\n",
      "           5       0.86      0.85      0.85       900\n",
      "           6       0.91      0.92      0.91       940\n",
      "           7       0.78      0.99      0.88       811\n",
      "           8       0.89      0.51      0.65      1695\n",
      "           9       0.45      0.80      0.57       563\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.87      0.85     10000\n",
      "weighted avg       0.87      0.85      0.84     10000\n",
      "\n",
      "Epoch 73: 8459 / 10000\n",
      "Accuracy = 84.59%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87862319 0.99428027 0.97755331 0.81228669 0.96612022 0.84437086\n",
      " 0.92055085 0.99486521 0.51449275 0.79109589]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1104\n",
      "           1       0.92      0.99      0.96      1049\n",
      "           2       0.84      0.98      0.91       891\n",
      "           3       0.94      0.81      0.87      1172\n",
      "           4       0.90      0.97      0.93       915\n",
      "           5       0.86      0.84      0.85       906\n",
      "           6       0.91      0.92      0.91       944\n",
      "           7       0.75      0.99      0.86       779\n",
      "           8       0.87      0.51      0.65      1656\n",
      "           9       0.46      0.79      0.58       584\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 74: 8443 / 10000\n",
      "Accuracy = 84.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88251366 0.99230769 0.97968397 0.79683597 0.96502732 0.84666667\n",
      " 0.91798107 0.99371859 0.50722022 0.8076225 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1098\n",
      "           1       0.91      0.99      0.95      1040\n",
      "           2       0.84      0.98      0.91       886\n",
      "           3       0.95      0.80      0.87      1201\n",
      "           4       0.90      0.97      0.93       915\n",
      "           5       0.85      0.85      0.85       900\n",
      "           6       0.91      0.92      0.91       951\n",
      "           7       0.77      0.99      0.87       796\n",
      "           8       0.87      0.51      0.64      1662\n",
      "           9       0.44      0.81      0.57       551\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 75: 8423 / 10000\n",
      "Accuracy = 84.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88010899 0.99524263 0.97544643 0.80694327 0.96615721 0.85520362\n",
      " 0.92275132 0.99489144 0.50588235 0.78821363]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1101\n",
      "           1       0.92      1.00      0.96      1051\n",
      "           2       0.85      0.98      0.91       896\n",
      "           3       0.94      0.81      0.87      1181\n",
      "           4       0.90      0.97      0.93       916\n",
      "           5       0.85      0.86      0.85       884\n",
      "           6       0.91      0.92      0.92       945\n",
      "           7       0.76      0.99      0.86       783\n",
      "           8       0.88      0.51      0.64      1700\n",
      "           9       0.42      0.79      0.55       543\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 76: 8422 / 10000\n",
      "Accuracy = 84.22%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86762075 0.9951784  0.97865169 0.80201342 0.97016575 0.85584563\n",
      " 0.91737288 0.99369483 0.49360465 0.78846154]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.92      1118\n",
      "           1       0.91      1.00      0.95      1037\n",
      "           2       0.84      0.98      0.91       890\n",
      "           3       0.95      0.80      0.87      1192\n",
      "           4       0.89      0.97      0.93       905\n",
      "           5       0.85      0.86      0.85       881\n",
      "           6       0.90      0.92      0.91       944\n",
      "           7       0.77      0.99      0.87       793\n",
      "           8       0.87      0.49      0.63      1720\n",
      "           9       0.41      0.79      0.54       520\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 77: 8374 / 10000\n",
      "Accuracy = 83.74%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8690583  0.99519693 0.97555556 0.80050293 0.96416938 0.85454545\n",
      " 0.91491597 0.99487179 0.5078219  0.77877698]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      1115\n",
      "           1       0.91      1.00      0.95      1041\n",
      "           2       0.85      0.98      0.91       900\n",
      "           3       0.95      0.80      0.87      1193\n",
      "           4       0.90      0.96      0.93       921\n",
      "           5       0.84      0.85      0.85       880\n",
      "           6       0.91      0.91      0.91       952\n",
      "           7       0.75      0.99      0.86       780\n",
      "           8       0.87      0.51      0.64      1662\n",
      "           9       0.43      0.78      0.55       556\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.87      0.84     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 78: 8402 / 10000\n",
      "Accuracy = 84.02%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85626102 0.99422522 0.97762864 0.80100756 0.9631636  0.83684795\n",
      " 0.91906283 0.99614891 0.49463647 0.78544061]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1134\n",
      "           1       0.91      0.99      0.95      1039\n",
      "           2       0.85      0.98      0.91       894\n",
      "           3       0.94      0.80      0.87      1191\n",
      "           4       0.91      0.96      0.93       923\n",
      "           5       0.85      0.84      0.84       901\n",
      "           6       0.90      0.92      0.91       939\n",
      "           7       0.75      1.00      0.86       779\n",
      "           8       0.85      0.49      0.63      1678\n",
      "           9       0.41      0.79      0.54       522\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.86      0.83     10000\n",
      "weighted avg       0.86      0.84      0.83     10000\n",
      "\n",
      "Epoch 79: 8354 / 10000\n",
      "Accuracy = 83.54%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86696429 0.99521531 0.97689769 0.78895301 0.96498906 0.85419059\n",
      " 0.92136026 0.99615877 0.49496744 0.78916828]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.92      1120\n",
      "           1       0.92      1.00      0.95      1045\n",
      "           2       0.86      0.98      0.91       909\n",
      "           3       0.95      0.79      0.86      1213\n",
      "           4       0.90      0.96      0.93       914\n",
      "           5       0.83      0.85      0.84       871\n",
      "           6       0.91      0.92      0.91       941\n",
      "           7       0.76      1.00      0.86       781\n",
      "           8       0.86      0.49      0.63      1689\n",
      "           9       0.40      0.79      0.53       517\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.86      0.84     10000\n",
      "weighted avg       0.86      0.84      0.84     10000\n",
      "\n",
      "Epoch 80: 8371 / 10000\n",
      "Accuracy = 83.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.86234458 0.9962157  0.97780244 0.79301746 0.96025779 0.83835006\n",
      " 0.91995731 0.99360614 0.49790795 0.79716024]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1126\n",
      "           1       0.93      1.00      0.96      1057\n",
      "           2       0.85      0.98      0.91       901\n",
      "           3       0.94      0.79      0.86      1203\n",
      "           4       0.91      0.96      0.93       931\n",
      "           5       0.84      0.84      0.84       897\n",
      "           6       0.90      0.92      0.91       937\n",
      "           7       0.76      0.99      0.86       782\n",
      "           8       0.86      0.50      0.63      1673\n",
      "           9       0.39      0.80      0.52       493\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.86      0.84     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 81: 8370 / 10000\n",
      "Accuracy = 83.70%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86157941 0.99519231 0.97560976 0.79566305 0.96116505 0.84382022\n",
      " 0.91889007 0.99368687 0.50180505 0.79580153]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1127\n",
      "           1       0.91      1.00      0.95      1040\n",
      "           2       0.85      0.98      0.91       902\n",
      "           3       0.94      0.80      0.86      1199\n",
      "           4       0.91      0.96      0.93       927\n",
      "           5       0.84      0.84      0.84       890\n",
      "           6       0.90      0.92      0.91       937\n",
      "           7       0.77      0.99      0.86       792\n",
      "           8       0.86      0.50      0.63      1662\n",
      "           9       0.41      0.80      0.54       524\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.86      0.84     10000\n",
      "weighted avg       0.86      0.84      0.84     10000\n",
      "\n",
      "Epoch 82: 8381 / 10000\n",
      "Accuracy = 83.81%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84742807 0.99435028 0.97339246 0.78665568 0.96813187 0.83689539\n",
      " 0.91304348 0.99375    0.50745342 0.81070746]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      1147\n",
      "           1       0.93      0.99      0.96      1062\n",
      "           2       0.85      0.97      0.91       902\n",
      "           3       0.95      0.79      0.86      1214\n",
      "           4       0.90      0.97      0.93       910\n",
      "           5       0.83      0.84      0.84       889\n",
      "           6       0.90      0.91      0.91       943\n",
      "           7       0.77      0.99      0.87       800\n",
      "           8       0.84      0.51      0.63      1610\n",
      "           9       0.42      0.81      0.55       523\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.86      0.84     10000\n",
      "weighted avg       0.86      0.84      0.84     10000\n",
      "\n",
      "Epoch 83: 8383 / 10000\n",
      "Accuracy = 83.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85853227 0.99615754 0.97653631 0.7732042  0.9613319  0.82685905\n",
      " 0.92540541 0.99487179 0.48808105 0.78496868]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1131\n",
      "           1       0.91      1.00      0.95      1041\n",
      "           2       0.85      0.98      0.91       895\n",
      "           3       0.95      0.77      0.85      1239\n",
      "           4       0.91      0.96      0.94       931\n",
      "           5       0.84      0.83      0.83       901\n",
      "           6       0.89      0.93      0.91       925\n",
      "           7       0.75      0.99      0.86       780\n",
      "           8       0.84      0.49      0.62      1678\n",
      "           9       0.37      0.78      0.51       479\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.86      0.83     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 84: 8307 / 10000\n",
      "Accuracy = 83.07%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84803493 0.99616491 0.97359736 0.79899497 0.96216216 0.83783784\n",
      " 0.91595745 0.99491094 0.49788264 0.77756286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      1145\n",
      "           1       0.92      1.00      0.95      1043\n",
      "           2       0.86      0.97      0.91       909\n",
      "           3       0.94      0.80      0.87      1194\n",
      "           4       0.91      0.96      0.93       925\n",
      "           5       0.83      0.84      0.84       888\n",
      "           6       0.90      0.92      0.91       940\n",
      "           7       0.76      0.99      0.86       786\n",
      "           8       0.84      0.50      0.63      1653\n",
      "           9       0.40      0.78      0.53       517\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.86      0.83     10000\n",
      "weighted avg       0.86      0.84      0.83     10000\n",
      "\n",
      "Epoch 85: 8351 / 10000\n",
      "Accuracy = 83.51%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84729494 0.99614644 0.97450111 0.79166667 0.96721311 0.82720178\n",
      " 0.91970021 0.99492386 0.47993019 0.77440347]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      1146\n",
      "           1       0.91      1.00      0.95      1038\n",
      "           2       0.85      0.97      0.91       902\n",
      "           3       0.94      0.79      0.86      1200\n",
      "           4       0.90      0.97      0.93       915\n",
      "           5       0.83      0.83      0.83       897\n",
      "           6       0.90      0.92      0.91       934\n",
      "           7       0.76      0.99      0.86       788\n",
      "           8       0.85      0.48      0.61      1719\n",
      "           9       0.35      0.77      0.49       461\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.86      0.83     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 86: 8286 / 10000\n",
      "Accuracy = 82.86%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83923941 0.99426386 0.97577093 0.784831   0.96428571 0.82438479\n",
      " 0.9195279  0.99363057 0.48888889 0.77310924]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1157\n",
      "           1       0.92      0.99      0.95      1046\n",
      "           2       0.86      0.98      0.91       908\n",
      "           3       0.94      0.78      0.86      1213\n",
      "           4       0.91      0.96      0.93       924\n",
      "           5       0.83      0.82      0.83       894\n",
      "           6       0.89      0.92      0.91       932\n",
      "           7       0.76      0.99      0.86       785\n",
      "           8       0.84      0.49      0.62      1665\n",
      "           9       0.36      0.77      0.50       476\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.86      0.83     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 87: 8296 / 10000\n",
      "Accuracy = 82.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84069264 0.99618684 0.97679558 0.79532164 0.9624866  0.81127983\n",
      " 0.92568306 0.99491094 0.48602023 0.77242888]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1155\n",
      "           1       0.92      1.00      0.96      1049\n",
      "           2       0.86      0.98      0.91       905\n",
      "           3       0.94      0.80      0.86      1197\n",
      "           4       0.91      0.96      0.94       933\n",
      "           5       0.84      0.81      0.82       922\n",
      "           6       0.88      0.93      0.90       915\n",
      "           7       0.76      0.99      0.86       786\n",
      "           8       0.84      0.49      0.62      1681\n",
      "           9       0.35      0.77      0.48       457\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.86      0.83     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 88: 8297 / 10000\n",
      "Accuracy = 82.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83923941 0.99431818 0.97579758 0.78086672 0.9613319  0.81939799\n",
      " 0.91982665 0.99482536 0.49034982 0.76109937]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1157\n",
      "           1       0.93      0.99      0.96      1056\n",
      "           2       0.86      0.98      0.91       909\n",
      "           3       0.95      0.78      0.86      1223\n",
      "           4       0.91      0.96      0.94       931\n",
      "           5       0.82      0.82      0.82       897\n",
      "           6       0.89      0.92      0.90       923\n",
      "           7       0.75      0.99      0.85       773\n",
      "           8       0.83      0.49      0.62      1658\n",
      "           9       0.36      0.76      0.49       473\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.85      0.83     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 89: 8284 / 10000\n",
      "Accuracy = 82.84%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.84448306 0.99618684 0.97458564 0.79056291 0.96124865 0.8160793\n",
      " 0.92       0.99493671 0.47658566 0.75669643]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1151\n",
      "           1       0.92      1.00      0.96      1049\n",
      "           2       0.85      0.97      0.91       905\n",
      "           3       0.95      0.79      0.86      1208\n",
      "           4       0.91      0.96      0.93       929\n",
      "           5       0.83      0.82      0.82       908\n",
      "           6       0.89      0.92      0.90       925\n",
      "           7       0.76      0.99      0.86       790\n",
      "           8       0.83      0.48      0.60      1687\n",
      "           9       0.34      0.76      0.47       448\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.85      0.82     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 90: 8268 / 10000\n",
      "Accuracy = 82.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8377912  0.99522445 0.97582418 0.76830249 0.96030043 0.83238312\n",
      " 0.91248666 0.99491094 0.48172558 0.77954545]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1159\n",
      "           1       0.92      1.00      0.96      1047\n",
      "           2       0.86      0.98      0.91       910\n",
      "           3       0.95      0.77      0.85      1243\n",
      "           4       0.91      0.96      0.94       932\n",
      "           5       0.82      0.83      0.83       877\n",
      "           6       0.89      0.91      0.90       937\n",
      "           7       0.76      0.99      0.86       786\n",
      "           8       0.83      0.48      0.61      1669\n",
      "           9       0.34      0.78      0.47       440\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.85      0.82     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 91: 8265 / 10000\n",
      "Accuracy = 82.65%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83290488 0.99617225 0.97682119 0.76731079 0.95846645 0.82227222\n",
      " 0.9197397  0.99485199 0.48764316 0.7753304 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91      1167\n",
      "           1       0.92      1.00      0.96      1045\n",
      "           2       0.86      0.98      0.91       906\n",
      "           3       0.94      0.77      0.85      1242\n",
      "           4       0.92      0.96      0.94       939\n",
      "           5       0.82      0.82      0.82       889\n",
      "           6       0.89      0.92      0.90       922\n",
      "           7       0.75      0.99      0.86       777\n",
      "           8       0.83      0.49      0.61      1659\n",
      "           9       0.35      0.78      0.48       454\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.85      0.82     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 92: 8264 / 10000\n",
      "Accuracy = 82.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83706897 0.99617956 0.97579758 0.76461169 0.96540541 0.80503834\n",
      " 0.91803279 0.99479844 0.47833935 0.75166297]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1160\n",
      "           1       0.92      1.00      0.96      1047\n",
      "           2       0.86      0.98      0.91       909\n",
      "           3       0.95      0.76      0.85      1249\n",
      "           4       0.91      0.97      0.94       925\n",
      "           5       0.82      0.81      0.81       913\n",
      "           6       0.88      0.92      0.90       915\n",
      "           7       0.74      0.99      0.85       769\n",
      "           8       0.82      0.48      0.60      1662\n",
      "           9       0.34      0.75      0.46       451\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.82     10000\n",
      "weighted avg       0.85      0.82      0.82     10000\n",
      "\n",
      "Epoch 93: 8223 / 10000\n",
      "Accuracy = 82.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83562823 0.99620853 0.97684675 0.75968379 0.96137339 0.82588774\n",
      " 0.91603875 0.99479167 0.47636146 0.74885845]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1162\n",
      "           1       0.93      1.00      0.96      1055\n",
      "           2       0.86      0.98      0.91       907\n",
      "           3       0.95      0.76      0.84      1265\n",
      "           4       0.91      0.96      0.94       932\n",
      "           5       0.81      0.83      0.82       873\n",
      "           6       0.89      0.92      0.90       929\n",
      "           7       0.74      0.99      0.85       768\n",
      "           8       0.82      0.48      0.60      1671\n",
      "           9       0.33      0.75      0.45       438\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.82     10000\n",
      "weighted avg       0.86      0.82      0.82     10000\n",
      "\n",
      "Epoch 94: 8225 / 10000\n",
      "Accuracy = 82.25%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82638298 0.99617591 0.97687225 0.75650118 0.96232508 0.81340782\n",
      " 0.9204793  0.99354005 0.48002459 0.75599129]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1175\n",
      "           1       0.92      1.00      0.96      1046\n",
      "           2       0.86      0.98      0.91       908\n",
      "           3       0.95      0.76      0.84      1269\n",
      "           4       0.91      0.96      0.94       929\n",
      "           5       0.82      0.81      0.81       895\n",
      "           6       0.88      0.92      0.90       918\n",
      "           7       0.75      0.99      0.85       774\n",
      "           8       0.80      0.48      0.60      1627\n",
      "           9       0.34      0.76      0.47       459\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.82     10000\n",
      "weighted avg       0.85      0.82      0.82     10000\n",
      "\n",
      "Epoch 95: 8224 / 10000\n",
      "Accuracy = 82.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82708688 0.99622642 0.97595628 0.7729116  0.96244635 0.81298992\n",
      " 0.91468683 0.99475066 0.47670251 0.73549884]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1174\n",
      "           1       0.93      1.00      0.96      1060\n",
      "           2       0.87      0.98      0.92       915\n",
      "           3       0.94      0.77      0.85      1233\n",
      "           4       0.91      0.96      0.94       932\n",
      "           5       0.81      0.81      0.81       893\n",
      "           6       0.88      0.91      0.90       926\n",
      "           7       0.74      0.99      0.85       762\n",
      "           8       0.82      0.48      0.60      1674\n",
      "           9       0.31      0.74      0.44       431\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.82     10000\n",
      "weighted avg       0.86      0.82      0.82     10000\n",
      "\n",
      "Epoch 96: 8216 / 10000\n",
      "Accuracy = 82.16%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82708688 0.99618684 0.97692308 0.76725522 0.95842217 0.8098434\n",
      " 0.92596685 0.99483871 0.47607656 0.75057208]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1174\n",
      "           1       0.92      1.00      0.96      1049\n",
      "           2       0.86      0.98      0.92       910\n",
      "           3       0.95      0.77      0.85      1246\n",
      "           4       0.92      0.96      0.94       938\n",
      "           5       0.81      0.81      0.81       894\n",
      "           6       0.87      0.93      0.90       905\n",
      "           7       0.75      0.99      0.86       775\n",
      "           8       0.82      0.48      0.60      1672\n",
      "           9       0.33      0.75      0.45       437\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.82     10000\n",
      "weighted avg       0.86      0.82      0.82     10000\n",
      "\n",
      "Epoch 97: 8217 / 10000\n",
      "Accuracy = 82.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82442748 0.99620493 0.97794928 0.76076555 0.95638298 0.79257642\n",
      " 0.92400881 0.99474376 0.47524155 0.75529412]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1179\n",
      "           1       0.93      1.00      0.96      1054\n",
      "           2       0.86      0.98      0.91       907\n",
      "           3       0.94      0.76      0.84      1254\n",
      "           4       0.92      0.96      0.94       940\n",
      "           5       0.81      0.79      0.80       916\n",
      "           6       0.88      0.92      0.90       908\n",
      "           7       0.74      0.99      0.85       761\n",
      "           8       0.81      0.48      0.60      1656\n",
      "           9       0.32      0.76      0.45       425\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.81     10000\n",
      "weighted avg       0.85      0.82      0.82     10000\n",
      "\n",
      "Epoch 98: 8192 / 10000\n",
      "Accuracy = 81.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.82094595 0.99526963 0.97707424 0.76076555 0.96428571 0.80444444\n",
      " 0.92265193 0.99474376 0.47233789 0.73684211]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1184\n",
      "           1       0.93      1.00      0.96      1057\n",
      "           2       0.87      0.98      0.92       916\n",
      "           3       0.94      0.76      0.84      1254\n",
      "           4       0.91      0.96      0.93       924\n",
      "           5       0.81      0.80      0.81       900\n",
      "           6       0.87      0.92      0.90       905\n",
      "           7       0.74      0.99      0.85       761\n",
      "           8       0.82      0.47      0.60      1681\n",
      "           9       0.31      0.74      0.43       418\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.84      0.81     10000\n",
      "weighted avg       0.85      0.82      0.82     10000\n",
      "\n",
      "Epoch 99: 8182 / 10000\n",
      "Accuracy = 81.82%\n"
     ]
    }
   ],
   "source": [
    "net = network_tanh.NetworkTanh([784, 30, 10])\n",
    "net.SGD(training_data, 100, 10, 0.5, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.95583239 0.98922625 0.93274112 0.66352429 0.82952381 0.9204947\n",
      " 0.97481481 0.9791395  0.55865922 0.72698413]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       883\n",
      "           1       0.89      0.99      0.94      1021\n",
      "           2       0.71      0.93      0.81       788\n",
      "           3       0.91      0.66      0.77      1379\n",
      "           4       0.89      0.83      0.86      1050\n",
      "           5       0.58      0.92      0.71       566\n",
      "           6       0.69      0.97      0.81       675\n",
      "           7       0.73      0.98      0.84       767\n",
      "           8       0.92      0.56      0.70      1611\n",
      "           9       0.91      0.73      0.81      1260\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.85      0.81     10000\n",
      "weighted avg       0.84      0.81      0.81     10000\n",
      "\n",
      "Epoch 0: 8121 / 10000\n",
      "Accuracy = 81.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96774194 0.99484004 0.95662651 0.70106222 0.8280543  0.9318569\n",
      " 0.98450704 0.98309859 0.52661382 0.8074141 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       899\n",
      "           1       0.85      0.99      0.92       969\n",
      "           2       0.77      0.96      0.85       830\n",
      "           3       0.91      0.70      0.79      1318\n",
      "           4       0.93      0.83      0.88      1105\n",
      "           5       0.61      0.93      0.74       587\n",
      "           6       0.73      0.98      0.84       710\n",
      "           7       0.68      0.98      0.80       710\n",
      "           8       0.95      0.53      0.68      1766\n",
      "           9       0.89      0.81      0.84      1106\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.87      0.83     10000\n",
      "weighted avg       0.85      0.82      0.82     10000\n",
      "\n",
      "Epoch 1: 8234 / 10000\n",
      "Accuracy = 82.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96371398 0.99653179 0.96449026 0.76567657 0.86463298 0.93290735\n",
      " 0.9871612  0.98198198 0.52044199 0.79913043]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       937\n",
      "           1       0.76      1.00      0.86       865\n",
      "           2       0.82      0.96      0.88       873\n",
      "           3       0.92      0.77      0.84      1212\n",
      "           4       0.92      0.86      0.89      1049\n",
      "           5       0.65      0.93      0.77       626\n",
      "           6       0.72      0.99      0.83       701\n",
      "           7       0.74      0.98      0.85       777\n",
      "           8       0.97      0.52      0.68      1810\n",
      "           9       0.91      0.80      0.85      1150\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.88      0.84     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 2: 8342 / 10000\n",
      "Accuracy = 83.42%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96818664 0.9988345  0.96283784 0.77112387 0.8653484  0.95727848\n",
      " 0.98790323 0.98414795 0.5388601  0.79051724]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       943\n",
      "           1       0.76      1.00      0.86       858\n",
      "           2       0.83      0.96      0.89       888\n",
      "           3       0.93      0.77      0.84      1219\n",
      "           4       0.94      0.87      0.90      1062\n",
      "           5       0.68      0.96      0.79       632\n",
      "           6       0.77      0.99      0.86       744\n",
      "           7       0.72      0.98      0.83       757\n",
      "           8       0.96      0.54      0.69      1737\n",
      "           9       0.91      0.79      0.85      1160\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.88      0.85     10000\n",
      "weighted avg       0.87      0.84      0.84     10000\n",
      "\n",
      "Epoch 3: 8422 / 10000\n",
      "Accuracy = 84.22%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96373057 0.99880096 0.96921323 0.78137988 0.89779559 0.97372742\n",
      " 0.98887344 0.98113208 0.51166576 0.75371901]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       965\n",
      "           1       0.73      1.00      0.85       834\n",
      "           2       0.82      0.97      0.89       877\n",
      "           3       0.93      0.78      0.85      1203\n",
      "           4       0.91      0.90      0.91       998\n",
      "           5       0.66      0.97      0.79       609\n",
      "           6       0.74      0.99      0.85       719\n",
      "           7       0.71      0.98      0.82       742\n",
      "           8       0.97      0.51      0.67      1843\n",
      "           9       0.90      0.75      0.82      1210\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.88      0.84     10000\n",
      "weighted avg       0.86      0.83      0.83     10000\n",
      "\n",
      "Epoch 4: 8336 / 10000\n",
      "Accuracy = 83.36%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96548117 0.99644128 0.94994675 0.80683761 0.90752033 0.94776119\n",
      " 0.98893499 0.98828125 0.48981723 0.83139535]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       956\n",
      "           1       0.74      1.00      0.85       843\n",
      "           2       0.86      0.95      0.91       939\n",
      "           3       0.93      0.81      0.87      1170\n",
      "           4       0.91      0.91      0.91       984\n",
      "           5       0.71      0.95      0.81       670\n",
      "           6       0.75      0.99      0.85       723\n",
      "           7       0.74      0.99      0.85       768\n",
      "           8       0.96      0.49      0.65      1915\n",
      "           9       0.85      0.83      0.84      1032\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.89      0.85     10000\n",
      "weighted avg       0.86      0.84      0.83     10000\n",
      "\n",
      "Epoch 5: 8397 / 10000\n",
      "Accuracy = 83.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96825397 0.99771429 0.96640538 0.84111311 0.92378991 0.95348837\n",
      " 0.98811096 0.98350254 0.49216301 0.77819905]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       945\n",
      "           1       0.77      1.00      0.87       875\n",
      "           2       0.84      0.97      0.90       893\n",
      "           3       0.93      0.84      0.88      1114\n",
      "           4       0.91      0.92      0.92       971\n",
      "           5       0.74      0.95      0.83       688\n",
      "           6       0.78      0.99      0.87       757\n",
      "           7       0.75      0.98      0.85       788\n",
      "           8       0.97      0.49      0.65      1914\n",
      "           9       0.81      0.78      0.80      1055\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.89      0.85     10000\n",
      "weighted avg       0.86      0.84      0.83     10000\n",
      "\n",
      "Epoch 6: 8427 / 10000\n",
      "Accuracy = 84.27%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96875    0.99721448 0.96061269 0.84163701 0.8962818  0.97005988\n",
      " 0.98982558 0.98256538 0.3879239  0.7620438 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       960\n",
      "           1       0.63      1.00      0.77       718\n",
      "           2       0.85      0.96      0.90       914\n",
      "           3       0.94      0.84      0.89      1124\n",
      "           4       0.93      0.90      0.91      1022\n",
      "           5       0.73      0.97      0.83       668\n",
      "           6       0.71      0.99      0.83       688\n",
      "           7       0.77      0.98      0.86       803\n",
      "           8       0.96      0.39      0.55      2418\n",
      "           9       0.52      0.76      0.62       685\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.88      0.81     10000\n",
      "weighted avg       0.84      0.80      0.78     10000\n",
      "\n",
      "Epoch 7: 7964 / 10000\n",
      "Accuracy = 79.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96580311 1.         0.96236559 0.82710686 0.93186583 0.98310811\n",
      " 0.99050204 0.98150432 0.36067459 0.69129721]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       965\n",
      "           1       0.57      1.00      0.72       642\n",
      "           2       0.87      0.96      0.91       930\n",
      "           3       0.94      0.83      0.88      1151\n",
      "           4       0.91      0.93      0.92       954\n",
      "           5       0.65      0.98      0.78       592\n",
      "           6       0.76      0.99      0.86       737\n",
      "           7       0.77      0.98      0.87       811\n",
      "           8       0.97      0.36      0.53      2609\n",
      "           9       0.42      0.69      0.52       609\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.87      0.79     10000\n",
      "weighted avg       0.84      0.78      0.76     10000\n",
      "\n",
      "Epoch 8: 7780 / 10000\n",
      "Accuracy = 77.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96601442 1.         0.96385542 0.84914182 0.93639208 0.96159317\n",
      " 0.99291785 0.97903822 0.37589499 0.73509015]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       971\n",
      "           1       0.52      1.00      0.69       595\n",
      "           2       0.85      0.96      0.90       913\n",
      "           3       0.93      0.85      0.89      1107\n",
      "           4       0.91      0.94      0.93       959\n",
      "           5       0.76      0.96      0.85       703\n",
      "           6       0.73      0.99      0.84       706\n",
      "           7       0.77      0.98      0.86       811\n",
      "           8       0.97      0.38      0.54      2514\n",
      "           9       0.53      0.74      0.61       721\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.88      0.81     10000\n",
      "weighted avg       0.84      0.79      0.77     10000\n",
      "\n",
      "Epoch 9: 7897 / 10000\n",
      "Accuracy = 78.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9697286  1.         0.96149615 0.84878488 0.93075356 0.96960926\n",
      " 0.99263623 0.98533333 0.33701461 0.70657673]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       958\n",
      "           1       0.46      1.00      0.63       520\n",
      "           2       0.85      0.96      0.90       909\n",
      "           3       0.93      0.85      0.89      1111\n",
      "           4       0.93      0.93      0.93       982\n",
      "           5       0.75      0.97      0.85       691\n",
      "           6       0.70      0.99      0.82       679\n",
      "           7       0.72      0.99      0.83       750\n",
      "           8       0.97      0.34      0.50      2807\n",
      "           9       0.42      0.71      0.52       593\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.77      0.87      0.78     10000\n",
      "weighted avg       0.84      0.76      0.74     10000\n",
      "\n",
      "Epoch 10: 7628 / 10000\n",
      "Accuracy = 76.28%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96976017 1.         0.95922747 0.83260298 0.91932271 0.96943231\n",
      " 0.99372057 0.98425197 0.30671031 0.591133  ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       959\n",
      "           1       0.37      1.00      0.54       417\n",
      "           2       0.87      0.96      0.91       932\n",
      "           3       0.94      0.83      0.88      1141\n",
      "           4       0.94      0.92      0.93      1004\n",
      "           5       0.75      0.97      0.84       687\n",
      "           6       0.66      0.99      0.79       637\n",
      "           7       0.73      0.98      0.84       762\n",
      "           8       0.96      0.31      0.47      3055\n",
      "           9       0.24      0.59      0.34       406\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.74      0.85      0.75     10000\n",
      "weighted avg       0.84      0.73      0.72     10000\n",
      "\n",
      "Epoch 11: 7340 / 10000\n",
      "Accuracy = 73.40%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96334012 0.99840256 0.96166134 0.81856899 0.93444329 0.96536797\n",
      " 0.99263623 0.98153034 0.34003656 0.51434879]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       982\n",
      "           1       0.55      1.00      0.71       626\n",
      "           2       0.88      0.96      0.92       939\n",
      "           3       0.95      0.82      0.88      1174\n",
      "           4       0.91      0.93      0.92       961\n",
      "           5       0.75      0.97      0.84       693\n",
      "           6       0.70      0.99      0.82       679\n",
      "           7       0.72      0.98      0.83       758\n",
      "           8       0.95      0.34      0.50      2735\n",
      "           9       0.23      0.51      0.32       453\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.85      0.77     10000\n",
      "weighted avg       0.84      0.76      0.75     10000\n",
      "\n",
      "Epoch 12: 7583 / 10000\n",
      "Accuracy = 75.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.97494781 0.99773243 0.95683453 0.83876652 0.91121951 0.96301565\n",
      " 0.99271137 0.98225602 0.31164039 0.54045307]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       958\n",
      "           1       0.39      1.00      0.56       441\n",
      "           2       0.90      0.96      0.93       973\n",
      "           3       0.94      0.84      0.89      1135\n",
      "           4       0.95      0.91      0.93      1025\n",
      "           5       0.76      0.96      0.85       703\n",
      "           6       0.71      0.99      0.83       686\n",
      "           7       0.75      0.98      0.85       789\n",
      "           8       0.95      0.31      0.47      2981\n",
      "           9       0.17      0.54      0.25       309\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.85      0.75     10000\n",
      "weighted avg       0.85      0.74      0.74     10000\n",
      "\n",
      "Epoch 13: 7420 / 10000\n",
      "Accuracy = 74.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95674044 1.         0.94861254 0.84322409 0.91924227 0.96875\n",
      " 0.99846626 0.9826087  0.31317568 0.45098039]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       994\n",
      "           1       0.33      1.00      0.49       372\n",
      "           2       0.89      0.95      0.92       973\n",
      "           3       0.94      0.84      0.89      1129\n",
      "           4       0.94      0.92      0.93      1003\n",
      "           5       0.76      0.97      0.85       704\n",
      "           6       0.68      1.00      0.81       652\n",
      "           7       0.77      0.98      0.86       805\n",
      "           8       0.95      0.31      0.47      2960\n",
      "           9       0.18      0.45      0.26       408\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.74      0.84      0.75     10000\n",
      "weighted avg       0.85      0.74      0.73     10000\n",
      "\n",
      "Epoch 14: 7355 / 10000\n",
      "Accuracy = 73.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96044625 1.         0.94934144 0.84656557 0.92756539 0.97323944\n",
      " 0.99398496 0.98730964 0.3118928  0.42435424]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       986\n",
      "           1       0.43      1.00      0.61       493\n",
      "           2       0.91      0.95      0.93       987\n",
      "           3       0.94      0.85      0.89      1121\n",
      "           4       0.94      0.93      0.93       994\n",
      "           5       0.77      0.97      0.86       710\n",
      "           6       0.69      0.99      0.81       665\n",
      "           7       0.76      0.99      0.86       788\n",
      "           8       0.96      0.31      0.47      2985\n",
      "           9       0.11      0.42      0.18       271\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.84      0.75     10000\n",
      "weighted avg       0.85      0.74      0.74     10000\n",
      "\n",
      "Epoch 15: 7424 / 10000\n",
      "Accuracy = 74.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95866935 1.         0.95589744 0.82152007 0.92763819 0.97875354\n",
      " 0.99095023 0.9877601  0.30915141 0.54609929]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       992\n",
      "           1       0.35      1.00      0.52       394\n",
      "           2       0.90      0.96      0.93       975\n",
      "           3       0.95      0.82      0.88      1171\n",
      "           4       0.94      0.93      0.93       995\n",
      "           5       0.77      0.98      0.86       706\n",
      "           6       0.69      0.99      0.81       663\n",
      "           7       0.79      0.99      0.87       817\n",
      "           8       0.95      0.31      0.47      3005\n",
      "           9       0.15      0.55      0.24       282\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.85      0.75     10000\n",
      "weighted avg       0.86      0.74      0.74     10000\n",
      "\n",
      "Epoch 16: 7400 / 10000\n",
      "Accuracy = 74.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96255061 1.         0.96413502 0.83246073 0.93449335 0.97454031\n",
      " 0.99419448 0.98604061 0.30399215 0.46473029]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       988\n",
      "           1       0.41      1.00      0.58       460\n",
      "           2       0.89      0.96      0.92       948\n",
      "           3       0.94      0.83      0.88      1146\n",
      "           4       0.93      0.93      0.93       977\n",
      "           5       0.77      0.97      0.86       707\n",
      "           6       0.72      0.99      0.83       689\n",
      "           7       0.76      0.99      0.86       788\n",
      "           8       0.95      0.30      0.46      3056\n",
      "           9       0.11      0.46      0.18       241\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.74      0.84      0.75     10000\n",
      "weighted avg       0.86      0.74      0.73     10000\n",
      "\n",
      "Epoch 17: 7384 / 10000\n",
      "Accuracy = 73.84%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.96367306 1.         0.95696721 0.83873795 0.91862745 0.97605634\n",
      " 0.99377916 0.98536585 0.31153588 0.49173554]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       991\n",
      "           1       0.42      1.00      0.59       475\n",
      "           2       0.91      0.96      0.93       976\n",
      "           3       0.95      0.84      0.89      1141\n",
      "           4       0.95      0.92      0.94      1020\n",
      "           5       0.78      0.98      0.87       710\n",
      "           6       0.67      0.99      0.80       643\n",
      "           7       0.79      0.99      0.87       820\n",
      "           8       0.95      0.31      0.47      2982\n",
      "           9       0.12      0.49      0.19       242\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.84      0.75     10000\n",
      "weighted avg       0.86      0.74      0.74     10000\n",
      "\n",
      "Epoch 18: 7446 / 10000\n",
      "Accuracy = 74.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.96258847 1.         0.94929006 0.77396166 0.92454728 0.97398844\n",
      " 0.99407407 0.98756219 0.31493056 0.4516129 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       989\n",
      "           1       0.40      1.00      0.57       449\n",
      "           2       0.91      0.95      0.93       986\n",
      "           3       0.96      0.77      0.86      1252\n",
      "           4       0.94      0.92      0.93       994\n",
      "           5       0.76      0.97      0.85       692\n",
      "           6       0.70      0.99      0.82       675\n",
      "           7       0.77      0.99      0.87       804\n",
      "           8       0.93      0.31      0.47      2880\n",
      "           9       0.12      0.45      0.20       279\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.83      0.75     10000\n",
      "weighted avg       0.85      0.74      0.74     10000\n",
      "\n",
      "Epoch 19: 7397 / 10000\n",
      "Accuracy = 73.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95983936 0.99753695 0.94879518 0.83275563 0.91905232 0.97103448\n",
      " 0.98809524 0.98554217 0.30310026 0.53409091]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.36      1.00      0.53       406\n",
      "           2       0.92      0.95      0.93       996\n",
      "           3       0.95      0.83      0.89      1154\n",
      "           4       0.95      0.92      0.93      1013\n",
      "           5       0.79      0.97      0.87       725\n",
      "           6       0.69      0.99      0.81       672\n",
      "           7       0.80      0.99      0.88       830\n",
      "           8       0.94      0.30      0.46      3032\n",
      "           9       0.09      0.53      0.16       176\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.84      0.74     10000\n",
      "weighted avg       0.87      0.74      0.74     10000\n",
      "\n",
      "Epoch 20: 7397 / 10000\n",
      "Accuracy = 73.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95983936 1.         0.94274432 0.82564103 0.92131474 0.97752809\n",
      " 0.98725212 0.98574822 0.31949773 0.44370861]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       996\n",
      "           1       0.47      1.00      0.64       539\n",
      "           2       0.93      0.94      0.93      1013\n",
      "           3       0.96      0.83      0.89      1170\n",
      "           4       0.94      0.92      0.93      1004\n",
      "           5       0.78      0.98      0.87       712\n",
      "           6       0.73      0.99      0.84       706\n",
      "           7       0.81      0.99      0.89       842\n",
      "           8       0.94      0.32      0.48      2867\n",
      "           9       0.07      0.44      0.12       151\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.76      0.84      0.75     10000\n",
      "weighted avg       0.87      0.75      0.76     10000\n",
      "\n",
      "Epoch 21: 7547 / 10000\n",
      "Accuracy = 75.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95328032 0.99807322 0.93780849 0.81334459 0.91889219 0.97274032\n",
      " 0.99005682 0.98913043 0.32243157 0.42222222]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1006\n",
      "           1       0.46      1.00      0.63       519\n",
      "           2       0.92      0.94      0.93      1013\n",
      "           3       0.95      0.81      0.88      1184\n",
      "           4       0.95      0.92      0.93      1011\n",
      "           5       0.76      0.97      0.85       697\n",
      "           6       0.73      0.99      0.84       704\n",
      "           7       0.80      0.99      0.88       828\n",
      "           8       0.93      0.32      0.48      2813\n",
      "           9       0.09      0.42      0.15       225\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.76      0.83      0.75     10000\n",
      "weighted avg       0.86      0.75      0.75     10000\n",
      "\n",
      "Epoch 22: 7515 / 10000\n",
      "Accuracy = 75.15%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95049505 1.         0.94135189 0.81825939 0.90403071 0.97752809\n",
      " 0.99281609 0.98660171 0.31269244 0.4507772 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1010\n",
      "           1       0.37      1.00      0.54       425\n",
      "           2       0.92      0.94      0.93      1006\n",
      "           3       0.95      0.82      0.88      1172\n",
      "           4       0.96      0.90      0.93      1042\n",
      "           5       0.78      0.98      0.87       712\n",
      "           6       0.72      0.99      0.84       696\n",
      "           7       0.79      0.99      0.88       821\n",
      "           8       0.94      0.31      0.47      2923\n",
      "           9       0.09      0.45      0.14       193\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.83      0.74     10000\n",
      "weighted avg       0.86      0.74      0.75     10000\n",
      "\n",
      "Epoch 23: 7431 / 10000\n",
      "Accuracy = 74.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9561753  0.99658703 0.94532803 0.82646048 0.92277228 0.97546898\n",
      " 0.99011299 0.98991173 0.31944444 0.41025641]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1004\n",
      "           1       0.51      1.00      0.68       586\n",
      "           2       0.92      0.95      0.93      1006\n",
      "           3       0.95      0.83      0.89      1164\n",
      "           4       0.95      0.92      0.94      1010\n",
      "           5       0.76      0.98      0.85       693\n",
      "           6       0.73      0.99      0.84       708\n",
      "           7       0.76      0.99      0.86       793\n",
      "           8       0.94      0.32      0.48      2880\n",
      "           9       0.06      0.41      0.11       156\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.76      0.83      0.75     10000\n",
      "weighted avg       0.87      0.75      0.75     10000\n",
      "\n",
      "Epoch 24: 7535 / 10000\n",
      "Accuracy = 75.35%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.94586614 1.         0.93608653 0.82222222 0.90201729 0.96716826\n",
      " 0.98891967 0.98566308 0.32824982 0.49723757]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1016\n",
      "           1       0.47      1.00      0.64       531\n",
      "           2       0.92      0.94      0.93      1017\n",
      "           3       0.95      0.82      0.88      1170\n",
      "           4       0.96      0.90      0.93      1041\n",
      "           5       0.79      0.97      0.87       731\n",
      "           6       0.75      0.99      0.85       722\n",
      "           7       0.80      0.99      0.88       837\n",
      "           8       0.93      0.33      0.48      2754\n",
      "           9       0.09      0.50      0.15       181\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.84      0.76     10000\n",
      "weighted avg       0.87      0.76      0.76     10000\n",
      "\n",
      "Epoch 25: 7585 / 10000\n",
      "Accuracy = 75.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95431976 0.99834437 0.94789579 0.82347901 0.9122807  0.97107438\n",
      " 0.98918919 0.98351001 0.33565664 0.43949045]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1007\n",
      "           1       0.53      1.00      0.69       604\n",
      "           2       0.92      0.95      0.93       998\n",
      "           3       0.95      0.82      0.88      1167\n",
      "           4       0.95      0.91      0.93      1026\n",
      "           5       0.79      0.97      0.87       726\n",
      "           6       0.76      0.99      0.86       740\n",
      "           7       0.81      0.98      0.89       849\n",
      "           8       0.94      0.34      0.49      2726\n",
      "           9       0.07      0.44      0.12       157\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.77      0.84      0.76     10000\n",
      "weighted avg       0.87      0.77      0.77     10000\n",
      "\n",
      "Epoch 26: 7663 / 10000\n",
      "Accuracy = 76.63%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.94975369 1.         0.94333996 0.80682764 0.89483748 0.97740113\n",
      " 0.99564586 0.98337292 0.32078153 0.36842105]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1015\n",
      "           1       0.50      1.00      0.66       564\n",
      "           2       0.92      0.94      0.93      1006\n",
      "           3       0.96      0.81      0.88      1201\n",
      "           4       0.95      0.89      0.92      1046\n",
      "           5       0.78      0.98      0.86       708\n",
      "           6       0.72      1.00      0.83       689\n",
      "           7       0.81      0.98      0.89       842\n",
      "           8       0.93      0.32      0.48      2815\n",
      "           9       0.04      0.37      0.07       114\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.76      0.82      0.75     10000\n",
      "weighted avg       0.87      0.75      0.76     10000\n",
      "\n",
      "Epoch 27: 7533 / 10000\n",
      "Accuracy = 75.33%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.95233366 0.99830221 0.94152626 0.78738884 0.8803016  0.97194951\n",
      " 0.9876881  0.98598131 0.33609023 0.48175182]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1007\n",
      "           1       0.52      1.00      0.68       589\n",
      "           2       0.92      0.94      0.93      1009\n",
      "           3       0.96      0.79      0.87      1237\n",
      "           4       0.95      0.88      0.91      1061\n",
      "           5       0.78      0.97      0.86       713\n",
      "           6       0.75      0.99      0.85       731\n",
      "           7       0.82      0.99      0.90       856\n",
      "           8       0.92      0.34      0.49      2660\n",
      "           9       0.07      0.48      0.12       137\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.77      0.83      0.76     10000\n",
      "weighted avg       0.87      0.76      0.77     10000\n",
      "\n",
      "Epoch 28: 7624 / 10000\n",
      "Accuracy = 76.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93780369 1.         0.94710579 0.80976431 0.90531401 0.97091413\n",
      " 0.98938992 0.9822695  0.32037437 0.40366972]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1029\n",
      "           1       0.47      1.00      0.64       537\n",
      "           2       0.92      0.95      0.93      1002\n",
      "           3       0.95      0.81      0.88      1188\n",
      "           4       0.95      0.91      0.93      1035\n",
      "           5       0.79      0.97      0.87       722\n",
      "           6       0.78      0.99      0.87       754\n",
      "           7       0.81      0.98      0.89       846\n",
      "           8       0.91      0.32      0.47      2778\n",
      "           9       0.04      0.40      0.08       109\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.83      0.75     10000\n",
      "weighted avg       0.87      0.76      0.76     10000\n",
      "\n",
      "Epoch 29: 7562 / 10000\n",
      "Accuracy = 75.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93683188 0.99830221 0.93437806 0.77634755 0.89731286 0.96848138\n",
      " 0.99039781 0.98313253 0.32788104 0.43410853]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1029\n",
      "           1       0.52      1.00      0.68       589\n",
      "           2       0.92      0.93      0.93      1021\n",
      "           3       0.96      0.78      0.86      1243\n",
      "           4       0.95      0.90      0.92      1042\n",
      "           5       0.76      0.97      0.85       698\n",
      "           6       0.75      0.99      0.86       729\n",
      "           7       0.79      0.98      0.88       830\n",
      "           8       0.91      0.33      0.48      2690\n",
      "           9       0.06      0.43      0.10       129\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.82      0.75     10000\n",
      "weighted avg       0.86      0.76      0.76     10000\n",
      "\n",
      "Epoch 30: 7558 / 10000\n",
      "Accuracy = 75.58%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93683188 1.         0.94268775 0.80183181 0.91130604 0.96021948\n",
      " 0.99456522 0.98237368 0.32113677 0.42156863]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1029\n",
      "           1       0.44      1.00      0.61       499\n",
      "           2       0.92      0.94      0.93      1012\n",
      "           3       0.95      0.80      0.87      1201\n",
      "           4       0.95      0.91      0.93      1026\n",
      "           5       0.78      0.96      0.86       729\n",
      "           6       0.76      0.99      0.86       736\n",
      "           7       0.81      0.98      0.89       851\n",
      "           8       0.93      0.32      0.48      2815\n",
      "           9       0.04      0.42      0.08       102\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.76      0.83      0.75     10000\n",
      "weighted avg       0.87      0.75      0.76     10000\n",
      "\n",
      "Epoch 31: 7530 / 10000\n",
      "Accuracy = 75.30%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93695441 0.99837925 0.93307468 0.78938776 0.88108614 0.96633941\n",
      " 0.99041096 0.98269896 0.34035222 0.48113208]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1031\n",
      "           1       0.54      1.00      0.70       617\n",
      "           2       0.93      0.93      0.93      1031\n",
      "           3       0.96      0.79      0.87      1225\n",
      "           4       0.96      0.88      0.92      1068\n",
      "           5       0.77      0.97      0.86       713\n",
      "           6       0.75      0.99      0.86       730\n",
      "           7       0.83      0.98      0.90       867\n",
      "           8       0.91      0.34      0.50      2612\n",
      "           9       0.05      0.48      0.09       106\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.77      0.83      0.76     10000\n",
      "weighted avg       0.87      0.77      0.77     10000\n",
      "\n",
      "Epoch 32: 7656 / 10000\n",
      "Accuracy = 76.56%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93326886 0.99807322 0.93786982 0.7463377  0.8962536  0.97925926\n",
      " 0.99579832 0.98222749 0.31508339 0.39423077]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1034\n",
      "           1       0.46      1.00      0.63       519\n",
      "           2       0.92      0.94      0.93      1014\n",
      "           3       0.96      0.75      0.84      1297\n",
      "           4       0.95      0.90      0.92      1041\n",
      "           5       0.74      0.98      0.84       675\n",
      "           6       0.74      1.00      0.85       714\n",
      "           7       0.81      0.98      0.89       844\n",
      "           8       0.89      0.32      0.47      2758\n",
      "           9       0.04      0.39      0.07       104\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.82      0.74     10000\n",
      "weighted avg       0.86      0.74      0.75     10000\n",
      "\n",
      "Epoch 33: 7446 / 10000\n",
      "Accuracy = 74.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93146718 0.99829642 0.9372549  0.75921569 0.87430168 0.96478873\n",
      " 0.99339498 0.98490128 0.33550864 0.49333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1036\n",
      "           1       0.52      1.00      0.68       587\n",
      "           2       0.93      0.94      0.93      1020\n",
      "           3       0.96      0.76      0.85      1275\n",
      "           4       0.96      0.87      0.91      1074\n",
      "           5       0.77      0.96      0.86       710\n",
      "           6       0.78      0.99      0.88       757\n",
      "           7       0.82      0.98      0.90       861\n",
      "           8       0.90      0.34      0.49      2605\n",
      "           9       0.04      0.49      0.07        75\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.77      0.83      0.75     10000\n",
      "weighted avg       0.87      0.76      0.77     10000\n",
      "\n",
      "Epoch 34: 7610 / 10000\n",
      "Accuracy = 76.10%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92795389 0.99816176 0.93190661 0.77081681 0.8650866  0.96473907\n",
      " 0.99335989 0.98387097 0.33692308 0.48484848]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      1041\n",
      "           1       0.48      1.00      0.65       544\n",
      "           2       0.93      0.93      0.93      1028\n",
      "           3       0.96      0.77      0.86      1261\n",
      "           4       0.97      0.87      0.91      1097\n",
      "           5       0.77      0.96      0.85       709\n",
      "           6       0.78      0.99      0.87       753\n",
      "           7       0.83      0.98      0.90       868\n",
      "           8       0.90      0.34      0.49      2600\n",
      "           9       0.05      0.48      0.09        99\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.83      0.75     10000\n",
      "weighted avg       0.87      0.76      0.77     10000\n",
      "\n",
      "Epoch 35: 7598 / 10000\n",
      "Accuracy = 75.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.92248804 0.99827883 0.92034549 0.7953604  0.85896269 0.96260388\n",
      " 0.99081365 0.97629797 0.34364128 0.46376812]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1045\n",
      "           1       0.51      1.00      0.68       581\n",
      "           2       0.93      0.92      0.92      1042\n",
      "           3       0.95      0.80      0.87      1207\n",
      "           4       0.96      0.86      0.91      1099\n",
      "           5       0.78      0.96      0.86       722\n",
      "           6       0.79      0.99      0.88       762\n",
      "           7       0.84      0.98      0.90       886\n",
      "           8       0.91      0.34      0.50      2587\n",
      "           9       0.03      0.46      0.06        69\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.77      0.82      0.75     10000\n",
      "weighted avg       0.88      0.76      0.78     10000\n",
      "\n",
      "Epoch 36: 7643 / 10000\n",
      "Accuracy = 76.43%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91485336 0.99860724 0.91634981 0.76062992 0.86944444 0.96275072\n",
      " 0.99335106 0.984      0.35340206 0.46575342]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1057\n",
      "           1       0.63      1.00      0.77       718\n",
      "           2       0.93      0.92      0.93      1052\n",
      "           3       0.96      0.76      0.85      1270\n",
      "           4       0.96      0.87      0.91      1080\n",
      "           5       0.75      0.96      0.85       698\n",
      "           6       0.78      0.99      0.87       752\n",
      "           7       0.84      0.98      0.90       875\n",
      "           8       0.88      0.35      0.50      2425\n",
      "           9       0.03      0.47      0.06        73\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.77      0.82      0.76     10000\n",
      "weighted avg       0.87      0.77      0.79     10000\n",
      "\n",
      "Epoch 37: 7724 / 10000\n",
      "Accuracy = 77.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.93507752 0.9984127  0.9348249  0.75743349 0.86568537 0.96453901\n",
      " 0.98947368 0.97424412 0.3443735  0.38271605]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1032\n",
      "           1       0.55      1.00      0.71       630\n",
      "           2       0.93      0.93      0.93      1028\n",
      "           3       0.96      0.76      0.85      1278\n",
      "           4       0.96      0.87      0.91      1087\n",
      "           5       0.76      0.96      0.85       705\n",
      "           6       0.78      0.99      0.88       760\n",
      "           7       0.85      0.97      0.91       893\n",
      "           8       0.89      0.34      0.50      2506\n",
      "           9       0.03      0.38      0.06        81\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.77      0.81      0.75     10000\n",
      "weighted avg       0.87      0.77      0.78     10000\n",
      "\n",
      "Epoch 38: 7660 / 10000\n",
      "Accuracy = 76.60%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9121813  0.99853801 0.9226361  0.7264574  0.86988848 0.96627566\n",
      " 0.98963731 0.9849711  0.34773577 0.48571429]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1059\n",
      "           1       0.60      1.00      0.75       684\n",
      "           2       0.94      0.92      0.93      1047\n",
      "           3       0.96      0.73      0.83      1338\n",
      "           4       0.95      0.87      0.91      1076\n",
      "           5       0.74      0.97      0.84       682\n",
      "           6       0.80      0.99      0.88       772\n",
      "           7       0.83      0.98      0.90       865\n",
      "           8       0.86      0.35      0.50      2407\n",
      "           9       0.03      0.49      0.06        70\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.77      0.82      0.75     10000\n",
      "weighted avg       0.87      0.77      0.78     10000\n",
      "\n",
      "Epoch 39: 7669 / 10000\n",
      "Accuracy = 76.69%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91148776 0.99848714 0.90534208 0.73536122 0.86308973 0.96969697\n",
      " 0.99340369 0.98394495 0.3420182  0.45205479]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1062\n",
      "           1       0.58      1.00      0.73       661\n",
      "           2       0.94      0.91      0.92      1067\n",
      "           3       0.96      0.74      0.83      1315\n",
      "           4       0.95      0.86      0.90      1081\n",
      "           5       0.75      0.97      0.85       693\n",
      "           6       0.79      0.99      0.88       758\n",
      "           7       0.83      0.98      0.90       872\n",
      "           8       0.85      0.34      0.49      2418\n",
      "           9       0.03      0.45      0.06        73\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.77      0.82      0.75     10000\n",
      "weighted avg       0.86      0.76      0.78     10000\n",
      "\n",
      "Epoch 40: 7637 / 10000\n",
      "Accuracy = 76.37%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.9038282  1.         0.90280374 0.74309816 0.83040422 0.97907324\n",
      " 0.98959688 0.98076923 0.35048097 0.39705882]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1071\n",
      "           1       0.56      1.00      0.72       636\n",
      "           2       0.94      0.90      0.92      1070\n",
      "           3       0.96      0.74      0.84      1304\n",
      "           4       0.96      0.83      0.89      1138\n",
      "           5       0.73      0.98      0.84       669\n",
      "           6       0.79      0.99      0.88       769\n",
      "           7       0.84      0.98      0.91       884\n",
      "           8       0.86      0.35      0.50      2391\n",
      "           9       0.03      0.40      0.05        68\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.77      0.81      0.75     10000\n",
      "weighted avg       0.87      0.76      0.78     10000\n",
      "\n",
      "Epoch 41: 7632 / 10000\n",
      "Accuracy = 76.32%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90721649 0.99826389 0.92581888 0.74096849 0.83362832 0.95804196\n",
      " 0.99219766 0.98486612 0.34206285 0.47619048]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1067\n",
      "           1       0.51      1.00      0.67       576\n",
      "           2       0.93      0.93      0.93      1038\n",
      "           3       0.95      0.74      0.83      1301\n",
      "           4       0.96      0.83      0.89      1130\n",
      "           5       0.77      0.96      0.85       715\n",
      "           6       0.80      0.99      0.88       769\n",
      "           7       0.82      0.98      0.90       859\n",
      "           8       0.87      0.34      0.49      2482\n",
      "           9       0.03      0.48      0.06        63\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.82      0.75     10000\n",
      "weighted avg       0.87      0.76      0.77     10000\n",
      "\n",
      "Epoch 42: 7583 / 10000\n",
      "Accuracy = 75.83%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.92974013 0.99829642 0.92015209 0.71449595 0.81369151 0.9713056\n",
      " 0.98983482 0.98470588 0.34556065 0.43421053]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      1039\n",
      "           1       0.52      1.00      0.68       587\n",
      "           2       0.94      0.92      0.93      1052\n",
      "           3       0.96      0.71      0.82      1359\n",
      "           4       0.96      0.81      0.88      1154\n",
      "           5       0.76      0.97      0.85       697\n",
      "           6       0.81      0.99      0.89       787\n",
      "           7       0.81      0.98      0.89       850\n",
      "           8       0.85      0.35      0.49      2399\n",
      "           9       0.03      0.43      0.06        76\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.81      0.75     10000\n",
      "weighted avg       0.86      0.76      0.77     10000\n",
      "\n",
      "Epoch 43: 7585 / 10000\n",
      "Accuracy = 75.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.91382576 0.99853157 0.90756303 0.69568345 0.82040105 0.96396396\n",
      " 0.99343832 0.98381503 0.35026042 0.46551724]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95      1056\n",
      "           1       0.60      1.00      0.75       681\n",
      "           2       0.94      0.91      0.92      1071\n",
      "           3       0.96      0.70      0.81      1390\n",
      "           4       0.96      0.82      0.88      1147\n",
      "           5       0.72      0.96      0.82       666\n",
      "           6       0.79      0.99      0.88       762\n",
      "           7       0.83      0.98      0.90       865\n",
      "           8       0.83      0.35      0.49      2304\n",
      "           9       0.03      0.47      0.05        58\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.81      0.75     10000\n",
      "weighted avg       0.86      0.76      0.78     10000\n",
      "\n",
      "Epoch 44: 7609 / 10000\n",
      "Accuracy = 76.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.90055762 0.99822064 0.90046512 0.72981132 0.81968641 0.97071742\n",
      " 0.99239544 0.98063781 0.33774834 0.52083333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1076\n",
      "           1       0.49      1.00      0.66       562\n",
      "           2       0.94      0.90      0.92      1075\n",
      "           3       0.96      0.73      0.83      1325\n",
      "           4       0.96      0.82      0.88      1148\n",
      "           5       0.74      0.97      0.84       683\n",
      "           6       0.82      0.99      0.90       789\n",
      "           7       0.84      0.98      0.90       878\n",
      "           8       0.84      0.34      0.48      2416\n",
      "           9       0.02      0.52      0.05        48\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.82      0.74     10000\n",
      "weighted avg       0.86      0.76      0.77     10000\n",
      "\n",
      "Epoch 45: 7554 / 10000\n",
      "Accuracy = 75.54%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8857404  0.99815838 0.91229743 0.72292756 0.80475382 0.94714286\n",
      " 0.99477124 0.98601399 0.3362391  0.53846154]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.93      1094\n",
      "           1       0.48      1.00      0.65       543\n",
      "           2       0.93      0.91      0.92      1049\n",
      "           3       0.96      0.72      0.82      1339\n",
      "           4       0.97      0.80      0.88      1178\n",
      "           5       0.74      0.95      0.83       700\n",
      "           6       0.79      0.99      0.88       765\n",
      "           7       0.82      0.99      0.90       858\n",
      "           8       0.83      0.34      0.48      2409\n",
      "           9       0.03      0.54      0.07        65\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.81      0.74     10000\n",
      "weighted avg       0.86      0.75      0.77     10000\n",
      "\n",
      "Epoch 46: 7499 / 10000\n",
      "Accuracy = 74.99%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90364827 0.99826389 0.90009337 0.66780588 0.78823529 0.96769231\n",
      " 0.9910828  0.97892272 0.35506302 0.56097561]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1069\n",
      "           1       0.51      1.00      0.67       576\n",
      "           2       0.93      0.90      0.92      1071\n",
      "           3       0.97      0.67      0.79      1463\n",
      "           4       0.96      0.79      0.86      1190\n",
      "           5       0.71      0.97      0.82       650\n",
      "           6       0.81      0.99      0.89       785\n",
      "           7       0.81      0.98      0.89       854\n",
      "           8       0.84      0.36      0.50      2301\n",
      "           9       0.02      0.56      0.04        41\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.81      0.73     10000\n",
      "weighted avg       0.86      0.75      0.77     10000\n",
      "\n",
      "Epoch 47: 7503 / 10000\n",
      "Accuracy = 75.03%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.90636704 0.99829352 0.90498589 0.66485014 0.78373847 0.96090226\n",
      " 0.99116162 0.97674419 0.35533895 0.54166667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1068\n",
      "           1       0.52      1.00      0.68       586\n",
      "           2       0.93      0.90      0.92      1063\n",
      "           3       0.97      0.66      0.79      1468\n",
      "           4       0.95      0.78      0.86      1193\n",
      "           5       0.72      0.96      0.82       665\n",
      "           6       0.82      0.99      0.90       792\n",
      "           7       0.82      0.98      0.89       860\n",
      "           8       0.82      0.36      0.50      2257\n",
      "           9       0.03      0.54      0.05        48\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.76      0.81      0.73     10000\n",
      "weighted avg       0.86      0.75      0.77     10000\n",
      "\n",
      "Epoch 48: 7518 / 10000\n",
      "Accuracy = 75.18%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88171065 0.99851412 0.88602941 0.67149758 0.78655462 0.97067901\n",
      " 0.99360614 0.98253783 0.3583602  0.48780488]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1099\n",
      "           1       0.59      1.00      0.74       673\n",
      "           2       0.93      0.89      0.91      1088\n",
      "           3       0.96      0.67      0.79      1449\n",
      "           4       0.95      0.79      0.86      1190\n",
      "           5       0.71      0.97      0.82       648\n",
      "           6       0.81      0.99      0.89       782\n",
      "           7       0.82      0.98      0.89       859\n",
      "           8       0.80      0.36      0.49      2171\n",
      "           9       0.02      0.49      0.04        41\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.80      0.74     10000\n",
      "weighted avg       0.86      0.76      0.78     10000\n",
      "\n",
      "Epoch 49: 7562 / 10000\n",
      "Accuracy = 75.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.89693593 0.99835255 0.88693234 0.67289073 0.79058032 0.97121212\n",
      " 0.99367089 0.9824356  0.34041611 0.46153846]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1077\n",
      "           1       0.53      1.00      0.70       607\n",
      "           2       0.93      0.89      0.91      1079\n",
      "           3       0.96      0.67      0.79      1446\n",
      "           4       0.96      0.79      0.87      1189\n",
      "           5       0.72      0.97      0.83       660\n",
      "           6       0.82      0.99      0.90       790\n",
      "           7       0.82      0.98      0.89       854\n",
      "           8       0.79      0.34      0.48      2259\n",
      "           9       0.02      0.46      0.03        39\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.80      0.73     10000\n",
      "weighted avg       0.85      0.75      0.77     10000\n",
      "\n",
      "Epoch 50: 7494 / 10000\n",
      "Accuracy = 74.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88251366 0.9984472  0.87671233 0.69318996 0.76803279 0.97542243\n",
      " 0.99489144 0.98591549 0.36289959 0.48780488]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1098\n",
      "           1       0.57      1.00      0.72       644\n",
      "           2       0.93      0.88      0.90      1095\n",
      "           3       0.96      0.69      0.80      1395\n",
      "           4       0.95      0.77      0.85      1220\n",
      "           5       0.71      0.98      0.82       651\n",
      "           6       0.81      0.99      0.89       783\n",
      "           7       0.82      0.99      0.89       852\n",
      "           8       0.83      0.36      0.50      2221\n",
      "           9       0.02      0.49      0.04        41\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.80      0.74     10000\n",
      "weighted avg       0.86      0.76      0.78     10000\n",
      "\n",
      "Epoch 51: 7556 / 10000\n",
      "Accuracy = 75.56%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87793852 0.99829352 0.86690647 0.71449704 0.81652174 0.95285714\n",
      " 0.98986058 0.9825784  0.34793926 0.58974359]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1106\n",
      "           1       0.52      1.00      0.68       586\n",
      "           2       0.93      0.87      0.90      1112\n",
      "           3       0.96      0.71      0.82      1352\n",
      "           4       0.96      0.82      0.88      1150\n",
      "           5       0.75      0.95      0.84       700\n",
      "           6       0.82      0.99      0.89       789\n",
      "           7       0.82      0.98      0.90       861\n",
      "           8       0.82      0.35      0.49      2305\n",
      "           9       0.02      0.59      0.04        39\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.76      0.81      0.74     10000\n",
      "weighted avg       0.86      0.75      0.77     10000\n",
      "\n",
      "Epoch 52: 7544 / 10000\n",
      "Accuracy = 75.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87635379 0.99808429 0.8950328  0.64084045 0.78734177 0.95678092\n",
      " 0.99483871 0.98465171 0.33893062 0.53846154]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1108\n",
      "           1       0.46      1.00      0.63       522\n",
      "           2       0.93      0.90      0.91      1067\n",
      "           3       0.97      0.64      0.77      1523\n",
      "           4       0.95      0.79      0.86      1185\n",
      "           5       0.72      0.96      0.82       671\n",
      "           6       0.80      0.99      0.89       775\n",
      "           7       0.81      0.98      0.89       847\n",
      "           8       0.79      0.34      0.47      2263\n",
      "           9       0.02      0.54      0.04        39\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.74      0.80      0.72     10000\n",
      "weighted avg       0.85      0.74      0.76     10000\n",
      "\n",
      "Epoch 53: 7391 / 10000\n",
      "Accuracy = 73.91%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.87681159 0.99821109 0.88029466 0.66009517 0.80051151 0.94674556\n",
      " 0.99236641 0.9870892  0.33673923 0.54761905]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1104\n",
      "           1       0.49      1.00      0.66       559\n",
      "           2       0.93      0.88      0.90      1086\n",
      "           3       0.96      0.66      0.78      1471\n",
      "           4       0.96      0.80      0.87      1173\n",
      "           5       0.72      0.95      0.82       676\n",
      "           6       0.81      0.99      0.89       786\n",
      "           7       0.82      0.99      0.89       852\n",
      "           8       0.78      0.34      0.47      2251\n",
      "           9       0.02      0.55      0.04        42\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.80      0.73     10000\n",
      "weighted avg       0.85      0.74      0.76     10000\n",
      "\n",
      "Epoch 54: 7434 / 10000\n",
      "Accuracy = 74.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.88321168 0.99823322 0.88180979 0.63140818 0.79058032 0.9618442\n",
      " 0.99245283 0.9800235  0.34493671 0.47368421]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1096\n",
      "           1       0.50      1.00      0.66       566\n",
      "           2       0.93      0.88      0.90      1083\n",
      "           3       0.96      0.63      0.76      1541\n",
      "           4       0.96      0.79      0.87      1189\n",
      "           5       0.68      0.96      0.80       629\n",
      "           6       0.82      0.99      0.90       795\n",
      "           7       0.81      0.98      0.89       851\n",
      "           8       0.78      0.34      0.48      2212\n",
      "           9       0.02      0.47      0.03        38\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.74      0.79      0.72     10000\n",
      "weighted avg       0.85      0.74      0.76     10000\n",
      "\n",
      "Epoch 55: 7410 / 10000\n",
      "Accuracy = 74.10%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87308731 0.99844961 0.86751361 0.69142857 0.78056951 0.96551724\n",
      " 0.99125    0.98245614 0.35844749 0.5       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      1111\n",
      "           1       0.57      1.00      0.72       645\n",
      "           2       0.93      0.87      0.90      1102\n",
      "           3       0.96      0.69      0.80      1400\n",
      "           4       0.95      0.78      0.86      1194\n",
      "           5       0.72      0.97      0.83       667\n",
      "           6       0.83      0.99      0.90       800\n",
      "           7       0.82      0.98      0.89       855\n",
      "           8       0.81      0.36      0.50      2190\n",
      "           9       0.02      0.50      0.03        36\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.80      0.74     10000\n",
      "weighted avg       0.86      0.76      0.78     10000\n",
      "\n",
      "Epoch 56: 7550 / 10000\n",
      "Accuracy = 75.50%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87466186 0.99832496 0.84969054 0.67552448 0.76784249 0.95599393\n",
      " 0.99484536 0.98097503 0.35267452 0.40625   ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      1109\n",
      "           1       0.53      1.00      0.69       597\n",
      "           2       0.93      0.85      0.89      1131\n",
      "           3       0.96      0.68      0.79      1430\n",
      "           4       0.95      0.77      0.85      1219\n",
      "           5       0.71      0.96      0.81       659\n",
      "           6       0.81      0.99      0.89       776\n",
      "           7       0.80      0.98      0.88       841\n",
      "           8       0.80      0.35      0.49      2206\n",
      "           9       0.01      0.41      0.02        32\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.79      0.72     10000\n",
      "weighted avg       0.85      0.74      0.77     10000\n",
      "\n",
      "Epoch 57: 7447 / 10000\n",
      "Accuracy = 74.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87556357 1.         0.85701599 0.66529774 0.76923077 0.96691729\n",
      " 0.99117276 0.97852029 0.35116598 0.48275862]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1109\n",
      "           1       0.51      1.00      0.68       583\n",
      "           2       0.94      0.86      0.89      1126\n",
      "           3       0.96      0.67      0.79      1461\n",
      "           4       0.95      0.77      0.85      1209\n",
      "           5       0.72      0.97      0.83       665\n",
      "           6       0.82      0.99      0.90       793\n",
      "           7       0.80      0.98      0.88       838\n",
      "           8       0.79      0.35      0.49      2187\n",
      "           9       0.01      0.48      0.03        29\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.79      0.73     10000\n",
      "weighted avg       0.85      0.75      0.77     10000\n",
      "\n",
      "Epoch 58: 7452 / 10000\n",
      "Accuracy = 74.52%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87477477 0.99817185 0.8719346  0.69186876 0.78279031 0.95614035\n",
      " 0.99126092 0.98319328 0.34797738 0.5       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      1110\n",
      "           1       0.48      1.00      0.65       547\n",
      "           2       0.93      0.87      0.90      1101\n",
      "           3       0.96      0.69      0.80      1402\n",
      "           4       0.95      0.78      0.86      1197\n",
      "           5       0.73      0.96      0.83       684\n",
      "           6       0.83      0.99      0.90       801\n",
      "           7       0.80      0.98      0.88       833\n",
      "           8       0.82      0.35      0.49      2299\n",
      "           9       0.01      0.50      0.03        26\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.80      0.73     10000\n",
      "weighted avg       0.86      0.75      0.77     10000\n",
      "\n",
      "Epoch 59: 7464 / 10000\n",
      "Accuracy = 74.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87230216 0.99818841 0.84041631 0.66483138 0.76677578 0.95886076\n",
      " 0.99249061 0.97997644 0.35115541 0.71428571]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      1112\n",
      "           1       0.49      1.00      0.65       552\n",
      "           2       0.94      0.84      0.89      1153\n",
      "           3       0.96      0.66      0.78      1453\n",
      "           4       0.95      0.77      0.85      1222\n",
      "           5       0.68      0.96      0.80       632\n",
      "           6       0.83      0.99      0.90       799\n",
      "           7       0.81      0.98      0.89       849\n",
      "           8       0.80      0.35      0.49      2207\n",
      "           9       0.01      0.71      0.03        21\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.81      0.72     10000\n",
      "weighted avg       0.85      0.74      0.76     10000\n",
      "\n",
      "Epoch 60: 7414 / 10000\n",
      "Accuracy = 74.14%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85701677 1.         0.82646048 0.65955983 0.76393443 0.96573209\n",
      " 0.99482536 0.97746145 0.35657089 0.30434783]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1133\n",
      "           1       0.55      1.00      0.71       625\n",
      "           2       0.93      0.83      0.88      1164\n",
      "           3       0.95      0.66      0.78      1454\n",
      "           4       0.95      0.76      0.85      1220\n",
      "           5       0.70      0.97      0.81       642\n",
      "           6       0.80      0.99      0.89       773\n",
      "           7       0.80      0.98      0.88       843\n",
      "           8       0.78      0.36      0.49      2123\n",
      "           9       0.01      0.30      0.01        23\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.75      0.77      0.72     10000\n",
      "weighted avg       0.85      0.74      0.77     10000\n",
      "\n",
      "Epoch 61: 7426 / 10000\n",
      "Accuracy = 74.26%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84508268 0.99837662 0.84452297 0.69905729 0.76132686 0.96101949\n",
      " 0.99486521 0.98218527 0.35779817 0.35      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      1149\n",
      "           1       0.54      1.00      0.70       616\n",
      "           2       0.93      0.84      0.88      1132\n",
      "           3       0.95      0.70      0.81      1379\n",
      "           4       0.96      0.76      0.85      1236\n",
      "           5       0.72      0.96      0.82       667\n",
      "           6       0.81      0.99      0.89       779\n",
      "           7       0.80      0.98      0.88       842\n",
      "           8       0.80      0.36      0.49      2180\n",
      "           9       0.01      0.35      0.01        20\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.78      0.73     10000\n",
      "weighted avg       0.86      0.75      0.77     10000\n",
      "\n",
      "Epoch 62: 7477 / 10000\n",
      "Accuracy = 74.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.84581882 0.99826389 0.81748727 0.62338501 0.76131687 0.95163807\n",
      " 0.98971722 0.98543689 0.33590734 0.45      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      1148\n",
      "           1       0.51      1.00      0.67       576\n",
      "           2       0.93      0.82      0.87      1178\n",
      "           3       0.96      0.62      0.75      1548\n",
      "           4       0.94      0.76      0.84      1215\n",
      "           5       0.68      0.95      0.80       641\n",
      "           6       0.80      0.99      0.89       778\n",
      "           7       0.79      0.99      0.88       824\n",
      "           8       0.71      0.34      0.46      2072\n",
      "           9       0.01      0.45      0.02        20\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.78      0.71     10000\n",
      "weighted avg       0.83      0.73      0.75     10000\n",
      "\n",
      "Epoch 63: 7296 / 10000\n",
      "Accuracy = 72.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86839749 0.99823322 0.84561404 0.60815047 0.74715447 0.95987159\n",
      " 0.99232737 0.986618   0.34443387 0.34782609]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      1117\n",
      "           1       0.50      1.00      0.66       566\n",
      "           2       0.93      0.85      0.89      1140\n",
      "           3       0.96      0.61      0.74      1595\n",
      "           4       0.94      0.75      0.83      1230\n",
      "           5       0.67      0.96      0.79       623\n",
      "           6       0.81      0.99      0.89       782\n",
      "           7       0.79      0.99      0.88       822\n",
      "           8       0.74      0.34      0.47      2102\n",
      "           9       0.01      0.35      0.02        23\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.77      0.71     10000\n",
      "weighted avg       0.84      0.73      0.75     10000\n",
      "\n",
      "Epoch 64: 7305 / 10000\n",
      "Accuracy = 73.05%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85828167 0.99850075 0.84805654 0.62982341 0.74461293 0.95377504\n",
      " 0.99086162 0.98184019 0.35844412 0.38888889]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1129\n",
      "           1       0.59      1.00      0.74       667\n",
      "           2       0.93      0.85      0.89      1132\n",
      "           3       0.95      0.63      0.76      1529\n",
      "           4       0.95      0.74      0.83      1253\n",
      "           5       0.69      0.95      0.80       649\n",
      "           6       0.79      0.99      0.88       766\n",
      "           7       0.79      0.98      0.87       826\n",
      "           8       0.75      0.36      0.48      2031\n",
      "           9       0.01      0.39      0.01        18\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.74      0.78      0.72     10000\n",
      "weighted avg       0.84      0.74      0.76     10000\n",
      "\n",
      "Epoch 65: 7415 / 10000\n",
      "Accuracy = 74.15%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.87364621 0.99870298 0.84440559 0.62857143 0.74041534 0.94631902\n",
      " 0.99226804 0.98212157 0.38165525 0.47619048]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      1108\n",
      "           1       0.68      1.00      0.81       771\n",
      "           2       0.94      0.84      0.89      1144\n",
      "           3       0.96      0.63      0.76      1540\n",
      "           4       0.94      0.74      0.83      1252\n",
      "           5       0.69      0.95      0.80       652\n",
      "           6       0.80      0.99      0.89       776\n",
      "           7       0.80      0.98      0.88       839\n",
      "           8       0.74      0.38      0.50      1897\n",
      "           9       0.01      0.48      0.02        21\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.76      0.79      0.73     10000\n",
      "weighted avg       0.85      0.75      0.78     10000\n",
      "\n",
      "Epoch 66: 7544 / 10000\n",
      "Accuracy = 75.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85626102 1.         0.8404908  0.61862245 0.7192846  0.96339434\n",
      " 0.99350649 0.98311218 0.35613208 0.375     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1134\n",
      "           1       0.47      1.00      0.64       535\n",
      "           2       0.93      0.84      0.88      1141\n",
      "           3       0.96      0.62      0.75      1568\n",
      "           4       0.94      0.72      0.82      1286\n",
      "           5       0.65      0.96      0.78       601\n",
      "           6       0.80      0.99      0.89       770\n",
      "           7       0.79      0.98      0.88       829\n",
      "           8       0.78      0.36      0.49      2120\n",
      "           9       0.01      0.38      0.01        16\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.77      0.70     10000\n",
      "weighted avg       0.85      0.73      0.75     10000\n",
      "\n",
      "Epoch 67: 7280 / 10000\n",
      "Accuracy = 72.80%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84274544 0.99849624 0.82297064 0.64757412 0.72677596 0.94915254\n",
      " 0.98971722 0.9819928  0.37072435 0.38461538]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1151\n",
      "           1       0.59      1.00      0.74       665\n",
      "           2       0.92      0.82      0.87      1158\n",
      "           3       0.95      0.65      0.77      1484\n",
      "           4       0.95      0.73      0.82      1281\n",
      "           5       0.69      0.95      0.80       649\n",
      "           6       0.80      0.99      0.89       778\n",
      "           7       0.80      0.98      0.88       833\n",
      "           8       0.76      0.37      0.50      1988\n",
      "           9       0.00      0.38      0.01        13\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.74      0.77      0.72     10000\n",
      "weighted avg       0.85      0.74      0.77     10000\n",
      "\n",
      "Epoch 68: 7425 / 10000\n",
      "Accuracy = 74.25%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84448306 1.         0.81825939 0.61562897 0.7192846  0.96574225\n",
      " 0.99344692 0.98207885 0.35343968 0.26666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1151\n",
      "           1       0.51      1.00      0.68       583\n",
      "           2       0.93      0.82      0.87      1172\n",
      "           3       0.96      0.62      0.75      1574\n",
      "           4       0.94      0.72      0.82      1286\n",
      "           5       0.66      0.97      0.79       613\n",
      "           6       0.79      0.99      0.88       763\n",
      "           7       0.80      0.98      0.88       837\n",
      "           8       0.73      0.35      0.48      2006\n",
      "           9       0.00      0.27      0.01        15\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.76      0.71     10000\n",
      "weighted avg       0.84      0.73      0.75     10000\n",
      "\n",
      "Epoch 69: 7293 / 10000\n",
      "Accuracy = 72.93%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.86339286 1.         0.81313131 0.60924636 0.56012085 0.95176849\n",
      " 0.99220779 0.97936893 0.4302397  0.23529412]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1120\n",
      "           1       0.53      1.00      0.69       598\n",
      "           2       0.94      0.81      0.87      1188\n",
      "           3       0.95      0.61      0.74      1579\n",
      "           4       0.94      0.56      0.70      1655\n",
      "           5       0.66      0.95      0.78       622\n",
      "           6       0.80      0.99      0.88       770\n",
      "           7       0.79      0.98      0.87       824\n",
      "           8       0.72      0.43      0.54      1627\n",
      "           9       0.00      0.24      0.01        17\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.74      0.70     10000\n",
      "weighted avg       0.84      0.73      0.76     10000\n",
      "\n",
      "Epoch 70: 7287 / 10000\n",
      "Accuracy = 72.87%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85663717 0.99845201 0.82695652 0.62031048 0.62922869 0.94495413\n",
      " 0.9934811  0.98076923 0.39550562 0.29411765]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1130\n",
      "           1       0.57      1.00      0.72       646\n",
      "           2       0.92      0.83      0.87      1150\n",
      "           3       0.95      0.62      0.75      1546\n",
      "           4       0.95      0.63      0.76      1478\n",
      "           5       0.69      0.94      0.80       654\n",
      "           6       0.80      0.99      0.88       767\n",
      "           7       0.79      0.98      0.88       832\n",
      "           8       0.72      0.40      0.51      1780\n",
      "           9       0.00      0.29      0.01        17\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.74      0.75      0.71     10000\n",
      "weighted avg       0.84      0.74      0.76     10000\n",
      "\n",
      "Epoch 71: 7358 / 10000\n",
      "Accuracy = 73.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.84554974 0.99845917 0.82722513 0.60590823 0.6407967  0.94761905\n",
      " 0.99089727 0.98170732 0.39325843 0.38461538]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      1146\n",
      "           1       0.57      1.00      0.73       649\n",
      "           2       0.92      0.83      0.87      1146\n",
      "           3       0.95      0.61      0.74      1591\n",
      "           4       0.95      0.64      0.77      1456\n",
      "           5       0.67      0.95      0.78       630\n",
      "           6       0.80      0.99      0.88       769\n",
      "           7       0.78      0.98      0.87       820\n",
      "           8       0.72      0.39      0.51      1780\n",
      "           9       0.00      0.38      0.01        13\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.74      0.76      0.71     10000\n",
      "weighted avg       0.84      0.73      0.76     10000\n",
      "\n",
      "Epoch 72: 7331 / 10000\n",
      "Accuracy = 73.31%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84215091 0.99853801 0.82672414 0.56806128 0.61933739 0.95454545\n",
      " 0.99092088 0.98161765 0.4034761  0.30769231]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1153\n",
      "           1       0.60      1.00      0.75       684\n",
      "           2       0.93      0.83      0.88      1160\n",
      "           3       0.95      0.57      0.71      1697\n",
      "           4       0.93      0.62      0.74      1479\n",
      "           5       0.66      0.95      0.78       616\n",
      "           6       0.80      0.99      0.88       771\n",
      "           7       0.78      0.98      0.87       816\n",
      "           8       0.67      0.40      0.50      1611\n",
      "           9       0.00      0.31      0.01        13\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.75      0.70     10000\n",
      "weighted avg       0.84      0.73      0.76     10000\n",
      "\n",
      "Epoch 73: 7300 / 10000\n",
      "Accuracy = 73.00%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83490972 0.99851412 0.82363162 0.56806128 0.55086258 0.95106036\n",
      " 0.99088542 0.97730139 0.45003446 0.2       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91      1163\n",
      "           1       0.59      1.00      0.74       673\n",
      "           2       0.92      0.82      0.87      1151\n",
      "           3       0.95      0.57      0.71      1697\n",
      "           4       0.94      0.55      0.70      1681\n",
      "           5       0.65      0.95      0.77       613\n",
      "           6       0.79      0.99      0.88       768\n",
      "           7       0.75      0.98      0.85       793\n",
      "           8       0.67      0.45      0.54      1451\n",
      "           9       0.00      0.20      0.00        10\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.73      0.70     10000\n",
      "weighted avg       0.84      0.73      0.75     10000\n",
      "\n",
      "Epoch 74: 7255 / 10000\n",
      "Accuracy = 72.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83119109 1.         0.78991597 0.59987516 0.56479218 0.94813614\n",
      " 0.98956975 0.98258706 0.41814838 0.27272727]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1167\n",
      "           1       0.51      1.00      0.67       575\n",
      "           2       0.91      0.79      0.85      1190\n",
      "           3       0.95      0.60      0.74      1602\n",
      "           4       0.94      0.56      0.71      1636\n",
      "           5       0.66      0.95      0.78       617\n",
      "           6       0.79      0.99      0.88       767\n",
      "           7       0.77      0.98      0.86       804\n",
      "           8       0.70      0.42      0.52      1631\n",
      "           9       0.00      0.27      0.01        11\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.74      0.69     10000\n",
      "weighted avg       0.84      0.72      0.75     10000\n",
      "\n",
      "Epoch 75: 7189 / 10000\n",
      "Accuracy = 71.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82764505 0.9982548  0.81190682 0.55741489 0.55866261 0.95121951\n",
      " 0.9933687  0.9800995  0.41042345 0.3       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1172\n",
      "           1       0.50      1.00      0.67       573\n",
      "           2       0.91      0.81      0.86      1159\n",
      "           3       0.96      0.56      0.70      1733\n",
      "           4       0.94      0.56      0.70      1645\n",
      "           5       0.66      0.95      0.78       615\n",
      "           6       0.78      0.99      0.88       754\n",
      "           7       0.77      0.98      0.86       804\n",
      "           8       0.65      0.41      0.50      1535\n",
      "           9       0.00      0.30      0.01        10\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.72      0.74      0.69     10000\n",
      "weighted avg       0.83      0.71      0.74     10000\n",
      "\n",
      "Epoch 76: 7123 / 10000\n",
      "Accuracy = 71.23%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.84055459 0.99854651 0.7800659  0.56745562 0.56284488 0.95090016\n",
      " 0.98835705 0.98004988 0.44241573 0.23076923]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      1154\n",
      "           1       0.61      1.00      0.75       688\n",
      "           2       0.92      0.78      0.84      1214\n",
      "           3       0.95      0.57      0.71      1690\n",
      "           4       0.93      0.56      0.70      1631\n",
      "           5       0.65      0.95      0.77       611\n",
      "           6       0.80      0.99      0.88       773\n",
      "           7       0.76      0.98      0.86       802\n",
      "           8       0.65      0.44      0.53      1424\n",
      "           9       0.00      0.23      0.01        13\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.73      0.73      0.70     10000\n",
      "weighted avg       0.84      0.72      0.75     10000\n",
      "\n",
      "Epoch 77: 7245 / 10000\n",
      "Accuracy = 72.45%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83133562 0.99831933 0.79443976 0.57710843 0.53873034 0.94822006\n",
      " 0.99208443 0.98479087 0.44       0.25      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1168\n",
      "           1       0.52      1.00      0.69       595\n",
      "           2       0.91      0.79      0.85      1187\n",
      "           3       0.95      0.58      0.72      1660\n",
      "           4       0.94      0.54      0.69      1717\n",
      "           5       0.66      0.95      0.78       618\n",
      "           6       0.78      0.99      0.88       758\n",
      "           7       0.76      0.98      0.86       789\n",
      "           8       0.68      0.44      0.53      1500\n",
      "           9       0.00      0.25      0.00         8\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.74      0.69     10000\n",
      "weighted avg       0.84      0.72      0.75     10000\n",
      "\n",
      "Epoch 78: 7168 / 10000\n",
      "Accuracy = 71.68%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83476764 1.         0.77149877 0.60789306 0.5346651  0.9375\n",
      " 0.99081365 0.97864322 0.44235751 0.125     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91      1162\n",
      "           1       0.52      1.00      0.69       594\n",
      "           2       0.91      0.77      0.84      1221\n",
      "           3       0.95      0.61      0.74      1571\n",
      "           4       0.93      0.53      0.68      1702\n",
      "           5       0.67      0.94      0.78       640\n",
      "           6       0.79      0.99      0.88       762\n",
      "           7       0.76      0.98      0.85       796\n",
      "           8       0.70      0.44      0.54      1544\n",
      "           9       0.00      0.12      0.00         8\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.72      0.69     10000\n",
      "weighted avg       0.84      0.72      0.75     10000\n",
      "\n",
      "Epoch 79: 7189 / 10000\n",
      "Accuracy = 71.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81612091 0.99832496 0.78978224 0.54576464 0.54637941 0.95059625\n",
      " 0.9934297  0.97987421 0.42189679 0.27272727]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1191\n",
      "           1       0.53      1.00      0.69       597\n",
      "           2       0.91      0.79      0.85      1194\n",
      "           3       0.95      0.55      0.69      1759\n",
      "           4       0.93      0.55      0.69      1671\n",
      "           5       0.63      0.95      0.75       587\n",
      "           6       0.79      0.99      0.88       761\n",
      "           7       0.76      0.98      0.85       795\n",
      "           8       0.62      0.42      0.50      1434\n",
      "           9       0.00      0.27      0.01        11\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.73      0.68     10000\n",
      "weighted avg       0.83      0.71      0.74     10000\n",
      "\n",
      "Epoch 80: 7085 / 10000\n",
      "Accuracy = 70.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.8139145  0.99833887 0.75537849 0.59339975 0.53747073 0.95008052\n",
      " 0.99205298 0.97769517 0.44190871 0.14285714]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      1193\n",
      "           1       0.53      1.00      0.69       602\n",
      "           2       0.92      0.76      0.83      1255\n",
      "           3       0.94      0.59      0.73      1606\n",
      "           4       0.93      0.54      0.68      1708\n",
      "           5       0.66      0.95      0.78       621\n",
      "           6       0.78      0.99      0.87       755\n",
      "           7       0.77      0.98      0.86       807\n",
      "           8       0.66      0.44      0.53      1446\n",
      "           9       0.00      0.14      0.00         7\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.72      0.69     10000\n",
      "weighted avg       0.83      0.72      0.75     10000\n",
      "\n",
      "Epoch 81: 7159 / 10000\n",
      "Accuracy = 71.59%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82623509 1.         0.77980132 0.55904596 0.54709058 0.95041322\n",
      " 0.99607843 0.97735849 0.44491525 0.22222222]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1174\n",
      "           1       0.57      1.00      0.72       642\n",
      "           2       0.91      0.78      0.84      1208\n",
      "           3       0.95      0.56      0.70      1719\n",
      "           4       0.93      0.55      0.69      1667\n",
      "           5       0.64      0.95      0.77       605\n",
      "           6       0.80      1.00      0.88       765\n",
      "           7       0.76      0.98      0.85       795\n",
      "           8       0.65      0.44      0.53      1416\n",
      "           9       0.00      0.22      0.00         9\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.73      0.69     10000\n",
      "weighted avg       0.83      0.72      0.75     10000\n",
      "\n",
      "Epoch 82: 7173 / 10000\n",
      "Accuracy = 71.73%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8        1.         0.75564516 0.54199773 0.53709199 0.93964111\n",
      " 0.99455782 0.98589744 0.44825073 0.28571429]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      1215\n",
      "           1       0.52      1.00      0.68       591\n",
      "           2       0.91      0.76      0.82      1240\n",
      "           3       0.95      0.54      0.69      1762\n",
      "           4       0.92      0.54      0.68      1685\n",
      "           5       0.65      0.94      0.77       613\n",
      "           6       0.76      0.99      0.86       735\n",
      "           7       0.75      0.99      0.85       780\n",
      "           8       0.63      0.45      0.52      1372\n",
      "           9       0.00      0.29      0.00         7\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.73      0.68     10000\n",
      "weighted avg       0.83      0.71      0.73     10000\n",
      "\n",
      "Epoch 83: 7053 / 10000\n",
      "Accuracy = 70.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82133785 0.99862259 0.77295082 0.57780458 0.55616606 0.94967532\n",
      " 0.99202128 0.97867001 0.46937322 0.25      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1181\n",
      "           1       0.64      1.00      0.78       726\n",
      "           2       0.91      0.77      0.84      1220\n",
      "           3       0.95      0.58      0.72      1658\n",
      "           4       0.93      0.56      0.70      1638\n",
      "           5       0.66      0.95      0.78       616\n",
      "           6       0.78      0.99      0.87       752\n",
      "           7       0.76      0.98      0.85       797\n",
      "           8       0.68      0.47      0.55      1404\n",
      "           9       0.00      0.25      0.00         8\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.74      0.70     10000\n",
      "weighted avg       0.84      0.73      0.76     10000\n",
      "\n",
      "Epoch 84: 7279 / 10000\n",
      "Accuracy = 72.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82233503 1.         0.75594295 0.56025867 0.54256595 0.94348509\n",
      " 0.99341238 0.98337596 0.45082556 0.33333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1182\n",
      "           1       0.53      1.00      0.70       607\n",
      "           2       0.92      0.76      0.83      1262\n",
      "           3       0.94      0.56      0.70      1701\n",
      "           4       0.92      0.54      0.68      1668\n",
      "           5       0.67      0.94      0.79       637\n",
      "           6       0.79      0.99      0.88       759\n",
      "           7       0.75      0.98      0.85       782\n",
      "           8       0.64      0.45      0.53      1393\n",
      "           9       0.00      0.33      0.01         9\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.72      0.74      0.69     10000\n",
      "weighted avg       0.83      0.71      0.74     10000\n",
      "\n",
      "Epoch 85: 7146 / 10000\n",
      "Accuracy = 71.46%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82242991 0.99848485 0.77446103 0.56364713 0.54431886 0.92227205\n",
      " 0.99339498 0.97977244 0.45154185 0.375     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1177\n",
      "           1       0.58      1.00      0.73       660\n",
      "           2       0.91      0.77      0.83      1206\n",
      "           3       0.94      0.56      0.71      1689\n",
      "           4       0.93      0.54      0.69      1681\n",
      "           5       0.69      0.92      0.79       669\n",
      "           6       0.78      0.99      0.88       757\n",
      "           7       0.75      0.98      0.85       791\n",
      "           8       0.63      0.45      0.53      1362\n",
      "           9       0.00      0.38      0.01         8\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.74      0.69     10000\n",
      "weighted avg       0.83      0.72      0.75     10000\n",
      "\n",
      "Epoch 86: 7190 / 10000\n",
      "Accuracy = 71.90%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82582838 1.         0.74624506 0.52908587 0.55867665 0.9424\n",
      " 0.9895288  0.97701149 0.44248466 0.3       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1177\n",
      "           1       0.59      1.00      0.74       665\n",
      "           2       0.91      0.75      0.82      1265\n",
      "           3       0.95      0.53      0.68      1805\n",
      "           4       0.91      0.56      0.69      1602\n",
      "           5       0.66      0.94      0.78       625\n",
      "           6       0.79      0.99      0.88       764\n",
      "           7       0.74      0.98      0.84       783\n",
      "           8       0.59      0.44      0.51      1304\n",
      "           9       0.00      0.30      0.01        10\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.73      0.68     10000\n",
      "weighted avg       0.83      0.71      0.74     10000\n",
      "\n",
      "Epoch 87: 7121 / 10000\n",
      "Accuracy = 71.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81649832 0.99848714 0.78505458 0.52767123 0.55256724 0.93004769\n",
      " 0.98951507 0.98049415 0.44845749 0.33333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.89      1188\n",
      "           1       0.58      1.00      0.73       661\n",
      "           2       0.91      0.79      0.84      1191\n",
      "           3       0.95      0.53      0.68      1825\n",
      "           4       0.92      0.55      0.69      1636\n",
      "           5       0.66      0.93      0.77       629\n",
      "           6       0.79      0.99      0.88       763\n",
      "           7       0.73      0.98      0.84       769\n",
      "           8       0.61      0.45      0.52      1329\n",
      "           9       0.00      0.33      0.01         9\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.74      0.69     10000\n",
      "weighted avg       0.83      0.71      0.74     10000\n",
      "\n",
      "Epoch 88: 7125 / 10000\n",
      "Accuracy = 71.25%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.83333333 1.         0.71908397 0.53433836 0.53345175 0.9384858\n",
      " 0.99061662 0.98069498 0.44496487 0.28571429]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      1164\n",
      "           1       0.53      1.00      0.69       601\n",
      "           2       0.91      0.72      0.80      1310\n",
      "           3       0.95      0.53      0.68      1791\n",
      "           4       0.92      0.53      0.67      1689\n",
      "           5       0.67      0.94      0.78       634\n",
      "           6       0.77      0.99      0.87       746\n",
      "           7       0.74      0.98      0.84       777\n",
      "           8       0.59      0.44      0.51      1281\n",
      "           9       0.00      0.29      0.00         7\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.71      0.73      0.68     10000\n",
      "weighted avg       0.82      0.70      0.73     10000\n",
      "\n",
      "Epoch 89: 7039 / 10000\n",
      "Accuracy = 70.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.81051753 1.         0.7066365  0.54488279 0.53202847 0.94805195\n",
      " 0.99335989 0.97972117 0.47979798 0.2       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      1198\n",
      "           1       0.60      1.00      0.75       685\n",
      "           2       0.91      0.71      0.79      1326\n",
      "           3       0.94      0.54      0.69      1749\n",
      "           4       0.91      0.53      0.67      1686\n",
      "           5       0.65      0.95      0.77       616\n",
      "           6       0.78      0.99      0.87       753\n",
      "           7       0.75      0.98      0.85       789\n",
      "           8       0.59      0.48      0.53      1188\n",
      "           9       0.00      0.20      0.00        10\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.72      0.68     10000\n",
      "weighted avg       0.83      0.71      0.74     10000\n",
      "\n",
      "Epoch 90: 7120 / 10000\n",
      "Accuracy = 71.20%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.80698835 1.         0.71615385 0.53214086 0.53735804 0.93780687\n",
      " 0.99330656 0.97712834 0.4227707  0.33333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      1202\n",
      "           1       0.55      1.00      0.71       629\n",
      "           2       0.90      0.72      0.80      1300\n",
      "           3       0.94      0.53      0.68      1789\n",
      "           4       0.92      0.54      0.68      1673\n",
      "           5       0.64      0.94      0.76       611\n",
      "           6       0.77      0.99      0.87       747\n",
      "           7       0.75      0.98      0.85       787\n",
      "           8       0.55      0.42      0.48      1256\n",
      "           9       0.00      0.33      0.00         6\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.70      0.73      0.67     10000\n",
      "weighted avg       0.82      0.70      0.73     10000\n",
      "\n",
      "Epoch 91: 6998 / 10000\n",
      "Accuracy = 69.98%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.80131904 1.         0.70104634 0.53789593 0.51884058 0.94012945\n",
      " 0.99315068 0.98       0.44768856 0.3       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      1213\n",
      "           1       0.54      1.00      0.70       615\n",
      "           2       0.91      0.70      0.79      1338\n",
      "           3       0.94      0.54      0.68      1768\n",
      "           4       0.91      0.52      0.66      1725\n",
      "           5       0.65      0.94      0.77       618\n",
      "           6       0.76      0.99      0.86       730\n",
      "           7       0.71      0.98      0.83       750\n",
      "           8       0.57      0.45      0.50      1233\n",
      "           9       0.00      0.30      0.01        10\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.70      0.72      0.67     10000\n",
      "weighted avg       0.82      0.70      0.73     10000\n",
      "\n",
      "Epoch 92: 6967 / 10000\n",
      "Accuracy = 69.67%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.80497925 1.         0.70504138 0.56469887 0.51164111 0.93364929\n",
      " 0.99051491 0.98445596 0.46369637 0.28571429]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      1205\n",
      "           1       0.59      1.00      0.74       666\n",
      "           2       0.91      0.71      0.79      1329\n",
      "           3       0.94      0.56      0.70      1677\n",
      "           4       0.92      0.51      0.66      1761\n",
      "           5       0.66      0.93      0.78       633\n",
      "           6       0.76      0.99      0.86       738\n",
      "           7       0.74      0.98      0.84       772\n",
      "           8       0.58      0.46      0.51      1212\n",
      "           9       0.00      0.29      0.00         7\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.72      0.68     10000\n",
      "weighted avg       0.82      0.71      0.74     10000\n",
      "\n",
      "Epoch 93: 7067 / 10000\n",
      "Accuracy = 70.67%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.79443079 1.         0.70172802 0.53690141 0.51590515 0.93548387\n",
      " 0.99173554 0.97927461 0.43811881 0.4       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      1221\n",
      "           1       0.54      1.00      0.70       609\n",
      "           2       0.91      0.70      0.79      1331\n",
      "           3       0.94      0.54      0.68      1775\n",
      "           4       0.91      0.52      0.66      1729\n",
      "           5       0.65      0.94      0.77       620\n",
      "           6       0.75      0.99      0.86       726\n",
      "           7       0.74      0.98      0.84       772\n",
      "           8       0.55      0.44      0.49      1212\n",
      "           9       0.00      0.40      0.00         5\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.70      0.73      0.67     10000\n",
      "weighted avg       0.82      0.69      0.72     10000\n",
      "\n",
      "Epoch 94: 6947 / 10000\n",
      "Accuracy = 69.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81459732 1.         0.6957809  0.51323609 0.53080569 0.9324547\n",
      " 0.99191375 0.97637795 0.42352941 0.28571429]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      1192\n",
      "           1       0.54      1.00      0.70       610\n",
      "           2       0.91      0.70      0.79      1351\n",
      "           3       0.94      0.51      0.66      1851\n",
      "           4       0.91      0.53      0.67      1688\n",
      "           5       0.63      0.93      0.76       607\n",
      "           6       0.77      0.99      0.87       742\n",
      "           7       0.72      0.98      0.83       762\n",
      "           8       0.52      0.42      0.47      1190\n",
      "           9       0.00      0.29      0.00         7\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.69      0.72      0.66     10000\n",
      "weighted avg       0.81      0.69      0.72     10000\n",
      "\n",
      "Epoch 95: 6919 / 10000\n",
      "Accuracy = 69.19%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.75800156 0.99825175 0.70626003 0.50529101 0.5301133  0.92833333\n",
      " 0.99452804 0.97532468 0.40032547 0.5       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86      1281\n",
      "           1       0.50      1.00      0.67       572\n",
      "           2       0.85      0.71      0.77      1246\n",
      "           3       0.95      0.51      0.66      1890\n",
      "           4       0.91      0.53      0.67      1677\n",
      "           5       0.62      0.93      0.75       600\n",
      "           6       0.76      0.99      0.86       731\n",
      "           7       0.73      0.98      0.84       770\n",
      "           8       0.51      0.40      0.45      1229\n",
      "           9       0.00      0.50      0.00         4\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.68      0.73      0.65     10000\n",
      "weighted avg       0.80      0.68      0.71     10000\n",
      "\n",
      "Epoch 96: 6795 / 10000\n",
      "Accuracy = 67.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.76175549 1.         0.69754553 0.53898691 0.51834862 0.93011647\n",
      " 0.99320652 0.98074454 0.4122807  0.4       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86      1276\n",
      "           1       0.52      1.00      0.68       585\n",
      "           2       0.85      0.70      0.77      1263\n",
      "           3       0.94      0.54      0.68      1757\n",
      "           4       0.92      0.52      0.66      1744\n",
      "           5       0.63      0.93      0.75       601\n",
      "           6       0.76      0.99      0.86       736\n",
      "           7       0.74      0.98      0.85       779\n",
      "           8       0.53      0.41      0.46      1254\n",
      "           9       0.00      0.40      0.00         5\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.69      0.72      0.66     10000\n",
      "weighted avg       0.81      0.69      0.72     10000\n",
      "\n",
      "Epoch 97: 6862 / 10000\n",
      "Accuracy = 68.62%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.78559871 1.         0.68584071 0.53547297 0.51148106 0.94285714\n",
      " 0.99158485 0.97766097 0.41726049 0.28571429]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      1236\n",
      "           1       0.49      1.00      0.65       551\n",
      "           2       0.90      0.69      0.78      1356\n",
      "           3       0.94      0.54      0.68      1776\n",
      "           4       0.91      0.51      0.65      1742\n",
      "           5       0.63      0.94      0.75       595\n",
      "           6       0.74      0.99      0.85       713\n",
      "           7       0.72      0.98      0.83       761\n",
      "           8       0.54      0.42      0.47      1263\n",
      "           9       0.00      0.29      0.00         7\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.69      0.71      0.66     10000\n",
      "weighted avg       0.81      0.68      0.71     10000\n",
      "\n",
      "Epoch 98: 6835 / 10000\n",
      "Accuracy = 68.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.75660964 0.9983871  0.66994701 0.50397035 0.51490357 0.92567568\n",
      " 0.99285714 0.97751323 0.42959002 0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86      1286\n",
      "           1       0.55      1.00      0.71       620\n",
      "           2       0.86      0.67      0.75      1321\n",
      "           3       0.94      0.50      0.66      1889\n",
      "           4       0.90      0.51      0.65      1711\n",
      "           5       0.61      0.93      0.74       592\n",
      "           6       0.73      0.99      0.84       700\n",
      "           7       0.72      0.98      0.83       756\n",
      "           8       0.49      0.43      0.46      1122\n",
      "           9       0.00      0.67      0.00         3\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.68      0.74      0.65     10000\n",
      "weighted avg       0.80      0.68      0.71     10000\n",
      "\n",
      "Epoch 99: 6776 / 10000\n",
      "Accuracy = 67.76%\n"
     ]
    }
   ],
   "source": [
    "net = network_tanh.NetworkTanh([784, 30, 10])\n",
    "net.SGD(training_data, 100, 10, 1.5, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.83826087 0.98907104 0.94318182 0.81834215 0.86645636 0.95125786\n",
      " 0.94789357 0.92274678 0.83583691 0.67075812]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91      1150\n",
      "           1       0.96      0.99      0.97      1098\n",
      "           2       0.80      0.94      0.87       880\n",
      "           3       0.92      0.82      0.87      1134\n",
      "           4       0.84      0.87      0.85       951\n",
      "           5       0.68      0.95      0.79       636\n",
      "           6       0.89      0.95      0.92       902\n",
      "           7       0.84      0.92      0.88       932\n",
      "           8       0.80      0.84      0.82       932\n",
      "           9       0.92      0.67      0.78      1385\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.86      0.88      0.86     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "Epoch 0: 8660 / 10000\n",
      "Accuracy = 86.60%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.8740942  0.99261311 0.96575342 0.85041551 0.90909091 0.98073836\n",
      " 0.96509009 0.97184987 0.83747412 0.56228172]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.93      1104\n",
      "           1       0.95      0.99      0.97      1083\n",
      "           2       0.82      0.97      0.89       876\n",
      "           3       0.91      0.85      0.88      1083\n",
      "           4       0.85      0.91      0.88       913\n",
      "           5       0.68      0.98      0.81       623\n",
      "           6       0.89      0.97      0.93       888\n",
      "           7       0.71      0.97      0.82       746\n",
      "           8       0.83      0.84      0.83       966\n",
      "           9       0.96      0.56      0.71      1718\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.89      0.86     10000\n",
      "weighted avg       0.88      0.86      0.86     10000\n",
      "\n",
      "Epoch 1: 8605 / 10000\n",
      "Accuracy = 86.05%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.77964744 0.99519231 0.97162316 0.91117764 0.89065606 0.98407643\n",
      " 0.97793264 0.9734104  0.78979771 0.69369369]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87      1248\n",
      "           1       0.91      1.00      0.95      1040\n",
      "           2       0.83      0.97      0.89       881\n",
      "           3       0.90      0.91      0.91      1002\n",
      "           4       0.91      0.89      0.90      1006\n",
      "           5       0.69      0.98      0.81       628\n",
      "           6       0.88      0.98      0.93       861\n",
      "           7       0.82      0.97      0.89       865\n",
      "           8       0.92      0.79      0.85      1137\n",
      "           9       0.92      0.69      0.79      1332\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "Epoch 2: 8797 / 10000\n",
      "Accuracy = 87.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.80264244 0.99172794 0.96112311 0.93390192 0.91167812 0.98726115\n",
      " 0.96491228 0.97807552 0.78373702 0.71483474]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      1211\n",
      "           1       0.95      0.99      0.97      1088\n",
      "           2       0.86      0.96      0.91       926\n",
      "           3       0.87      0.93      0.90       938\n",
      "           4       0.95      0.91      0.93      1019\n",
      "           5       0.70      0.99      0.82       628\n",
      "           6       0.92      0.96      0.94       912\n",
      "           7       0.78      0.98      0.87       821\n",
      "           8       0.93      0.78      0.85      1156\n",
      "           9       0.92      0.71      0.81      1301\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 3: 8885 / 10000\n",
      "Accuracy = 88.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85777385 0.99531396 0.96479648 0.91510365 0.9260385  0.98176292\n",
      " 0.95891892 0.98305085 0.78979239 0.70761115]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1132\n",
      "           1       0.94      1.00      0.96      1067\n",
      "           2       0.85      0.96      0.90       909\n",
      "           3       0.92      0.92      0.92      1013\n",
      "           4       0.93      0.93      0.93       987\n",
      "           5       0.72      0.98      0.83       658\n",
      "           6       0.93      0.96      0.94       925\n",
      "           7       0.79      0.98      0.88       826\n",
      "           8       0.94      0.79      0.86      1156\n",
      "           9       0.93      0.71      0.80      1327\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.91      0.89     10000\n",
      "weighted avg       0.90      0.89      0.89     10000\n",
      "\n",
      "Epoch 4: 8948 / 10000\n",
      "Accuracy = 89.48%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.85701677 0.99162011 0.96034298 0.919      0.85868587 0.9910045\n",
      " 0.97315436 0.97192982 0.80123675 0.74104913]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1133\n",
      "           1       0.94      0.99      0.96      1074\n",
      "           2       0.87      0.96      0.91       933\n",
      "           3       0.91      0.92      0.91      1000\n",
      "           4       0.97      0.86      0.91      1111\n",
      "           5       0.74      0.99      0.85       667\n",
      "           6       0.91      0.97      0.94       894\n",
      "           7       0.81      0.97      0.88       855\n",
      "           8       0.93      0.80      0.86      1132\n",
      "           9       0.88      0.74      0.81      1201\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.89      0.91      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 5: 8964 / 10000\n",
      "Accuracy = 89.64%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81841216 0.99337748 0.96861472 0.93839836 0.89721422 0.98843931\n",
      " 0.95991333 0.98646617 0.79221927 0.65933286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1184\n",
      "           1       0.93      0.99      0.96      1057\n",
      "           2       0.87      0.97      0.92       924\n",
      "           3       0.90      0.94      0.92       974\n",
      "           4       0.95      0.90      0.92      1041\n",
      "           5       0.77      0.99      0.86       692\n",
      "           6       0.92      0.96      0.94       923\n",
      "           7       0.64      0.99      0.77       665\n",
      "           8       0.92      0.79      0.85      1131\n",
      "           9       0.92      0.66      0.77      1409\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.90      0.88     10000\n",
      "weighted avg       0.90      0.88      0.88     10000\n",
      "\n",
      "Epoch 6: 8813 / 10000\n",
      "Accuracy = 88.13%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.77857714 0.99267399 0.95670539 0.9079334  0.78747941 0.9953125\n",
      " 0.97635934 0.98639456 0.89006342 0.65366972]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87      1251\n",
      "           1       0.96      0.99      0.97      1092\n",
      "           2       0.88      0.96      0.92       947\n",
      "           3       0.92      0.91      0.91      1021\n",
      "           4       0.97      0.79      0.87      1214\n",
      "           5       0.71      1.00      0.83       640\n",
      "           6       0.86      0.98      0.92       846\n",
      "           7       0.71      0.99      0.82       735\n",
      "           8       0.86      0.89      0.88       946\n",
      "           9       0.85      0.65      0.74      1308\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.87     10000\n",
      "weighted avg       0.89      0.87      0.87     10000\n",
      "\n",
      "Epoch 7: 8732 / 10000\n",
      "Accuracy = 87.32%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.76656151 0.99204771 0.97013274 0.94968553 0.85470852 0.99380805\n",
      " 0.96457143 0.98738966 0.78005343 0.68161094]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.86      1268\n",
      "           1       0.88      0.99      0.93      1006\n",
      "           2       0.85      0.97      0.91       904\n",
      "           3       0.90      0.95      0.92       954\n",
      "           4       0.97      0.85      0.91      1115\n",
      "           5       0.72      0.99      0.83       646\n",
      "           6       0.88      0.96      0.92       875\n",
      "           7       0.76      0.99      0.86       793\n",
      "           8       0.90      0.78      0.84      1123\n",
      "           9       0.89      0.68      0.77      1316\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.88     10000\n",
      "weighted avg       0.89      0.87      0.87     10000\n",
      "\n",
      "Epoch 8: 8748 / 10000\n",
      "Accuracy = 87.48%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.77494014 0.99064546 0.96495071 0.96038544 0.78083333 0.99148936\n",
      " 0.96759777 0.98529412 0.78779599 0.66582278]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.87      1253\n",
      "           1       0.93      0.99      0.96      1069\n",
      "           2       0.85      0.96      0.91       913\n",
      "           3       0.89      0.96      0.92       934\n",
      "           4       0.95      0.78      0.86      1200\n",
      "           5       0.78      0.99      0.88       705\n",
      "           6       0.90      0.97      0.93       895\n",
      "           7       0.72      0.99      0.83       748\n",
      "           8       0.89      0.79      0.83      1098\n",
      "           9       0.78      0.67      0.72      1185\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.87      0.89      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "Epoch 9: 8701 / 10000\n",
      "Accuracy = 87.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.82318105 0.99339623 0.97590361 0.94467213 0.75157729 0.99117647\n",
      " 0.96241458 0.97664071 0.84123911 0.7389739 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1182\n",
      "           1       0.93      0.99      0.96      1060\n",
      "           2       0.86      0.98      0.92       913\n",
      "           3       0.91      0.94      0.93       976\n",
      "           4       0.97      0.75      0.85      1268\n",
      "           5       0.76      0.99      0.86       680\n",
      "           6       0.88      0.96      0.92       878\n",
      "           7       0.85      0.98      0.91       899\n",
      "           8       0.89      0.84      0.87      1033\n",
      "           9       0.81      0.74      0.77      1111\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.89      0.90      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Epoch 10: 8879 / 10000\n",
      "Accuracy = 88.79%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.79672131 0.99067164 0.97544643 0.96059638 0.75216365 0.98959881\n",
      " 0.96547884 0.98043478 0.79818182 0.76755687]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88      1220\n",
      "           1       0.94      0.99      0.96      1072\n",
      "           2       0.85      0.98      0.91       896\n",
      "           3       0.89      0.96      0.93       939\n",
      "           4       0.97      0.75      0.85      1271\n",
      "           5       0.75      0.99      0.85       673\n",
      "           6       0.91      0.97      0.93       898\n",
      "           7       0.88      0.98      0.93       920\n",
      "           8       0.90      0.80      0.85      1100\n",
      "           9       0.77      0.77      0.77      1011\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10000\n",
      "   macro avg       0.88      0.90      0.89     10000\n",
      "weighted avg       0.89      0.89      0.88     10000\n",
      "\n",
      "Epoch 11: 8855 / 10000\n",
      "Accuracy = 88.55%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.81338912 0.99081726 0.96166134 0.94201424 0.7912179  0.99012694\n",
      " 0.9609375  0.97986577 0.84494603 0.78016838]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      1195\n",
      "           1       0.95      0.99      0.97      1089\n",
      "           2       0.88      0.96      0.92       939\n",
      "           3       0.92      0.94      0.93       983\n",
      "           4       0.97      0.79      0.87      1207\n",
      "           5       0.79      0.99      0.88       709\n",
      "           6       0.90      0.96      0.93       896\n",
      "           7       0.85      0.98      0.91       894\n",
      "           8       0.88      0.84      0.86      1019\n",
      "           9       0.83      0.78      0.80      1069\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.90      0.91      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Epoch 12: 8969 / 10000\n",
      "Accuracy = 89.69%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.76295133 0.99513619 0.96801706 0.939      0.50586354 0.99411765\n",
      " 0.9631829  0.98087739 0.79339623 0.53026634]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86      1274\n",
      "           1       0.90      1.00      0.95      1028\n",
      "           2       0.88      0.97      0.92       938\n",
      "           3       0.93      0.94      0.93      1000\n",
      "           4       0.97      0.51      0.66      1876\n",
      "           5       0.76      0.99      0.86       680\n",
      "           6       0.85      0.96      0.90       842\n",
      "           7       0.85      0.98      0.91       889\n",
      "           8       0.86      0.79      0.83      1060\n",
      "           9       0.22      0.53      0.31       413\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.84      0.81     10000\n",
      "weighted avg       0.87      0.82      0.83     10000\n",
      "\n",
      "Epoch 13: 8210 / 10000\n",
      "Accuracy = 82.10%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.75251353 0.99261993 0.96861472 0.93406593 0.52236334 0.99019608\n",
      " 0.96376812 0.97542735 0.84932921 0.64772727]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.86      1293\n",
      "           1       0.95      0.99      0.97      1084\n",
      "           2       0.87      0.97      0.92       924\n",
      "           3       0.93      0.93      0.93      1001\n",
      "           4       0.96      0.52      0.68      1811\n",
      "           5       0.79      0.99      0.88       714\n",
      "           6       0.83      0.96      0.89       828\n",
      "           7       0.89      0.98      0.93       936\n",
      "           8       0.84      0.85      0.85       969\n",
      "           9       0.28      0.65      0.39       440\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.83      0.86      0.83     10000\n",
      "weighted avg       0.88      0.84      0.84     10000\n",
      "\n",
      "Epoch 14: 8351 / 10000\n",
      "Accuracy = 83.51%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.75096376 0.99255121 0.96851249 0.95564942 0.52894885 0.97574124\n",
      " 0.9625731  0.97529538 0.80187793 0.6092545 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.86      1297\n",
      "           1       0.94      0.99      0.97      1074\n",
      "           2       0.86      0.97      0.91       921\n",
      "           3       0.90      0.96      0.92       947\n",
      "           4       0.96      0.53      0.68      1779\n",
      "           5       0.81      0.98      0.89       742\n",
      "           6       0.86      0.96      0.91       855\n",
      "           7       0.88      0.98      0.93       931\n",
      "           8       0.88      0.80      0.84      1065\n",
      "           9       0.23      0.61      0.34       389\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.85      0.82     10000\n",
      "weighted avg       0.88      0.83      0.84     10000\n",
      "\n",
      "Epoch 15: 8324 / 10000\n",
      "Accuracy = 83.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.74923077 0.99358387 0.97345133 0.93260654 0.4981608  0.98309859\n",
      " 0.96432818 0.97033898 0.81800391 0.61594203]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85      1300\n",
      "           1       0.96      0.99      0.97      1091\n",
      "           2       0.85      0.97      0.91       904\n",
      "           3       0.93      0.93      0.93      1009\n",
      "           4       0.97      0.50      0.66      1903\n",
      "           5       0.78      0.98      0.87       710\n",
      "           6       0.85      0.96      0.90       841\n",
      "           7       0.89      0.97      0.93       944\n",
      "           8       0.86      0.82      0.84      1022\n",
      "           9       0.17      0.62      0.26       276\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.82      0.85      0.81     10000\n",
      "weighted avg       0.89      0.83      0.84     10000\n",
      "\n",
      "Epoch 16: 8258 / 10000\n",
      "Accuracy = 82.58%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.70266379 0.99351251 0.9765625  0.96777658 0.51226158 0.97596796\n",
      " 0.96597813 0.9789357  0.78477444 0.63855422]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82      1389\n",
      "           1       0.94      0.99      0.97      1079\n",
      "           2       0.85      0.98      0.91       896\n",
      "           3       0.89      0.97      0.93       931\n",
      "           4       0.96      0.51      0.67      1835\n",
      "           5       0.82      0.98      0.89       749\n",
      "           6       0.83      0.97      0.89       823\n",
      "           7       0.86      0.98      0.92       902\n",
      "           8       0.86      0.78      0.82      1064\n",
      "           9       0.21      0.64      0.32       332\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.81     10000\n",
      "weighted avg       0.88      0.82      0.83     10000\n",
      "\n",
      "Epoch 17: 8220 / 10000\n",
      "Accuracy = 82.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.71681416 0.99092559 0.97835991 0.94242424 0.47961264 0.98639456\n",
      " 0.96278511 0.9769989  0.84733607 0.56862745]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.72      0.83      1356\n",
      "           1       0.96      0.99      0.98      1102\n",
      "           2       0.83      0.98      0.90       878\n",
      "           3       0.92      0.94      0.93       990\n",
      "           4       0.96      0.48      0.64      1962\n",
      "           5       0.81      0.99      0.89       735\n",
      "           6       0.84      0.96      0.90       833\n",
      "           7       0.87      0.98      0.92       913\n",
      "           8       0.85      0.85      0.85       976\n",
      "           9       0.14      0.57      0.23       255\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.85      0.81     10000\n",
      "weighted avg       0.89      0.82      0.83     10000\n",
      "\n",
      "Epoch 18: 8188 / 10000\n",
      "Accuracy = 81.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.72135994 0.99259259 0.97155361 0.94843276 0.4685176  0.98433048\n",
      " 0.96981132 0.97590361 0.83165323 0.55918367]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84      1353\n",
      "           1       0.94      0.99      0.97      1080\n",
      "           2       0.86      0.97      0.91       914\n",
      "           3       0.93      0.95      0.94       989\n",
      "           4       0.96      0.47      0.63      2017\n",
      "           5       0.77      0.98      0.87       702\n",
      "           6       0.80      0.97      0.88       795\n",
      "           7       0.87      0.98      0.92       913\n",
      "           8       0.85      0.83      0.84       992\n",
      "           9       0.14      0.56      0.22       245\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.84      0.80     10000\n",
      "weighted avg       0.89      0.81      0.82     10000\n",
      "\n",
      "Epoch 19: 8134 / 10000\n",
      "Accuracy = 81.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.68178646 0.99085923 0.98206278 0.94041708 0.49392499 0.98559078\n",
      " 0.96867168 0.97613883 0.82706002 0.54577465]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81      1433\n",
      "           1       0.96      0.99      0.97      1094\n",
      "           2       0.85      0.98      0.91       892\n",
      "           3       0.94      0.94      0.94      1007\n",
      "           4       0.95      0.49      0.65      1893\n",
      "           5       0.77      0.99      0.86       694\n",
      "           6       0.81      0.97      0.88       798\n",
      "           7       0.88      0.98      0.92       922\n",
      "           8       0.83      0.83      0.83       983\n",
      "           9       0.15      0.55      0.24       284\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.84      0.80     10000\n",
      "weighted avg       0.88      0.81      0.83     10000\n",
      "\n",
      "Epoch 20: 8144 / 10000\n",
      "Accuracy = 81.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.60123077 0.9918552  0.98290598 0.94472362 0.48115183 0.98369565\n",
      " 0.96827411 0.97888889 0.83990981 0.5787234 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75      1625\n",
      "           1       0.97      0.99      0.98      1105\n",
      "           2       0.78      0.98      0.87       819\n",
      "           3       0.93      0.94      0.94       995\n",
      "           4       0.94      0.48      0.64      1910\n",
      "           5       0.81      0.98      0.89       736\n",
      "           6       0.80      0.97      0.87       788\n",
      "           7       0.86      0.98      0.91       900\n",
      "           8       0.76      0.84      0.80       887\n",
      "           9       0.13      0.58      0.22       235\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.84      0.79     10000\n",
      "weighted avg       0.87      0.80      0.81     10000\n",
      "\n",
      "Epoch 21: 7986 / 10000\n",
      "Accuracy = 79.86%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.69670959 0.99166667 0.97902098 0.93141153 0.48107017 0.98092643\n",
      " 0.95449102 0.96972973 0.82072539 0.57798165]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82      1398\n",
      "           1       0.94      0.99      0.97      1080\n",
      "           2       0.81      0.98      0.89       858\n",
      "           3       0.93      0.93      0.93      1006\n",
      "           4       0.97      0.48      0.64      1981\n",
      "           5       0.81      0.98      0.89       734\n",
      "           6       0.83      0.95      0.89       835\n",
      "           7       0.87      0.97      0.92       925\n",
      "           8       0.81      0.82      0.82       965\n",
      "           9       0.12      0.58      0.21       218\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.84      0.80     10000\n",
      "weighted avg       0.89      0.81      0.82     10000\n",
      "\n",
      "Epoch 22: 8107 / 10000\n",
      "Accuracy = 81.07%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.64186965 0.98984303 0.98045977 0.93452381 0.46955209 0.98950525\n",
      " 0.96488947 0.97084233 0.82640333 0.55980861]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.78      1519\n",
      "           1       0.94      0.99      0.97      1083\n",
      "           2       0.83      0.98      0.90       870\n",
      "           3       0.93      0.93      0.93      1008\n",
      "           4       0.95      0.47      0.63      1987\n",
      "           5       0.74      0.99      0.85       667\n",
      "           6       0.77      0.96      0.86       769\n",
      "           7       0.87      0.97      0.92       926\n",
      "           8       0.82      0.83      0.82       962\n",
      "           9       0.12      0.56      0.19       209\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.83      0.78     10000\n",
      "weighted avg       0.88      0.80      0.81     10000\n",
      "\n",
      "Epoch 23: 7988 / 10000\n",
      "Accuracy = 79.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.68443198 0.98822464 0.98181818 0.89690722 0.46600496 0.98011364\n",
      " 0.95915679 0.97916667 0.84649123 0.59276018]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81      1426\n",
      "           1       0.96      0.99      0.97      1104\n",
      "           2       0.84      0.98      0.90       880\n",
      "           3       0.95      0.90      0.92      1067\n",
      "           4       0.96      0.47      0.63      2015\n",
      "           5       0.77      0.98      0.86       704\n",
      "           6       0.76      0.96      0.85       759\n",
      "           7       0.87      0.98      0.92       912\n",
      "           8       0.79      0.85      0.82       912\n",
      "           9       0.13      0.59      0.21       221\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.84      0.79     10000\n",
      "weighted avg       0.88      0.80      0.82     10000\n",
      "\n",
      "Epoch 24: 8041 / 10000\n",
      "Accuracy = 80.41%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.68469101 0.99090082 0.9871345  0.90648855 0.47000496 0.98850575\n",
      " 0.95558376 0.9715847  0.81276151 0.62376238]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81      1424\n",
      "           1       0.96      0.99      0.97      1099\n",
      "           2       0.82      0.99      0.89       855\n",
      "           3       0.94      0.91      0.92      1048\n",
      "           4       0.97      0.47      0.63      2017\n",
      "           5       0.77      0.99      0.87       696\n",
      "           6       0.79      0.96      0.86       788\n",
      "           7       0.86      0.97      0.92       915\n",
      "           8       0.80      0.81      0.81       956\n",
      "           9       0.12      0.62      0.21       202\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.84      0.79     10000\n",
      "weighted avg       0.88      0.80      0.82     10000\n",
      "\n",
      "Epoch 25: 8039 / 10000\n",
      "Accuracy = 80.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.66507503 0.98912058 0.98281787 0.93020937 0.47424242 0.97913769\n",
      " 0.95869837 0.97186147 0.83443709 0.59471366]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80      1466\n",
      "           1       0.96      0.99      0.97      1103\n",
      "           2       0.83      0.98      0.90       873\n",
      "           3       0.92      0.93      0.93      1003\n",
      "           4       0.96      0.47      0.63      1980\n",
      "           5       0.79      0.98      0.87       719\n",
      "           6       0.80      0.96      0.87       799\n",
      "           7       0.87      0.97      0.92       924\n",
      "           8       0.78      0.83      0.80       906\n",
      "           9       0.13      0.59      0.22       227\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.80      0.84      0.79     10000\n",
      "weighted avg       0.88      0.81      0.82     10000\n",
      "\n",
      "Epoch 26: 8055 / 10000\n",
      "Accuracy = 80.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.65153538 0.98823529 0.97703789 0.93850806 0.47011145 0.96714849\n",
      " 0.96291718 0.9767184  0.84078517 0.65497076]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79      1498\n",
      "           1       0.96      0.99      0.97      1105\n",
      "           2       0.82      0.98      0.89       871\n",
      "           3       0.92      0.94      0.93       992\n",
      "           4       0.95      0.47      0.63      1974\n",
      "           5       0.83      0.97      0.89       761\n",
      "           6       0.81      0.96      0.88       809\n",
      "           7       0.86      0.98      0.91       902\n",
      "           8       0.79      0.84      0.82       917\n",
      "           9       0.11      0.65      0.19       171\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.80      0.84      0.79     10000\n",
      "weighted avg       0.89      0.81      0.82     10000\n",
      "\n",
      "Epoch 27: 8057 / 10000\n",
      "Accuracy = 80.57%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.64361001 0.98820327 0.98265896 0.92920354 0.47727273 0.97490092\n",
      " 0.96534653 0.97152245 0.84623894 0.67222222]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78      1518\n",
      "           1       0.96      0.99      0.97      1102\n",
      "           2       0.82      0.98      0.90       865\n",
      "           3       0.94      0.93      0.93      1017\n",
      "           4       0.94      0.48      0.63      1936\n",
      "           5       0.83      0.97      0.90       757\n",
      "           6       0.81      0.97      0.88       808\n",
      "           7       0.86      0.97      0.91       913\n",
      "           8       0.79      0.85      0.81       904\n",
      "           9       0.12      0.67      0.20       180\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.85      0.79     10000\n",
      "weighted avg       0.89      0.81      0.82     10000\n",
      "\n",
      "Epoch 28: 8076 / 10000\n",
      "Accuracy = 80.76%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.56744186 0.98997265 0.97186401 0.94426919 0.45912263 0.9757085\n",
      " 0.95208071 0.98057143 0.81942715 0.62732919]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.72      1720\n",
      "           1       0.96      0.99      0.97      1097\n",
      "           2       0.80      0.97      0.88       853\n",
      "           3       0.89      0.94      0.92       951\n",
      "           4       0.94      0.46      0.62      2006\n",
      "           5       0.81      0.98      0.89       741\n",
      "           6       0.79      0.95      0.86       793\n",
      "           7       0.83      0.98      0.90       875\n",
      "           8       0.68      0.82      0.74       803\n",
      "           9       0.10      0.63      0.17       161\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.83      0.77     10000\n",
      "weighted avg       0.87      0.78      0.79     10000\n",
      "\n",
      "Epoch 29: 7805 / 10000\n",
      "Accuracy = 78.05%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.54333333 0.99263352 0.98175182 0.92477432 0.42931197 0.99141631\n",
      " 0.96035242 0.97303371 0.84553928 0.61842105]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.54      0.70      1800\n",
      "           1       0.95      0.99      0.97      1086\n",
      "           2       0.78      0.98      0.87       822\n",
      "           3       0.91      0.92      0.92       997\n",
      "           4       0.93      0.43      0.59      2122\n",
      "           5       0.78      0.99      0.87       699\n",
      "           6       0.68      0.96      0.80       681\n",
      "           7       0.84      0.97      0.90       890\n",
      "           8       0.65      0.85      0.74       751\n",
      "           9       0.09      0.62      0.16       152\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.83      0.75     10000\n",
      "weighted avg       0.86      0.76      0.77     10000\n",
      "\n",
      "Epoch 30: 7638 / 10000\n",
      "Accuracy = 76.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.59259259 0.99097473 0.97701149 0.93476045 0.42095672 0.98055556\n",
      " 0.94429348 0.97425997 0.83333333 0.61111111]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.59      0.74      1647\n",
      "           1       0.97      0.99      0.98      1108\n",
      "           2       0.82      0.98      0.89       870\n",
      "           3       0.91      0.93      0.92       981\n",
      "           4       0.94      0.42      0.58      2195\n",
      "           5       0.79      0.98      0.88       720\n",
      "           6       0.73      0.94      0.82       736\n",
      "           7       0.74      0.97      0.84       777\n",
      "           8       0.70      0.83      0.76       822\n",
      "           9       0.09      0.61      0.15       144\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.77      0.83      0.76     10000\n",
      "weighted avg       0.87      0.77      0.78     10000\n",
      "\n",
      "Epoch 31: 7696 / 10000\n",
      "Accuracy = 76.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.60160099 0.99091735 0.97800926 0.90847784 0.43779904 0.98214286\n",
      " 0.95061728 0.97374429 0.85308642 0.60714286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75      1624\n",
      "           1       0.96      0.99      0.98      1101\n",
      "           2       0.82      0.98      0.89       864\n",
      "           3       0.93      0.91      0.92      1038\n",
      "           4       0.93      0.44      0.60      2090\n",
      "           5       0.80      0.98      0.88       728\n",
      "           6       0.72      0.95      0.82       729\n",
      "           7       0.83      0.97      0.90       876\n",
      "           8       0.71      0.85      0.77       810\n",
      "           9       0.08      0.61      0.15       140\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.83      0.77     10000\n",
      "weighted avg       0.87      0.78      0.79     10000\n",
      "\n",
      "Epoch 32: 7808 / 10000\n",
      "Accuracy = 78.08%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.56959814 0.99184044 0.97921478 0.92719919 0.46632911 0.9776848\n",
      " 0.96197719 0.96896552 0.81398104 0.66153846]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73      1717\n",
      "           1       0.96      0.99      0.98      1103\n",
      "           2       0.82      0.98      0.89       866\n",
      "           3       0.91      0.93      0.92       989\n",
      "           4       0.94      0.47      0.62      1975\n",
      "           5       0.79      0.98      0.87       717\n",
      "           6       0.79      0.96      0.87       789\n",
      "           7       0.82      0.97      0.89       870\n",
      "           8       0.71      0.81      0.76       844\n",
      "           9       0.09      0.66      0.15       130\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.83      0.77     10000\n",
      "weighted avg       0.87      0.78      0.80     10000\n",
      "\n",
      "Epoch 33: 7834 / 10000\n",
      "Accuracy = 78.34%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.57209848 0.99172033 0.97655334 0.89367816 0.45653254 0.97066667\n",
      " 0.95816464 0.96536313 0.83550914 0.68965517]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73      1706\n",
      "           1       0.95      0.99      0.97      1087\n",
      "           2       0.81      0.98      0.88       853\n",
      "           3       0.92      0.89      0.91      1044\n",
      "           4       0.94      0.46      0.61      2013\n",
      "           5       0.82      0.97      0.89       750\n",
      "           6       0.74      0.96      0.84       741\n",
      "           7       0.84      0.97      0.90       895\n",
      "           8       0.66      0.84      0.74       766\n",
      "           9       0.10      0.69      0.17       145\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.83      0.76     10000\n",
      "weighted avg       0.87      0.78      0.79     10000\n",
      "\n",
      "Epoch 34: 7781 / 10000\n",
      "Accuracy = 77.81%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.61243719 0.98827773 0.98457888 0.89453861 0.43417367 0.98470097\n",
      " 0.95081967 0.97674419 0.85324675 0.57309942]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.61      0.76      1592\n",
      "           1       0.97      0.99      0.98      1109\n",
      "           2       0.80      0.98      0.89       843\n",
      "           3       0.94      0.89      0.92      1062\n",
      "           4       0.95      0.43      0.60      2142\n",
      "           5       0.79      0.98      0.88       719\n",
      "           6       0.73      0.95      0.82       732\n",
      "           7       0.82      0.98      0.89       860\n",
      "           8       0.67      0.85      0.75       770\n",
      "           9       0.10      0.57      0.17       171\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.83      0.76     10000\n",
      "weighted avg       0.87      0.78      0.79     10000\n",
      "\n",
      "Epoch 35: 7780 / 10000\n",
      "Accuracy = 77.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.55448354 0.98918919 0.98104265 0.90909091 0.43950851 0.9667129\n",
      " 0.96503497 0.96412556 0.86266094 0.62790698]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71      1762\n",
      "           1       0.97      0.99      0.98      1110\n",
      "           2       0.80      0.98      0.88       844\n",
      "           3       0.91      0.91      0.91      1012\n",
      "           4       0.95      0.44      0.60      2116\n",
      "           5       0.78      0.97      0.86       721\n",
      "           6       0.72      0.97      0.82       715\n",
      "           7       0.84      0.96      0.90       892\n",
      "           8       0.62      0.86      0.72       699\n",
      "           9       0.08      0.63      0.14       129\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.77      0.83      0.75     10000\n",
      "weighted avg       0.87      0.77      0.78     10000\n",
      "\n",
      "Epoch 36: 7684 / 10000\n",
      "Accuracy = 76.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.56228374 0.98831986 0.97701149 0.92784553 0.40173913 0.97567954\n",
      " 0.95416667 0.96442688 0.83633842 0.56      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.56      0.72      1734\n",
      "           1       0.97      0.99      0.98      1113\n",
      "           2       0.82      0.98      0.89       870\n",
      "           3       0.90      0.93      0.92       984\n",
      "           4       0.94      0.40      0.56      2300\n",
      "           5       0.76      0.98      0.86       699\n",
      "           6       0.72      0.95      0.82       720\n",
      "           7       0.71      0.96      0.82       759\n",
      "           8       0.62      0.84      0.71       721\n",
      "           9       0.06      0.56      0.10       100\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.81      0.74     10000\n",
      "weighted avg       0.86      0.75      0.76     10000\n",
      "\n",
      "Epoch 37: 7522 / 10000\n",
      "Accuracy = 75.22%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.55568182 0.98651079 0.98448687 0.89941973 0.4367654  0.97043011\n",
      " 0.95867769 0.97613065 0.81843575 0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.71      1760\n",
      "           1       0.97      0.99      0.98      1112\n",
      "           2       0.80      0.98      0.88       838\n",
      "           3       0.92      0.90      0.91      1034\n",
      "           4       0.95      0.44      0.60      2127\n",
      "           5       0.81      0.97      0.88       744\n",
      "           6       0.73      0.96      0.83       726\n",
      "           7       0.76      0.98      0.85       796\n",
      "           8       0.60      0.82      0.69       716\n",
      "           9       0.10      0.67      0.17       147\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.76      0.83      0.75     10000\n",
      "weighted avg       0.86      0.76      0.78     10000\n",
      "\n",
      "Epoch 38: 7638 / 10000\n",
      "Accuracy = 76.38%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.58418214 0.98907104 0.98146002 0.89714286 0.44411908 0.98595506\n",
      " 0.93982074 0.97477932 0.79465371 0.67283951]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.58      0.74      1669\n",
      "           1       0.96      0.99      0.97      1098\n",
      "           2       0.82      0.98      0.89       863\n",
      "           3       0.93      0.90      0.91      1050\n",
      "           4       0.93      0.44      0.60      2049\n",
      "           5       0.79      0.99      0.88       712\n",
      "           6       0.77      0.94      0.84       781\n",
      "           7       0.75      0.97      0.85       793\n",
      "           8       0.67      0.79      0.73       823\n",
      "           9       0.11      0.67      0.19       162\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.77      0.83      0.76     10000\n",
      "weighted avg       0.86      0.77      0.78     10000\n",
      "\n",
      "Epoch 39: 7732 / 10000\n",
      "Accuracy = 77.32%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.57369348 0.98917944 0.98352941 0.88512241 0.40097045 0.9787234\n",
      " 0.94344828 0.97192513 0.86221591 0.60629921]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73      1703\n",
      "           1       0.97      0.99      0.98      1109\n",
      "           2       0.81      0.98      0.89       850\n",
      "           3       0.93      0.89      0.91      1062\n",
      "           4       0.93      0.40      0.56      2267\n",
      "           5       0.77      0.98      0.86       705\n",
      "           6       0.71      0.94      0.81       725\n",
      "           7       0.71      0.97      0.82       748\n",
      "           8       0.62      0.86      0.72       704\n",
      "           9       0.08      0.61      0.14       127\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.82      0.74     10000\n",
      "weighted avg       0.86      0.75      0.76     10000\n",
      "\n",
      "Epoch 40: 7544 / 10000\n",
      "Accuracy = 75.44%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.57001167 0.99008115 0.98163031 0.89483748 0.40069991 0.9789916\n",
      " 0.95921238 0.9715505  0.86239782 0.66071429]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73      1714\n",
      "           1       0.97      0.99      0.98      1109\n",
      "           2       0.83      0.98      0.90       871\n",
      "           3       0.93      0.89      0.91      1046\n",
      "           4       0.93      0.40      0.56      2286\n",
      "           5       0.78      0.98      0.87       714\n",
      "           6       0.71      0.96      0.82       711\n",
      "           7       0.66      0.97      0.79       703\n",
      "           8       0.65      0.86      0.74       734\n",
      "           9       0.07      0.66      0.13       112\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.75      0.83      0.74     10000\n",
      "weighted avg       0.86      0.76      0.77     10000\n",
      "\n",
      "Epoch 41: 7553 / 10000\n",
      "Accuracy = 75.53%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.60197166 0.98831986 0.97212544 0.85714286 0.39686684 0.95339547\n",
      " 0.95944056 0.97038082 0.88210818 0.6       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75      1623\n",
      "           1       0.97      0.99      0.98      1113\n",
      "           2       0.81      0.97      0.88       861\n",
      "           3       0.93      0.86      0.89      1099\n",
      "           4       0.93      0.40      0.56      2298\n",
      "           5       0.80      0.95      0.87       751\n",
      "           6       0.72      0.96      0.82       715\n",
      "           7       0.67      0.97      0.79       709\n",
      "           8       0.65      0.88      0.75       721\n",
      "           9       0.07      0.60      0.12       110\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.75      0.82      0.74     10000\n",
      "weighted avg       0.86      0.76      0.77     10000\n",
      "\n",
      "Epoch 42: 7560 / 10000\n",
      "Accuracy = 75.60%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.56695652 0.98567592 0.98261877 0.90536585 0.40377028 0.97361111\n",
      " 0.96242775 0.97087379 0.84090909 0.7037037 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.72      1725\n",
      "           1       0.97      0.99      0.98      1117\n",
      "           2       0.82      0.98      0.89       863\n",
      "           3       0.92      0.91      0.91      1025\n",
      "           4       0.94      0.40      0.56      2281\n",
      "           5       0.79      0.97      0.87       720\n",
      "           6       0.70      0.96      0.81       692\n",
      "           7       0.68      0.97      0.80       721\n",
      "           8       0.65      0.84      0.73       748\n",
      "           9       0.08      0.70      0.14       108\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.83      0.74     10000\n",
      "weighted avg       0.86      0.75      0.77     10000\n",
      "\n",
      "Epoch 43: 7548 / 10000\n",
      "Accuracy = 75.48%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.57025761 0.99012567 0.97719498 0.88761905 0.39147287 0.95967742\n",
      " 0.95305832 0.97375691 0.87481371 0.6091954 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.57      0.72      1708\n",
      "           1       0.97      0.99      0.98      1114\n",
      "           2       0.83      0.98      0.90       877\n",
      "           3       0.92      0.89      0.90      1050\n",
      "           4       0.93      0.39      0.55      2322\n",
      "           5       0.80      0.96      0.87       744\n",
      "           6       0.70      0.95      0.81       703\n",
      "           7       0.69      0.97      0.80       724\n",
      "           8       0.60      0.87      0.71       671\n",
      "           9       0.05      0.61      0.10        87\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.82      0.74     10000\n",
      "weighted avg       0.86      0.75      0.76     10000\n",
      "\n",
      "Epoch 44: 7504 / 10000\n",
      "Accuracy = 75.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.53622393 0.98652291 0.98249708 0.87855787 0.37873056 0.97323944\n",
      " 0.95129376 0.97262248 0.84109149 0.59340659]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.54      0.70      1822\n",
      "           1       0.97      0.99      0.98      1113\n",
      "           2       0.82      0.98      0.89       857\n",
      "           3       0.92      0.88      0.90      1054\n",
      "           4       0.92      0.38      0.54      2379\n",
      "           5       0.77      0.97      0.86       710\n",
      "           6       0.65      0.95      0.77       657\n",
      "           7       0.66      0.97      0.78       694\n",
      "           8       0.54      0.84      0.66       623\n",
      "           9       0.05      0.59      0.10        91\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.81      0.72     10000\n",
      "weighted avg       0.85      0.73      0.74     10000\n",
      "\n",
      "Epoch 45: 7313 / 10000\n",
      "Accuracy = 73.13%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.51970181 0.98480786 0.98658537 0.87276155 0.4064781  0.97230321\n",
      " 0.94759207 0.95827901 0.86384977 0.67424242]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.52      0.68      1878\n",
      "           1       0.97      0.98      0.98      1119\n",
      "           2       0.78      0.99      0.87       820\n",
      "           3       0.92      0.87      0.89      1061\n",
      "           4       0.91      0.41      0.56      2192\n",
      "           5       0.75      0.97      0.85       686\n",
      "           6       0.70      0.95      0.80       706\n",
      "           7       0.71      0.96      0.82       767\n",
      "           8       0.57      0.86      0.68       639\n",
      "           9       0.09      0.67      0.16       132\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.74      0.82      0.73     10000\n",
      "weighted avg       0.85      0.74      0.75     10000\n",
      "\n",
      "Epoch 46: 7416 / 10000\n",
      "Accuracy = 74.16%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.55354108 0.98829883 0.98245614 0.86611265 0.40921409 0.97226075\n",
      " 0.94910591 0.97323944 0.85931034 0.61797753]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71      1765\n",
      "           1       0.97      0.99      0.98      1111\n",
      "           2       0.81      0.98      0.89       855\n",
      "           3       0.93      0.87      0.90      1083\n",
      "           4       0.92      0.41      0.57      2214\n",
      "           5       0.79      0.97      0.87       721\n",
      "           6       0.72      0.95      0.82       727\n",
      "           7       0.67      0.97      0.80       710\n",
      "           8       0.64      0.86      0.73       725\n",
      "           9       0.05      0.62      0.10        89\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     10000\n",
      "   macro avg       0.75      0.82      0.74     10000\n",
      "weighted avg       0.86      0.75      0.77     10000\n",
      "\n",
      "Epoch 47: 7519 / 10000\n",
      "Accuracy = 75.19%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.49796126 0.98490231 0.97303634 0.88104449 0.40795353 0.96460177\n",
      " 0.94660895 0.96159122 0.86363636 0.7311828 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.66      1962\n",
      "           1       0.98      0.98      0.98      1126\n",
      "           2       0.80      0.97      0.88       853\n",
      "           3       0.90      0.88      0.89      1034\n",
      "           4       0.93      0.41      0.57      2238\n",
      "           5       0.73      0.96      0.83       678\n",
      "           6       0.68      0.95      0.79       693\n",
      "           7       0.68      0.96      0.80       729\n",
      "           8       0.53      0.86      0.65       594\n",
      "           9       0.07      0.73      0.12        93\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.82      0.72     10000\n",
      "weighted avg       0.85      0.73      0.74     10000\n",
      "\n",
      "Epoch 48: 7332 / 10000\n",
      "Accuracy = 73.32%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.53986711 0.98835125 0.97914253 0.89178744 0.38830013 0.97105644\n",
      " 0.95216741 0.96438356 0.85602504 0.69565217]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.54      0.70      1806\n",
      "           1       0.97      0.99      0.98      1116\n",
      "           2       0.82      0.98      0.89       863\n",
      "           3       0.91      0.89      0.90      1035\n",
      "           4       0.93      0.39      0.55      2359\n",
      "           5       0.75      0.97      0.85       691\n",
      "           6       0.66      0.95      0.78       669\n",
      "           7       0.68      0.96      0.80       730\n",
      "           8       0.56      0.86      0.68       639\n",
      "           9       0.06      0.70      0.12        92\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     10000\n",
      "   macro avg       0.74      0.82      0.72     10000\n",
      "weighted avg       0.86      0.74      0.75     10000\n",
      "\n",
      "Epoch 49: 7385 / 10000\n",
      "Accuracy = 73.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.50752465 0.98741007 0.98095238 0.87295476 0.3862955  0.96740741\n",
      " 0.94314869 0.96746818 0.86463621 0.63636364]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.51      0.67      1927\n",
      "           1       0.97      0.99      0.98      1112\n",
      "           2       0.80      0.98      0.88       840\n",
      "           3       0.90      0.87      0.89      1039\n",
      "           4       0.92      0.39      0.54      2335\n",
      "           5       0.73      0.97      0.83       675\n",
      "           6       0.68      0.94      0.79       686\n",
      "           7       0.67      0.97      0.79       707\n",
      "           8       0.52      0.86      0.65       591\n",
      "           9       0.06      0.64      0.10        88\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.72      0.81      0.71     10000\n",
      "weighted avg       0.85      0.73      0.74     10000\n",
      "\n",
      "Epoch 50: 7260 / 10000\n",
      "Accuracy = 72.60%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.50256937 0.99101527 0.97748815 0.85239852 0.38101266 0.97352025\n",
      " 0.95495495 0.97458894 0.86130137 0.59756098]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67      1946\n",
      "           1       0.97      0.99      0.98      1113\n",
      "           2       0.80      0.98      0.88       844\n",
      "           3       0.91      0.85      0.88      1084\n",
      "           4       0.92      0.38      0.54      2370\n",
      "           5       0.70      0.97      0.81       642\n",
      "           6       0.66      0.95      0.78       666\n",
      "           7       0.63      0.97      0.77       669\n",
      "           8       0.52      0.86      0.65       584\n",
      "           9       0.05      0.60      0.09        82\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.81      0.71     10000\n",
      "weighted avg       0.85      0.72      0.73     10000\n",
      "\n",
      "Epoch 51: 7198 / 10000\n",
      "Accuracy = 71.98%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.49872514 0.98567592 0.9739645  0.85123967 0.3898232  0.9675425\n",
      " 0.94555874 0.96793003 0.87079646 0.67123288]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67      1961\n",
      "           1       0.97      0.99      0.98      1117\n",
      "           2       0.80      0.97      0.88       845\n",
      "           3       0.92      0.85      0.88      1089\n",
      "           4       0.92      0.39      0.55      2319\n",
      "           5       0.70      0.97      0.81       647\n",
      "           6       0.69      0.95      0.80       698\n",
      "           7       0.65      0.97      0.77       686\n",
      "           8       0.51      0.87      0.64       565\n",
      "           9       0.05      0.67      0.09        73\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.81      0.71     10000\n",
      "weighted avg       0.85      0.72      0.74     10000\n",
      "\n",
      "Epoch 52: 7224 / 10000\n",
      "Accuracy = 72.24%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.47406689 0.98742138 0.98086124 0.84831461 0.39749329 0.97909968\n",
      " 0.95049505 0.97308782 0.85537919 0.58333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.47      0.64      2063\n",
      "           1       0.97      0.99      0.98      1113\n",
      "           2       0.79      0.98      0.88       836\n",
      "           3       0.90      0.85      0.87      1068\n",
      "           4       0.90      0.40      0.55      2234\n",
      "           5       0.68      0.98      0.80       622\n",
      "           6       0.70      0.95      0.81       707\n",
      "           7       0.67      0.97      0.79       706\n",
      "           8       0.50      0.86      0.63       567\n",
      "           9       0.05      0.58      0.09        84\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.80      0.70     10000\n",
      "weighted avg       0.85      0.72      0.73     10000\n",
      "\n",
      "Epoch 53: 7193 / 10000\n",
      "Accuracy = 71.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.50412797 0.98567592 0.97450753 0.82562278 0.38944614 0.9591528\n",
      " 0.94314869 0.97205882 0.90036232 0.61627907]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67      1938\n",
      "           1       0.97      0.99      0.98      1117\n",
      "           2       0.81      0.97      0.89       863\n",
      "           3       0.92      0.83      0.87      1124\n",
      "           4       0.91      0.39      0.55      2293\n",
      "           5       0.71      0.96      0.82       661\n",
      "           6       0.68      0.94      0.79       686\n",
      "           7       0.64      0.97      0.77       680\n",
      "           8       0.51      0.90      0.65       552\n",
      "           9       0.05      0.62      0.10        86\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.81      0.71     10000\n",
      "weighted avg       0.85      0.72      0.74     10000\n",
      "\n",
      "Epoch 54: 7232 / 10000\n",
      "Accuracy = 72.32%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.51177394 0.98664292 0.98352941 0.84509624 0.39437229 0.96960486\n",
      " 0.94751773 0.97125567 0.87205387 0.64948454]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.51      0.68      1911\n",
      "           1       0.98      0.99      0.98      1123\n",
      "           2       0.81      0.98      0.89       850\n",
      "           3       0.91      0.85      0.88      1091\n",
      "           4       0.93      0.39      0.55      2310\n",
      "           5       0.72      0.97      0.82       658\n",
      "           6       0.70      0.95      0.80       705\n",
      "           7       0.62      0.97      0.76       661\n",
      "           8       0.53      0.87      0.66       594\n",
      "           9       0.06      0.65      0.11        97\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.81      0.71     10000\n",
      "weighted avg       0.85      0.73      0.74     10000\n",
      "\n",
      "Epoch 55: 7284 / 10000\n",
      "Accuracy = 72.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.46263009 0.98579041 0.98108747 0.83041475 0.37785292 0.97101449\n",
      " 0.9484193  0.97622585 0.8671875  0.625     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63      2114\n",
      "           1       0.98      0.99      0.98      1126\n",
      "           2       0.80      0.98      0.88       846\n",
      "           3       0.89      0.83      0.86      1085\n",
      "           4       0.91      0.38      0.53      2366\n",
      "           5       0.68      0.97      0.80       621\n",
      "           6       0.59      0.95      0.73       601\n",
      "           7       0.64      0.98      0.77       673\n",
      "           8       0.46      0.87      0.60       512\n",
      "           9       0.03      0.62      0.07        56\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.70      0.80      0.69     10000\n",
      "weighted avg       0.85      0.70      0.72     10000\n",
      "\n",
      "Epoch 56: 7022 / 10000\n",
      "Accuracy = 70.22%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.45446097 0.98476703 0.98102017 0.88331627 0.38256763 0.96267496\n",
      " 0.95405819 0.97383721 0.86981132 0.52173913]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62      2152\n",
      "           1       0.97      0.98      0.98      1116\n",
      "           2       0.80      0.98      0.88       843\n",
      "           3       0.85      0.88      0.87       977\n",
      "           4       0.91      0.38      0.54      2329\n",
      "           5       0.69      0.96      0.81       643\n",
      "           6       0.65      0.95      0.77       653\n",
      "           7       0.65      0.97      0.78       688\n",
      "           8       0.47      0.87      0.61       530\n",
      "           9       0.04      0.52      0.07        69\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.70      0.80      0.69     10000\n",
      "weighted avg       0.84      0.71      0.72     10000\n",
      "\n",
      "Epoch 57: 7067 / 10000\n",
      "Accuracy = 70.67%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.48558648 0.98408488 0.97889801 0.82711556 0.37312812 0.98003328\n",
      " 0.95245642 0.96783626 0.88636364 0.59649123]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.49      0.65      2012\n",
      "           1       0.98      0.98      0.98      1131\n",
      "           2       0.81      0.98      0.89       853\n",
      "           3       0.90      0.83      0.86      1099\n",
      "           4       0.91      0.37      0.53      2404\n",
      "           5       0.66      0.98      0.79       601\n",
      "           6       0.63      0.95      0.76       631\n",
      "           7       0.64      0.97      0.77       684\n",
      "           8       0.48      0.89      0.62       528\n",
      "           9       0.03      0.60      0.06        57\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.70      0.80      0.69     10000\n",
      "weighted avg       0.85      0.71      0.72     10000\n",
      "\n",
      "Epoch 58: 7085 / 10000\n",
      "Accuracy = 70.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.46852475 0.98387097 0.9608076  0.87896825 0.38696983 0.93859649\n",
      " 0.91532847 0.975      0.88148148 0.64935065]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.47      0.64      2081\n",
      "           1       0.97      0.98      0.98      1116\n",
      "           2       0.78      0.96      0.86       842\n",
      "           3       0.88      0.88      0.88      1008\n",
      "           4       0.90      0.39      0.54      2287\n",
      "           5       0.72      0.94      0.81       684\n",
      "           6       0.65      0.92      0.76       685\n",
      "           7       0.64      0.97      0.78       680\n",
      "           8       0.49      0.88      0.63       540\n",
      "           9       0.05      0.65      0.09        77\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.80      0.70     10000\n",
      "weighted avg       0.84      0.71      0.72     10000\n",
      "\n",
      "Epoch 59: 7111 / 10000\n",
      "Accuracy = 71.11%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.48851149 0.98309609 0.97638725 0.85340803 0.39329806 0.96044304\n",
      " 0.95021962 0.96423462 0.87540984 0.640625  ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.49      0.66      2002\n",
      "           1       0.97      0.98      0.98      1124\n",
      "           2       0.80      0.98      0.88       847\n",
      "           3       0.90      0.85      0.88      1071\n",
      "           4       0.91      0.39      0.55      2268\n",
      "           5       0.68      0.96      0.80       632\n",
      "           6       0.68      0.95      0.79       683\n",
      "           7       0.66      0.96      0.78       699\n",
      "           8       0.55      0.88      0.67       610\n",
      "           9       0.04      0.64      0.08        64\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.81      0.71     10000\n",
      "weighted avg       0.85      0.72      0.73     10000\n",
      "\n",
      "Epoch 60: 7221 / 10000\n",
      "Accuracy = 72.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.45315399 0.98491571 0.97503121 0.83533765 0.38682948 0.97034596\n",
      " 0.94444444 0.96935933 0.87728938 0.53658537]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62      2156\n",
      "           1       0.98      0.98      0.98      1127\n",
      "           2       0.76      0.98      0.85       801\n",
      "           3       0.89      0.84      0.86      1081\n",
      "           4       0.90      0.39      0.54      2293\n",
      "           5       0.66      0.97      0.79       607\n",
      "           6       0.62      0.94      0.75       630\n",
      "           7       0.68      0.97      0.80       718\n",
      "           8       0.49      0.88      0.63       546\n",
      "           9       0.02      0.54      0.04        41\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.70      0.79      0.69     10000\n",
      "weighted avg       0.84      0.70      0.72     10000\n",
      "\n",
      "Epoch 61: 7039 / 10000\n",
      "Accuracy = 70.39%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.46219282 0.97799296 0.98134328 0.80052493 0.37046414 0.96742671\n",
      " 0.94233937 0.97716895 0.8802521  0.62337662]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63      2116\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.76      0.98      0.86       804\n",
      "           3       0.91      0.80      0.85      1143\n",
      "           4       0.89      0.37      0.52      2370\n",
      "           5       0.67      0.97      0.79       614\n",
      "           6       0.60      0.94      0.73       607\n",
      "           7       0.62      0.98      0.76       657\n",
      "           8       0.43      0.88      0.58       476\n",
      "           9       0.05      0.62      0.09        77\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.69      0.80      0.68     10000\n",
      "weighted avg       0.84      0.69      0.71     10000\n",
      "\n",
      "Epoch 62: 6946 / 10000\n",
      "Accuracy = 69.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.45890089 0.98577778 0.97018349 0.81727273 0.3668363  0.96517413\n",
      " 0.95492487 0.97412481 0.88142292 0.49019608]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63      2129\n",
      "           1       0.98      0.99      0.98      1125\n",
      "           2       0.82      0.97      0.89       872\n",
      "           3       0.89      0.82      0.85      1100\n",
      "           4       0.88      0.37      0.52      2358\n",
      "           5       0.65      0.97      0.78       603\n",
      "           6       0.60      0.95      0.73       599\n",
      "           7       0.62      0.97      0.76       657\n",
      "           8       0.46      0.88      0.60       506\n",
      "           9       0.02      0.49      0.05        51\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.69      0.79      0.68     10000\n",
      "weighted avg       0.84      0.70      0.71     10000\n",
      "\n",
      "Epoch 63: 6961 / 10000\n",
      "Accuracy = 69.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.47016362 0.98658318 0.97365269 0.79376083 0.38183384 0.96666667\n",
      " 0.94351145 0.97103659 0.88139059 0.61290323]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.47      0.64      2078\n",
      "           1       0.97      0.99      0.98      1118\n",
      "           2       0.79      0.97      0.87       835\n",
      "           3       0.91      0.79      0.85      1154\n",
      "           4       0.90      0.38      0.54      2323\n",
      "           5       0.68      0.97      0.80       630\n",
      "           6       0.65      0.94      0.77       655\n",
      "           7       0.62      0.97      0.76       656\n",
      "           8       0.44      0.88      0.59       489\n",
      "           9       0.04      0.61      0.07        62\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.70      0.80      0.69     10000\n",
      "weighted avg       0.84      0.70      0.72     10000\n",
      "\n",
      "Epoch 64: 7029 / 10000\n",
      "Accuracy = 70.29%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.48823235 0.98056537 0.97215777 0.81571816 0.378367   0.96732026\n",
      " 0.9456     0.97185185 0.89087657 0.54545455]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.49      0.66      1997\n",
      "           1       0.98      0.98      0.98      1132\n",
      "           2       0.81      0.97      0.88       862\n",
      "           3       0.89      0.82      0.85      1107\n",
      "           4       0.92      0.38      0.54      2376\n",
      "           5       0.66      0.97      0.79       612\n",
      "           6       0.62      0.95      0.75       625\n",
      "           7       0.64      0.97      0.77       675\n",
      "           8       0.51      0.89      0.65       559\n",
      "           9       0.03      0.55      0.06        55\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.80      0.69     10000\n",
      "weighted avg       0.85      0.71      0.72     10000\n",
      "\n",
      "Epoch 65: 7092 / 10000\n",
      "Accuracy = 70.92%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.50464876 0.98311111 0.97638725 0.8484565  0.36553106 0.96474359\n",
      " 0.92697466 0.96747967 0.89335664 0.5       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67      1936\n",
      "           1       0.97      0.98      0.98      1125\n",
      "           2       0.80      0.98      0.88       847\n",
      "           3       0.90      0.85      0.87      1069\n",
      "           4       0.93      0.37      0.52      2495\n",
      "           5       0.67      0.96      0.79       624\n",
      "           6       0.65      0.93      0.76       671\n",
      "           7       0.58      0.97      0.72       615\n",
      "           8       0.52      0.89      0.66       572\n",
      "           9       0.02      0.50      0.04        46\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.70      0.79      0.69     10000\n",
      "weighted avg       0.85      0.71      0.72     10000\n",
      "\n",
      "Epoch 66: 7082 / 10000\n",
      "Accuracy = 70.82%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.45761124 0.98059965 0.97705314 0.79680568 0.36169321 0.96260163\n",
      " 0.94217687 0.97256098 0.90208333 0.52941176]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63      2135\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.78      0.98      0.87       828\n",
      "           3       0.89      0.80      0.84      1127\n",
      "           4       0.88      0.36      0.51      2386\n",
      "           5       0.66      0.96      0.79       615\n",
      "           6       0.58      0.94      0.72       588\n",
      "           7       0.62      0.97      0.76       656\n",
      "           8       0.44      0.90      0.60       480\n",
      "           9       0.03      0.53      0.05        51\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.69      0.79      0.67     10000\n",
      "weighted avg       0.84      0.69      0.70     10000\n",
      "\n",
      "Epoch 67: 6903 / 10000\n",
      "Accuracy = 69.03%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.45933239 0.98317095 0.97772277 0.81318681 0.37578815 0.9616\n",
      " 0.9376947  0.97160883 0.90540541 0.54347826]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63      2127\n",
      "           1       0.98      0.98      0.98      1129\n",
      "           2       0.77      0.98      0.86       808\n",
      "           3       0.88      0.81      0.84      1092\n",
      "           4       0.91      0.38      0.53      2379\n",
      "           5       0.67      0.96      0.79       625\n",
      "           6       0.63      0.94      0.75       642\n",
      "           7       0.60      0.97      0.74       634\n",
      "           8       0.48      0.91      0.63       518\n",
      "           9       0.02      0.54      0.05        46\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     10000\n",
      "   macro avg       0.69      0.79      0.68     10000\n",
      "weighted avg       0.84      0.70      0.71     10000\n",
      "\n",
      "Epoch 68: 6972 / 10000\n",
      "Accuracy = 69.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.43230088 0.98230088 0.97044335 0.82462687 0.37628866 0.96721311\n",
      " 0.91959799 0.97829457 0.90080972 0.57692308]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60      2260\n",
      "           1       0.98      0.98      0.98      1130\n",
      "           2       0.76      0.97      0.85       812\n",
      "           3       0.88      0.82      0.85      1072\n",
      "           4       0.89      0.38      0.53      2328\n",
      "           5       0.66      0.97      0.79       610\n",
      "           6       0.57      0.92      0.71       597\n",
      "           7       0.61      0.98      0.75       645\n",
      "           8       0.46      0.90      0.61       494\n",
      "           9       0.03      0.58      0.06        52\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.68      0.79      0.67     10000\n",
      "weighted avg       0.84      0.69      0.70     10000\n",
      "\n",
      "Epoch 69: 6880 / 10000\n",
      "Accuracy = 68.80%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.43752799 0.98311111 0.97890819 0.82434944 0.37336705 0.9647651\n",
      " 0.93964111 0.97511664 0.88405797 0.53846154]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61      2233\n",
      "           1       0.97      0.98      0.98      1125\n",
      "           2       0.76      0.98      0.86       806\n",
      "           3       0.88      0.82      0.85      1076\n",
      "           4       0.90      0.37      0.53      2373\n",
      "           5       0.64      0.96      0.77       596\n",
      "           6       0.60      0.94      0.73       613\n",
      "           7       0.61      0.98      0.75       643\n",
      "           8       0.44      0.88      0.59       483\n",
      "           9       0.03      0.54      0.05        52\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.68      0.79      0.67     10000\n",
      "weighted avg       0.84      0.69      0.70     10000\n",
      "\n",
      "Epoch 70: 6878 / 10000\n",
      "Accuracy = 68.78%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.44591511 0.98217469 0.9824781  0.80690877 0.36569038 0.96828047\n",
      " 0.9168     0.9712     0.88655462 0.45454545]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62      2191\n",
      "           1       0.97      0.98      0.98      1122\n",
      "           2       0.76      0.98      0.86       799\n",
      "           3       0.90      0.81      0.85      1129\n",
      "           4       0.89      0.37      0.52      2390\n",
      "           5       0.65      0.97      0.78       599\n",
      "           6       0.60      0.92      0.72       625\n",
      "           7       0.59      0.97      0.73       625\n",
      "           8       0.43      0.89      0.58       476\n",
      "           9       0.02      0.45      0.04        44\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.68      0.78      0.67     10000\n",
      "weighted avg       0.84      0.69      0.70     10000\n",
      "\n",
      "Epoch 71: 6851 / 10000\n",
      "Accuracy = 68.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.44388914 0.98056537 0.97029703 0.81186284 0.3573201  0.97619048\n",
      " 0.94407895 0.97588424 0.88888889 0.55      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61      2201\n",
      "           1       0.98      0.98      0.98      1132\n",
      "           2       0.76      0.97      0.85       808\n",
      "           3       0.87      0.81      0.84      1079\n",
      "           4       0.88      0.36      0.51      2418\n",
      "           5       0.64      0.98      0.78       588\n",
      "           6       0.60      0.94      0.73       608\n",
      "           7       0.59      0.98      0.74       622\n",
      "           8       0.46      0.89      0.61       504\n",
      "           9       0.02      0.55      0.04        40\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.68      0.79      0.67     10000\n",
      "weighted avg       0.83      0.68      0.69     10000\n",
      "\n",
      "Epoch 72: 6836 / 10000\n",
      "Accuracy = 68.36%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.43680214 0.98576512 0.97610063 0.81561618 0.36079545 0.95602606\n",
      " 0.95796848 0.97381342 0.88636364 0.34285714]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61      2239\n",
      "           1       0.98      0.99      0.98      1124\n",
      "           2       0.75      0.98      0.85       795\n",
      "           3       0.86      0.82      0.84      1063\n",
      "           4       0.91      0.36      0.52      2464\n",
      "           5       0.66      0.96      0.78       614\n",
      "           6       0.57      0.96      0.72       571\n",
      "           7       0.58      0.97      0.73       611\n",
      "           8       0.44      0.89      0.59       484\n",
      "           9       0.01      0.34      0.02        35\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.68      0.77      0.66     10000\n",
      "weighted avg       0.84      0.68      0.69     10000\n",
      "\n",
      "Epoch 73: 6788 / 10000\n",
      "Accuracy = 67.88%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.42264477 0.98490231 0.97365119 0.83430233 0.34345048 0.96428571\n",
      " 0.93553719 0.9706422  0.91150442 0.43243243]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59      2314\n",
      "           1       0.98      0.98      0.98      1126\n",
      "           2       0.75      0.97      0.85       797\n",
      "           3       0.85      0.83      0.84      1032\n",
      "           4       0.88      0.34      0.49      2504\n",
      "           5       0.64      0.96      0.77       588\n",
      "           6       0.59      0.94      0.72       605\n",
      "           7       0.51      0.97      0.67       545\n",
      "           8       0.42      0.91      0.58       452\n",
      "           9       0.02      0.43      0.03        37\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.66      0.78      0.65     10000\n",
      "weighted avg       0.83      0.67      0.68     10000\n",
      "\n",
      "Epoch 74: 6674 / 10000\n",
      "Accuracy = 66.74%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.47399125 0.97969991 0.97139452 0.79411765 0.36047463 0.95954693\n",
      " 0.93958665 0.97945205 0.89788054 0.56363636]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.47      0.64      2057\n",
      "           1       0.98      0.98      0.98      1133\n",
      "           2       0.79      0.97      0.87       839\n",
      "           3       0.88      0.79      0.84      1122\n",
      "           4       0.90      0.36      0.51      2444\n",
      "           5       0.66      0.96      0.79       618\n",
      "           6       0.62      0.94      0.74       629\n",
      "           7       0.56      0.98      0.71       584\n",
      "           8       0.48      0.90      0.62       519\n",
      "           9       0.03      0.56      0.06        55\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.69      0.79      0.68     10000\n",
      "weighted avg       0.84      0.69      0.71     10000\n",
      "\n",
      "Epoch 75: 6925 / 10000\n",
      "Accuracy = 69.25%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.44555809 0.98059965 0.97177914 0.80709736 0.34944695 0.96277496\n",
      " 0.94158076 0.96173045 0.91902834 0.52083333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62      2195\n",
      "           1       0.98      0.98      0.98      1134\n",
      "           2       0.77      0.97      0.86       815\n",
      "           3       0.88      0.81      0.84      1099\n",
      "           4       0.87      0.35      0.50      2441\n",
      "           5       0.64      0.96      0.77       591\n",
      "           6       0.57      0.94      0.71       582\n",
      "           7       0.56      0.96      0.71       601\n",
      "           8       0.47      0.92      0.62       494\n",
      "           9       0.02      0.52      0.05        48\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.68      0.79      0.66     10000\n",
      "weighted avg       0.83      0.68      0.69     10000\n",
      "\n",
      "Epoch 76: 6796 / 10000\n",
      "Accuracy = 67.96%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.43865169 0.98138298 0.97115385 0.8479307  0.34765155 0.9643436\n",
      " 0.93853821 0.97101449 0.90187891 0.51428571]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61      2225\n",
      "           1       0.98      0.98      0.98      1128\n",
      "           2       0.78      0.97      0.87       832\n",
      "           3       0.87      0.85      0.86      1039\n",
      "           4       0.88      0.35      0.50      2491\n",
      "           5       0.67      0.96      0.79       617\n",
      "           6       0.59      0.94      0.72       602\n",
      "           7       0.52      0.97      0.68       552\n",
      "           8       0.44      0.90      0.59       479\n",
      "           9       0.02      0.51      0.03        35\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.67      0.79      0.66     10000\n",
      "weighted avg       0.83      0.68      0.69     10000\n",
      "\n",
      "Epoch 77: 6784 / 10000\n",
      "Accuracy = 67.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.44791189 0.97627417 0.97662977 0.7962963  0.34927066 0.96068376\n",
      " 0.95414462 0.96917808 0.89473684 0.39473684]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62      2179\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.77      0.98      0.86       813\n",
      "           3       0.89      0.80      0.84      1134\n",
      "           4       0.88      0.35      0.50      2468\n",
      "           5       0.63      0.96      0.76       585\n",
      "           6       0.56      0.95      0.71       567\n",
      "           7       0.55      0.97      0.70       584\n",
      "           8       0.45      0.89      0.60       494\n",
      "           9       0.01      0.39      0.03        38\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.67      0.77      0.66     10000\n",
      "weighted avg       0.83      0.68      0.69     10000\n",
      "\n",
      "Epoch 78: 6772 / 10000\n",
      "Accuracy = 67.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.41985389 0.97885463 0.97704082 0.79906542 0.33676296 0.96797153\n",
      " 0.94223827 0.9704797  0.88986784 0.35555556]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59      2327\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.74      0.98      0.84       784\n",
      "           3       0.85      0.80      0.82      1070\n",
      "           4       0.87      0.34      0.49      2527\n",
      "           5       0.61      0.97      0.75       562\n",
      "           6       0.54      0.94      0.69       554\n",
      "           7       0.51      0.97      0.67       542\n",
      "           8       0.41      0.89      0.57       454\n",
      "           9       0.02      0.36      0.03        45\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.65      0.76      0.64     10000\n",
      "weighted avg       0.82      0.66      0.67     10000\n",
      "\n",
      "Epoch 79: 6572 / 10000\n",
      "Accuracy = 65.72%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.43989194 0.97627417 0.96958637 0.7823372  0.34573393 0.96964587\n",
      " 0.93664384 0.9742268  0.92705882 0.41463415]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61      2221\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.77      0.97      0.86       822\n",
      "           3       0.87      0.78      0.82      1121\n",
      "           4       0.87      0.35      0.49      2473\n",
      "           5       0.64      0.97      0.77       593\n",
      "           6       0.57      0.94      0.71       584\n",
      "           7       0.55      0.97      0.70       582\n",
      "           8       0.40      0.93      0.56       425\n",
      "           9       0.02      0.41      0.03        41\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.67      0.77      0.65     10000\n",
      "weighted avg       0.83      0.67      0.68     10000\n",
      "\n",
      "Epoch 80: 6717 / 10000\n",
      "Accuracy = 67.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.43314083 0.97960993 0.97468354 0.8094804  0.33835182 0.96539792\n",
      " 0.92495637 0.97482014 0.90967742 0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.43      0.60      2251\n",
      "           1       0.97      0.98      0.98      1128\n",
      "           2       0.75      0.97      0.85       790\n",
      "           3       0.88      0.81      0.84      1097\n",
      "           4       0.87      0.34      0.49      2524\n",
      "           5       0.63      0.97      0.76       578\n",
      "           6       0.55      0.92      0.69       573\n",
      "           7       0.53      0.97      0.68       556\n",
      "           8       0.43      0.91      0.59       465\n",
      "           9       0.02      0.42      0.03        38\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.66      0.77      0.65     10000\n",
      "weighted avg       0.83      0.67      0.68     10000\n",
      "\n",
      "Epoch 81: 6661 / 10000\n",
      "Accuracy = 66.61%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.44023455 0.9822695  0.97536946 0.81979458 0.3522449  0.95959596\n",
      " 0.93489149 0.96457327 0.90658174 0.45945946]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61      2217\n",
      "           1       0.98      0.98      0.98      1128\n",
      "           2       0.77      0.98      0.86       812\n",
      "           3       0.87      0.82      0.84      1071\n",
      "           4       0.88      0.35      0.50      2450\n",
      "           5       0.64      0.96      0.77       594\n",
      "           6       0.58      0.93      0.72       599\n",
      "           7       0.58      0.96      0.73       621\n",
      "           8       0.44      0.91      0.59       471\n",
      "           9       0.02      0.46      0.03        37\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.67      0.78      0.66     10000\n",
      "weighted avg       0.83      0.68      0.69     10000\n",
      "\n",
      "Epoch 82: 6790 / 10000\n",
      "Accuracy = 67.90%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.42707424 0.97285464 0.97650131 0.76875552 0.34706882 0.95986622\n",
      " 0.94522968 0.96850394 0.91666667 0.5       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60      2290\n",
      "           1       0.98      0.97      0.98      1142\n",
      "           2       0.72      0.98      0.83       766\n",
      "           3       0.86      0.77      0.81      1133\n",
      "           4       0.83      0.35      0.49      2354\n",
      "           5       0.64      0.96      0.77       598\n",
      "           6       0.56      0.95      0.70       566\n",
      "           7       0.60      0.97      0.74       635\n",
      "           8       0.46      0.92      0.62       492\n",
      "           9       0.01      0.50      0.02        24\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.67      0.78      0.66     10000\n",
      "weighted avg       0.82      0.67      0.68     10000\n",
      "\n",
      "Epoch 83: 6712 / 10000\n",
      "Accuracy = 67.12%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.4057309  0.97368421 0.96915167 0.77135231 0.33527697 0.96276596\n",
      " 0.93978102 0.97241379 0.93533487 0.29166667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.41      0.58      2408\n",
      "           1       0.98      0.97      0.98      1140\n",
      "           2       0.73      0.97      0.83       778\n",
      "           3       0.86      0.77      0.81      1124\n",
      "           4       0.82      0.34      0.48      2401\n",
      "           5       0.61      0.96      0.75       564\n",
      "           6       0.54      0.94      0.68       548\n",
      "           7       0.55      0.97      0.70       580\n",
      "           8       0.42      0.94      0.58       433\n",
      "           9       0.01      0.29      0.01        24\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     10000\n",
      "   macro avg       0.65      0.76      0.64     10000\n",
      "weighted avg       0.82      0.65      0.67     10000\n",
      "\n",
      "Epoch 84: 6547 / 10000\n",
      "Accuracy = 65.47%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.41258446 0.97787611 0.96216898 0.80375587 0.34351775 0.97202797\n",
      " 0.93816254 0.97670549 0.92533937 0.48780488]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.41      0.58      2368\n",
      "           1       0.97      0.98      0.98      1130\n",
      "           2       0.74      0.96      0.84       793\n",
      "           3       0.85      0.80      0.83      1065\n",
      "           4       0.85      0.34      0.49      2422\n",
      "           5       0.62      0.97      0.76       572\n",
      "           6       0.55      0.94      0.70       566\n",
      "           7       0.57      0.98      0.72       601\n",
      "           8       0.42      0.93      0.58       442\n",
      "           9       0.02      0.49      0.04        41\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.66      0.78      0.65     10000\n",
      "weighted avg       0.82      0.66      0.67     10000\n",
      "\n",
      "Epoch 85: 6636 / 10000\n",
      "Accuracy = 66.36%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.44117647 0.97539543 0.97657213 0.75236457 0.34036511 0.96790541\n",
      " 0.94210526 0.97158082 0.92427617 0.53846154]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.44      0.61      2210\n",
      "           1       0.98      0.98      0.98      1138\n",
      "           2       0.77      0.98      0.86       811\n",
      "           3       0.87      0.75      0.81      1163\n",
      "           4       0.85      0.34      0.49      2465\n",
      "           5       0.64      0.97      0.77       592\n",
      "           6       0.56      0.94      0.70       570\n",
      "           7       0.53      0.97      0.69       563\n",
      "           8       0.43      0.92      0.58       449\n",
      "           9       0.02      0.54      0.04        39\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.66      0.78      0.65     10000\n",
      "weighted avg       0.82      0.67      0.68     10000\n",
      "\n",
      "Epoch 86: 6684 / 10000\n",
      "Accuracy = 66.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.45206114 0.97210113 0.97218863 0.76182287 0.33776703 0.96046129\n",
      " 0.92998205 0.976234   0.92291667 0.5625    ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62      2159\n",
      "           1       0.98      0.97      0.98      1147\n",
      "           2       0.78      0.97      0.86       827\n",
      "           3       0.88      0.76      0.82      1163\n",
      "           4       0.85      0.34      0.48      2481\n",
      "           5       0.65      0.96      0.78       607\n",
      "           6       0.54      0.93      0.68       557\n",
      "           7       0.52      0.98      0.68       547\n",
      "           8       0.45      0.92      0.61       480\n",
      "           9       0.02      0.56      0.03        32\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.67      0.78      0.65     10000\n",
      "weighted avg       0.83      0.67      0.68     10000\n",
      "\n",
      "Epoch 87: 6715 / 10000\n",
      "Accuracy = 67.15%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.44837081 0.97973568 0.96614268 0.80384968 0.3458132  0.95322581\n",
      " 0.93015332 0.96864686 0.92152466 0.48      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62      2179\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.77      0.97      0.86       827\n",
      "           3       0.87      0.80      0.83      1091\n",
      "           4       0.87      0.35      0.50      2484\n",
      "           5       0.66      0.95      0.78       620\n",
      "           6       0.57      0.93      0.71       587\n",
      "           7       0.57      0.97      0.72       606\n",
      "           8       0.42      0.92      0.58       446\n",
      "           9       0.01      0.48      0.02        25\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.67      0.78      0.66     10000\n",
      "weighted avg       0.83      0.68      0.69     10000\n",
      "\n",
      "Epoch 88: 6771 / 10000\n",
      "Accuracy = 67.71%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.40305281 0.97377622 0.96282528 0.79425394 0.34306261 0.97377622\n",
      " 0.93442623 0.96729776 0.90423163 0.51612903]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57      2424\n",
      "           1       0.98      0.97      0.98      1144\n",
      "           2       0.75      0.96      0.85       807\n",
      "           3       0.85      0.79      0.82      1079\n",
      "           4       0.83      0.34      0.48      2364\n",
      "           5       0.62      0.97      0.76       572\n",
      "           6       0.54      0.93      0.68       549\n",
      "           7       0.55      0.97      0.70       581\n",
      "           8       0.42      0.90      0.57       449\n",
      "           9       0.02      0.52      0.03        31\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.65      0.78      0.64     10000\n",
      "weighted avg       0.82      0.66      0.67     10000\n",
      "\n",
      "Epoch 89: 6590 / 10000\n",
      "Accuracy = 65.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.4575715  0.97541703 0.96643519 0.80956762 0.345535   0.95153473\n",
      " 0.92372881 0.96458685 0.90987124 0.26086957]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63      2133\n",
      "           1       0.98      0.98      0.98      1139\n",
      "           2       0.81      0.97      0.88       864\n",
      "           3       0.87      0.81      0.84      1087\n",
      "           4       0.87      0.35      0.50      2486\n",
      "           5       0.66      0.95      0.78       619\n",
      "           6       0.57      0.92      0.70       590\n",
      "           7       0.56      0.96      0.71       593\n",
      "           8       0.44      0.91      0.59       466\n",
      "           9       0.01      0.26      0.01        23\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.68      0.76      0.66     10000\n",
      "weighted avg       0.83      0.68      0.69     10000\n",
      "\n",
      "Epoch 90: 6797 / 10000\n",
      "Accuracy = 67.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.44581056 0.97377622 0.96823529 0.75508475 0.33279678 0.96790541\n",
      " 0.91725352 0.96357013 0.92788462 0.4       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62      2196\n",
      "           1       0.98      0.97      0.98      1144\n",
      "           2       0.80      0.97      0.87       850\n",
      "           3       0.88      0.76      0.81      1180\n",
      "           4       0.84      0.33      0.48      2485\n",
      "           5       0.64      0.97      0.77       592\n",
      "           6       0.54      0.92      0.68       568\n",
      "           7       0.51      0.96      0.67       549\n",
      "           8       0.40      0.93      0.56       416\n",
      "           9       0.01      0.40      0.02        20\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.66      0.77      0.65     10000\n",
      "weighted avg       0.83      0.67      0.68     10000\n",
      "\n",
      "Epoch 91: 6651 / 10000\n",
      "Accuracy = 66.51%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.42670157 0.97799296 0.97132616 0.80146386 0.33294025 0.96453901\n",
      " 0.933213   0.96940727 0.91183295 0.34615385]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60      2292\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.79      0.97      0.87       837\n",
      "           3       0.87      0.80      0.83      1093\n",
      "           4       0.86      0.33      0.48      2544\n",
      "           5       0.61      0.96      0.75       564\n",
      "           6       0.54      0.93      0.68       554\n",
      "           7       0.49      0.97      0.65       523\n",
      "           8       0.40      0.91      0.56       431\n",
      "           9       0.01      0.35      0.02        26\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.65      0.76      0.64     10000\n",
      "weighted avg       0.83      0.66      0.67     10000\n",
      "\n",
      "Epoch 92: 6595 / 10000\n",
      "Accuracy = 65.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.41440678 0.97297297 0.96940024 0.80054152 0.33895447 0.96335079\n",
      " 0.92416226 0.97178131 0.9055794  0.43478261]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.41      0.59      2360\n",
      "           1       0.98      0.97      0.98      1147\n",
      "           2       0.77      0.97      0.86       817\n",
      "           3       0.88      0.80      0.84      1108\n",
      "           4       0.82      0.34      0.48      2372\n",
      "           5       0.62      0.96      0.75       573\n",
      "           6       0.55      0.92      0.69       567\n",
      "           7       0.54      0.97      0.69       567\n",
      "           8       0.43      0.91      0.59       466\n",
      "           9       0.01      0.43      0.02        23\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.66      0.77      0.65     10000\n",
      "weighted avg       0.82      0.66      0.68     10000\n",
      "\n",
      "Epoch 93: 6636 / 10000\n",
      "Accuracy = 66.36%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.42155172 0.97799296 0.96924969 0.79357798 0.32676056 0.95876289\n",
      " 0.92114695 0.97173145 0.92941176 0.36      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59      2320\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.76      0.97      0.85       813\n",
      "           3       0.86      0.79      0.82      1090\n",
      "           4       0.83      0.33      0.47      2485\n",
      "           5       0.63      0.96      0.76       582\n",
      "           6       0.54      0.92      0.68       558\n",
      "           7       0.54      0.97      0.69       566\n",
      "           8       0.41      0.93      0.56       425\n",
      "           9       0.01      0.36      0.02        25\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.65      0.76      0.64     10000\n",
      "weighted avg       0.82      0.66      0.67     10000\n",
      "\n",
      "Epoch 94: 6580 / 10000\n",
      "Accuracy = 65.80%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.435247   0.97467249 0.97277228 0.80401094 0.3410475  0.96357616\n",
      " 0.91666667 0.96795953 0.90574713 0.53125   ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61      2247\n",
      "           1       0.98      0.97      0.98      1145\n",
      "           2       0.76      0.97      0.85       808\n",
      "           3       0.87      0.80      0.84      1097\n",
      "           4       0.86      0.34      0.49      2463\n",
      "           5       0.65      0.96      0.78       604\n",
      "           6       0.55      0.92      0.69       576\n",
      "           7       0.56      0.97      0.71       593\n",
      "           8       0.40      0.91      0.56       435\n",
      "           9       0.02      0.53      0.03        32\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.67      0.78      0.65     10000\n",
      "weighted avg       0.83      0.67      0.68     10000\n",
      "\n",
      "Epoch 95: 6697 / 10000\n",
      "Accuracy = 66.97%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.42118863 0.97711268 0.9607362  0.79779412 0.3437247  0.9614711\n",
      " 0.93133803 0.9699115  0.90888889 0.4       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59      2322\n",
      "           1       0.98      0.98      0.98      1136\n",
      "           2       0.76      0.96      0.85       815\n",
      "           3       0.86      0.80      0.83      1088\n",
      "           4       0.86      0.34      0.49      2470\n",
      "           5       0.62      0.96      0.75       571\n",
      "           6       0.55      0.93      0.69       568\n",
      "           7       0.53      0.97      0.69       565\n",
      "           8       0.42      0.91      0.57       450\n",
      "           9       0.01      0.40      0.01        15\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.66      0.77      0.65     10000\n",
      "weighted avg       0.83      0.66      0.68     10000\n",
      "\n",
      "Epoch 96: 6629 / 10000\n",
      "Accuracy = 66.29%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.39739943 0.97968198 0.96645963 0.82318271 0.32962669 0.96160558\n",
      " 0.93661972 0.96633663 0.91959799 0.22727273]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57      2461\n",
      "           1       0.98      0.98      0.98      1132\n",
      "           2       0.75      0.97      0.85       805\n",
      "           3       0.83      0.82      0.83      1018\n",
      "           4       0.85      0.33      0.47      2518\n",
      "           5       0.62      0.96      0.75       573\n",
      "           6       0.56      0.94      0.70       568\n",
      "           7       0.47      0.97      0.64       505\n",
      "           8       0.38      0.92      0.53       398\n",
      "           9       0.00      0.23      0.01        22\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     10000\n",
      "   macro avg       0.64      0.75      0.63     10000\n",
      "weighted avg       0.82      0.65      0.66     10000\n",
      "\n",
      "Epoch 97: 6475 / 10000\n",
      "Accuracy = 64.75%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.39683184 0.97361478 0.9749059  0.80420248 0.33961491 0.98070175\n",
      " 0.92014519 0.96936937 0.89208633 0.34782609]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57      2462\n",
      "           1       0.98      0.97      0.97      1137\n",
      "           2       0.75      0.97      0.85       797\n",
      "           3       0.83      0.80      0.82      1047\n",
      "           4       0.84      0.34      0.48      2441\n",
      "           5       0.63      0.98      0.76       570\n",
      "           6       0.53      0.92      0.67       551\n",
      "           7       0.52      0.97      0.68       555\n",
      "           8       0.38      0.89      0.53       417\n",
      "           9       0.01      0.35      0.02        23\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     10000\n",
      "   macro avg       0.65      0.76      0.64     10000\n",
      "weighted avg       0.82      0.65      0.66     10000\n",
      "\n",
      "Epoch 98: 6516 / 10000\n",
      "Accuracy = 65.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.43530458 0.97043478 0.97317073 0.78966455 0.32723735 0.96033058\n",
      " 0.92518248 0.96963563 0.92063492 0.2       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61      2249\n",
      "           1       0.98      0.97      0.98      1150\n",
      "           2       0.77      0.97      0.86       820\n",
      "           3       0.86      0.79      0.82      1103\n",
      "           4       0.86      0.33      0.47      2570\n",
      "           5       0.65      0.96      0.78       605\n",
      "           6       0.53      0.93      0.67       548\n",
      "           7       0.47      0.97      0.63       494\n",
      "           8       0.42      0.92      0.57       441\n",
      "           9       0.00      0.20      0.01        20\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.65      0.75      0.64     10000\n",
      "weighted avg       0.83      0.66      0.67     10000\n",
      "\n",
      "Epoch 99: 6582 / 10000\n",
      "Accuracy = 65.82%\n"
     ]
    }
   ],
   "source": [
    "net = network_tanh.NetworkTanh([784, 30, 10])\n",
    "net.SGD(training_data, 100, 10, 3.0, test_data=test_data) #training_data, epochs, mini_batch_size, eta, test_data=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.37716406 0.54523346 0.26652565 0.58832808 0.33595692 0.11538462\n",
      " 0.83333333 0.96767241 0.         0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.38      0.54      2426\n",
      "           1       0.99      0.55      0.70      2056\n",
      "           2       0.49      0.27      0.34      1891\n",
      "           3       0.37      0.59      0.45       634\n",
      "           4       0.83      0.34      0.48      2414\n",
      "           5       0.01      0.12      0.01        52\n",
      "           6       0.05      0.83      0.09        54\n",
      "           7       0.44      0.97      0.60       464\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.42      0.42      0.42     10000\n",
      "   macro avg       0.41      0.40      0.32     10000\n",
      "weighted avg       0.77      0.42      0.51     10000\n",
      "\n",
      "Epoch 0: 4224 / 10000\n",
      "Accuracy = 42.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "network_tanh.py:149: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0+np.exp(-z))\n",
      "network_tanh.py:156: RuntimeWarning: overflow encountered in exp\n",
      "  return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
      "network_tanh.py:156: RuntimeWarning: invalid value encountered in divide\n",
      "  return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.16660888 0.31568926 0.32997988 0.         0.73913043        nan\n",
      "        nan 0.23076923        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.17      0.28      5768\n",
      "           1       0.73      0.32      0.44      2626\n",
      "           2       0.48      0.33      0.39      1491\n",
      "           3       0.00      0.00      0.00        79\n",
      "           4       0.02      0.74      0.03        23\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.23      0.01        13\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.23      0.23      0.23     10000\n",
      "   macro avg       0.22      0.18      0.12     10000\n",
      "weighted avg       0.83      0.23      0.34     10000\n",
      "\n",
      "Epoch 1: 2302 / 10000\n",
      "Accuracy = 23.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "network_tanh.py:136: RuntimeWarning: invalid value encountered in divide\n",
      "  matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.13489655 0.28639618 0.20164986 0.03571429 0.6626506         nan\n",
      " 0.66666667 0.33333333        nan 1.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.13      0.24      7250\n",
      "           1       0.11      0.29      0.15       419\n",
      "           2       0.43      0.20      0.27      2182\n",
      "           3       0.00      0.04      0.00        56\n",
      "           4       0.06      0.66      0.10        83\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.67      0.01         6\n",
      "           7       0.00      0.33      0.00         3\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      1.00      0.00         1\n",
      "\n",
      "   micro avg       0.16      0.16      0.16     10000\n",
      "   macro avg       0.16      0.33      0.08     10000\n",
      "weighted avg       0.82      0.16      0.24     10000\n",
      "\n",
      "Epoch 2: 1601 / 10000\n",
      "Accuracy = 16.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.19615774 0.64211975 0.19984076 0.03067485 0.37478559 0.15283843\n",
      " 0.         0.48148148        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.20      0.33      4945\n",
      "           1       0.82      0.64      0.72      1453\n",
      "           2       0.24      0.20      0.22      1256\n",
      "           3       0.01      0.03      0.02       489\n",
      "           4       0.45      0.37      0.41      1166\n",
      "           5       0.04      0.15      0.06       229\n",
      "           6       0.00      0.00      0.00       381\n",
      "           7       0.04      0.48      0.07        81\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.27      0.27      0.27     10000\n",
      "   macro avg       0.26      0.21      0.18     10000\n",
      "weighted avg       0.69      0.27      0.34     10000\n",
      "\n",
      "Epoch 3: 2680 / 10000\n",
      "Accuracy = 26.80%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.12838392 0.54089422 0.14417178 0.0952381  0.37429112 0.14915254\n",
      " 1.         0.2               nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.13      0.23      7314\n",
      "           1       0.44      0.54      0.48       917\n",
      "           2       0.09      0.14      0.11       652\n",
      "           3       0.03      0.10      0.04       273\n",
      "           4       0.20      0.37      0.26       529\n",
      "           5       0.05      0.15      0.07       295\n",
      "           6       0.01      1.00      0.02        10\n",
      "           7       0.00      0.20      0.00        10\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.18      0.18      0.18     10000\n",
      "   macro avg       0.18      0.26      0.12     10000\n",
      "weighted avg       0.76      0.18      0.23     10000\n",
      "\n",
      "Epoch 4: 1809 / 10000\n",
      "Accuracy = 18.09%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.12710155 0.64242424 0.10750988 0.01731602 0.4266055  0.6\n",
      " 0.         0.5               nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.13      0.22      7435\n",
      "           1       0.47      0.64      0.54       825\n",
      "           2       0.13      0.11      0.12      1265\n",
      "           3       0.00      0.02      0.01       231\n",
      "           4       0.09      0.43      0.15       218\n",
      "           5       0.01      0.60      0.03        20\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.50      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.17      0.17      0.17     10000\n",
      "   macro avg       0.17      0.24      0.11     10000\n",
      "weighted avg       0.77      0.17      0.23     10000\n",
      "\n",
      "Epoch 5: 1721 / 10000\n",
      "Accuracy = 17.21%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.12422113 0.5995086  0.08444444 0.22317597 0.66304348 0.52222222\n",
      " 0.                nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.12      0.22      7543\n",
      "           1       0.43      0.60      0.50       814\n",
      "           2       0.07      0.08      0.08       900\n",
      "           3       0.10      0.22      0.14       466\n",
      "           4       0.12      0.66      0.21       184\n",
      "           5       0.05      0.52      0.10        90\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.18      0.18      0.18     10000\n",
      "   macro avg       0.17      0.22      0.12     10000\n",
      "weighted avg       0.77      0.18      0.22     10000\n",
      "\n",
      "Epoch 6: 1774 / 10000\n",
      "Accuracy = 17.74%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.10932106 0.81818182 0.05513308 0.0129199  1.                nan\n",
      "        nan        nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.11      0.20      8690\n",
      "           1       0.29      0.82      0.42       396\n",
      "           2       0.03      0.06      0.04       526\n",
      "           3       0.00      0.01      0.01       387\n",
      "           4       0.00      1.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.13      0.13      0.13     10000\n",
      "   macro avg       0.13      0.20      0.07     10000\n",
      "weighted avg       0.86      0.13      0.19     10000\n",
      "\n",
      "Epoch 7: 1309 / 10000\n",
      "Accuracy = 13.09%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.10052333 0.61283644 0.12101911 0.         0.55555556 0.5\n",
      " 0.17045455 0.08333333        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.10      0.18      9172\n",
      "           1       0.26      0.61      0.37       483\n",
      "           2       0.02      0.12      0.03       157\n",
      "           3       0.00      0.00      0.00        69\n",
      "           4       0.01      0.56      0.01         9\n",
      "           5       0.01      0.50      0.01        10\n",
      "           6       0.02      0.17      0.03        88\n",
      "           7       0.00      0.08      0.00        12\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.13      0.13      0.13     10000\n",
      "   macro avg       0.12      0.21      0.06     10000\n",
      "weighted avg       0.88      0.13      0.19     10000\n",
      "\n",
      "Epoch 8: 1263 / 10000\n",
      "Accuracy = 12.63%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.10402388 0.47979798 0.15606936 0.01694915 0.44736842 0.55555556\n",
      " 0.3015873         nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.10      0.19      9046\n",
      "           1       0.25      0.48      0.33       594\n",
      "           2       0.03      0.16      0.04       173\n",
      "           3       0.00      0.02      0.00        59\n",
      "           4       0.02      0.45      0.03        38\n",
      "           5       0.02      0.56      0.03        27\n",
      "           6       0.02      0.30      0.04        63\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.13      0.13      0.13     10000\n",
      "   macro avg       0.13      0.21      0.07     10000\n",
      "weighted avg       0.88      0.13      0.19     10000\n",
      "\n",
      "Epoch 9: 1305 / 10000\n",
      "Accuracy = 13.05%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.10425861 0.59395248 0.11462451 0.01639344 0.29787234 0.82857143\n",
      " 0.36842105 0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.10      0.19      9064\n",
      "           1       0.24      0.59      0.34       463\n",
      "           2       0.03      0.11      0.05       253\n",
      "           3       0.00      0.02      0.00        61\n",
      "           4       0.01      0.30      0.03        47\n",
      "           5       0.03      0.83      0.06        35\n",
      "           6       0.03      0.37      0.05        76\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.13      0.13      0.13     10000\n",
      "   macro avg       0.13      0.23      0.07     10000\n",
      "weighted avg       0.89      0.13      0.19     10000\n",
      "\n",
      "Epoch 10: 1321 / 10000\n",
      "Accuracy = 13.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.10382276 0.6865285  0.104      0.02702703 0.26923077 0.69230769\n",
      " 0.30714286        nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.10      0.19      9208\n",
      "           1       0.23      0.69      0.35       386\n",
      "           2       0.01      0.10      0.02       125\n",
      "           3       0.00      0.03      0.00        37\n",
      "           4       0.02      0.27      0.04        78\n",
      "           5       0.02      0.69      0.04        26\n",
      "           6       0.04      0.31      0.08       140\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.13      0.13      0.13     10000\n",
      "   macro avg       0.13      0.22      0.07     10000\n",
      "weighted avg       0.91      0.13      0.19     10000\n",
      "\n",
      "Epoch 11: 1317 / 10000\n",
      "Accuracy = 13.17%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.10459795 0.64125561 0.12345679 0.01612903 0.29850746 0.84615385\n",
      " 0.39869281        nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.10      0.19      9178\n",
      "           1       0.25      0.64      0.36       446\n",
      "           2       0.01      0.12      0.02        81\n",
      "           3       0.00      0.02      0.00        62\n",
      "           4       0.02      0.30      0.04        67\n",
      "           5       0.01      0.85      0.02        13\n",
      "           6       0.06      0.40      0.11       153\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.13      0.13      0.13     10000\n",
      "   macro avg       0.13      0.24      0.07     10000\n",
      "weighted avg       0.91      0.13      0.19     10000\n",
      "\n",
      "Epoch 12: 1349 / 10000\n",
      "Accuracy = 13.49%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.10324324 0.51522248 0.15151515 0.         0.44927536 0.42857143\n",
      " 0.20245399 0.25              nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.10      0.19      9250\n",
      "           1       0.19      0.52      0.28       427\n",
      "           2       0.00      0.15      0.01        33\n",
      "           3       0.00      0.00      0.00        26\n",
      "           4       0.03      0.45      0.06        69\n",
      "           5       0.01      0.43      0.03        28\n",
      "           6       0.03      0.20      0.06       163\n",
      "           7       0.00      0.25      0.00         4\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.13      0.13      0.13     10000\n",
      "   macro avg       0.13      0.21      0.06     10000\n",
      "weighted avg       0.91      0.13      0.19     10000\n",
      "\n",
      "Epoch 13: 1257 / 10000\n",
      "Accuracy = 12.57%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.10042644 0.56268222 0.17021277 0.03125    0.20670391 0.44444444\n",
      " 0.                nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.10      0.18      9380\n",
      "           1       0.17      0.56      0.26       343\n",
      "           2       0.01      0.17      0.01        47\n",
      "           3       0.00      0.03      0.00        32\n",
      "           4       0.04      0.21      0.06       179\n",
      "           5       0.00      0.44      0.01         9\n",
      "           6       0.00      0.00      0.00        10\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     10000\n",
      "   macro avg       0.12      0.15      0.05     10000\n",
      "weighted avg       0.91      0.12      0.18     10000\n",
      "\n",
      "Epoch 14: 1185 / 10000\n",
      "Accuracy = 11.85%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.10068259 0.55617978 0.21052632 0.02941176 0.16494845 0.45454545\n",
      " 0.                nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.10      0.18      9376\n",
      "           1       0.17      0.56      0.27       356\n",
      "           2       0.00      0.21      0.01        19\n",
      "           3       0.00      0.03      0.00        34\n",
      "           4       0.03      0.16      0.05       194\n",
      "           5       0.01      0.45      0.01        11\n",
      "           6       0.00      0.00      0.00        10\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     10000\n",
      "   macro avg       0.12      0.15      0.05     10000\n",
      "weighted avg       0.91      0.12      0.18     10000\n",
      "\n",
      "Epoch 15: 1184 / 10000\n",
      "Accuracy = 11.84%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.10073418 0.50226244 0.14285714 0.03225806 0.18018018 0.4\n",
      " 0.04761905        nan        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.10      0.18      9262\n",
      "           1       0.20      0.50      0.28       442\n",
      "           2       0.00      0.14      0.00         7\n",
      "           3       0.00      0.03      0.00        31\n",
      "           4       0.04      0.18      0.07       222\n",
      "           5       0.01      0.40      0.01        15\n",
      "           6       0.00      0.05      0.00        21\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     10000\n",
      "   macro avg       0.12      0.14      0.05     10000\n",
      "weighted avg       0.89      0.12      0.18     10000\n",
      "\n",
      "Epoch 16: 1204 / 10000\n",
      "Accuracy = 12.04%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.1016767  0.46956522 0.         0.         0.19620253 0.39285714\n",
      " 0.11111111 0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.10      0.18      9304\n",
      "           1       0.19      0.47      0.27       460\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       0.03      0.20      0.05       158\n",
      "           5       0.01      0.39      0.02        28\n",
      "           6       0.00      0.11      0.01        36\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.12      0.12      0.12     10000\n",
      "   macro avg       0.12      0.13      0.05     10000\n",
      "weighted avg       0.91      0.12      0.18     10000\n",
      "\n",
      "Epoch 17: 1208 / 10000\n",
      "Accuracy = 12.08%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.09763524 0.07777778        nan 0.         0.11111111 0.23809524\n",
      "        nan 0.14285714        nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.10      0.18      9853\n",
      "           1       0.01      0.08      0.01        90\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.11      0.01        27\n",
      "           5       0.01      0.24      0.01        21\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.14      0.00         7\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.07      0.02     10000\n",
      "weighted avg       0.97      0.10      0.18     10000\n",
      "\n",
      "Epoch 18: 978 / 10000\n",
      "Accuracy = 9.78%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.09651883 0.03883495        nan 0.         0.09090909 0.33333333\n",
      " 0.         0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.10      0.18      9853\n",
      "           1       0.00      0.04      0.01       103\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.09      0.00        22\n",
      "           5       0.00      0.33      0.01        12\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.06      0.02     10000\n",
      "weighted avg       0.96      0.10      0.17     10000\n",
      "\n",
      "Epoch 19: 961 / 10000\n",
      "Accuracy = 9.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.09659726 0.03508772        nan 0.         0.         0.36363636\n",
      " 0.         0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.10      0.18      9845\n",
      "           1       0.00      0.04      0.01       114\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00        17\n",
      "           5       0.00      0.36      0.01        11\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         8\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.05      0.02     10000\n",
      "weighted avg       0.96      0.10      0.17     10000\n",
      "\n",
      "Epoch 20: 959 / 10000\n",
      "Accuracy = 9.59%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.0963121  0.04651163        nan 0.         0.09090909 0.22727273\n",
      " 0.08333333 0.25              nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.10      0.18      9843\n",
      "           1       0.00      0.05      0.01        86\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.09      0.00        22\n",
      "           5       0.01      0.23      0.01        22\n",
      "           6       0.00      0.08      0.00        12\n",
      "           7       0.00      0.25      0.01        12\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.08      0.02     10000\n",
      "weighted avg       0.95      0.10      0.17     10000\n",
      "\n",
      "Epoch 21: 963 / 10000\n",
      "Accuracy = 9.63%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.09796167 0.09302326 0.5        0.         0.29545455 0.11764706\n",
      " 0.16666667 0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.10      0.18      9861\n",
      "           1       0.00      0.09      0.01        43\n",
      "           2       0.00      0.50      0.00         2\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.01      0.30      0.03        44\n",
      "           5       0.00      0.12      0.01        34\n",
      "           6       0.00      0.17      0.00         6\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.13      0.02     10000\n",
      "weighted avg       0.97      0.10      0.18     10000\n",
      "\n",
      "Epoch 22: 989 / 10000\n",
      "Accuracy = 9.89%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.09811474 0.09756098 0.66666667 0.         0.46153846 0.22857143\n",
      " 0.125      0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.10      0.18      9866\n",
      "           1       0.00      0.10      0.01        41\n",
      "           2       0.00      0.67      0.00         3\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.02      0.46      0.04        39\n",
      "           5       0.01      0.23      0.02        35\n",
      "           6       0.00      0.12      0.00         8\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.17      0.02     10000\n",
      "weighted avg       0.97      0.10      0.18     10000\n",
      "\n",
      "Epoch 23: 1001 / 10000\n",
      "Accuracy = 10.01%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.09813463 0.08333333        nan 0.14285714 0.29787234 0.23076923\n",
      " 0.         0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.10      0.18      9864\n",
      "           1       0.00      0.08      0.01        48\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.14      0.00         7\n",
      "           4       0.01      0.30      0.03        47\n",
      "           5       0.01      0.23      0.01        26\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.09      0.02     10000\n",
      "weighted avg       0.97      0.10      0.18     10000\n",
      "\n",
      "Epoch 24: 993 / 10000\n",
      "Accuracy = 9.93%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.09861153 0.08888889        nan 0.         0.14285714 0.21568627\n",
      " 0.25       0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.10      0.18      9867\n",
      "           1       0.00      0.09      0.01        45\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.00      0.14      0.00        14\n",
      "           5       0.01      0.22      0.02        51\n",
      "           6       0.00      0.25      0.00         4\n",
      "           7       0.00      0.00      0.00         8\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.08      0.02     10000\n",
      "weighted avg       0.98      0.10      0.18     10000\n",
      "\n",
      "Epoch 25: 991 / 10000\n",
      "Accuracy = 9.91%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.09876543 0.11428571 1.         0.0625     0.31578947 0.05\n",
      " 0.6        0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18      9882\n",
      "           1       0.00      0.11      0.01        35\n",
      "           2       0.00      1.00      0.00         2\n",
      "           3       0.00      0.06      0.00        16\n",
      "           4       0.01      0.32      0.01        19\n",
      "           5       0.00      0.05      0.00        40\n",
      "           6       0.00      0.60      0.01         5\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.22      0.02     10000\n",
      "weighted avg       0.98      0.10      0.18     10000\n",
      "\n",
      "Epoch 26: 994 / 10000\n",
      "Accuracy = 9.94%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.09860296 0.19047619 1.         0.         0.35714286 0.10204082\n",
      " 0.25       0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.10      0.18      9878\n",
      "           1       0.01      0.19      0.01        42\n",
      "           2       0.00      1.00      0.00         2\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.01      0.36      0.01        14\n",
      "           5       0.01      0.10      0.01        49\n",
      "           6       0.00      0.25      0.00         4\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.20      0.02     10000\n",
      "weighted avg       0.98      0.10      0.18     10000\n",
      "\n",
      "Epoch 27: 995 / 10000\n",
      "Accuracy = 9.95%\n",
      "\n",
      "Accuracy for each class\n",
      "[0.09815021 0.13333333 0.         0.         0.24       0.7\n",
      " 0.33333333 0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.10      0.18      9893\n",
      "           1       0.01      0.13      0.01        60\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.01      0.24      0.01        25\n",
      "           5       0.01      0.70      0.02        10\n",
      "           6       0.00      0.33      0.00         3\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.15      0.02     10000\n",
      "weighted avg       0.98      0.10      0.18     10000\n",
      "\n",
      "Epoch 28: 993 / 10000\n",
      "Accuracy = 9.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each class\n",
      "[0.09831916 0.17391304 0.33333333 0.         0.29545455 0.15384615\n",
      " 0.         0.                nan        nan]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.10      0.18      9876\n",
      "           1       0.01      0.17      0.01        46\n",
      "           2       0.00      0.33      0.00         3\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.01      0.30      0.03        44\n",
      "           5       0.00      0.15      0.01        26\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     10000\n",
      "   macro avg       0.10      0.11      0.02     10000\n",
      "weighted avg       0.98      0.10      0.18     10000\n",
      "\n",
      "Epoch 29: 997 / 10000\n",
      "Accuracy = 9.97%\n"
     ]
    }
   ],
   "source": [
    "net = network_tanh.NetworkTanh([784, 30, 30, 10])\n",
    "net.SGD(training_data, 30, 1, 3.0, test_data=test_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c3b02fa24688d32a1d09351b7f8eac82a87272ad081601c73caead00a8e1fc4"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
