{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZHeZKqb3Nwe"
      },
      "source": [
        "# MiniProjeto 2 - Convolutional Neural Networks - Redes Neurais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Wyzwmx3VOD"
      },
      "source": [
        "## Reconhecimento de Dígitos com CNN\n",
        "\n",
        "## Grupo: Josenildo Vicente de Araújo (jva@cin.ufpe.br), Lucas Thierry Chaves Muniz (ltcm@cin.ufpe.br), Nicholas Henrique Justino Ferreira (nhjf@cin.ufpe.br), Renato Joaquim Miranda Ferreira (rjmf@cin.ufpe.br)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ehiGkuq3kjg"
      },
      "source": [
        "O seguinte MiniProjeto tem como objetivo praticar os conceitos e teorias aprendidas na disciplina de Redes Neurais a respeito do funcionamento do modelo de Redes Neurais Convolucionais. De maneira a variar os parâmetros do modelo treinado e observar seus resultados. A rede utilizada em questão, tem como função fazer o reconhecimento de dígitos escritos manualmente por 250 pessoas, entre as quais eram estudantes do Ensino Médio e funcionários do Departamento do Censo dos Estados Unidos. O conjunto desses dígitos está reunido no _dataset_ MNIST, que possuí 60000 imagens para treinamento do modelo da rede neural e 10000 imagens para teste do modelo da rede neural. Cada uma dessas imagens são formadas por 784 _pixels_ (28x28) em uma escala da cor cinza.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FgMkRTu3m4w"
      },
      "source": [
        "Começamos pela importação do pacote das bibliotecas do keras para construção do modelo, importação do dataset. O matplotlib será a biblioteca gráfica e será usada quando for pertinente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jTj1s-55uovX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZL5oopX7zaA"
      },
      "source": [
        "Importação do dataset e separação entre os conjuntos de teste e treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6DYkojTu635"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4thY6_o76Hs"
      },
      "source": [
        "explorando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "eiA4JBUgvHtc",
        "outputId": "40e5bcca-7924-451a-e374-f184b8f0c41a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1c30a2fdfd0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLBwKGbL77kW"
      },
      "source": [
        "Reshape para treinamento do modelo do keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o9xiX6h1vSnj"
      },
      "outputs": [],
      "source": [
        "#reshape data to fit model\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX6hd2vfvTan",
        "outputId": "e45c8ae5-f14b-4775-e51f-ff0288114dea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zJUclD88NCA"
      },
      "source": [
        "Criação do modelo Sequencial, escolhemos o sequencial pois permite a criação do modelo layer a layer. \n",
        "\n",
        "Utilizamos 3 layers diferentes para lidar com o dataset, as 2 primeiras layers convolucionais de uma matriz com 2 dimensões, uma vez que o nosso dataset está de acordo com as 2 dimensões a serem vistas e utilizadas, bem como uma 'liga' representada pelo Flatten que serve para ligar as matrizes convolucionais com as camadas mais densas do modelo.\n",
        "\n",
        "As camadas convolucionais são representadas pelos tamanhos 64 e 32, que são os números de nodes em cada layer, esse parâmetros podem ser ajustados dependendo do modelo.\n",
        "\n",
        "As funções de ativação 'relu' e 'softmax' serão utilizadas em suas respectivas camadas.\n",
        "\n",
        "A camada 'Dense' diz respeito a geração de outputs muito utilizadas nas mais diversas redes neurais, ela receberá 10 nodes, que representam o dígitos de 0-9 do nosso dataset. \n",
        "\n",
        "O modelo faz a predição baseado em qual foi o node que teve a maior probabilidade para uma dada amostra, em outras palavras, dada uma imagem X, será feita uma lista de probabilidades para tentar adivinhar qual foi o dígito fornecido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bk7tnoB2vVeB"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "\n",
        "    #add model layers\n",
        "    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    #compile model using accuracy as a measure of model performance\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l4tcu2XpvXY4"
      },
      "outputs": [],
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPI2H2javaBc",
        "outputId": "64f037e8-6688-432a-9f94-d37f004f3f27"
      },
      "outputs": [],
      "source": [
        "# define the grid search parameters\n",
        "batch_size = [10, 20]\n",
        "epochs = [10, 20, 30]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "# n_jobs needs to be set to your specific rig, -1 will eat your PC alive\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=4, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.974700 using {'batch_size': 20, 'epochs': 30}\n",
            "0.968883 (0.001552) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.970467 (0.001513) with: {'batch_size': 10, 'epochs': 20}\n",
            "0.972300 (0.002031) with: {'batch_size': 10, 'epochs': 30}\n",
            "0.971317 (0.001088) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.974000 (0.000512) with: {'batch_size': 20, 'epochs': 20}\n",
            "0.974700 (0.001662) with: {'batch_size': 20, 'epochs': 30}\n"
          ]
        }
      ],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW06-WEM-NuF"
      },
      "source": [
        "Após o treinamento de 3 épocas com o nosso modelo em mãos, foi possível obter uma acurácia média para o nosso dataset de 97%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps0jd93x4J6g",
        "outputId": "d2320a39-c694-4dd0-8c13-ae6f64625553"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'KerasClassifier' object has no attribute 'model'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12644/3573324394.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \"\"\"\n\u001b[1;32m--> 236\u001b[1;33m     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m       \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'model'"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(X_test[:5])\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YycIy1E5QNJ",
        "outputId": "13a77688-0721-441b-b7ca-68bfccef4e47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adicionando Pooling e Filtros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "\n",
        "    #add model layers\n",
        "    model.add(Conv2D(32, (5, 5), padding=\"same\", activation=\"relu\", input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    #compile model using accuracy as a measure of model performance\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the grid search parameters\n",
        "batch_size = [50, 100]\n",
        "epochs = [10, 20]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "# n_jobs needs to be set to your specific rig, -1 will eat your PC alive\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=None, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.982683 using {'batch_size': 50, 'epochs': 20}\n",
            "0.979667 (0.002705) with: {'batch_size': 50, 'epochs': 10}\n",
            "0.982683 (0.000517) with: {'batch_size': 50, 'epochs': 20}\n",
            "0.979683 (0.003029) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.981883 (0.002063) with: {'batch_size': 100, 'epochs': 20}\n"
          ]
        }
      ],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos uma melhora de 97.5% para 98.2% e ainda conseguimos ver que o número de Epochs tem um efeito notável"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "\n",
        "    #add model layers\n",
        "    model.add(Conv2D(128, (5, 5), padding=\"same\", activation=\"relu\", input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    #compile model using accuracy as a measure of model performance\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 27s 13ms/step - loss: 0.4143 - accuracy: 0.9625 - val_loss: 0.0595 - val_accuracy: 0.9827\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0658 - accuracy: 0.9812 - val_loss: 0.0636 - val_accuracy: 0.9819\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0603 - accuracy: 0.9837 - val_loss: 0.0602 - val_accuracy: 0.9829\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0598 - accuracy: 0.9839 - val_loss: 0.0727 - val_accuracy: 0.9830\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0518 - accuracy: 0.9865 - val_loss: 0.0575 - val_accuracy: 0.9859\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0480 - accuracy: 0.9878 - val_loss: 0.0640 - val_accuracy: 0.9850\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0488 - accuracy: 0.9884 - val_loss: 0.0842 - val_accuracy: 0.9844\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0447 - accuracy: 0.9898 - val_loss: 0.1437 - val_accuracy: 0.9747\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0449 - accuracy: 0.9909 - val_loss: 0.0827 - val_accuracy: 0.9863\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0495 - accuracy: 0.9915 - val_loss: 0.1006 - val_accuracy: 0.9871\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0407 - accuracy: 0.9930 - val_loss: 0.1435 - val_accuracy: 0.9849\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0416 - accuracy: 0.9935 - val_loss: 0.2001 - val_accuracy: 0.9824\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0498 - accuracy: 0.9934 - val_loss: 0.2088 - val_accuracy: 0.9811\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0508 - accuracy: 0.9936 - val_loss: 0.2531 - val_accuracy: 0.9826\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0498 - accuracy: 0.9942 - val_loss: 0.2519 - val_accuracy: 0.9854\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0510 - accuracy: 0.9946 - val_loss: 0.2332 - val_accuracy: 0.9866\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0565 - accuracy: 0.9947 - val_loss: 0.2590 - val_accuracy: 0.9887\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0518 - accuracy: 0.9955 - val_loss: 0.3255 - val_accuracy: 0.9860\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0615 - accuracy: 0.9954 - val_loss: 0.4432 - val_accuracy: 0.9830\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0554 - accuracy: 0.9961 - val_loss: 0.3266 - val_accuracy: 0.9873\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0581 - accuracy: 0.9962 - val_loss: 0.4012 - val_accuracy: 0.9857\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0745 - accuracy: 0.9957 - val_loss: 0.3678 - val_accuracy: 0.9871\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0588 - accuracy: 0.9965 - val_loss: 0.4093 - val_accuracy: 0.9877\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0412 - accuracy: 0.9973 - val_loss: 0.5561 - val_accuracy: 0.9834\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0695 - accuracy: 0.9967 - val_loss: 0.5993 - val_accuracy: 0.9856\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0689 - accuracy: 0.9968 - val_loss: 0.4670 - val_accuracy: 0.9890\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0707 - accuracy: 0.9971 - val_loss: 0.5465 - val_accuracy: 0.9867\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0764 - accuracy: 0.9971 - val_loss: 0.6730 - val_accuracy: 0.9880\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0645 - accuracy: 0.9972 - val_loss: 0.4722 - val_accuracy: 0.9904\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0640 - accuracy: 0.9974 - val_loss: 0.5475 - val_accuracy: 0.9891\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0570 - accuracy: 0.9979 - val_loss: 0.8062 - val_accuracy: 0.9880\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0811 - accuracy: 0.9973 - val_loss: 0.7227 - val_accuracy: 0.9887\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0710 - accuracy: 0.9976 - val_loss: 0.6313 - val_accuracy: 0.9900\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0686 - accuracy: 0.9978 - val_loss: 0.8115 - val_accuracy: 0.9881\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0666 - accuracy: 0.9980 - val_loss: 0.8163 - val_accuracy: 0.9895\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0584 - accuracy: 0.9981 - val_loss: 0.9600 - val_accuracy: 0.9882\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0692 - accuracy: 0.9980 - val_loss: 1.1109 - val_accuracy: 0.9868\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0650 - accuracy: 0.9981 - val_loss: 0.8672 - val_accuracy: 0.9868\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0862 - accuracy: 0.9980 - val_loss: 0.8695 - val_accuracy: 0.9892\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0537 - accuracy: 0.9984 - val_loss: 0.9692 - val_accuracy: 0.9894\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0946 - accuracy: 0.9981 - val_loss: 0.9892 - val_accuracy: 0.9896\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0803 - accuracy: 0.9983 - val_loss: 1.4142 - val_accuracy: 0.9876\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0954 - accuracy: 0.9981 - val_loss: 1.1206 - val_accuracy: 0.9902\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0757 - accuracy: 0.9985 - val_loss: 1.7910 - val_accuracy: 0.9861\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0704 - accuracy: 0.9987 - val_loss: 1.0922 - val_accuracy: 0.9898\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0799 - accuracy: 0.9983 - val_loss: 1.1972 - val_accuracy: 0.9898\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0740 - accuracy: 0.9987 - val_loss: 1.3657 - val_accuracy: 0.9906\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1048 - accuracy: 0.9983 - val_loss: 1.4835 - val_accuracy: 0.9897\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0709 - accuracy: 0.9985 - val_loss: 1.7178 - val_accuracy: 0.9875\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0815 - accuracy: 0.9983 - val_loss: 1.5695 - val_accuracy: 0.9890\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0577 - accuracy: 0.9990 - val_loss: 1.5332 - val_accuracy: 0.9893\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0778 - accuracy: 0.9988 - val_loss: 1.9518 - val_accuracy: 0.9873\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0915 - accuracy: 0.9985 - val_loss: 1.7169 - val_accuracy: 0.9890\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0773 - accuracy: 0.9989 - val_loss: 2.0354 - val_accuracy: 0.9897\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0645 - accuracy: 0.9990 - val_loss: 1.7789 - val_accuracy: 0.9896\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0757 - accuracy: 0.9990 - val_loss: 1.8081 - val_accuracy: 0.9885\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1017 - accuracy: 0.9985 - val_loss: 1.7325 - val_accuracy: 0.9892\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0960 - accuracy: 0.9988 - val_loss: 2.0184 - val_accuracy: 0.9888\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1020 - accuracy: 0.9990 - val_loss: 1.8482 - val_accuracy: 0.9902\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0718 - accuracy: 0.9990 - val_loss: 2.1486 - val_accuracy: 0.9886\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1134 - accuracy: 0.9987 - val_loss: 1.8705 - val_accuracy: 0.9898\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0729 - accuracy: 0.9992 - val_loss: 2.0905 - val_accuracy: 0.9906\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0920 - accuracy: 0.9988 - val_loss: 2.3000 - val_accuracy: 0.9887\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0732 - accuracy: 0.9991 - val_loss: 2.0599 - val_accuracy: 0.9919\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1080 - accuracy: 0.9990 - val_loss: 2.1024 - val_accuracy: 0.9907\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0806 - accuracy: 0.9990 - val_loss: 1.8031 - val_accuracy: 0.9911\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1257 - accuracy: 0.9988 - val_loss: 2.3105 - val_accuracy: 0.9913\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0480 - accuracy: 0.9994 - val_loss: 2.1645 - val_accuracy: 0.9912\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0798 - accuracy: 0.9991 - val_loss: 2.6357 - val_accuracy: 0.9882\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0748 - accuracy: 0.9992 - val_loss: 2.4475 - val_accuracy: 0.9906\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1255 - accuracy: 0.9991 - val_loss: 3.1510 - val_accuracy: 0.9895\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0775 - accuracy: 0.9993 - val_loss: 2.4731 - val_accuracy: 0.9897\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0778 - accuracy: 0.9992 - val_loss: 2.9582 - val_accuracy: 0.9889\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1089 - accuracy: 0.9990 - val_loss: 2.7486 - val_accuracy: 0.9910\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0892 - accuracy: 0.9992 - val_loss: 3.4435 - val_accuracy: 0.9876\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0551 - accuracy: 0.9995 - val_loss: 3.2020 - val_accuracy: 0.9893\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0908 - accuracy: 0.9990 - val_loss: 3.3681 - val_accuracy: 0.9898\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0617 - accuracy: 0.9993 - val_loss: 4.0725 - val_accuracy: 0.9884\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0958 - accuracy: 0.9992 - val_loss: 3.3692 - val_accuracy: 0.9910\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1120 - accuracy: 0.9992 - val_loss: 4.0714 - val_accuracy: 0.9897\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0910 - accuracy: 0.9992 - val_loss: 3.1307 - val_accuracy: 0.9908\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0961 - accuracy: 0.9991 - val_loss: 3.5235 - val_accuracy: 0.9904\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0846 - accuracy: 0.9992 - val_loss: 3.6560 - val_accuracy: 0.9905\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0993 - accuracy: 0.9993 - val_loss: 4.3118 - val_accuracy: 0.9880\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0903 - accuracy: 0.9992 - val_loss: 3.7525 - val_accuracy: 0.9914\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0485 - accuracy: 0.9994 - val_loss: 3.6918 - val_accuracy: 0.9901\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1226 - accuracy: 0.9993 - val_loss: 4.5584 - val_accuracy: 0.9897\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1207 - accuracy: 0.9991 - val_loss: 3.8494 - val_accuracy: 0.9903\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0511 - accuracy: 0.9995 - val_loss: 3.9101 - val_accuracy: 0.9911\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1067 - accuracy: 0.9992 - val_loss: 4.2952 - val_accuracy: 0.9906\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1113 - accuracy: 0.9993 - val_loss: 4.4473 - val_accuracy: 0.9902\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0893 - accuracy: 0.9994 - val_loss: 4.6212 - val_accuracy: 0.9899\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0941 - accuracy: 0.9994 - val_loss: 5.3565 - val_accuracy: 0.9902\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1170 - accuracy: 0.9993 - val_loss: 4.3109 - val_accuracy: 0.9910\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1113 - accuracy: 0.9994 - val_loss: 4.1574 - val_accuracy: 0.9903\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1117 - accuracy: 0.9994 - val_loss: 3.9532 - val_accuracy: 0.9910\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1012 - accuracy: 0.9994 - val_loss: 4.6732 - val_accuracy: 0.9903\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1502 - accuracy: 0.9991 - val_loss: 4.3019 - val_accuracy: 0.9910\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1144 - accuracy: 0.9993 - val_loss: 4.9968 - val_accuracy: 0.9906\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0829 - accuracy: 0.9995 - val_loss: 4.8327 - val_accuracy: 0.9908\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1c310eacd00>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1 = create_model()\n",
        "model1.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora usando uma rede muito mais densa com 128 nós na primeira camada, fizemos um teste de estresse com 100 épocas, com uma acurácia de validação de 98.6% na época 9 e variações de 97.5% a 98.7% ao seu redor. Chegamos pela primeira vez a taxa de 99% na época 59 e até a época 100 só temos uma melhora até 99.1%. Assim definimos 59 épocas como um bom limiar de treinamento, muito próximo aos 60 definido pelo experimento original."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "miniprojeto2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "e5a903eea30aa08e1f9d27b74a5ed310161c979055b2deac4a4d6b5123a4d6b6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
