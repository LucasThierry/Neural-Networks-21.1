{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZHeZKqb3Nwe"
      },
      "source": [
        "# MiniProjeto 2 - Convolutional Neural Networks - Redes Neurais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Wyzwmx3VOD"
      },
      "source": [
        "## Reconhecimento de Dígitos com CNN\n",
        "\n",
        "## Grupo: Josenildo Vicente de Araújo (jva@cin.ufpe.br), Lucas Thierry Chaves Muniz (ltcm@cin.ufpe.br), Nicholas Henrique Justino Ferreira (nhjf@cin.ufpe.br), Renato Joaquim Miranda Ferreira (rjmf@cin.ufpe.br)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ehiGkuq3kjg"
      },
      "source": [
        "O seguinte MiniProjeto tem como objetivo praticar os conceitos e teorias aprendidas na disciplina de Redes Neurais a respeito do funcionamento do modelo de Redes Neurais Convolucionais. De maneira a variar os parâmetros do modelo treinado e observar seus resultados. A rede utilizada em questão, tem como função fazer o reconhecimento de dígitos escritos manualmente por 250 pessoas, entre as quais eram estudantes do Ensino Médio e funcionários do Departamento do Censo dos Estados Unidos. O conjunto desses dígitos está reunido no _dataset_ MNIST, que possuí 60000 imagens para treinamento do modelo da rede neural e 10000 imagens para teste do modelo da rede neural. Cada uma dessas imagens são formadas por 784 _pixels_ (28x28) em uma escala da cor cinza.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FgMkRTu3m4w"
      },
      "source": [
        "Começamos pela importação do pacote das bibliotecas do keras para construção do modelo, importação do dataset. O matplotlib será a biblioteca gráfica e será usada quando for pertinente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jTj1s-55uovX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZL5oopX7zaA"
      },
      "source": [
        "Importação do dataset e separação entre os conjuntos de teste e treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6DYkojTu635"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4thY6_o76Hs"
      },
      "source": [
        "explorando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "eiA4JBUgvHtc",
        "outputId": "40e5bcca-7924-451a-e374-f184b8f0c41a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1bb89764fd0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLBwKGbL77kW"
      },
      "source": [
        "Reshape para treinamento do modelo do keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o9xiX6h1vSnj"
      },
      "outputs": [],
      "source": [
        "#reshape data to fit model\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX6hd2vfvTan",
        "outputId": "e45c8ae5-f14b-4775-e51f-ff0288114dea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zJUclD88NCA"
      },
      "source": [
        "Criação do modelo Sequencial, escolhemos o sequencial pois permite a criação do modelo layer a layer. \n",
        "\n",
        "Utilizamos 3 layers diferentes para lidar com o dataset, as 2 primeiras layers convolucionais de uma matriz com 2 dimensões, uma vez que o nosso dataset está de acordo com as 2 dimensões a serem vistas e utilizadas, bem como uma 'liga' representada pelo Flatten que serve para ligar as matrizes convolucionais com as camadas mais densas do modelo.\n",
        "\n",
        "As camadas convolucionais são representadas pelos tamanhos 64 e 32, que são os números de nodes em cada layer, esse parâmetros podem ser ajustados dependendo do modelo.\n",
        "\n",
        "As funções de ativação 'relu' e 'softmax' serão utilizadas em suas respectivas camadas.\n",
        "\n",
        "A camada 'Dense' diz respeito a geração de outputs muito utilizadas nas mais diversas redes neurais, ela receberá 10 nodes, que representam o dígitos de 0-9 do nosso dataset. \n",
        "\n",
        "O modelo faz a predição baseado em qual foi o node que teve a maior probabilidade para uma dada amostra, em outras palavras, dada uma imagem X, será feita uma lista de probabilidades para tentar adivinhar qual foi o dígito fornecido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bk7tnoB2vVeB"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "\n",
        "    #add model layers\n",
        "    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    #compile model using accuracy as a measure of model performance\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l4tcu2XpvXY4"
      },
      "outputs": [],
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assim iniciamos o processo de busca grosseira utilizando Grid Search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPI2H2javaBc",
        "outputId": "64f037e8-6688-432a-9f94-d37f004f3f27"
      },
      "outputs": [],
      "source": [
        "# define the grid search parameters\n",
        "batch_size = [10, 20]\n",
        "epochs = [10, 20, 30]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "# n_jobs needs to be set to your specific rig, -1 will eat your PC alive\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=None, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.974700 using {'batch_size': 20, 'epochs': 30}\n",
            "0.968883 (0.001552) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.970467 (0.001513) with: {'batch_size': 10, 'epochs': 20}\n",
            "0.972300 (0.002031) with: {'batch_size': 10, 'epochs': 30}\n",
            "0.971317 (0.001088) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.974000 (0.000512) with: {'batch_size': 20, 'epochs': 20}\n",
            "0.974700 (0.001662) with: {'batch_size': 20, 'epochs': 30}\n"
          ]
        }
      ],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conseguimos perceber um ganho através do uso de mais epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adicionando Pooling e Filtros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model_filter():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "\n",
        "    #add model layers\n",
        "    model.add(Conv2D(32, (5, 5), padding=\"same\", activation=\"relu\", input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    #compile model using accuracy as a measure of model performance\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = KerasClassifier(build_fn=create_model_filter, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the grid search parameters\n",
        "batch_size = [50, 100]\n",
        "epochs = [10, 20]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "# n_jobs needs to be set to your specific rig, -1 will eat your PC alive\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=None, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.982683 using {'batch_size': 50, 'epochs': 20}\n",
            "0.979667 (0.002705) with: {'batch_size': 50, 'epochs': 10}\n",
            "0.982683 (0.000517) with: {'batch_size': 50, 'epochs': 20}\n",
            "0.979683 (0.003029) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.981883 (0.002063) with: {'batch_size': 100, 'epochs': 20}\n"
          ]
        }
      ],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos uma melhora de 97.5% para 98.2% e ainda conseguimos ver que o número de Epochs tem um efeito notável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iniciamos experimentos com modelagem da rede, começando através da alteração do números de nós."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model_net_expansion():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "\n",
        "    #add model layers\n",
        "    model.add(Conv2D(128, (5, 5), padding=\"same\", activation=\"relu\", input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    #compile model using accuracy as a measure of model performance\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 27s 13ms/step - loss: 0.4143 - accuracy: 0.9625 - val_loss: 0.0595 - val_accuracy: 0.9827\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0658 - accuracy: 0.9812 - val_loss: 0.0636 - val_accuracy: 0.9819\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0603 - accuracy: 0.9837 - val_loss: 0.0602 - val_accuracy: 0.9829\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0598 - accuracy: 0.9839 - val_loss: 0.0727 - val_accuracy: 0.9830\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0518 - accuracy: 0.9865 - val_loss: 0.0575 - val_accuracy: 0.9859\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0480 - accuracy: 0.9878 - val_loss: 0.0640 - val_accuracy: 0.9850\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0488 - accuracy: 0.9884 - val_loss: 0.0842 - val_accuracy: 0.9844\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0447 - accuracy: 0.9898 - val_loss: 0.1437 - val_accuracy: 0.9747\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0449 - accuracy: 0.9909 - val_loss: 0.0827 - val_accuracy: 0.9863\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0495 - accuracy: 0.9915 - val_loss: 0.1006 - val_accuracy: 0.9871\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0407 - accuracy: 0.9930 - val_loss: 0.1435 - val_accuracy: 0.9849\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0416 - accuracy: 0.9935 - val_loss: 0.2001 - val_accuracy: 0.9824\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0498 - accuracy: 0.9934 - val_loss: 0.2088 - val_accuracy: 0.9811\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0508 - accuracy: 0.9936 - val_loss: 0.2531 - val_accuracy: 0.9826\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0498 - accuracy: 0.9942 - val_loss: 0.2519 - val_accuracy: 0.9854\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0510 - accuracy: 0.9946 - val_loss: 0.2332 - val_accuracy: 0.9866\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0565 - accuracy: 0.9947 - val_loss: 0.2590 - val_accuracy: 0.9887\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0518 - accuracy: 0.9955 - val_loss: 0.3255 - val_accuracy: 0.9860\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0615 - accuracy: 0.9954 - val_loss: 0.4432 - val_accuracy: 0.9830\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0554 - accuracy: 0.9961 - val_loss: 0.3266 - val_accuracy: 0.9873\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0581 - accuracy: 0.9962 - val_loss: 0.4012 - val_accuracy: 0.9857\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0745 - accuracy: 0.9957 - val_loss: 0.3678 - val_accuracy: 0.9871\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0588 - accuracy: 0.9965 - val_loss: 0.4093 - val_accuracy: 0.9877\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0412 - accuracy: 0.9973 - val_loss: 0.5561 - val_accuracy: 0.9834\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0695 - accuracy: 0.9967 - val_loss: 0.5993 - val_accuracy: 0.9856\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0689 - accuracy: 0.9968 - val_loss: 0.4670 - val_accuracy: 0.9890\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0707 - accuracy: 0.9971 - val_loss: 0.5465 - val_accuracy: 0.9867\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0764 - accuracy: 0.9971 - val_loss: 0.6730 - val_accuracy: 0.9880\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0645 - accuracy: 0.9972 - val_loss: 0.4722 - val_accuracy: 0.9904\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0640 - accuracy: 0.9974 - val_loss: 0.5475 - val_accuracy: 0.9891\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0570 - accuracy: 0.9979 - val_loss: 0.8062 - val_accuracy: 0.9880\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0811 - accuracy: 0.9973 - val_loss: 0.7227 - val_accuracy: 0.9887\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0710 - accuracy: 0.9976 - val_loss: 0.6313 - val_accuracy: 0.9900\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0686 - accuracy: 0.9978 - val_loss: 0.8115 - val_accuracy: 0.9881\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0666 - accuracy: 0.9980 - val_loss: 0.8163 - val_accuracy: 0.9895\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0584 - accuracy: 0.9981 - val_loss: 0.9600 - val_accuracy: 0.9882\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0692 - accuracy: 0.9980 - val_loss: 1.1109 - val_accuracy: 0.9868\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0650 - accuracy: 0.9981 - val_loss: 0.8672 - val_accuracy: 0.9868\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0862 - accuracy: 0.9980 - val_loss: 0.8695 - val_accuracy: 0.9892\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0537 - accuracy: 0.9984 - val_loss: 0.9692 - val_accuracy: 0.9894\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0946 - accuracy: 0.9981 - val_loss: 0.9892 - val_accuracy: 0.9896\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0803 - accuracy: 0.9983 - val_loss: 1.4142 - val_accuracy: 0.9876\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0954 - accuracy: 0.9981 - val_loss: 1.1206 - val_accuracy: 0.9902\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0757 - accuracy: 0.9985 - val_loss: 1.7910 - val_accuracy: 0.9861\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0704 - accuracy: 0.9987 - val_loss: 1.0922 - val_accuracy: 0.9898\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0799 - accuracy: 0.9983 - val_loss: 1.1972 - val_accuracy: 0.9898\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0740 - accuracy: 0.9987 - val_loss: 1.3657 - val_accuracy: 0.9906\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1048 - accuracy: 0.9983 - val_loss: 1.4835 - val_accuracy: 0.9897\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0709 - accuracy: 0.9985 - val_loss: 1.7178 - val_accuracy: 0.9875\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0815 - accuracy: 0.9983 - val_loss: 1.5695 - val_accuracy: 0.9890\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0577 - accuracy: 0.9990 - val_loss: 1.5332 - val_accuracy: 0.9893\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0778 - accuracy: 0.9988 - val_loss: 1.9518 - val_accuracy: 0.9873\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0915 - accuracy: 0.9985 - val_loss: 1.7169 - val_accuracy: 0.9890\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0773 - accuracy: 0.9989 - val_loss: 2.0354 - val_accuracy: 0.9897\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0645 - accuracy: 0.9990 - val_loss: 1.7789 - val_accuracy: 0.9896\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0757 - accuracy: 0.9990 - val_loss: 1.8081 - val_accuracy: 0.9885\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1017 - accuracy: 0.9985 - val_loss: 1.7325 - val_accuracy: 0.9892\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0960 - accuracy: 0.9988 - val_loss: 2.0184 - val_accuracy: 0.9888\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1020 - accuracy: 0.9990 - val_loss: 1.8482 - val_accuracy: 0.9902\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0718 - accuracy: 0.9990 - val_loss: 2.1486 - val_accuracy: 0.9886\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1134 - accuracy: 0.9987 - val_loss: 1.8705 - val_accuracy: 0.9898\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0729 - accuracy: 0.9992 - val_loss: 2.0905 - val_accuracy: 0.9906\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0920 - accuracy: 0.9988 - val_loss: 2.3000 - val_accuracy: 0.9887\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0732 - accuracy: 0.9991 - val_loss: 2.0599 - val_accuracy: 0.9919\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1080 - accuracy: 0.9990 - val_loss: 2.1024 - val_accuracy: 0.9907\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0806 - accuracy: 0.9990 - val_loss: 1.8031 - val_accuracy: 0.9911\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1257 - accuracy: 0.9988 - val_loss: 2.3105 - val_accuracy: 0.9913\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0480 - accuracy: 0.9994 - val_loss: 2.1645 - val_accuracy: 0.9912\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0798 - accuracy: 0.9991 - val_loss: 2.6357 - val_accuracy: 0.9882\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0748 - accuracy: 0.9992 - val_loss: 2.4475 - val_accuracy: 0.9906\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1255 - accuracy: 0.9991 - val_loss: 3.1510 - val_accuracy: 0.9895\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0775 - accuracy: 0.9993 - val_loss: 2.4731 - val_accuracy: 0.9897\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0778 - accuracy: 0.9992 - val_loss: 2.9582 - val_accuracy: 0.9889\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1089 - accuracy: 0.9990 - val_loss: 2.7486 - val_accuracy: 0.9910\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0892 - accuracy: 0.9992 - val_loss: 3.4435 - val_accuracy: 0.9876\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0551 - accuracy: 0.9995 - val_loss: 3.2020 - val_accuracy: 0.9893\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0908 - accuracy: 0.9990 - val_loss: 3.3681 - val_accuracy: 0.9898\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0617 - accuracy: 0.9993 - val_loss: 4.0725 - val_accuracy: 0.9884\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0958 - accuracy: 0.9992 - val_loss: 3.3692 - val_accuracy: 0.9910\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1120 - accuracy: 0.9992 - val_loss: 4.0714 - val_accuracy: 0.9897\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0910 - accuracy: 0.9992 - val_loss: 3.1307 - val_accuracy: 0.9908\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0961 - accuracy: 0.9991 - val_loss: 3.5235 - val_accuracy: 0.9904\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0846 - accuracy: 0.9992 - val_loss: 3.6560 - val_accuracy: 0.9905\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0993 - accuracy: 0.9993 - val_loss: 4.3118 - val_accuracy: 0.9880\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0903 - accuracy: 0.9992 - val_loss: 3.7525 - val_accuracy: 0.9914\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0485 - accuracy: 0.9994 - val_loss: 3.6918 - val_accuracy: 0.9901\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1226 - accuracy: 0.9993 - val_loss: 4.5584 - val_accuracy: 0.9897\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1207 - accuracy: 0.9991 - val_loss: 3.8494 - val_accuracy: 0.9903\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0511 - accuracy: 0.9995 - val_loss: 3.9101 - val_accuracy: 0.9911\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1067 - accuracy: 0.9992 - val_loss: 4.2952 - val_accuracy: 0.9906\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1113 - accuracy: 0.9993 - val_loss: 4.4473 - val_accuracy: 0.9902\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0893 - accuracy: 0.9994 - val_loss: 4.6212 - val_accuracy: 0.9899\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0941 - accuracy: 0.9994 - val_loss: 5.3565 - val_accuracy: 0.9902\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1170 - accuracy: 0.9993 - val_loss: 4.3109 - val_accuracy: 0.9910\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1113 - accuracy: 0.9994 - val_loss: 4.1574 - val_accuracy: 0.9903\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1117 - accuracy: 0.9994 - val_loss: 3.9532 - val_accuracy: 0.9910\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1012 - accuracy: 0.9994 - val_loss: 4.6732 - val_accuracy: 0.9903\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1502 - accuracy: 0.9991 - val_loss: 4.3019 - val_accuracy: 0.9910\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1144 - accuracy: 0.9993 - val_loss: 4.9968 - val_accuracy: 0.9906\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0829 - accuracy: 0.9995 - val_loss: 4.8327 - val_accuracy: 0.9908\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1c310eacd00>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1 = create_model_net_expansion()\n",
        "model1.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora usando uma rede muito mais densa com 128 nós na primeira camada, fizemos um teste de estresse com 100 épocas (19 minutos), com uma acurácia de validação de 98.6% na época 9 e variações de 97.5% a 98.7% ao seu redor. Chegamos pela primeira vez a taxa de 99% na época 59 e até a época 100 só temos uma melhora até 99.1%. Assim definimos 59 épocas como um bom limiar de treinamento, muito próximo aos 60 definido pelo experimento original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adicionando 20% de Dropout entre camadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model_dropout():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "\n",
        "    #add model layers\n",
        "    model.add(Conv2D(128, (5, 5), padding=\"same\", activation=\"relu\", input_shape=(28,28,1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    #compile model using accuracy as a measure of model performance\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/59\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.6759 - accuracy: 0.9553 - val_loss: 0.0671 - val_accuracy: 0.9788\n",
            "Epoch 2/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0778 - accuracy: 0.9776 - val_loss: 0.0809 - val_accuracy: 0.9754\n",
            "Epoch 3/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0823 - accuracy: 0.9771 - val_loss: 0.0571 - val_accuracy: 0.9842\n",
            "Epoch 4/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0799 - accuracy: 0.9791 - val_loss: 0.0594 - val_accuracy: 0.9840\n",
            "Epoch 5/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0754 - accuracy: 0.9809 - val_loss: 0.0471 - val_accuracy: 0.9864\n",
            "Epoch 6/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0723 - accuracy: 0.9817 - val_loss: 0.0708 - val_accuracy: 0.9820\n",
            "Epoch 7/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0741 - accuracy: 0.9825 - val_loss: 0.0517 - val_accuracy: 0.9866\n",
            "Epoch 8/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0664 - accuracy: 0.9854 - val_loss: 0.0508 - val_accuracy: 0.9866\n",
            "Epoch 9/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0715 - accuracy: 0.9841 - val_loss: 0.0705 - val_accuracy: 0.9830\n",
            "Epoch 10/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0767 - accuracy: 0.9841 - val_loss: 0.0803 - val_accuracy: 0.9830\n",
            "Epoch 11/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0765 - accuracy: 0.9850 - val_loss: 0.0815 - val_accuracy: 0.9830\n",
            "Epoch 12/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0725 - accuracy: 0.9869 - val_loss: 0.0771 - val_accuracy: 0.9839\n",
            "Epoch 13/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0751 - accuracy: 0.9871 - val_loss: 0.0750 - val_accuracy: 0.9850\n",
            "Epoch 14/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0687 - accuracy: 0.9873 - val_loss: 0.0783 - val_accuracy: 0.9875\n",
            "Epoch 15/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0774 - accuracy: 0.9883 - val_loss: 0.0986 - val_accuracy: 0.9852\n",
            "Epoch 16/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0906 - accuracy: 0.9878 - val_loss: 0.1015 - val_accuracy: 0.9866\n",
            "Epoch 17/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0864 - accuracy: 0.9894 - val_loss: 0.1111 - val_accuracy: 0.9861\n",
            "Epoch 18/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0749 - accuracy: 0.9899 - val_loss: 0.0927 - val_accuracy: 0.9869\n",
            "Epoch 19/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0867 - accuracy: 0.9887 - val_loss: 0.1045 - val_accuracy: 0.9877\n",
            "Epoch 20/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0804 - accuracy: 0.9897 - val_loss: 0.1147 - val_accuracy: 0.9876\n",
            "Epoch 21/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0986 - accuracy: 0.9896 - val_loss: 0.1085 - val_accuracy: 0.9869\n",
            "Epoch 22/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0876 - accuracy: 0.9905 - val_loss: 0.1170 - val_accuracy: 0.9862\n",
            "Epoch 23/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0908 - accuracy: 0.9903 - val_loss: 0.1473 - val_accuracy: 0.9864\n",
            "Epoch 24/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0888 - accuracy: 0.9907 - val_loss: 0.1510 - val_accuracy: 0.9862\n",
            "Epoch 25/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0926 - accuracy: 0.9917 - val_loss: 0.2383 - val_accuracy: 0.9836\n",
            "Epoch 26/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0846 - accuracy: 0.9917 - val_loss: 0.1712 - val_accuracy: 0.9879\n",
            "Epoch 27/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0921 - accuracy: 0.9926 - val_loss: 0.1785 - val_accuracy: 0.9868\n",
            "Epoch 28/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0958 - accuracy: 0.9919 - val_loss: 0.2405 - val_accuracy: 0.9862\n",
            "Epoch 29/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1030 - accuracy: 0.9924 - val_loss: 0.2350 - val_accuracy: 0.9864\n",
            "Epoch 30/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1188 - accuracy: 0.9929 - val_loss: 0.2200 - val_accuracy: 0.9862\n",
            "Epoch 31/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.1024 - accuracy: 0.9930 - val_loss: 0.2015 - val_accuracy: 0.9900\n",
            "Epoch 32/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1144 - accuracy: 0.9931 - val_loss: 0.2180 - val_accuracy: 0.9898\n",
            "Epoch 33/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0943 - accuracy: 0.9941 - val_loss: 0.2325 - val_accuracy: 0.9886\n",
            "Epoch 34/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.1072 - accuracy: 0.9937 - val_loss: 0.2841 - val_accuracy: 0.9877\n",
            "Epoch 35/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.1127 - accuracy: 0.9941 - val_loss: 0.3276 - val_accuracy: 0.9885\n",
            "Epoch 36/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.1389 - accuracy: 0.9938 - val_loss: 0.2983 - val_accuracy: 0.9873\n",
            "Epoch 37/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.1227 - accuracy: 0.9947 - val_loss: 0.3417 - val_accuracy: 0.9895\n",
            "Epoch 38/59\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1291 - accuracy: 0.9947 - val_loss: 0.3263 - val_accuracy: 0.9889\n",
            "Epoch 39/59\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1295 - accuracy: 0.9944 - val_loss: 0.3756 - val_accuracy: 0.9875\n",
            "Epoch 40/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1363 - accuracy: 0.9947 - val_loss: 0.3904 - val_accuracy: 0.9880\n",
            "Epoch 41/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1518 - accuracy: 0.9946 - val_loss: 0.3802 - val_accuracy: 0.9890\n",
            "Epoch 42/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1378 - accuracy: 0.9951 - val_loss: 0.3907 - val_accuracy: 0.9898\n",
            "Epoch 43/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1412 - accuracy: 0.9954 - val_loss: 0.4530 - val_accuracy: 0.9891\n",
            "Epoch 44/59\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1121 - accuracy: 0.9963 - val_loss: 0.5945 - val_accuracy: 0.9876\n",
            "Epoch 45/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1720 - accuracy: 0.9949 - val_loss: 0.5508 - val_accuracy: 0.9880\n",
            "Epoch 46/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1692 - accuracy: 0.9952 - val_loss: 0.5915 - val_accuracy: 0.9890\n",
            "Epoch 47/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1480 - accuracy: 0.9958 - val_loss: 0.4742 - val_accuracy: 0.9899\n",
            "Epoch 48/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1779 - accuracy: 0.9954 - val_loss: 0.5926 - val_accuracy: 0.9888\n",
            "Epoch 49/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1533 - accuracy: 0.9957 - val_loss: 0.5855 - val_accuracy: 0.9894\n",
            "Epoch 50/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1682 - accuracy: 0.9961 - val_loss: 0.6679 - val_accuracy: 0.9893\n",
            "Epoch 51/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1647 - accuracy: 0.9964 - val_loss: 0.6303 - val_accuracy: 0.9893\n",
            "Epoch 52/59\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1582 - accuracy: 0.9965 - val_loss: 0.7290 - val_accuracy: 0.9893\n",
            "Epoch 53/59\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1655 - accuracy: 0.9966 - val_loss: 0.6738 - val_accuracy: 0.9895\n",
            "Epoch 54/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1478 - accuracy: 0.9967 - val_loss: 0.7492 - val_accuracy: 0.9896\n",
            "Epoch 55/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1582 - accuracy: 0.9969 - val_loss: 0.6966 - val_accuracy: 0.9901\n",
            "Epoch 56/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1807 - accuracy: 0.9966 - val_loss: 0.8906 - val_accuracy: 0.9902\n",
            "Epoch 57/59\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1991 - accuracy: 0.9963 - val_loss: 0.9981 - val_accuracy: 0.9888\n",
            "Epoch 58/59\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1886 - accuracy: 0.9966 - val_loss: 0.9327 - val_accuracy: 0.9909\n",
            "Epoch 59/59\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.1969 - accuracy: 0.9968 - val_loss: 1.0163 - val_accuracy: 0.9894\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x19710ced7f0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1 = create_model_dropout()\n",
        "model1.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=59)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com os 20% Dropout agora podemos ver um ganho pequeno indo para 99.1% na época 58, mas devido a margem de erro devemos considerar um empate. Notavelmente temos uma reduçao muito grande na perda entre treinamento e validação, no caso sem Dropout tivemos uma perda de 2.01 enquanto agora tivemos 0.93, o que mostra que Dropout tem uma influência notável evitando que a Rede se \"vicie\" nos dados obtidos através do treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imprimindo uma matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 979    0    0    0    0    0    0    0    1    0]\n",
            " [   1 1126    2    2    1    0    3    0    0    0]\n",
            " [   1    0 1024    1    0    0    0    5    1    0]\n",
            " [   0    0    1 1005    0    3    0    1    0    0]\n",
            " [   0    0    0    0  970    0    1    4    1    6]\n",
            " [   1    0    0    7    0  881    1    0    0    2]\n",
            " [   3    2    1    0    2    0  948    0    2    0]\n",
            " [   0    2    3    0    0    0    0 1023    0    0]\n",
            " [   5    1    2    5    1    3    1    1  951    4]\n",
            " [   1    2    0    2    9    3    0    5    0  987]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.98      1.00      0.99      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       0.99      0.99      0.99       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.98      1.00      0.99      1028\n",
            "           8       0.99      0.98      0.99       974\n",
            "           9       0.99      0.98      0.98      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = model1.predict(X_test)\n",
        "y_pred = (predictions > 0.5)\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "print(matrix)\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com o uso de uma matriz de confusão, podemos ver onde existem o maior número de conflitos. Usando o nosso último modelo com Dropout, podemos ver que o maior números de \"confusões\" existe na previsão da classe 3 onde existem sete interpretações como se fosse a classe 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testando strides maiores que o padrão 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model_strides():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "\n",
        "    #add model layers\n",
        "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\", activation=\"relu\", input_shape=(28,28,1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(256, (5, 5), strides=(2, 2), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    #compile model using accuracy as a measure of model performance\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/59\n",
            "1875/1875 [==============================] - 14s 4ms/step - loss: 0.5902 - accuracy: 0.9357 - val_loss: 0.0751 - val_accuracy: 0.9767\n",
            "Epoch 2/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1132 - accuracy: 0.9677 - val_loss: 0.0999 - val_accuracy: 0.9721\n",
            "Epoch 3/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1140 - accuracy: 0.9701 - val_loss: 0.0713 - val_accuracy: 0.9792\n",
            "Epoch 4/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1193 - accuracy: 0.9701 - val_loss: 0.1107 - val_accuracy: 0.9732\n",
            "Epoch 5/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1083 - accuracy: 0.9735 - val_loss: 0.0851 - val_accuracy: 0.9802\n",
            "Epoch 6/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1075 - accuracy: 0.9745 - val_loss: 0.0730 - val_accuracy: 0.9810\n",
            "Epoch 7/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1077 - accuracy: 0.9753 - val_loss: 0.0924 - val_accuracy: 0.9799\n",
            "Epoch 8/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0987 - accuracy: 0.9781 - val_loss: 0.0868 - val_accuracy: 0.9837\n",
            "Epoch 9/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1103 - accuracy: 0.9770 - val_loss: 0.0902 - val_accuracy: 0.9795\n",
            "Epoch 10/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1018 - accuracy: 0.9785 - val_loss: 0.0829 - val_accuracy: 0.9819\n",
            "Epoch 11/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1004 - accuracy: 0.9794 - val_loss: 0.1066 - val_accuracy: 0.9812\n",
            "Epoch 12/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0930 - accuracy: 0.9810 - val_loss: 0.0896 - val_accuracy: 0.9861\n",
            "Epoch 13/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1082 - accuracy: 0.9806 - val_loss: 0.1129 - val_accuracy: 0.9816\n",
            "Epoch 14/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0996 - accuracy: 0.9815 - val_loss: 0.1139 - val_accuracy: 0.9829\n",
            "Epoch 15/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0959 - accuracy: 0.9833 - val_loss: 0.1105 - val_accuracy: 0.9834\n",
            "Epoch 16/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1061 - accuracy: 0.9824 - val_loss: 0.1173 - val_accuracy: 0.9825\n",
            "Epoch 17/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1038 - accuracy: 0.9825 - val_loss: 0.1379 - val_accuracy: 0.9838\n",
            "Epoch 18/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1140 - accuracy: 0.9832 - val_loss: 0.1223 - val_accuracy: 0.9839\n",
            "Epoch 19/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0985 - accuracy: 0.9842 - val_loss: 0.1390 - val_accuracy: 0.9833\n",
            "Epoch 20/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1323 - accuracy: 0.9828 - val_loss: 0.1723 - val_accuracy: 0.9808\n",
            "Epoch 21/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1089 - accuracy: 0.9848 - val_loss: 0.1505 - val_accuracy: 0.9837\n",
            "Epoch 22/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1177 - accuracy: 0.9839 - val_loss: 0.1838 - val_accuracy: 0.9851\n",
            "Epoch 23/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1282 - accuracy: 0.9851 - val_loss: 0.1662 - val_accuracy: 0.9807\n",
            "Epoch 24/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1147 - accuracy: 0.9857 - val_loss: 0.2096 - val_accuracy: 0.9816\n",
            "Epoch 25/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1165 - accuracy: 0.9865 - val_loss: 0.1722 - val_accuracy: 0.9836\n",
            "Epoch 26/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1244 - accuracy: 0.9860 - val_loss: 0.1957 - val_accuracy: 0.9856\n",
            "Epoch 27/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1277 - accuracy: 0.9868 - val_loss: 0.1862 - val_accuracy: 0.9844\n",
            "Epoch 28/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1204 - accuracy: 0.9870 - val_loss: 0.1916 - val_accuracy: 0.9839\n",
            "Epoch 29/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1249 - accuracy: 0.9868 - val_loss: 0.2034 - val_accuracy: 0.9846\n",
            "Epoch 30/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1250 - accuracy: 0.9880 - val_loss: 0.2083 - val_accuracy: 0.9859\n",
            "Epoch 31/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1499 - accuracy: 0.9871 - val_loss: 0.2896 - val_accuracy: 0.9821\n",
            "Epoch 32/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1201 - accuracy: 0.9883 - val_loss: 0.2665 - val_accuracy: 0.9826\n",
            "Epoch 33/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1568 - accuracy: 0.9882 - val_loss: 0.3404 - val_accuracy: 0.9845\n",
            "Epoch 34/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1493 - accuracy: 0.9890 - val_loss: 0.3094 - val_accuracy: 0.9869\n",
            "Epoch 35/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1355 - accuracy: 0.9896 - val_loss: 0.3408 - val_accuracy: 0.9853\n",
            "Epoch 36/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1479 - accuracy: 0.9892 - val_loss: 0.2966 - val_accuracy: 0.9857\n",
            "Epoch 37/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1395 - accuracy: 0.9896 - val_loss: 0.3856 - val_accuracy: 0.9849\n",
            "Epoch 38/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1486 - accuracy: 0.9900 - val_loss: 0.3847 - val_accuracy: 0.9846\n",
            "Epoch 39/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1668 - accuracy: 0.9905 - val_loss: 0.4439 - val_accuracy: 0.9841\n",
            "Epoch 40/59\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1564 - accuracy: 0.9901 - val_loss: 0.3648 - val_accuracy: 0.9850\n",
            "Epoch 41/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1796 - accuracy: 0.9895 - val_loss: 0.3611 - val_accuracy: 0.9838\n",
            "Epoch 42/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1657 - accuracy: 0.9909 - val_loss: 0.5173 - val_accuracy: 0.9851\n",
            "Epoch 43/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1764 - accuracy: 0.9896 - val_loss: 0.3868 - val_accuracy: 0.9872\n",
            "Epoch 44/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1548 - accuracy: 0.9905 - val_loss: 0.4083 - val_accuracy: 0.9848\n",
            "Epoch 45/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2002 - accuracy: 0.9896 - val_loss: 0.3711 - val_accuracy: 0.9868\n",
            "Epoch 46/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1941 - accuracy: 0.9902 - val_loss: 0.3820 - val_accuracy: 0.9863\n",
            "Epoch 47/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1498 - accuracy: 0.9919 - val_loss: 0.6487 - val_accuracy: 0.9841\n",
            "Epoch 48/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1796 - accuracy: 0.9916 - val_loss: 0.4796 - val_accuracy: 0.9857\n",
            "Epoch 49/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1997 - accuracy: 0.9910 - val_loss: 0.5170 - val_accuracy: 0.9862\n",
            "Epoch 50/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1736 - accuracy: 0.9920 - val_loss: 0.5006 - val_accuracy: 0.9862\n",
            "Epoch 51/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1838 - accuracy: 0.9918 - val_loss: 0.5639 - val_accuracy: 0.9854\n",
            "Epoch 52/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1774 - accuracy: 0.9922 - val_loss: 0.5922 - val_accuracy: 0.9858\n",
            "Epoch 53/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1856 - accuracy: 0.9929 - val_loss: 0.5956 - val_accuracy: 0.9847\n",
            "Epoch 54/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1899 - accuracy: 0.9922 - val_loss: 0.6150 - val_accuracy: 0.9856\n",
            "Epoch 55/59\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2175 - accuracy: 0.9924 - val_loss: 0.5501 - val_accuracy: 0.9867\n",
            "Epoch 56/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1890 - accuracy: 0.9921 - val_loss: 0.5919 - val_accuracy: 0.9826\n",
            "Epoch 57/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2166 - accuracy: 0.9917 - val_loss: 0.7022 - val_accuracy: 0.9847\n",
            "Epoch 58/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2133 - accuracy: 0.9928 - val_loss: 0.6773 - val_accuracy: 0.9869\n",
            "Epoch 59/59\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2278 - accuracy: 0.9925 - val_loss: 0.7059 - val_accuracy: 0.9865\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1bb9018c640>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1 = create_model_strides()\n",
        "model1.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=59)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos ver uma redução na acurácia de validação de 99.0 para 98.6% mais existe um ganho notável em velocidade de treinamento, onde antes eram processados um epoch numa média de 13s, agora temos um custo costante de 8s por Epoch.\n",
        "Assim podemos dizer que o stride maior que 1 pode ser útil numa refinamento grosseiro de parâmetros, para menos custo de tempo do pesquisador e depois retirado no modelo final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assim o nosso melhor modelo acabou tendo 2 camadas convolucionais com filtros 5x5, função de ativação relu e dropout de 20%, a primeira camada com 128 nós e a segunda com 256."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "miniprojeto2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "e5a903eea30aa08e1f9d27b74a5ed310161c979055b2deac4a4d6b5123a4d6b6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
